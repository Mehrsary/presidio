{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Presidio: Data Protection and De-identification SDK","text":"<p>Presidio (Origin from Latin praesidium \u2018protection, garrison\u2019) helps to ensure sensitive data is properly managed and governed. It provides fast identification and anonymization modules for private entities in text and images such as credit card numbers, names, locations, social security numbers, bitcoin wallets, US phone numbers, financial data and more.</p>"},{"location":"#goals","title":"Goals","text":"<ul> <li>Allow organizations to preserve privacy in a simpler way by democratizing de-identification technologies and introducing transparency in decisions.</li> <li>Embrace extensibility and customizability to a specific business need.</li> <li>Facilitate both fully automated and semi-automated PII de-identification flows on multiple platforms.</li> </ul>"},{"location":"#how-it-works","title":"How it works","text":""},{"location":"#main-features","title":"Main features","text":"<ol> <li>Predefined or custom PII recognizers leveraging Named Entity Recognition, regular expressions, rule based logic and checksum with relevant context in multiple languages.</li> <li>Options for connecting to external PII detection models.</li> <li>Multiple usage options, from Python or PySpark workloads through Docker to Kubernetes.</li> <li>Customizability in PII identification and anonymization.</li> <li>Module for redacting PII text in images.</li> </ol> <p>Warning</p> <p>Presidio can help identify sensitive/PII data in un/structured text. However, because it is using automated detection mechanisms, there is no guarantee that Presidio will find all sensitive information. Consequently, additional systems and protections should be employed.</p>"},{"location":"#demo-frequently-asked-questions","title":"Demo | Frequently Asked Questions","text":""},{"location":"#are-you-using-presidio-wed-love-to-know-how","title":"Are you using Presidio? We'd love to know how","text":"<p>Please help us improve by taking this short anonymous survey.</p>"},{"location":"#presidios-modules","title":"Presidio's modules","text":"<ol> <li>Presidio analyzer: PII identification in text</li> <li>Presidio anonymizer: De-identify detected PII entities using different operators</li> <li>Presidio image redactor: Redact PII entities from images using OCR and PII identification</li> </ol>"},{"location":"#installing-presidio","title":"Installing Presidio","text":"<ol> <li>Supported Python Versions</li> <li>Using pip</li> <li>Using Docker</li> <li>From source</li> <li>Migrating from V1 to V2</li> </ol>"},{"location":"#running-presidio","title":"Running Presidio","text":"<ol> <li>Samples for running Presidio via code</li> <li>Running Presidio as an HTTP service</li> <li>Setting up a development environment</li> <li>Perform PII identification using presidio-analyzer</li> <li>Perform PII de-identification using presidio-anonymizer</li> <li>Perform PII identification and redaction in images using presidio-image-redactor</li> <li>Example deployments</li> </ol>"},{"location":"#support","title":"Support","text":"<ul> <li>Before you submit an issue, please go over the documentation. For general discussions, please use the Github repo's discussion board.</li> <li>If you have a usage question, found a bug or have a suggestion for improvement, please file a Github issue.</li> <li>For other matters, please email presidio@microsoft.com.</li> </ul>"},{"location":"api/","title":"Presidio API","text":"<p>Api reference for Presidio's main python modules</p> <ul> <li>Presidio analyzer Python API reference</li> <li>Presidio anonymizer Python API reference</li> <li>Presidio image redactor Python API reference</li> </ul>"},{"location":"build_release/","title":"Build and release process","text":"<p>Presidio leverages Azure DevOps YAML pipelines to validate, build, release and deliver presidio. The pipelines make use of templates for code reuse using YAML Schema.</p>"},{"location":"build_release/#description","title":"Description","text":"<p>The following pipelines are provided and maintained as part of presidio development process:</p> <ul> <li>PR Validation - used to validate pull requests.<ul> <li>Linting</li> <li>Security and compliance analysis</li> <li>Unit tests</li> <li>E2E tests</li> </ul> </li> <li>CI - triggered on merge to main branch.<ul> <li>Linting</li> <li>Security and compliance analysis</li> <li>Unit tests</li> <li>E2E tests</li> <li>deploys the artifacts to an internal dev environment.</li> </ul> </li> <li>Release - manually triggered.<ul> <li>releases presidio official artifacts<ul> <li>pypi</li> <li>Microsoft container registry (and docker hub)</li> <li>GitHub</li> </ul> </li> <li>updates the official demo environment.</li> </ul> </li> </ul>"},{"location":"build_release/#variables-used-by-the-pipelines","title":"Variables used by the pipelines","text":""},{"location":"build_release/#ci-pipeline","title":"CI Pipeline","text":"<ul> <li>ACR_AZURE_SUBSCRIPTION - Service connection to Azure subscription where Azure Container Registry is.</li> <li>ACR_REGISTRY_NAME - Name of Azure Container Registry.</li> <li>ANALYZER_DEV_APP_NAME - Name of existing App Service for Analyzer (development environment).</li> <li>ANONYMIZER_DEV_APP_NAME - Name of existing App Service for Anonymizer (development environment).</li> <li>IMAGE_REDACTOR_DEV_APP_NAME - Name of existing App Service for Image Redactor (development environment).</li> <li>DEV_AZURE_SUBSCRIPTION - Service connection to Azure subscription where App Services are (development environment).</li> <li>DEV_RESOURCE_GROUP_NAME - Name of resource group where App Services are (development environment).</li> </ul>"},{"location":"build_release/#release-pipeline","title":"Release Pipeline","text":"<ul> <li>ACR_AZURE_SUBSCRIPTION - Service connection to Azure subscription where Azure Container Registry is.</li> <li>ACR_REGISTRY_NAME - Name of Azure Container Registry.</li> <li>ANALYZER_PROD_APP_NAME - Name of existing App Service for Analyzer (production environment).</li> <li>ANONYMIZER_PROD_APP_NAME - Name of existing App Service for Anonymizer (production environment).</li> <li>PROD_AZURE_SUBSCRIPTION - Service connection to Azure subscription where App Services are (production environment).</li> <li>PROD_RESOURCE_GROUP_NAME - Name of resource group where App Services are (production environment).</li> </ul>"},{"location":"build_release/#import-a-pipeline-to-azure-devops","title":"Import a pipeline to Azure Devops","text":"<ul> <li>Sign in to your Azure DevOps organization and navigate to your project.</li> <li>In your project, navigate to the Pipelines page. Then choose the action to create a new pipeline.</li> <li>Walk through the steps of the wizard by first selecting 'Use the classic editor, and select GitHub as the location of your source code.</li> <li>You might be redirected to GitHub to sign in. If so, enter your GitHub credentials.</li> <li>When the list of repositories appears, select presidio repository.</li> <li>Point Azure Pipelines to the relevant yaml definition you'd like to import.     Set the pipeline's name, the required triggers and variables and Select Save and run.</li> <li>A new run is started. Wait for the run to finish.</li> </ul>"},{"location":"community/","title":"Presidio eco-system","text":"<p>This section collects different resources developed with Presidio. </p>"},{"location":"community/#resources","title":"Resources","text":"Resource Description Obsei Obsei is an open-source, low-code, AI powered automation tool data-describe data-describe is a Python toolkit for Exploratory Data Analysis (EDA). It aims to accelerate data exploration and analysis by providing automated and polished analysis widgets. Azure Search Power Skills Power Skills are a collection of useful functions to be deployed as custom skills for Azure Cognitive Search. The skills can be used as templates or starting points for your own custom skills, or they can be deployed and used as they are if they happen to meet your requirements. DataOps for the Modern Data Warehouse Contains numerous code samples and artifacts on how to apply DevOps principles to data pipelines built according to the Modern Data Warehouse (MDW) architectural pattern on Microsoft Azure. Extending Power BI with Python and R Code repository for Extending Power BI with Python and R, published by Packt. HebSafeHarbor Clinical notes anonymization in Hebrew. Presidio Github Action Github Action that analyzes text for PII entities with Microsoft's Presidio framework. HashiCorp Vault Operator A library that allows to integrate Presidio with HashiCorp Vault for anonymization and deanonymization. Rasa bot framework Use Presidio to de-identify chat bot messages in Rasa. LangChain De-identification and reversible anonymization within LangChain. LlamaIndex De-identification and reversible anonymization within LlamaIndex. LiteLLM Itegrate Presidio into LiteLLM Guardrails-ai Use Presidio as an LLM guardrails using the Guardrails AI suite. Presidio in LLMGuard Integrate Presidio into LLM Guard - The Security Toolkit for LLM Interactions. Privy Integrate Presidio into Privy. Huggingface Automatic PII detection on Huggingface datasets. KNIME Use Presidio within the KNIME framework. OpenMetadata Auto PII tagging for Sensitive/NonSensitive at the column level. * Please create a PR if you're interested in adding your tool to this list."},{"location":"design/","title":"Presidio design","text":""},{"location":"design/#analyzer","title":"Analyzer","text":""},{"location":"design/#anonymizer","title":"Anonymizer","text":""},{"location":"design/#image-redactor","title":"Image Redactor","text":""},{"location":"design/#standard-image-types","title":"Standard Image Types","text":""},{"location":"design/#dicom-images","title":"DICOM Images","text":""},{"location":"development/","title":"Setting Up a Development Environment","text":""},{"location":"development/#getting-started","title":"Getting started","text":""},{"location":"development/#cloning-the-repo","title":"Cloning the repo","text":"<p>To create a local copy of Presidio repository, follow Github instructions on how to clone a project using git. The project is structured so that:</p> <ul> <li>Each Presidio service has a designated directory:</li> <li>The service logic.</li> <li>Tests, both unit and integration.</li> <li>Serving it as an HTTP service (found in app.py).</li> <li>Python Packaging setup script (setup.py).</li> <li>In the project root directory, you will find common code for using, serving and testing Presidio     as a cluster of services, as well as CI/CD pipelines codebase and documentation.</li> </ul>"},{"location":"development/#setting-up-poetry","title":"Setting up Poetry","text":"<p>Poetry is Python package manager. It is used to manage dependencies and virtual environments for Presidio services. Follow these steps when starting to work on a Presidio service with poetry:</p> <ol> <li> <p>Install poetry</p> <ul> <li> <p>Using Pip</p> <pre><code>pip install poetry\n</code></pre> </li> <li> <p>Using Homebrew (in MacOS)</p> <pre><code>brew install poetry\n</code></pre> </li> </ul> <p>Additional installation instructions for poetry: https://python-poetry.org/docs/#installation</p> </li> <li> <p>Have poetry create a virtualenv for the project and install all requirements in the pyproject.toml,     including dev requirements.</p> <p>For example, in the <code>presidio-analyzer</code> folder, run:</p> <pre><code>poetry install --all-extras\n</code></pre> </li> <li> <p>Run all tests:</p> <pre><code>poetry run pytest\n</code></pre> </li> <li> <p>To run arbitrary scripts within the virtual env, start the command with     <code>poetry run</code>. For example:</p> <ol> <li><code>poetry run ruff check</code></li> <li><code>poetry run pip freeze</code></li> <li><code>poetry run python -m spacy download en_core_web_lg</code></li> </ol> <p>Command 3 downloads the default spacy model needed for Presidio Analyzer.`</p> </li> </ol>"},{"location":"development/#alternatively-activate-the-virtual-environment-and-use-the-commands-using-this-method","title":"Alternatively, activate the virtual environment and use the commands using this method.","text":""},{"location":"development/#development-guidelines","title":"Development guidelines","text":"<ul> <li>A Github issue suggesting the change should be opened prior to a PR.</li> <li>All contributions should be documented, tested and linted. Please verify that all tests and lint checks pass successfully before proposing a change.</li> <li>To make the linting process easier, you can use pre-commit hooks to verify and automatically format code upon a git commit</li> <li>In order for a pull request to be accepted, the CI (containing unit tests, e2e tests and linting) needs to succeed, in addition to approvals from two maintainers.</li> <li>PRs should be small and solve/improve one issue at a time. If you have multiple suggestions for improvement, please open multiple PRs.</li> </ul>"},{"location":"development/#local-build-process","title":"Local build process","text":"<p>After modifying presidio codebase, you might want to build presidio cluster locally, and run tests to spot regressions. The recommended way of doing so is using docker-compose (bundled with 'Docker Desktop' for Windows and Mac systems, more information can be found here). Once installed, to start presidio cluster with all of its services in HTTP mode, run from the project root:</p> <pre><code>docker-compose up --build -d\n</code></pre> <p>Note</p> <p>Building for the first time might take some time, mainly on downloading the default spacy models.</p> <p>To validate that the services were built and started successfully, and to see the designated port for each, use docker-compose ps:</p> <pre><code>&gt;docker-compose ps\nCONTAINER ID   IMAGE                       COMMAND                  CREATED         STATUS         PORTS                    NAMES\n6d5a258d19c2   presidio-anonymizer         \"/bin/sh -c 'poetry \u2026\"   6 minutes ago   Up 6 minutes   0.0.0.0:5001-&gt;5001/tcp   presidio_presidio-anonymizer_1\n9aad2b68f93c   presidio-analyzer           \"/bin/sh -c 'poetry \u2026\"   2 days ago      Up 6 minutes   0.0.0.0:5002-&gt;5001/tcp   presidio_presidio-analyzer_1\n1448dfb3ec2b   presidio-image-redactor     \"/bin/sh -c 'poetry \u2026\"   2 seconds ago   Up 2 seconds   0.0.0.0:5003-&gt;5001/tcp   presidio_presidio-image-redactor_1\n</code></pre> <p>Edit docker-compose.yml configuration file to change the default ports.</p> <p>Starting part of the cluster, or one service only, can be done by stating its image name as argument for docker-compose. For example for analyzer service:</p> <pre><code>docker-compose up --build -d presidio-analyzer\n</code></pre>"},{"location":"development/#testing","title":"Testing","text":"<p>We strive to have a full test coverage in Presidio, and expect every pull request to include tests.</p> <p>In each service directory, a 'test' directory can be found. In it, both unit tests, for testing single files or classes, and integration tests, for testing integration between the service components, or integration with external packages.</p>"},{"location":"development/#basic-conventions","title":"Basic conventions","text":"<p>For tests to be consistent and predictable, we use the following basic conventions:</p> <ol> <li>Treat tests as production code. Keep the tests concise and readable, with descriptive namings.</li> <li>Assert on one behavior at a time in each test.</li> <li>Test names should follow a pattern of <code>test_when_[condition_to_test]_then_[expected_behavior]</code>.    For example: <code>test_given_an_unknown_entity_then_anonymize_uses_defaults</code>.</li> <li>Use test doubles and mocks    when writing unit tests. Make less use of them when writing integration tests.</li> </ol>"},{"location":"development/#running-tests","title":"Running tests","text":"<p>Presidio uses the pytest framework for testing. See the pytest documentation for more information.</p> <p>Running the tests locally can be done in two ways:</p> <ol> <li> <p>Using cli, from each service directory, run:</p> <pre><code>poetry run pytest\n</code></pre> </li> <li> <p>Using your IDE.    See configuration examples for    JetBrains PyCharm / IntelliJ IDEA    and Visual Studio Code</p> </li> </ol>"},{"location":"development/#end-to-end-tests","title":"End-to-end tests","text":"<p>Since Presidio services can function as HTTP servers, Presidio uses an additional end-to-end (e2e) testing layer to test their REST APIs. This e2e test framework is located under 'e2e-tests' directory. In it, you can also find test scenarios testing the integration between Presidio services through REST API. These tests should be annotated with 'integration' pytest marker <code>@pytest.mark.integration</code>, while tests calling a single service API layer should be annotated with 'api' pytest marker <code>@pytest.mark.api</code>.</p> <p>Running the e2e-tests locally can be done in two ways:</p> <ol> <li> <p>Using cli, from e2e-tests directory, run:</p> <p>On Mac / Linux / WSL:</p> <pre><code># Create a virtualenv named presidio-e2e (needs to be done only on the first run)\npython -m venv presidio-e2e\n# Activate the virtualenv\nsource presidio-e2e/bin/activate\n# Install e2e-tests requirements using pip\npip install -r requirements.txt\n# Run pytest\npytest\n# Deactivate the virtualenv\ndeactivate\n</code></pre> <p>On Windows CMD / Powershell:</p> <pre><code># Create a virtualenv named presidio-e2e (needs to be done only on the first run)\npy -m venv presidio-e2e\n# Activate the virtualenv\npresidio-e2e\\Scripts\\activate\n# Install e2e-tests requirements using pip\npip install -r requirements.txt\n# Run pytest\npytest\n# Deactivate the virtualenv\ndeactivate\n</code></pre> </li> <li> <p>Using your IDE</p> <p>See references in the section above.</p> </li> </ol> <p>Note</p> <p>The e2e tests require a Presidio cluster to be up, for example using the containerized cluster with docker-compose.</p>"},{"location":"development/#build-and-run-end-to-end-tests-locally","title":"Build and run end-to-end tests locally","text":"<p>Building and testing presidio locally, as explained above, can give good assurance on new changes and on regressions that might have introduced during development. As an easier method to build and automatically run end-to-end tests, is to use the <code>run.bat</code> script found in the project root:</p> <p>On Mac / Linux / WSL:</p> <pre><code>chmod +x run.bat\n./run.bat\n</code></pre> <p>On Windows CMD / Powershell:</p> <pre><code>run.bat\n</code></pre>"},{"location":"development/#linting","title":"Linting","text":"<p>Presidio services are PEP8 compliant and continuously enforced on style guide issues during the build process using <code>ruff</code>, in turn running <code>flake8</code> and other linters.</p> <p>Running ruff locally, using <code>poetry run ruff check</code>, you can check for those issues prior to committing a change.</p> <p>Ruff runs linters in addition to the basic <code>flake8</code> functionality, Presidio uses linters as part as ruff such as:</p> <ul> <li>pep8-naming: To check that variable names are PEP8 compliant.</li> <li>flake8-docstrings: To check that docstrings are compliant.</li> </ul>"},{"location":"development/#automatically-format-code-and-check-for-code-styling","title":"Automatically format code and check for code styling","text":"<p>To make the linting process easier, you can use pre-commit hooks to verify and automatically format code upon a git commit, using <code>ruff-format</code>:</p> <ol> <li> <p>Install pre-commit package manager locally.</p> </li> <li> <p>From the project's root, enable pre-commit, installing git hooks in the <code>.git/</code> directory by running: <code>pre-commit install</code>.</p> </li> <li> <p>Commit non PEP8 compliant code will cause commit failure and automatically     format your code using, as well as checking code formatting using <code>ruff</code></p> </li> </ol> <pre><code>[INFO] Initializing environment for https://github.com/astral-sh/ruff-pre-commit.\n[INFO] Installing environment for https://github.com/astral-sh/ruff-pre-commit.\n[INFO] Once installed this environment will be reused.\n[INFO] This may take a few minutes...\nruff.....................................................................Passed\nruff-format..............................................................Failed\n- hook id: ruff-format\n- files were modified by this hook\n  5 files reformatted, 4 files left unchanged\n</code></pre> <ol> <li>Committing again will finish successfully, with a well-formatted code.</li> </ol>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":"<ul> <li>General</li> <li>What is Presidio?</li> <li>Why did Microsoft create Presidio?</li> <li>Is Microsoft Presidio an official Microsoft product?</li> <li>What is the difference between Presidio and different PII detection services like Azure Text Analytics and Amazon Comprehend?</li> <li>Using Presidio</li> <li>How can I start using Presidio?</li> <li>What are the main building blocks in Presidio?</li> <li>Customizing Presidio</li> <li>How can Presidio be customized to my needs?</li> <li>What NLP frameworks does Presidio support?</li> <li>Can Presidio be used for Pseudonymization?</li> <li>Does Presidio work on structured/tabular data?</li> <li>Improving detection accuracy</li> <li>What can I do if Presidio does not detect some of the PII entities in my data (False Negatives)?</li> <li>What can I do if Presidio falsely detects text as PII entities (False Positives)?</li> <li>How can I evaluate the performance of my Presidio instance?</li> <li>Deployment</li> <li>How can I deploy Presidio into my environment?</li> <li>Contributing</li> <li>How can I contribute to Presidio?</li> <li>How can I report security vulnerabilities?</li> </ul>"},{"location":"faq/#general","title":"General","text":""},{"location":"faq/#what-is-presidio","title":"What is Presidio?","text":"<p>Presidio (Origin from Latin praesidium \u2018protection, garrison\u2019) helps to ensure sensitive data is properly managed and governed. It provides fast identification and anonymization modules for private entities in text and images. It is fully customizable and pluggable, can be adapted to your needs and be deployed into various environments.</p> <p>Note</p> <p>Presidio is a library or SDK rather than a service. It is meant to be customized to the user's or organization's specific needs.</p> <p>Warning</p> <p>Presidio can help identify sensitive/PII data in un/structured text. However, because Presidio is using trained ML models, there is no guarantee that Presidio will find all sensitive information. Consequently, additional systems and protections should be employed.</p>"},{"location":"faq/#why-did-microsoft-create-presidio","title":"Why did Microsoft create Presidio?","text":"<p>By developing Presidio, our goals are:</p> <ol> <li>Allow organizations to preserve privacy in a simpler way by democratizing de-identification technologies and introducing transparency in decisions.</li> <li>Embrace extensibility and customizability to a specific business need.</li> <li>Facilitate both fully automated and semi-automated PII de-identification flows on multiple platforms.</li> </ol>"},{"location":"faq/#is-microsoft-presidio-an-official-microsoft-product","title":"Is Microsoft Presidio an official Microsoft product?","text":"<p>The authors and maintainers of Presidio come from the Industry Solutions Engineering team. We work with customers on various engineering problems, and have found the proper handling of private and sensitive data a recurring challenge across many customers and industries.</p> <p>Note</p> <p>Microsoft Presidio is not an official Microsoft product. Usage terms are defined in the repository's license.</p>"},{"location":"faq/#what-is-the-difference-between-presidio-and-different-pii-detection-services-like-azure-text-analytics-and-amazon-comprehend","title":"What is the difference between Presidio and different PII detection services like Azure Text Analytics and Amazon Comprehend?","text":"<p>In a nutshell, Presidio is a library which is meant to be customized, whereas different SaaS tools for PII detection have less customization capabilities. Most of these SaaS offerings use dedicated ML models and other logic for PII detection and often have better entity coverage or accuracy than Presidio.</p> <p>Based on our internal research, leveraging Presidio in parallel to 3rd party PII detection services like Azure Text Analytics can bring optimal results mainly when the data in hand has entity types or values not supported by the 3rd party service. (see example here).</p>"},{"location":"faq/#using-presidio","title":"Using Presidio","text":""},{"location":"faq/#how-can-i-start-using-presidio","title":"How can I start using Presidio?","text":"<ol> <li>Check out the installation docs.</li> <li>Take a look at the different samples.</li> <li>Try the demo website.</li> </ol>"},{"location":"faq/#what-are-the-main-building-blocks-in-presidio","title":"What are the main building blocks in Presidio?","text":"<p>Presidio is a suite built of several packages and building blocks:</p> <ol> <li>Presidio Analyzer: a package for detecting PII entities in natural language.</li> <li>Presidio Anonymizer: a package for manipulating PII entities in text (e.g. remove, redact, hash, encrypt).</li> <li>Presidio Image Redactor: A package for detecting PII entities in image using OCR.</li> <li>A set of sample deployments as Python packages or Docker containers for Kubernetes, Azure Data Factory, Spark and more.</li> </ol>"},{"location":"faq/#customizing-presidio","title":"Customizing Presidio","text":""},{"location":"faq/#how-can-presidio-be-customized-to-my-needs","title":"How can Presidio be customized to my needs?","text":"<p>Users can customize Presidio in multiple ways:</p> <ol> <li>Create new or updated PII recognizers (docs).</li> <li>Adapt Presidio to new languages (docs).</li> <li>Leverage state of the art Named Entity Recognition models (docs).</li> <li>Add new types of anonymizers (docs).</li> <li>Create PII analysis and anonymization pipelines on different environments using Docker or Python (samples).</li> </ol> <p>And more.</p>"},{"location":"faq/#what-nlp-frameworks-does-presidio-support","title":"What NLP frameworks does Presidio support?","text":"<p>Presidio supports spaCy version 3+ for Named Entity Recognition, tokenization, lemmatization and more. We also support Stanza using the spacy-stanza package, and it is further possible to create PII recognizers leveraging other frameworks like transformers or Flair.</p> <p>For more information, see the docs.</p>"},{"location":"faq/#can-presidio-be-used-for-pseudonymization","title":"Can Presidio be used for Pseudonymization?","text":"<p>Pseudonymization is a de-identification technique in which the real data is replaced with fake data in a reversible way. Since there are various ways and approaches for this, we provide a simple sample which can be extended for more sophisticated usage. If you have a question or a request on this topic, please open an issue on the repo.</p>"},{"location":"faq/#does-presidio-work-on-structuredtabular-data","title":"Does Presidio work on structured/tabular data?","text":"<p>This is an area we are actively looking into. We have an example implementation of using Presidio on structured/semi-structured data. Also see the different discussions on this topic on the Discussions section. If you have a question, suggestion, or a contribution in this area, please reach out by opening an issue, starting a discussion or reaching us directly at presidio@microsoft.com</p>"},{"location":"faq/#improving-detection-accuracy","title":"Improving detection accuracy","text":""},{"location":"faq/#what-can-i-do-if-presidio-does-not-detect-some-of-the-pii-entities-in-my-data-false-negatives","title":"What can I do if Presidio does not detect some of the PII entities in my data (False Negatives)?","text":"<p>Presidio comes loaded with several PII recognizers (see list here), however its main strength lies in its customization capabilities to new entities, specific datasets, languages or use cases. For a recommended process for improving detection accuracy, see these guidelines.</p>"},{"location":"faq/#what-can-i-do-if-presidio-falsely-detects-text-as-pii-entities-false-positives","title":"What can I do if Presidio falsely detects text as PII entities (False Positives)?","text":"<p>Some PII recognizers are less specific than others. A driver's license number, for example, could be any 9-digit number. While Presidio leverages context words and other logic to improve the detection quality, it could still falsely detect non-entity values as PII entities.</p> <p>In order to avoid false positives, one could try to:</p> <ol> <li>Change the acceptance threshold, which defines what is the minimum confidence value for a detected entity to be returned.</li> <li>Remove unnecessary PII recognizers, if the dataset does not contain these entities.</li> <li>Update/replace the logic of specific recognizers to better suit a specific dataset or use case.</li> <li>Replace PII recognizers with those coming from 3rd party services.</li> </ol> <p>Every PII identification logic would have its errors, and there is a trade-off between false positives (falsely detected text) and false negatives (PII entities which are not detected).</p>"},{"location":"faq/#how-can-i-evaluate-the-performance-of-my-presidio-instance","title":"How can I evaluate the performance of my Presidio instance?","text":"<p>In addition to Presidio, we maintain a repo focused on evaluation of models and PII recognizers here. It also features a simple PII data generator.</p>"},{"location":"faq/#deployment","title":"Deployment","text":""},{"location":"faq/#how-can-i-deploy-presidio-into-my-environment","title":"How can I deploy Presidio into my environment?","text":"<p>The main Presidio modules (analyzer, anonymizer, image-redactor) can be used both as a Python package and as a dockerized REST API. See the different deployment samples for example deployments.</p>"},{"location":"faq/#contributing","title":"Contributing","text":""},{"location":"faq/#how-can-i-contribute-to-presidio","title":"How can I contribute to Presidio?","text":"<p>First, review the contribution guidelines, and feel free to reach out by opening an issue, posting a discussion or emailing us at presidio@microsoft.com</p>"},{"location":"faq/#how-can-i-report-security-vulnerabilities","title":"How can I report security vulnerabilities?","text":"<p>Please see the security information.</p>"},{"location":"getting_started/","title":"Getting started with Presidio","text":""},{"location":"getting_started/#simple-flow","title":"Simple flow","text":"<p>Using Presidio's modules as Python packages to get started:</p> Anonymize PII in text (Default spaCy model)Anonymize PII in text (transformers) <ol> <li> <p>Install Presidio</p> <pre><code>pip install presidio-analyzer\npip install presidio-anonymizer\npython -m spacy download en_core_web_lg\n</code></pre> </li> <li> <p>Analyze + Anonymize</p> <pre><code>from presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine\n\ntext=\"My phone number is 212-555-5555\"\n\n# Set up the engine, loads the NLP module (spaCy model by default) \n# and other PII recognizers\nanalyzer = AnalyzerEngine()\n\n# Call analyzer to get results\nresults = analyzer.analyze(text=text,\n                           entities=[\"PHONE_NUMBER\"],\n                           language='en')\nprint(results)\n\n# Analyzer results are passed to the AnonymizerEngine for anonymization\n\nanonymizer = AnonymizerEngine()\n\nanonymized_text = anonymizer.anonymize(text=text,analyzer_results=results)\n\nprint(anonymized_text)\n</code></pre> </li> </ol> <ol> <li> <p>Install Presidio</p> <pre><code>pip install \"presidio-analyzer[transformers]\"\npip install presidio-anonymizer\npython -m spacy download en_core_web_sm\n</code></pre> </li> <li> <p>Analyze + Anonymize</p> <pre><code>from presidio_analyzer import AnalyzerEngine\nfrom presidio_analyzer.nlp_engine import TransformersNlpEngine\nfrom presidio_anonymizer import AnonymizerEngine\n\ntext = \"My name is Don and my phone number is 212-555-5555\"\n\n# Define which transformers model to use\nmodel_config = [{\"lang_code\": \"en\", \"model_name\": {\n    \"spacy\": \"en_core_web_sm\",  # use a small spaCy model for lemmas, tokens etc.\n    \"transformers\": \"dslim/bert-base-NER\"\n    }\n}]\n\nnlp_engine = TransformersNlpEngine(models=model_config)\n\n# Set up the engine, loads the NLP module (spaCy model by default) \n# and other PII recognizers\nanalyzer = AnalyzerEngine(nlp_engine=nlp_engine)\n\n# Call analyzer to get results\nresults = analyzer.analyze(text=text, language='en')\nprint(results)\n\n# Analyzer results are passed to the AnonymizerEngine for anonymization\n\nanonymizer = AnonymizerEngine()\n\nanonymized_text = anonymizer.anonymize(text=text, analyzer_results=results)\n\nprint(anonymized_text)\n</code></pre> <p>Tip: Downloading models</p> <p>If not available, the transformers model and the spacy model would be downloaded on the first call to the <code>AnalyzerEngine</code>. To pre-download, see this doc.</p> </li> </ol>"},{"location":"getting_started/#simple-flow-images","title":"Simple flow: Images","text":"Anonymize PII in imagesRedact text PII in DICOM images <ol> <li> <p>Install presidio-image-redactor</p> <pre><code>pip install presidio-image-redactor\n</code></pre> </li> <li> <p>Redact PII from image</p> <pre><code>from presidio_image_redactor import ImageRedactorEngine\nfrom PIL import Image\n\nimage = Image.open(path_to_image_file)\n\nredactor = ImageRedactorEngine()\nredactor.redact(image=image)\n</code></pre> </li> </ol> <ol> <li> <p>Install presidio-image-redactor</p> <pre><code>pip install presidio-image-redactor\n</code></pre> </li> <li> <p>Redact text PII from DICOM image</p> <pre><code>import pydicom\nfrom presidio_image_redactor import DicomImageRedactorEngine\n\n# Set input and output paths\ninput_path = \"path/to/your/dicom/file.dcm\"\noutput_dir = \"./output\"\n\n# Initialize the engine\nengine = DicomImageRedactorEngine()\n\n# Option 1: Redact from a loaded DICOM image\ndicom_image = pydicom.dcmread(input_path)\nredacted_dicom_image = engine.redact(dicom_image, fill=\"contrast\")\n\n# Option 2: Redact from DICOM file\nengine.redact_from_file(input_path, output_dir, padding_width=25, fill=\"contrast\")\n\n# Option 3: Redact from directory\nengine.redact_from_directory(\"path/to/your/dicom\", output_dir, padding_width=25, fill=\"contrast\")\n</code></pre> </li> </ol>"},{"location":"getting_started/#read-more","title":"Read more","text":"<ul> <li>Installing Presidio</li> <li>PII detection in text</li> <li>PII anonymization in text</li> <li>PII redaction in images</li> <li>Discussion board</li> </ul>"},{"location":"installation/","title":"Installing Presidio","text":""},{"location":"installation/#description","title":"Description","text":"<p>This document describes the installation of the entire Presidio suite using <code>pip</code> (as Python packages) or using <code>Docker</code> (As containerized services).</p>"},{"location":"installation/#using-pip","title":"Using pip","text":"<p>Note</p> <p>Consider installing the Presidio python packages in a virtual environment like venv or conda.</p>"},{"location":"installation/#supported-python-versions","title":"Supported Python Versions","text":"<p>Presidio is supported for the following python versions:</p> <ul> <li>3.9</li> <li>3.10</li> <li>3.11</li> <li>3.12</li> </ul>"},{"location":"installation/#pii-anonymization-on-text","title":"PII anonymization on text","text":"<p>For PII anonymization on text, install the <code>presidio-analyzer</code> and <code>presidio-anonymizer</code> packages with at least one NLP engine (<code>spaCy</code>, <code>transformers</code> or <code>stanza</code>):</p> spaCy (default)TransformersStanza <pre><code>pip install presidio_analyzer\npip install presidio_anonymizer\npython -m spacy download en_core_web_lg\n</code></pre> <pre><code>pip install \"presidio_analyzer[transformers]\"\npip install presidio_anonymizer\npython -m spacy download en_core_web_sm\n</code></pre> <p>Note</p> <p>When using a transformers NLP engine, Presidio would still use spaCy for other capabilities, therefore a small spaCy model (such as en_core_web_sm) is required.  Transformers models would be loaded lazily. To pre-load them, see: Downloading a pre-trained model</p> <pre><code>pip install \"presidio_analyzer[stanza]\"\npip install presidio_anonymizer\n</code></pre> <p>Note</p> <p>Stanza models would be loaded lazily. To pre-load them, see: Downloading a pre-trained model.</p>"},{"location":"installation/#pii-redaction-in-images","title":"PII redaction in images","text":"<p>For PII redaction in images</p> <ol> <li> <p>Install the <code>presidio-image-redactor</code> package:</p> <pre><code>pip install presidio_image_redactor\n\n# Presidio image redactor uses the presidio-analyzer\n# which requires a spaCy language model:\npython -m spacy download en_core_web_lg\n</code></pre> </li> <li> <p>Install an OCR engine. The default version uses the Tesseract OCR Engine.  More information on installation can be found here.</p> </li> </ol>"},{"location":"installation/#using-docker","title":"Using Docker","text":"<p>Presidio can expose REST endpoints for each service using Flask and Docker. To download the Presidio Docker containers, run the following command:</p> <p>Note</p> <p>This requires Docker to be installed. Download Docker.</p>"},{"location":"installation/#for-pii-anonymization-in-text","title":"For PII anonymization in text","text":"<p>For PII detection and anonymization in text, the <code>presidio-analyzer</code> and <code>presidio-anonymizer</code> modules are required.</p> <pre><code># Download Docker images\ndocker pull mcr.microsoft.com/presidio-analyzer\ndocker pull mcr.microsoft.com/presidio-anonymizer\n\n# Run containers with default ports\ndocker run -d -p 5002:3000 mcr.microsoft.com/presidio-analyzer:latest\n\ndocker run -d -p 5001:3000 mcr.microsoft.com/presidio-anonymizer:latest\n</code></pre>"},{"location":"installation/#for-pii-redaction-in-images","title":"For PII redaction in images","text":"<p>For PII detection in images, the <code>presidio-image-redactor</code> is required.</p> <pre><code># Download Docker image\ndocker pull mcr.microsoft.com/presidio-image-redactor\n\n# Run container with the default port\ndocker run -d -p 5003:3000 mcr.microsoft.com/presidio-image-redactor:latest\n</code></pre> <p>Once the services are running, their APIs are available. API reference and example calls can be found here.</p>"},{"location":"installation/#install-from-source","title":"Install from source","text":"<p>To install Presidio from source, first clone the repo:</p> <ul> <li>using HTTPS</li> </ul> <pre><code>git clone https://github.com/microsoft/presidio.git\n</code></pre> <ul> <li>Using SSH</li> </ul> <pre><code>git clone git@github.com:microsoft/presidio.git\n</code></pre> <p>Then, build the containers locally.</p> <p>Note</p> <p>Presidio uses docker-compose to manage the different Presidio containers.</p> <p>From the root folder of the repo:</p> <pre><code>docker-compose up --build\n</code></pre> <p>Alternatively, you can build and run individual services. For example, for the <code>presidio-anonymizer</code> service:</p> <pre><code>docker build ./presidio-anonymizer -t presidio/presidio-anonymizer\n</code></pre> <p>And run:</p> <pre><code>docker run -d -p 5001:5001 presidio/presidio-anonymizer\n</code></pre> <p>For more information on developing locally, refer to the setting up a development environment section.</p>"},{"location":"presidio_V2/","title":"Presidio Revamp (aka V2)","text":"<p>As of March 2021, Presidio had undergo a revamp to a new version refereed to as V2.</p> <p>The main changes introduced in V2 are:</p> <ol> <li>gRPC replaced with HTTP to allow more customizable APIs and easier debugging</li> <li> <p>Focus on the Analyzer and Anonymizer services.</p> <ol> <li>Presidio Anonymizer is now Python based and pip installable.</li> <li>Presidio Analyzer does not use templates and external recognizer store.</li> <li>Image Redactor (formerly presidio-image-anonymizer) is in early beta and is Python based and pip installable.</li> <li>Other services are deprecated and potentially be migrated over time to V2 with the help of the community.</li> </ol> </li> <li> <p>Improved documentation, samples and build flows.</p> </li> <li> <p>Format Preserving Encryption replaced with Advanced Encryption Standard (AES) </p> </li> </ol>"},{"location":"presidio_V2/#v1-availability","title":"V1 Availability","text":"<p>Version V1 (legacy) is still available for download. To continue using the previous version: -   For docker containers, use tag=v1  -   For python packages, download version &lt; 2 (e.g. pip install presidio-analyzer==0.95)</p> <p>Note</p> <p>The legacy V1 code base will continue to be available under branch V1 but will no longer be officially supported.</p>"},{"location":"presidio_V2/#api-changes","title":"API Changes","text":"<p>The move from gRPC to HTTP based APIs included changes to the API requests.</p> <ol> <li> <p>Change in payload - moving from structures to jsons.</p> </li> <li> <p>Removing templates from the API - includes flattening the json.</p> </li> <li>Using snake_case instead of camelCase .</li> </ol> <p>Below is a detailed outline of all the changes done to the Analyzer and Anonymizer.</p>"},{"location":"presidio_V2/#analyzer-api-changes","title":"Analyzer API Changes","text":""},{"location":"presidio_V2/#legacy-json-request-grpc","title":"Legacy json request (gRPC)","text":"<pre><code>{\n    \"text\": \"My phone number is 212-555-5555\",\n    \"AnalyzeTemplateId\": \"1234\",\n    \"AnalyzeTemplate\": {\n        \"Fields\": [\n            {\n                \"Name\": \"PHONE_NUMBER\",\n                \"MinScore\": \"0.5\"\n            }\n        ],\n        \"AllFields\": true,\n        \"Description\": \"template description\",\n        \"CreateTime\": \"template creation time\",\n        \"ModifiedTime\": \"template modification time\",\n        \"Language\": \"fr\",\n        \"ResultsScoreThreshold\": 0.5\n    }\n}\n</code></pre>"},{"location":"presidio_V2/#v2-json-request-http","title":"V2 json request (HTTP)","text":"<pre><code>{\n    \"text\": \"My phone number is 212-555-5555\",\n    \"entities\": [\"PHONE_NUMBER\"],\n    \"language\": \"en\",\n    \"correlation_id\": \"213\",\n    \"score_threshold\": 0.5,\n    \"trace\": true,\n    \"return_decision_process\": true\n}\n</code></pre>"},{"location":"presidio_V2/#anonymizer-api-changes","title":"Anonymizer API Changes","text":""},{"location":"presidio_V2/#legacy-json-request-grpc_1","title":"Legacy json request (gRPC)","text":"<pre><code>{\n  \"text\": \"hello world, my name is Jane Doe. My number is: 034453334\",\n  \"template\": {\n    \"description\": \"DEPRECATED\",\n    \"create_time\": \"DEPRECATED\",\n    \"modified_time\": \"DEPRECATED\",\n    \"default_transformation\": {\n      \"replace_value\": {...},\n      \"redact_value\": {...},\n      \"hash_value\": {...},\n      \"mask_value\": {...},\n      \"fpe_value\": {...}\n    },\n    \"field_type_transformations\": [\n      {\n        \"fields\": [\n          {\n            \"name\": \"FIRST_NAME\",\n            \"min_score\": \"0.2\"\n          }\n        ],\n        \"transfomarion\": {\n          \"replace_value\": {...},\n          \"redact_value\": {...},\n          \"hash_value\": {...},\n          \"mask_value\": {...},\n          \"fpe_value\": {...}\n        }\n      }\n    ],\n    \"analyze_results\": [\n      {\n        \"text\": \"Jane\",\n        \"field\": {\n          \"name\": \"FIRST_NAME\",\n          \"min_score\": \"0.5\"\n        },\n        \"location\": {\n          \"start\": 24,\n          \"end\": 32,\n          \"length\": 6\n        },\n        \"score\": 0.8\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"presidio_V2/#v2-json-request-http_1","title":"V2 json request (HTTP)","text":"<pre><code>{\n    \"text\": \"hello world, my name is Jane Doe. My number is: 034453334\",\n    \"anonymizers\": {\n        \"DEFAULT\": {\n            \"type\": \"replace\",\n            \"new_value\": \"val\"\n        },\n        \"PHONE_NUMBER\": {\n            \"type\": \"mask\",\n            \"masking_char\": \"*\",\n            \"chars_to_mask\": 4,\n            \"from_end\": true\n        }\n    },\n    \"analyzer_results\": [\n        {\n            \"start\": 24,\n            \"end\": 32,\n            \"score\": 0.8,\n            \"entity_type\": \"NAME\"\n        },\n        {\n            \"start\": 24,\n            \"end\": 28,\n            \"score\": 0.8,\n            \"entity_type\": \"FIRST_NAME\"\n        },\n        {\n            \"start\": 29,\n            \"end\": 32,\n            \"score\": 0.6,\n            \"entity_type\": \"LAST_NAME\"\n        },\n        {\n            \"start\": 48,\n            \"end\": 57,\n            \"score\": 0.95,\n            \"entity_type\": \"PHONE_NUMBER\"\n        }\n    ]\n}\n</code></pre> <p>Specific for each anonymization type:</p> Anonymization name Legacy format (V1) New json format (V2) Replace <pre>string newValue = 1;</pre> <pre>{ \"new_value\": \"VALUE\" }</pre> Redact NONE NONE Mask <pre>string maskingCharacter = 1;int32 charsToMask = 2; bool fromEnd = 3;</pre> <pre>{ \"chars_to_mask\": 10, \"from_end\": true, \"masking_char\": \"*\" }</pre> Hash NONE <pre>{\"hash_type\": \"VALUE\"}</pre> FPE (now Encrypt) <pre>string key = 3t6w9z$C&amp;F)J@NcR;int32 tweak = D8E7920AFA330A73</pre> <pre>{\"key\": \"3t6w9z$C&amp;F)J@NcR\"}</pre> <p>Note</p> <p>The V2 API keeps changing please follow the change log for updates.</p>"},{"location":"supported_entities/","title":"PII entities supported by Presidio","text":"<p>Presidio contains predefined recognizers for PII entities. This page describes the different entities Presidio can detect and the method Presidio employs to detect those.</p> <p>In addition, Presidio allows you to add custom entity recognizers. For more information, refer to the adding new recognizers documentation.</p>"},{"location":"supported_entities/#list-of-supported-entities","title":"List of supported entities","text":""},{"location":"supported_entities/#global","title":"Global","text":"Entity Type Description Detection Method CREDIT_CARD A credit card number is between 12 to 19 digits. https://en.wikipedia.org/wiki/Payment_card_number Pattern match and checksum CRYPTO A Crypto wallet number. Currently only Bitcoin address is supported Pattern match, context and checksum DATE_TIME Absolute or relative dates or periods or times smaller than a day. Pattern match and context EMAIL_ADDRESS An email address identifies an email box to which email messages are delivered Pattern match, context and RFC-822 validation IBAN_CODE The International Bank Account Number (IBAN) is an internationally agreed system of identifying bank accounts across national borders to facilitate the communication and processing of cross border transactions with a reduced risk of transcription errors. Pattern match, context and checksum IP_ADDRESS An Internet Protocol (IP) address (either IPv4 or IPv6). Pattern match, context and checksum NRP A person\u2019s Nationality, religious or political group. Custom logic and context LOCATION Name of politically or geographically defined location (cities, provinces, countries, international regions, bodies of water, mountains Custom logic and context PERSON A full person name, which can include first names, middle names or initials, and last names. Custom logic and context PHONE_NUMBER A telephone number Custom logic, pattern match and context MEDICAL_LICENSE Common medical license numbers. Pattern match, context and checksum URL A URL (Uniform Resource Locator), unique identifier used to locate a resource on the Internet Pattern match, context and top level url validation"},{"location":"supported_entities/#usa","title":"USA","text":"Entity Type Description Detection Method US_BANK_NUMBER A US bank account number is between 8 to 17 digits. Pattern match and context US_DRIVER_LICENSE A US driver license according to https://ntsi.com/drivers-license-format/ Pattern match and context US_ITIN US Individual Taxpayer Identification Number (ITIN). Nine digits that start with a \"9\" and contain a \"7\" or \"8\" as the 4 digit. Pattern match and context US_PASSPORT A US passport number with 9 digits. Pattern match and context US_SSN A US Social Security Number (SSN) with 9 digits. Pattern match and context"},{"location":"supported_entities/#uk","title":"UK","text":"Entity Type Description Detection Method UK_NHS A UK NHS number is 10 digits. Pattern match, context and checksum UK_NINO UK National Insurance Number is a unique identifier used in the administration of National Insurance and tax. Pattern match and context"},{"location":"supported_entities/#spain","title":"Spain","text":"Entity Type Description Detection Method ES_NIF A spanish NIF number (Personal tax ID) . Pattern match, context and checksum ES_NIE A spanish NIE number (Foreigners ID card) . Pattern match, context and checksum"},{"location":"supported_entities/#italy","title":"Italy","text":"Entity Type Description Detection Method IT_FISCAL_CODE An Italian personal identification code. https://en.wikipedia.org/wiki/Italian_fiscal_code Pattern match, context and checksum IT_DRIVER_LICENSE An Italian driver license number. Pattern match and context IT_VAT_CODE An Italian VAT code number Pattern match, context and checksum IT_PASSPORT An Italian passport number. Pattern match and context IT_IDENTITY_CARD An Italian identity card number. https://en.wikipedia.org/wiki/Italian_electronic_identity_card Pattern match and context"},{"location":"supported_entities/#poland","title":"Poland","text":"Entity Type Description Detection Method PL_PESEL Polish PESEL number Pattern match, context and checksum"},{"location":"supported_entities/#singapore","title":"Singapore","text":"FieldType Description Detection Method SG_NRIC_FIN A National Registration Identification Card Pattern match and context SG_UEN A Unique Entity Number (UEN) is a standard identification number for entities registered in Singapore. Pattern match, context, and checksum"},{"location":"supported_entities/#australia","title":"Australia","text":"FieldType Description Detection Method AU_ABN The Australian Business Number (ABN) is a unique 11 digit identifier issued to all entities registered in the Australian Business Register (ABR). Pattern match, context, and checksum AU_ACN An Australian Company Number is a unique nine-digit number issued by the Australian Securities and Investments Commission to every company registered under the Commonwealth Corporations Act 2001 as an identifier. Pattern match, context, and checksum AU_TFN The tax file number (TFN) is a unique identifier issued by the Australian Taxation Office to each taxpaying entity Pattern match, context, and checksum AU_MEDICARE Medicare number is a unique identifier issued by Australian Government that enables the cardholder to receive a rebates of medical expenses under Australia's Medicare system Pattern match, context, and checksum"},{"location":"supported_entities/#india","title":"India","text":"FieldType Description Detection Method IN_PAN The Indian Permanent Account Number (PAN) is a unique 12 character alphanumeric identifier issued to all business and individual entities registered as Tax Payers. Pattern match, context IN_AADHAAR Indian government issued unique 12 digit individual identity number Pattern match, context, and checksum IN_VEHICLE_REGISTRATION Indian government issued transport (govt, personal, diplomatic, defence)  vehicle registration number Pattern match, context, and checksum IN_VOTER Indian Election Commission issued 10 digit alpha numeric voter id for all indian citizens (age 18 or above) Pattern match, context IN_PASSPORT Indian Passport Number Pattern match, Context"},{"location":"supported_entities/#finland","title":"Finland","text":"FieldType Description Detection Method FI_PERSONAL_IDENTITY_CODE The Finnish Personal Identity Code (Henkil\u00f6tunnus) is a unique 11 character individual identity number. Pattern match, context and custom logic."},{"location":"supported_entities/#adding-a-custom-pii-entity","title":"Adding a custom PII entity","text":"<p>See this documentation for instructions on how to add a new Recognizer for a new type of PII entity.</p>"},{"location":"supported_entities/#complementing-presidio-with-azure-ai-language-pii","title":"Complementing Presidio with Azure AI Language PII","text":"<p>Azure AI Language PII  is a cloud-based service that provides Natural Language Processing (NLP) features for detecting PII in text.</p> <p>A list of supported entities by Azure AI Language PII can be found here.</p> <p>To add Azure AI language into Presidio, see this sample.</p>"},{"location":"supported_entities/#connecting-to-3rd-party-pii-detectors","title":"Connecting to 3rd party PII detectors","text":"<p>See this documentation for instructions on how to implement an external PII detector for a new or existing type of PII entity.</p>"},{"location":"text_anonymization/","title":"Text anonymization","text":"<p>Presidio's features two main modules for anonymization PII in text:</p> <ul> <li>Presidio analyzer: Identification of PII in text</li> <li>Presidio anonymizer: De-identify detected PII entities using different operators</li> </ul> <p>In most cases, we would run the Presidio analyzer to detect where PII entities exist, and then the Presidio anonymizer to remove those using specific operators (such as redact, replace, hash or encrypt)</p> <p>This figure presents the overall flow in high level:</p> <p></p> <ul> <li>The Presidio Analyzer holds multiple recognizers, each one capable of detecting specific PII entities. These recognizers leverage regular expressions, deny lists, checksum, rule based logic, Named Entity Recognition ML models and context from surrounding words.</li> <li>The Presidio Anonymizer holds multiple operators, each one can be used to anonymize the PII entity in a different way. Additionally, it can be used to de-anonymize an already anonymized entity (For example, decrypt an encrypted entity)</li> </ul>"},{"location":"analyzer/","title":"Presidio Analyzer","text":"<p>The Presidio analyzer is a Python based service for detecting PII entities in text.</p> <p>During analysis, it runs a set of different PII Recognizers, each one in charge of detecting one or more PII entities using different mechanisms.</p> <p>Presidio analyzer comes with a set of predefined recognizers, but can easily be extended with other types of custom recognizers. Predefined and custom recognizers leverage regex, Named Entity Recognition and other types of logic to detect PII in unstructured text.</p> <p></p>"},{"location":"analyzer/#installation","title":"Installation","text":"<p>see Installing Presidio.</p>"},{"location":"analyzer/#getting-started","title":"Getting started","text":"PythonAs an HTTP server <p>Once the Presidio-analyzer package is installed, run this simple analysis script:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\n\n# Set up the engine, loads the NLP module (spaCy model by default) and other PII recognizers\nanalyzer = AnalyzerEngine()\n\n# Call analyzer to get results\nresults = analyzer.analyze(text=\"My phone number is 212-555-5555\",\n                           entities=[\"PHONE_NUMBER\"],\n                           language='en')\nprint(results)\n</code></pre> <p>You can run presidio analyzer as an http server using either python runtime or using a docker container.</p>"},{"location":"analyzer/#using-docker-container","title":"Using docker container","text":"<pre><code>cd presidio-analyzer\ndocker run -p 5002:3000 presidio-analyzer\n</code></pre>"},{"location":"analyzer/#using-python-runtime","title":"Using python runtime","text":"<p>Note</p> <p>This requires the Presidio Github repository to be cloned.</p> <pre><code>cd presidio-analyzer\npython app.py\ncurl -d '{\"text\":\"John Smith drivers license is AC432223\", \"language\":\"en\"}' -H \"Content-Type: application/json\" -X POST http://localhost:3000/analyze\n</code></pre>"},{"location":"analyzer/#creating-pii-recognizers","title":"Creating PII recognizers","text":"<p>Presidio analyzer can be easily extended to support additional PII entities. See this tutorial on adding new PII recognizers for more information.</p>"},{"location":"analyzer/#multi-language-support","title":"Multi-language support","text":"<p>Presidio can be used to detect PII entities in multiple languages. Refer to the multi-language support for more information.</p>"},{"location":"analyzer/#outputting-the-analyzer-decision-process","title":"Outputting the analyzer decision process","text":"<p>Presidio analyzer has a built in mechanism for tracing each decision made. This can be useful when attempting to understand a specific PII detection. For more info, see the decision process documentation.</p>"},{"location":"analyzer/#supported-entities","title":"Supported entities","text":"<p>For a list of the current supported entities: Supported entities.</p>"},{"location":"analyzer/#api-reference","title":"API reference","text":"<p>Follow the API Spec for the Analyzer REST API reference details and Analyzer Python API for Python API reference</p>"},{"location":"analyzer/#samples","title":"Samples","text":"<p>Samples illustrating the usage of the Presidio Analyzer can be found in the Python samples.</p>"},{"location":"analyzer/adding_recognizers/","title":"Supporting detection of new types of PII entities","text":"<p>Presidio can be extended to support detection of new types of PII entities, and to support additional languages. These PII recognizers could be added via code or ad-hoc as part of the request.</p>"},{"location":"analyzer/adding_recognizers/#introduction-to-recognizer-development","title":"Introduction to recognizer development","text":"<p>Entity recognizers are Python objects capable of detecting one or more entities in a specific language. In order to extend Presidio's detection capabilities to new types of PII entities, these <code>EntityRecognizer</code> objects should be added to the existing list of recognizers.</p>"},{"location":"analyzer/adding_recognizers/#types-of-recognizer-classes-in-presidio","title":"Types of recognizer classes in Presidio","text":"<p>The following class diagram shows the different types of recognizer families Presidio contains.</p> <p></p> <ul> <li>The <code>EntityRecognizer</code> is an abstract class for all recognizers.</li> <li>The <code>RemoteRecognizer</code> is an abstract class for calling external PII detectors. See more info here.</li> <li>The abstract class <code>LocalRecognizer</code> is implemented by all recognizers running within the Presidio-analyzer process.</li> <li>The <code>PatternRecognizer</code> is an class for supporting regex and deny-list based recognition logic, including validation (e.g., with checksum) and context support. See an example here.</li> </ul>"},{"location":"analyzer/adding_recognizers/#extending-the-analyzer-for-additional-pii-entities","title":"Extending the analyzer for additional PII entities","text":"<ol> <li>Create a new class based on <code>EntityRecognizer</code>.</li> <li>Add the new recognizer to the recognizer registry so that the <code>AnalyzerEngine</code> can use the new recognizer during analysis.</li> </ol>"},{"location":"analyzer/adding_recognizers/#simple-example","title":"Simple example","text":"<p>For simple recognizers based on regular expressions or deny-lists, we can leverage the provided <code>PatternRecognizer</code>:</p> <pre><code>from presidio_analyzer import PatternRecognizer\ntitles_recognizer = PatternRecognizer(supported_entity=\"TITLE\",\n                                      deny_list=[\"Mr.\",\"Mrs.\",\"Miss\"])\n</code></pre> <p>Calling the recognizer itself:</p> <pre><code>titles_recognizer.analyze(text=\"Mr. Schmidt\", entities=\"TITLE\")\n</code></pre> <p>Adding it to the list of recognizers:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\nregistry = RecognizerRegistry()\nregistry.load_predefined_recognizers()\n\n# Add the recognizer to the existing list of recognizers\nregistry.add_recognizer(titles_recognizer)\n\n# Set up analyzer with our updated recognizer registry\nanalyzer = AnalyzerEngine(registry=registry)\n\n# Run with input text\ntext=\"His name is Mr. Jones\"\nresults = analyzer.analyze(text=text, language=\"en\")\nprint(results)\n</code></pre> <p>Alternatively, we can add the recognizer directly to the existing registry:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\n\nanalyzer = AnalyzerEngine()\n\nanalyzer.registry.add_recognizer(titles_recognizer)\n\nresults = analyzer.analyze(text=text, language=\"en\")\nprint(results)\n</code></pre> <p>For pattern based recognizers, it is possible to change the regex flags, either for one recognizer or for all. For one recognizer, use the <code>global_regex_flags</code> parameter in the <code>PatternRecognizer</code> constructor. For all recognizers, use the <code>global_regex_flags</code> parameter in the <code>RecognizerRegistry</code> constructor:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\nimport regex as re\n\nregistry = RecognizerRegistry(global_regex_flags=re.DOTALL | re.MULTILINE | re.IGNORECASE)\nengine = AnalyzerEngine(registry=registry)\nengine.analyze(...)\n</code></pre>"},{"location":"analyzer/adding_recognizers/#creating-a-new-entityrecognizer-in-code","title":"Creating a new <code>EntityRecognizer</code> in code","text":"<p>To create a new recognizer via code:</p> <ol> <li> <p>Create a new Python class which implements LocalRecognizer. (<code>LocalRecognizer</code> implements the base EntityRecognizer class)</p> <p>This class has the following functions:</p> <p>i. load: load a model / resource to be used during recognition</p> <p> <pre><code>def load(self)\n</code></pre></p> <p>ii. analyze: The main function to be called for getting entities out of the new recognizer:</p> <p> <pre><code>def analyze(self, text, entities, nlp_artifacts)\n</code></pre></p> <p>Notes: 1. Each recognizer has access to different NLP assets such as tokens, lemmas, and more. These are given through the <code>nlp_artifacts</code> parameter. Refer to the source code for more information.</p> <ol> <li>The <code>analyze</code> method should return a list of RecognizerResult.</li> </ol> </li> <li> <p>Add it to the recognizer registry using <code>registry.add_recognizer(my_recognizer)</code>.</p> </li> </ol> <p>For more examples, see the Customizing Presidio Analyzer jupyter notebook.</p>"},{"location":"analyzer/adding_recognizers/#creating-a-remote-recognizer","title":"Creating a remote recognizer","text":"<p>A remote recognizer is an <code>EntityRecognizer</code> object interacting with an external service. The external service could be a 3rd party PII detection service or a custom service deployed in parallel to Presidio.</p> <p>Sample implementation of a <code>RemoteRecognizer</code>. In this example, an external PII detection service exposes two APIs: <code>detect</code> and <code>supported_entities</code>. The class implemented here, <code>ExampleRemoteRecognizer</code>, uses the <code>requests</code> package to call the external service via HTTP.</p> <p>In this code snippet, we simulate the external PII detector by using the Presidio analyzer. In reality, we would adapt this code to fit the external PII detector we have in hand.</p> <p>For an example of integrating a <code>RemoteRecognizer</code> with Presidio-Analyzer, see this example.</p>"},{"location":"analyzer/adding_recognizers/#creating-pre-defined-recognizers","title":"Creating pre-defined recognizers","text":"<p>Once a recognizer is created, it can either be added to the <code>RecognizerRegistry</code> via the <code>add_recognizer</code> method, or it could be added into the list of predefined recognizers. To add a recognizer to the list of pre-defined recognizers:</p> <ol> <li>Clone the repo.</li> <li>Create a file containing the new recognizer Python class.</li> <li>Add the recognizer to the <code>recognizers</code> in the <code>default_recognizers</code> config. Details of recognizer paramers are given Here.</li> <li>Optional: Update documentation (e.g., the supported entities list).</li> </ol>"},{"location":"analyzer/adding_recognizers/#azure-ai-language-recognizer","title":"Azure AI Language recognizer","text":"<p>On how to integrate Presidio with Azure AI Language PII detection service, and a sample for a Text Analytics Remote Recognizer, refer to the Azure Text Analytics Integration document.</p>"},{"location":"analyzer/adding_recognizers/#creating-ad-hoc-recognizers","title":"Creating ad-hoc recognizers","text":"<p>In addition to recognizers in code, it is possible to create ad-hoc recognizers via the Presidio Analyzer API for regex and deny-list based logic. These recognizers, in JSON form, are added to the <code>/analyze</code> request and are only used in the context of this request.</p> <ul> <li> <p>The json structure for a regex ad-hoc recognizer is the following:</p> <pre><code>{\n    \"text\": \"John Smith drivers license is AC432223. Zip code: 10023\",\n    \"language\": \"en\",\n    \"ad_hoc_recognizers\":[\n        {\n        \"name\": \"Zip code Recognizer\",\n        \"supported_language\": \"en\",\n        \"patterns\": [\n            {\n            \"name\": \"zip code (weak)\", \n            \"regex\": \"(\\\\b\\\\d{5}(?:\\\\-\\\\d{4})?\\\\b)\", \n            \"score\": 0.01\n            }\n        ],\n        \"context\": [\"zip\", \"code\"],\n        \"supported_entity\":\"ZIP\"\n        }\n    ]\n}\n</code></pre> </li> <li> <p>The json structure for a deny-list based recognizers is the following:</p> <pre><code>{\n    \"text\": \"Mr. John Smith's drivers license is AC432223\",\n    \"language\": \"en\",\n    \"ad_hoc_recognizers\":[\n        {\n        \"name\": \"Mr. Recognizer\",\n        \"supported_language\": \"en\",\n        \"deny_list\": [\"Mr\", \"Mr.\", \"Mister\"],\n        \"supported_entity\":\"MR_TITLE\"\n        },\n        {\n        \"name\": \"Ms. Recognizer\",\n        \"supported_language\": \"en\",\n        \"deny_list\": [\"Ms\", \"Ms.\", \"Miss\", \"Mrs\", \"Mrs.\"],\n        \"supported_entity\":\"MS_TITLE\"\n        }\n    ]\n}\n</code></pre> </li> </ul> <p>In both examples, the <code>/analyze</code> request is extended with a list of <code>ad_hoc_recognizers</code>, which could be either <code>patterns</code>, <code>deny_list</code> or both.</p> <p>Additional examples can be found in the OpenAPI spec.</p>"},{"location":"analyzer/adding_recognizers/#reading-pattern-recognizers-from-yaml","title":"Reading pattern recognizers from YAML","text":"<p>Recognizers can be loaded from a YAML file, which allows users to add recognition logic without writing code. An example YAML file can be found here.</p> <p>Once the YAML file is created, it can be loaded into the <code>RecognizerRegistry</code> instance.</p> <p>This example creates a <code>RecognizerRegistry</code> holding only the recognizers in the YAML file:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\nyaml_file = \"recognizers.yaml\"\nregistry = RecognizerRegistry()\nregistry.add_recognizers_from_yaml(yaml_file)\n\nanalyzer = AnalyzerEngine(registry=registry)\nanalyzer.analyze(text=\"Mr. and Mrs. Smith\", language=\"en\")\n</code></pre> <p>This example adds the new recognizers to the predefined recognizers in Presidio:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\nyaml_file = \"recognizers.yaml\"\nregistry = RecognizerRegistry()\nregistry.load_predefined_recognizers()\n\nregistry.add_recognizers_from_yaml(yaml_file)\n\nanalyzer = AnalyzerEngine()\nanalyzer.analyze(text=\"Mr. and Mrs. Smith\", language=\"en\")\n</code></pre> <p>Further reading:</p> <ol> <li>PII detection in different languages.</li> <li>Customizing the NLP model.</li> <li>Best practices for developing PII recognizers.</li> <li>Code samples for customizing Presidio Analyzer with new recognizers.</li> </ol>"},{"location":"analyzer/analyzer_engine_provider/","title":"Configuring the Analyzer Engine from file","text":"<p>Presidio uses <code>AnalyzerEngineProvider</code> to load <code>AnalyzerEngine</code> configuration from file.  Configuration can be loaded in three different ways:</p>"},{"location":"analyzer/analyzer_engine_provider/#using-a-single-file","title":"Using a single file","text":"<p>Create an <code>AnalyzerEngineProvider</code> using a single configuration file and set its path to <code>analyzer_engine_conf_file</code>, then create <code>AnalyzerEngine</code> based on it:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, AnalyzerEngineProvider\n\nanalyzer_conf_file = \"./analyzer/analyzer-config-all.yml\"\n\nprovider = AnalyzerEngineProvider(\n    analyzer_engine_conf_file=analyzer_conf_file\n    )\nanalyzer = provider.create_engine()\n\nresults = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\nprint(results)\n</code></pre> <p>An example configuration file:</p> <pre><code>supported_languages: \n- en\ndefault_score_threshold: 0\n\nnlp_configuration:\n  nlp_engine_name: spacy\n  models:\n  -\n    lang_code: en\n    model_name: en_core_web_lg\n  -\n    lang_code: es\n    model_name: es_core_news_md\n  ner_model_configuration:\n    model_to_presidio_entity_mapping:\n      PER: PERSON\n      PERSON: PERSON\n      LOC: LOCATION\n      LOCATION: LOCATION\n      GPE: LOCATION\n      ORG: ORGANIZATION\n      DATE: DATE_TIME\n      TIME: DATE_TIME\n      NORP: NRP\n\n    low_confidence_score_multiplier: 0.4\n    low_score_entity_names:\n    - ORGANIZATION\n    - ORG\n    default_score: 0.85\n\nrecognizer_registry:\n  global_regex_flags: 26\n  recognizers: \n  - name: CreditCardRecognizer\n    supported_languages: \n      - en\n    supported_entity: IT_FISCAL_CODE\n    type: predefined\n\n  - name: ItFiscalCodeRecognizer\n    type: predefined\n</code></pre> <p>The configuration file contains the following parameters:</p> <ul> <li><code>supported_languages</code>: A list of supported languages that the analyzer will support.</li> <li><code>default_score_threshold</code>: A score that determines the minimal threshold for detection.</li> <li><code>nlp_configuration</code>: Configuration given to the NLP engine which will detect the PIIs and extract features for the downstream logic.</li> <li><code>recognizer_registry</code>: All the recognizers that will be used by the analyzer. </li> </ul> <p>Note</p> <p><code>supported_languages</code> must be identical to the same field in recognizer_registry</p>"},{"location":"analyzer/analyzer_engine_provider/#using-multiple-files","title":"Using multiple files","text":"<p>Create an <code>AnalyzerEngineProvider</code> using three different configuration files for each of the following components:</p> <ul> <li>Analyzer</li> <li>NLP Engine</li> <li>Recognizer Registry</li> </ul> <p>Note</p> <p>Each of these parameters is optional and in case it's not set, the default configuration will be used. </p> <pre><code>from presidio_analyzer import AnalyzerEngine, AnalyzerEngineProvider\n\nanalyzer_conf_file = \"./analyzer/analyzer-config.yml\"\nnlp_engine_conf_file = \"./analyzer/nlp-config.yml\"\nrecognizer_registry_conf_file = \"./analyzer/recognizers-config.yml\"\n\nprovider = AnalyzerEngineProvider(\n    analyzer_engine_conf_file=analyzer_conf_file,\n    nlp_engine_conf_file=nlp_engine_conf_file,\n    recognizer_registry_conf_file=recognizer_registry_conf_file,\n    )\nanalyzer = provider.create_engine()\n\nresults = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\nprint(results)\n</code></pre> <p>The structure of the configuration files is as follows:</p> <ul> <li> <p>Analyzer engine configuration file:</p> <pre><code>supported_languages: \n- en\ndefault_score_threshold: 0\n</code></pre> </li> <li> <p>NLP engine configuration file structure is examined thoroughly in the Customizing the NLP model section.</p> </li> <li> <p>Recognizer registry configuration file structure is examined thoroughly in the Customizing recognizer registry from file section.</p> </li> </ul>"},{"location":"analyzer/analyzer_engine_provider/#using-the-default-configuration","title":"Using the default configuration","text":"<p>Create an <code>AnalyzerEngineProvider</code> without any parameters. This will load the default configuration:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, AnalyzerEngineProvider\n\nprovider = AnalyzerEngineProvider().create_engine()\n\nresults = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\nprint(results)\n</code></pre> <p>The default configuration of <code>AnalyzerEngine</code> is defined in the following files: </p> <ul> <li>Analyzer Engine</li> <li>NLP Engine</li> <li>Recognizer Registry</li> </ul>"},{"location":"analyzer/customizing_nlp_models/","title":"Customizing the NLP engine in Presidio Analyzer","text":"<p>Presidio uses NLP engines for two main tasks: NER based PII identification, and feature extraction for downstream rule based logic (such as leveraging context words for improved detection). While Presidio comes with an open-source model (the <code>en_core_web_lg</code> model from spaCy), additional NLP models and frameworks could be plugged in, either public or proprietary. These models can be trained or downloaded from existing NLP frameworks like spaCy, Stanza and transformers.</p> <p>In addition, other types of NLP frameworks can be integrated into Presidio.</p>"},{"location":"analyzer/customizing_nlp_models/#setting-up-a-custom-nlp-model","title":"Setting up a custom NLP model","text":"<ul> <li>spaCy or stanza</li> <li>transformers</li> </ul>"},{"location":"analyzer/customizing_nlp_models/#configure-presidio-to-use-the-new-model","title":"Configure Presidio to use the new model","text":"<p>Configuration can be done in two ways:</p> <ul> <li> <p>Via code: Create an <code>NlpEngine</code> using the <code>NlpEnginerProvider</code> class, and pass it to the <code>AnalyzerEngine</code> as input:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\nfrom presidio_analyzer.nlp_engine import NlpEngineProvider\n\n# Create configuration containing engine name and models\nconfiguration = {\n    \"nlp_engine_name\": \"spacy\",\n    \"models\": [{\"lang_code\": \"es\", \"model_name\": \"es_core_news_md\"},\n                {\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"}],\n}\n\n# Create NLP engine based on configuration\nprovider = NlpEngineProvider(nlp_configuration=configuration)\nnlp_engine_with_spanish = provider.create_engine()\n\n# Pass the created NLP engine and supported_languages to the AnalyzerEngine\nanalyzer = AnalyzerEngine(\n    nlp_engine=nlp_engine_with_spanish, \n    supported_languages=[\"en\", \"es\"]\n)\n\n# Analyze in different languages\nresults_spanish = analyzer.analyze(text=\"Mi nombre es Morris\", language=\"es\")\nprint(results_spanish)\n\nresults_english = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\nprint(results_english)\n</code></pre> </li> <li> <p>Via configuration: Set up the models which should be used in the default <code>conf</code> file.</p> <p>An example Conf file:</p> <pre><code>nlp_engine_name: spacy\nmodels:\n    -\n    lang_code: en\n    model_name: en_core_web_lg\n    -\n    lang_code: es\n    model_name: es_core_news_md \nner_model_configuration:\nlabels_to_ignore:\n- O\nmodel_to_presidio_entity_mapping:\n    PER: PERSON\n    LOC: LOCATION\n    ORG: ORGANIZATION\n    AGE: AGE\n    ID: ID\n    DATE: DATE_TIME\nlow_confidence_score_multiplier: 0.4\nlow_score_entity_names:\n- ID\n- ORG\n</code></pre> <p>The <code>ner_model_configuration</code> section contains the following parameters:</p> </li> <li> <p><code>labels_to_ignore</code>: A list of labels to ignore. For example, <code>O</code> (no entity) or entities you are not interested in returning.</p> </li> <li><code>model_to_presidio_entity_mapping</code>: A mapping between the transformers model labels and the Presidio entity types.</li> <li><code>low_confidence_score_multiplier</code>: A multiplier to apply to the score of entities with low confidence.</li> <li> <p><code>low_score_entity_names</code>: A list of entity types to apply the low confidence score multiplier to.</p> <p>The default conf file is read during the default initialization of the <code>AnalyzerEngine</code>. Alternatively, the path to a custom configuration file can be passed to the <code>NlpEngineProvider</code>:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\nfrom presidio_analyzer.nlp_engine import NlpEngineProvider\n\nLANGUAGES_CONFIG_FILE = \"./docs/analyzer/languages-config.yml\"\n\n# Create NLP engine based on configuration file\nprovider = NlpEngineProvider(conf_file=LANGUAGES_CONFIG_FILE)\nnlp_engine_with_spanish = provider.create_engine()\n\n# Pass created NLP engine and supported_languages to the AnalyzerEngine\nanalyzer = AnalyzerEngine(\n    nlp_engine=nlp_engine_with_spanish, \n    supported_languages=[\"en\", \"es\"]\n)\n\n# Analyze in different languages\nresults_spanish = analyzer.analyze(text=\"Mi nombre es David\", language=\"es\")\nprint(results_spanish)\n\nresults_english = analyzer.analyze(text=\"My name is David\", language=\"en\")\nprint(results_english)\n</code></pre> <p>In this examples we:     a. create an <code>NlpEngine</code> holding two spaCy models (one in English: <code>en_core_web_lg</code> and one in Spanish: <code>es_core_news_md</code>).     b. define the <code>supported_languages</code> parameter accordingly.     c. pass requests in each of these languages.</p> <p>Note</p> <p>Presidio can currently use one NER model per language via the <code>NlpEngine</code>. If multiple are required, consider wrapping NER models as additional recognizers (see sample here).</p> </li> </ul>"},{"location":"analyzer/customizing_nlp_models/#leverage-frameworks-other-than-spacy-stanza-and-transformers-for-ml-based-pii-detection","title":"Leverage frameworks other than spaCy, Stanza and transformers for ML based PII detection","text":"<p>In addition to the built-in spaCy/Stanza/transformers capabitilies, it is possible to create new recognizers which serve as interfaces to other models. For more information:</p> <ul> <li>Remote recognizer documentation and samples.</li> <li>Flair recognizer example</li> </ul> <p>For considerations for creating such recognizers, see the best practices for adding ML recognizers documentation.</p>"},{"location":"analyzer/decision_process/","title":"The Presidio-analyzer decision process","text":""},{"location":"analyzer/decision_process/#background","title":"Background","text":"<p>Presidio-analyzer's decision process exposes information on why a specific PII was detected. Such information could contain:</p> <ul> <li>Which recognizer detected the entity</li> <li>Which regex pattern was used</li> <li>Interpretability mechanisms in ML models</li> <li>Which context words improved the score</li> <li>Confidence scores before and after each step</li> </ul> <p>And more.</p>"},{"location":"analyzer/decision_process/#usage","title":"Usage","text":"<p>The decision process can be leveraged in two ways:</p> <ol> <li>Presidio-analyzer can log its decision process into a designated logger, which allows you to investigate a specific api request, by exposing a <code>correlation-id</code> as part of the api response headers.</li> <li>The decision process can be returned as part of the <code>/analyze</code>  response.</li> </ol>"},{"location":"analyzer/decision_process/#getting-the-decision-process-as-part-of-the-response","title":"Getting the decision process as part of the response","text":"<p>The decision process result can be added to the response. To enable it, call the <code>analyze</code> method with <code>return_decision_process</code> set as True.</p> <p>For example:</p> HTTPPython <pre><code>curl -d '{\n    \"text\": \"John Smith drivers license is AC432223\", \n    \"language\": \"en\", \n    \"return_decision_process\": true}' -H \"Content-Type: application/json\" -X POST http://localhost:3000/analyze\n</code></pre> <pre><code>from presidio_analyzer import AnalyzerEngine\n\n# Set up the engine, loads the NLP module (spaCy model by default)\n# and other PII recognizers\nanalyzer = AnalyzerEngine()\n\n# Call analyzer to get results\nresults = analyzer.analyze(text='My phone number is 212-555-5555', \n                        entities=['PHONE_NUMBER'], \n                        language='en', \n                        return_decision_process=True)\n\n# Get the decision process results for the first result\nprint(results[0].analysis_explanation)\n</code></pre>"},{"location":"analyzer/decision_process/#logging-the-decision-process","title":"Logging the decision process","text":"<p>Logging of the decision process is turned off by default. To turn it on, create the <code>AnalyzerEngine</code> object with <code>log_decision_process=True</code>.</p> <p>For example:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\n\n# Set up the engine, loads the NLP module (spaCy model by default)\n# and other PII recognizers\nanalyzer = AnalyzerEngine(log_decision_process=True)\n\n# Call analyzer to get results\nresults = analyzer.analyze(text='My phone number is 212-555-5555', \n                           entities=['PHONE_NUMBER'], \n                           language='en', \n                           correlation_id=\"xyz\")\n</code></pre> <p>The decision process logs will be written to standard output. Note that it is possible to define a <code>correlation-id</code> which is the trace identification. It will help you to query the stdout logs. The id can be retrieved from each API response header: <code>x-correlation-id</code>.</p> <p>By having the traces written into the <code>stdout</code> it's very easy to configure a monitoring solution to ease the process of reading processing the tracing logs in a distributed system.</p>"},{"location":"analyzer/decision_process/#examples","title":"Examples","text":"<p>For the a request with the following text:</p> <pre><code>My name is Bart Simpson, my Credit card is: 4095-2609-9393-4932,  my phone is 425 8829090 \n</code></pre> <p>The following traces will be written to log, with this format:</p> <p><code>[Date Time][decision_process][Log Level][Unique Correlation ID][Trace Message]</code></p> <pre><code>[2019-07-14 14:22:32,409][decision_process][INFO][00000000-0000-0000-0000-000000000000][nlp artifacts:{'entities': (Bart Simpson, 4095, 425), 'tokens': ['My', 'name', 'is', 'Bart', 'Simpson', ',', 'my', 'Credit', 'card', 'is', ':', '4095', '-', '2609', '-', '9393', '-', '4932', ',', ' ', 'my', 'phone', 'is', '425', '8829090'], 'lemmas': ['My', 'name', 'be', 'Bart', 'Simpson', ',', 'my', 'Credit', 'card', 'be', ':', '4095', '-', '2609', '-', '9393', '-', '4932', ',', ' ', 'my', 'phone', 'be', '425', '8829090'], 'tokens_indices': [0, 3, 8, 11, 16, 23, 25, 28, 35, 40, 42, 44, 48, 49, 53, 54, 58, 59, 63, 65, 66, 69, 75, 78, 82], 'keywords': ['bart', 'simpson', 'credit', 'card', '4095', '2609', '9393', '4932', ' ', 'phone', '425', '8829090']}]\n\n[2019-07-14 14:22:32,417][decision_process][INFO][00000000-0000-0000-0000-000000000000][[\"{'entity_type': 'CREDIT_CARD', 'start': 44, 'end': 63, 'score': 1.0, 'analysis_explanation': {'recognizer': 'CreditCardRecognizer', 'pattern_name': 'All Credit Cards (weak)', 'pattern': '\\\\\\\\b((4\\\\\\\\d{3})|(5[0-5]\\\\\\\\d{2})|(6\\\\\\\\d{3})|(1\\\\\\\\d{3})|(3\\\\\\\\d{3}))[- ]?(\\\\\\\\d{3,4})[- ]?(\\\\\\\\d{3,4})[- ]?(\\\\\\\\d{3,5})\\\\\\\\b', 'original_score': 0.3, 'score': 1.0, 'textual_explanation': None, 'score_context_improvement': 0.7, 'supportive_context_word': 'credit', 'validation_result': True}}\", \"{'entity_type': 'PERSON', 'start': 11, 'end': 23, 'score': 0.85, 'analysis_explanation': {'recognizer': 'SpacyRecognizer', 'pattern_name': None, 'pattern': None, 'original_score': 0.85, 'score': 0.85, 'textual_explanation': \\\"Identified as PERSON by Spacy's Named Entity Recognition\\\", 'score_context_improvement': 0, 'supportive_context_word': '', 'validation_result': None}}\", \"{'entity_type': 'PHONE_NUMBER', 'start': 78, 'end': 89, 'score': 0.85, 'analysis_explanation': {'recognizer': 'UsPhoneRecognizer', 'pattern_name': 'Phone (medium)', 'pattern': '\\\\\\\\b(\\\\\\\\d{3}[-\\\\\\\\.\\\\\\\\s]\\\\\\\\d{3}[-\\\\\\\\.\\\\\\\\s]??\\\\\\\\d{4})\\\\\\\\b', 'original_score': 0.5, 'score': 0.85, 'textual_explanation': None, 'score_context_improvement': 0.35, 'supportive_context_word': 'phone', 'validation_result': None}}\"]]\n</code></pre>"},{"location":"analyzer/decision_process/#writing-custom-decision-process-for-a-recognizer","title":"Writing custom decision process for a recognizer","text":"<p>When creating new PII recognizers, it is possible to add information about the recognizer's decision process. This information will be traced or returned to the user, depending on the configuration.</p> <p>For example, the spacy_recognizer.py implements a custom trace as follows:</p> <pre><code>SPACY_DEFAULT_EXPLANATION = \"Identified as {} by Spacy's Named Entity Recognition\"\n\ndef build_spacy_explanation(recognizer_name, original_score, entity):\n    explanation = AnalysisExplanation(\n        recognizer=recognizer_name,\n        original_score=original_score,\n        textual_explanation=SPACY_DEFAULT_EXPLANATION.format(entity))\n    return explanation\n</code></pre> <p>The <code>textual_explanation</code> field in <code>AnalysisExplanation</code> class allows you to add your own custom text into the final trace which will be written.</p> <p>Note</p> <p>These traces leverage the Python <code>logging</code> mechanisms. In the default configuration, A <code>StreamHandler</code> is used to write these logs to <code>sys.stdout</code>.</p> <p>Warning</p> <p>Decision-process traces explain why PIIs were detected, but not why they were not detected!</p>"},{"location":"analyzer/developing_recognizers/","title":"Recognizers Development - Best Practices and Considerations","text":"<p>Recognizers are the main building blocks in Presidio. Each recognizer is in charge of detecting one or more entities in one or more languages. Recognizers define the logic for detection, as well as the confidence a prediction receives and a list of words to be used when context is leveraged.</p>"},{"location":"analyzer/developing_recognizers/#implementation-considerations","title":"Implementation Considerations","text":""},{"location":"analyzer/developing_recognizers/#accuracy","title":"Accuracy","text":"<p>Each recognizer, regardless of its complexity, could have false positives and false negatives. When adding new recognizers, we try to balance the effect of each recognizer on the entire system.  A recognizer with many false positives would affect the system's usability, while a recognizer with many false negatives might require more work before it can be integrated. For reproducibility purposes, it is be best to note how the recognizer's accuracy was tested, and on which datasets. For tools and documentation on evaluating and analyzing recognizers, refer to the presidio-research Github repository.</p> <p>Note</p> <p>When contributing recognizers to the Presidio OSS, new predefined recognizers should be added to the supported entities list, and follow the contribution guidelines.</p>"},{"location":"analyzer/developing_recognizers/#performance","title":"Performance","text":"<p>Make sure your recognizer doesn't take too long to process text. Anything above 100ms per request with 100 tokens is probably not good enough.</p>"},{"location":"analyzer/developing_recognizers/#environment","title":"Environment","text":"<p>When adding new recognizers that have 3rd party dependencies, make sure that the new dependencies don't interfere with Presidio's dependencies.  In the case of a conflict, one can create an isolated model environment (outside the main presidio-analyzer process) and implement a <code>RemoteRecognizer</code> on the presidio-analyzer side to interact with the model's endpoint.</p>"},{"location":"analyzer/developing_recognizers/#recognizer-types","title":"Recognizer Types","text":"<p>Generally speaking, there are three types of recognizers:</p>"},{"location":"analyzer/developing_recognizers/#deny-lists","title":"Deny Lists","text":"<p>A deny list is a list of words that should be removed during text analysis. For example, it can include a list of titles (<code>[\"Mr.\", \"Mrs.\", \"Ms.\", \"Dr.\"]</code> to detect a \"Title\" entity.)</p> <p>See this documentation on adding a new recognizer. The <code>PatternRecognizer</code> class has built-in support for a deny-list input.</p>"},{"location":"analyzer/developing_recognizers/#pattern-based","title":"Pattern Based","text":"<p>Pattern based recognizers use regular expressions to identify entities in text. See this documentation on adding a new recognizer via code. The <code>PatternRecognizer</code> class should be extended. See some examples here:</p> <p>Examples</p> <p>Examples of pattern based recognizers are the <code>CreditCardRecognizer</code> and <code>EmailRecognizer</code>.</p>"},{"location":"analyzer/developing_recognizers/#machine-learning-ml-based-or-rule-based","title":"Machine Learning (ML) Based or Rule-Based","text":"<p>Many PII entities are undetectable using naive approaches like deny-lists or regular expressions. In these cases, we would wish to utilize a Machine Learning model capable of identifying entities in free text, or a rule-based recognizer.</p>"},{"location":"analyzer/developing_recognizers/#ml-utilize-spacy-stanza-or-transformers","title":"ML: Utilize SpaCy, Stanza or Transformers","text":"<p>Presidio currently uses spaCy as a framework for text analysis and Named Entity Recognition (NER), and stanza and huggingface transformers as an alternative. To avoid introducing new tools, it is recommended to first try to use <code>spaCy</code>, <code>stanza</code> or <code>transformers</code> over other tools if possible. <code>spaCy</code> provides descent results compared to state-of-the-art NER models, but with much better computational performance. <code>spaCy</code>, <code>stanza</code> and <code>transformers</code> models could be trained from scratch, used in combination with pre-trained embeddings, or be fine-tuned.</p> <p>In addition to those, it is also possible to use other ML models. In that case, a new <code>EntityRecognizer</code> should be created.  See an example using Flair here.</p>"},{"location":"analyzer/developing_recognizers/#apply-custom-logic","title":"Apply Custom Logic","text":"<p>In some cases, rule-based logic provides reasonable ways for detecting entities. The Presidio <code>EntityRecognizer</code> API allows you to use <code>spaCy</code> extracted features like lemmas, part of speech, dependencies and more to create your logic.  When integrating such logic into Presidio, a class inheriting from the <code>EntityRecognizer</code> should be created.</p> <p>Considerations for selecting one option over another</p> <ul> <li>Accuracy.</li> <li>Ease of integration.</li> <li>Runtime considerations (For example if the new model requires a GPU).</li> <li>3rd party dependencies of the new model vs. the existing <code>presidio-analyzer</code> package.</li> </ul>"},{"location":"analyzer/languages/","title":"PII detection in different languages","text":"<p>Presidio supports PII detection in multiple languages. In its default configuration, it contains recognizers and models for English.</p> <p>To extend Presidio to detect PII in an additional language, these modules require modification:</p> <ol> <li>The <code>NlpEngine</code> containing the NLP model which performs tokenization, lemmatization, Named Entity Recognition and other NLP tasks.</li> <li>PII recognizers (different <code>EntityRecognizer</code> objects) should be adapted or created.</li> </ol> <p>Note</p> <p>While different detection mechanisms such as regular expressions are language agnostic, the context words used to increase the PII detection confidence aren't. Consider updating the list of context words for each recognizer to leverage context words in additional languages.</p>"},{"location":"analyzer/languages/#table-of-contents","title":"Table of contents","text":"<ul> <li>Configuring the NLP Engine</li> <li>Set up language specific recognizers</li> <li>Automatically install NLP models into the Docker container</li> </ul>"},{"location":"analyzer/languages/#configuring-the-nlp-engine","title":"Configuring the NLP Engine","text":"<p>Presidio's NLP engine can be adapted to support multiple languages and frameworks (such as spaCy, Stanza and transformers). Configuring the NLP engine for a new language or NLP framework is done by downloading or using a model trained on a different language, and providing a configuration. See the NLP model customization documentation for details on how to configure models for new languages.</p>"},{"location":"analyzer/languages/#set-up-language-specific-recognizers","title":"Set up language specific recognizers","text":"<p>Recognizers are language dependent either by their logic or by the context words used while scanning the surrounding of a detected entity. As these context words are used to increase score, they should be in the expected input language.</p> <p>Consider updating the context words of existing recognizers or add new recognizers to support new languages. Each recognizer can support one language. For example:</p> <p><pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\nfrom presidio_analyzer.predefined_recognizers import EmailRecognizer\nfrom presidio_analyzer.nlp_engine import NlpEngineProvider\n\nLANGUAGES_CONFIG_FILE = \"./docs/analyzer/languages-config.yml\"\n\n# Create NLP engine based on configuration file\nprovider = NlpEngineProvider(conf_file=LANGUAGES_CONFIG_FILE)\nnlp_engine_with_spanish = provider.create_engine()\n\n# Setting up an English Email recognizer:\nemail_recognizer_en = EmailRecognizer(supported_language=\"en\", context=[\"email\", \"mail\"])\n\n# Setting up a Spanish Email recognizer\nemail_recognizer_es = EmailRecognizer(supported_language=\"es\", context=[\"correo\", \"electr\u00f3nico\"])\n\nregistry = RecognizerRegistry()\n\n# Add recognizers to registry\nregistry.add_recognizer(email_recognizer_en)\nregistry.add_recognizer(email_recognizer_es)\n\n# Set up analyzer with our updated recognizer registry\nanalyzer = AnalyzerEngine(\n    registry=registry,\n    supported_languages=[\"en\",\"es\"],\n    nlp_engine=nlp_engine_with_spanish)\n\nanalyzer.analyze(text=\"My name is David\", language=\"en\")\n</code></pre> Link to LANGUAGES_CONFIG_FILE=languages-config.yml</p>"},{"location":"analyzer/languages/#automatically-install-nlp-models-into-the-docker-container","title":"Automatically install NLP models into the Docker container","text":"<p>When packaging the code into a Docker container, NLP models are automatically installed. To define which models should be installed, update the conf/default.yaml file. This file is read during the <code>docker build</code> phase and the models defined in it are installed automatically.</p> <p>For <code>transformers</code> based models, the configuration can be found here.  A docker file supporting transformers models can be found here.</p>"},{"location":"analyzer/recognizer_registry_provider/","title":"Customizing recognizer registry from file","text":"<p>To load recognizers from file, use <code>RecognizerRegistryProvider</code> to instantiate the recognizer registry and then pass it through to the analyzer engine:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\nfrom presidio_analyzer.recognizer_registry import RecognizerRegistryProvider\n\nrecognizer_registry_conf_file = \"./analyzer/recognizers-config.yml\"\n\nprovider = RecognizerRegistryProvider(\n                conf_file=recognizer_registry_conf_file\n            )\nregistry = provider.create_recognizer_registry()\nanalyzer = AnalyzerEngine(registry=registry)\n\nresults = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\nprint(results)\n</code></pre>"},{"location":"analyzer/recognizer_registry_provider/#configuration-file-structure","title":"Configuration file structure","text":"<pre><code>global_regex_flags: 26\n\nsupported_languages: \n  - en\n\nrecognizers: \n...\n</code></pre> <p>The configuration file consists of two parts:</p> <ul> <li><code>global_regex_flags</code>: regex flags to be used in regex matching (see regex flags).</li> <li><code>supported_languages</code>: A list of supported languages that the registry will support.</li> <li><code>recognizers</code>: a list of recognizers to be loaded by the recognizer registry. This list consists of two different types of recognizers: <ul> <li>Predefined: A set of already defined recognizer classes in presidio. This includes all recognizers defined in the codebase (along with user defined recognizers) that inherit from EntityRecognizer.</li> <li>Custom: custom created pattern recognizers that are created based on the fields provided in the configuration file.</li> </ul> </li> </ul> <p>Note</p> <p>supported_languages must be identical to the same field in analyzer_engine</p>"},{"location":"analyzer/recognizer_registry_provider/#recognizer-list","title":"Recognizer list","text":"<p>The recognizer list comprises of both the predefined and custom recognizers, for example: </p> <pre><code>...\n  - name: CreditCardRecognizer\n    supported_languages:\n    - language: en\n      context: [credit, card, visa, mastercard, cc, amex, discover, jcb, diners, maestro, instapayment]\n    - language: es\n      context: [tarjeta, credito, visa, mastercard, cc, amex, discover, jcb, diners, maestro, instapayment]\n    - language: it\n    - language: pl\n    type: predefined\n\n  - name: UsBankRecognizer\n    supported_languages: \n    - en\n    type: predefined\n\n  - name: MedicalLicenseRecognizer\n    type: predefined\n\n  - name: ExampleCustomRecognizer\n    patterns:\n    - name: \"zip code (weak)\"\n      regex: \"(\\\\b\\\\d{5}(?:\\\\-\\\\d{4})?\\\\b)\"\n      score: 0.01\n    - name: \"zip code (weak)\"\n      regex: \"(\\\\b\\\\d{5}(?:\\\\-\\\\d{4})?\\\\b)\"\n      score: 0.01\n    supported_languages:\n    - language: en\n      context: [zip, code]\n    - language: es\n      context: [c\u00f3digo, postal]\n    supported_entity: \"ZIP\"\n    type: custom\n    enabled: true\n\n  - name: \"TitlesRecognizer\"\n    supported_language: \"en\"\n    supported_entity: \"TITLE\"\n    deny_list: [Mr., Mrs., Ms., Miss, Dr., Prof.]\n    deny_list_score: 1\n</code></pre>"},{"location":"analyzer/recognizer_registry_provider/#the-recognizer-parameters","title":"The recognizer parameters","text":"<ul> <li><code>supported_languages</code>: A list of supported languages that the analyzer will support. In case this field is missing, a recognizer will be created for each supported language provided to the <code>AnalyzerEngine</code>.    In addition to the language code, this field also contains a list of context words, which increases confidence in the detection in case it is found in the surroundings of a detected entity (as seen in the credit card example above).</li> <li><code>type</code>: this could be either predefined or custom. As this is optional, if not stated otherwise, the default type is custom.</li> <li><code>name</code>: Different per the type of the recognizer. For predefined recognizers, this is the class name as defined in presidio, while for custom recognizers, it will be set as the name of the recognizer.</li> <li><code>patterns</code>: a list of objects of type <code>Pattern</code> that contains a name, score and regex that define matching patterns.</li> <li><code>enabled</code>: enables or disables the recognizer.</li> <li><code>supported_entity</code>: the detected entity associated by the recognizer.</li> <li><code>deny_list</code>: A list of words to detect, in case the recognizer uses a predefined list of words.</li> <li><code>deny_list_score</code>: confidence score for a term identified using a deny-list.</li> </ul>"},{"location":"analyzer/nlp_engines/spacy_stanza/","title":"spaCy/Stanza NLP engine","text":"<p>Presidio can be loaded with pre-trained or custom models coming from spaCy or Stanza.</p>"},{"location":"analyzer/nlp_engines/spacy_stanza/#using-a-public-pre-trained-spacystanza-model","title":"Using a public pre-trained spaCy/Stanza model","text":""},{"location":"analyzer/nlp_engines/spacy_stanza/#download-the-pre-trained-model","title":"Download the pre-trained model","text":"<p>To replace the default model with a different public model, first download the desired spaCy/Stanza NER models.</p> <ul> <li> <p>To download a new model with spaCy:</p> <pre><code>python -m spacy download es_core_news_md\n</code></pre> <p>In this example we download the medium size model for Spanish.</p> </li> <li> <p>To download a new model with Stanza:</p> <p> <pre><code>import stanza\nstanza.download(\"en\") # where en is the language code of the model.\n</code></pre></p> </li> </ul> <p>For the available models, follow these links: spaCy, stanza.</p> <p>Tip</p> <p>For Person, Location and Organization detection, it could be useful to try out the transformers based models (e.g. <code>en_core_web_trf</code>) which uses a more modern deep-learning architecture, but is generally slower than the default <code>en_core_web_lg</code> model.</p>"},{"location":"analyzer/nlp_engines/spacy_stanza/#configure-presidio-to-use-the-pre-trained-model","title":"Configure Presidio to use the pre-trained model","text":"<p>Once created, see the NLP configuration documentation for more information.</p>"},{"location":"analyzer/nlp_engines/spacy_stanza/#how-ner-results-flow-within-presidio","title":"How NER results flow within Presidio","text":"<p>This diagram describes the flow of NER results within Presidio, and the relationship between the <code>SpacyNlpEngine</code> component and the <code>SpacyRecognizer</code> component: <pre><code>sequenceDiagram\n    AnalyzerEngine-&gt;&gt;SpacyNlpEngine: Call engine.process_text(text) &lt;br&gt;to get model results\n    SpacyNlpEngine-&gt;&gt;spaCy: Call spaCy pipeline\n    spaCy-&gt;&gt;SpacyNlpEngine: return entities and other attributes\n    Note over SpacyNlpEngine: Map entity names to Presidio's, &lt;BR&gt;update scores, &lt;BR&gt;remove unwanted entities &lt;BR&gt; based on NerModelConfiguration\n    SpacyNlpEngine-&gt;&gt;AnalyzerEngine: Pass NlpArtifacts&lt;BR&gt;(Entities, lemmas, tokens, scores etc.)\n    Note over AnalyzerEngine: Call all recognizers\n    AnalyzerEngine-&gt;&gt;SpacyRecognizer: Pass NlpArtifacts\n    Note over SpacyRecognizer: Extract PII entities out of NlpArtifacts\n    SpacyRecognizer-&gt;&gt;AnalyzerEngine: Return List[RecognizerResult]\n</code></pre></p>"},{"location":"analyzer/nlp_engines/spacy_stanza/#training-your-own-model","title":"Training your own model","text":"<p>Note</p> <p>A labeled dataset containing text and labeled PII entities is required for training a new model.</p> <p>For more information on model training and evaluation for Presidio, see the Presidio-Research Github repository.</p> <p>To train your own model, see these links on spaCy and Stanza:</p> <ul> <li>Train your own spaCy model.</li> <li>Train your own Stanza model.</li> </ul> <p>Once models are trained, they should be installed locally in the same environment as Presidio Analyzer.</p>"},{"location":"analyzer/nlp_engines/spacy_stanza/#using-a-previously-loaded-spacy-pipeline","title":"Using a previously loaded spaCy pipeline","text":"<p>If the app is already loading an existing spaCy NLP pipeline, it can be re-used to prevent presidio from loading it again by extending the relevant engine.</p> <pre><code>from presidio_analyzer import AnalyzerEngine\nfrom presidio_analyzer.nlp_engine import SpacyNlpEngine\nimport spacy\n\n# Create a class inheriting from SpacyNlpEngine\nclass LoadedSpacyNlpEngine(SpacyNlpEngine):\n    def __init__(self, loaded_spacy_model):\n        super().__init__()\n        self.nlp = {\"en\": loaded_spacy_model}\n\n# Load a model a-priori\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Pass the loaded model to the new LoadedSpacyNlpEngine\nloaded_nlp_engine = LoadedSpacyNlpEngine(loaded_spacy_model = nlp)\n\n# Pass the engine to the analyzer\nanalyzer = AnalyzerEngine(nlp_engine = loaded_nlp_engine)\n\n# Analyze text\nanalyzer.analyze(text=\"My name is Bob\", language=\"en\")\n</code></pre>"},{"location":"analyzer/nlp_engines/transformers/","title":"Transformers based Named Entity Recognition models","text":"<p>Presidio's <code>TransformersNlpEngine</code> consists of a spaCy pipeline which encapsulates a Huggingface Transformers model instead of the spaCy NER component:</p> <p></p> <p>Presidio leverages other types of information from spaCy such as tokens, lemmas and part-of-speech. Therefore the pipeline returns both the NER model results as well as results from other pipeline components.</p>"},{"location":"analyzer/nlp_engines/transformers/#how-ner-results-flow-within-presidio","title":"How NER results flow within Presidio","text":"<p>This diagram describes the flow of NER results within Presidio, and the relationship between the <code>TransformersNlpEngine</code> component and the <code>TransformersRecognizer</code> component: <pre><code>sequenceDiagram\n    AnalyzerEngine-&gt;&gt;TransformersNlpEngine: Call engine.process_text(text) &lt;br&gt;to get model results\n    TransformersNlpEngine-&gt;&gt;spaCy: Call spaCy pipeline\n    spaCy-&gt;&gt;transformers: call NER model\n    transformers-&gt;&gt;spaCy: get entities\n    spaCy-&gt;&gt;TransformersNlpEngine: return transformers entities &lt;BR&gt;+ spaCy attributes\n    Note over TransformersNlpEngine: Map entity names to Presidio's, &lt;BR&gt;update scores, &lt;BR&gt;remove unwanted entities &lt;BR&gt; based on NerModelConfiguration\n    TransformersNlpEngine-&gt;&gt;AnalyzerEngine: Pass NlpArtifacts&lt;BR&gt;(Entities, lemmas, tokens, scores etc.)\n    Note over AnalyzerEngine: Call all recognizers\n    AnalyzerEngine-&gt;&gt;TransformersRecognizer: Pass NlpArtifacts\n    Note over TransformersRecognizer: Extract PII entities out of NlpArtifacts\n    TransformersRecognizer-&gt;&gt;AnalyzerEngine: Return List[RecognizerResult]\n</code></pre></p>"},{"location":"analyzer/nlp_engines/transformers/#adding-a-new-model","title":"Adding a new model","text":"<p>As the underlying transformers model, you can choose from either a public pretrained model or a custom model.</p>"},{"location":"analyzer/nlp_engines/transformers/#using-a-public-pre-trained-transformers-model","title":"Using a public pre-trained transformers model","text":""},{"location":"analyzer/nlp_engines/transformers/#downloading-a-pre-trained-model","title":"Downloading a pre-trained model","text":"<p>To download the desired NER model from HuggingFace:</p> <pre><code>import transformers\nfrom huggingface_hub import snapshot_download\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\n\ntransformers_model = &lt;PATH_TO_MODEL&gt; # e.g. \"obi/deid_roberta_i2b2\"\n\nsnapshot_download(repo_id=transformers_model)\n\n# Instantiate to make sure it's downloaded during installation and not runtime\nAutoTokenizer.from_pretrained(transformers_model)\nAutoModelForTokenClassification.from_pretrained(transformers_model)\n</code></pre> <p>Then, also download a spaCy pipeline/model:</p> <pre><code>python -m spacy download en_core_web_sm\n</code></pre>"},{"location":"analyzer/nlp_engines/transformers/#configuring-the-ner-pipeline","title":"Configuring the NER pipeline","text":"<p>Once the models are downloaded, one option to configure them is to create a YAML configuration file. Note that the configuration needs to contain both a <code>spaCy</code> pipeline name and a transformers model name. In addition, different configurations for parsing the results of the transformers model can be added.</p> <p>The NER model configuration can be done in a YAML file or in Python:</p>"},{"location":"analyzer/nlp_engines/transformers/#configuring-the-ner-pipeline-via-code","title":"Configuring the NER pipeline via code","text":"<p>Example configuration in Python:</p> <pre><code># Transformer model config\nmodel_config = [\n    {\"lang_code\": \"en\",\n     \"model_name\": {\n         \"spacy\": \"en_core_web_sm\", # for tokenization, lemmatization\n         \"transformers\": \"StanfordAIMI/stanford-deidentifier-base\" # for NER\n    }\n}]\n\n# Entity mappings between the model's and Presidio's\nmapping = dict(\n    PER=\"PERSON\",\n    LOC=\"LOCATION\",\n    ORG=\"ORGANIZATION\",\n    AGE=\"AGE\",\n    ID=\"ID\",\n    EMAIL=\"EMAIL\",\n    DATE=\"DATE_TIME\",\n    PHONE=\"PHONE_NUMBER\",\n    PERSON=\"PERSON\",\n    LOCATION=\"LOCATION\",\n    GPE=\"LOCATION\",\n    ORGANIZATION=\"ORGANIZATION\",\n    NORP=\"NRP\",\n    PATIENT=\"PERSON\",\n    STAFF=\"PERSON\",\n    HOSP=\"LOCATION\",\n    PATORG=\"ORGANIZATION\",\n    TIME=\"DATE_TIME\",\n    HCW=\"PERSON\",\n    HOSPITAL=\"LOCATION\",\n    FACILITY=\"LOCATION\",\n    VENDOR=\"ORGANIZATION\",\n)\n\nlabels_to_ignore = [\"O\"]\n\nner_model_configuration = NerModelConfiguration(\n    model_to_presidio_entity_mapping=mapping,\n    alignment_mode=\"expand\", # \"strict\", \"contract\", \"expand\"\n    aggregation_strategy=\"max\", # \"simple\", \"first\", \"average\", \"max\"\n    labels_to_ignore = labels_to_ignore)\n\ntransformers_nlp_engine = TransformersNlpEngine(\n    models=model_config,\n    ner_model_configuration=ner_model_configuration)\n\n# Transformer-based analyzer\nanalyzer = AnalyzerEngine(\n    nlp_engine=transformers_nlp_engine, \n    supported_languages=[\"en\"]\n)\n</code></pre>"},{"location":"analyzer/nlp_engines/transformers/#creating-a-yaml-configuration-file","title":"Creating a YAML configuration file","text":"<p>Once the models are downloaded, one option to configure them is to create a YAML configuration file. Note that the configuration needs to contain both a <code>spaCy</code> pipeline name and a transformers model name. In addition, different configurations for parsing the results of the transformers model can be added.</p> <p>Example configuration (in YAML):</p> <pre><code>nlp_engine_name: transformers\nmodels:\n  -\n    lang_code: en\n    model_name:\n      spacy: en_core_web_sm\n      transformers: StanfordAIMI/stanford-deidentifier-base\n\nner_model_configuration:\n  labels_to_ignore:\n  - O\n  aggregation_strategy: max # \"simple\", \"first\", \"average\", \"max\"\n  stride: 16\n  alignment_mode: expand # \"strict\", \"contract\", \"expand\"\n  model_to_presidio_entity_mapping:\n    PER: PERSON\n    LOC: LOCATION\n    ORG: ORGANIZATION\n    AGE: AGE\n    ID: ID\n    EMAIL: EMAIL\n    PATIENT: PERSON\n    STAFF: PERSON\n    HOSP: ORGANIZATION\n    PATORG: ORGANIZATION\n    DATE: DATE_TIME\n    PHONE: PHONE_NUMBER\n    HCW: PERSON\n    HOSPITAL: LOCATION\n    VENDOR: ORGANIZATION\n\n  low_confidence_score_multiplier: 0.4\n  low_score_entity_names:\n  - ID\n</code></pre>"},{"location":"analyzer/nlp_engines/transformers/#calling-the-new-model","title":"Calling the new model","text":"<p>Once the configuration file is created, it can be used to create a new <code>TransformersNlpEngine</code>:</p> <pre><code>    from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n    from presidio_analyzer.nlp_engine import NlpEngineProvider\n\n    # Create configuration containing engine name and models\n    conf_file = PATH_TO_CONF_FILE\n\n    # Create NLP engine based on configuration\n    provider = NlpEngineProvider(conf_file=conf_file)\n    nlp_engine = provider.create_engine()\n\n    # Pass the created NLP engine and supported_languages to the AnalyzerEngine\n    analyzer = AnalyzerEngine(\n        nlp_engine=nlp_engine, \n        supported_languages=[\"en\"]\n    )\n\n    results_english = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\n    print(results_english)\n</code></pre>"},{"location":"analyzer/nlp_engines/transformers/#explaning-the-configuration-options","title":"Explaning the configuration options","text":"<ul> <li><code>model_name.spacy</code> is a name of a spaCy model/pipeline, which would wrap the transformers NER model. For example, <code>en_core_web_sm</code>.</li> <li>The <code>model_name.transformers</code> is the full path for a huggingface model. Models can be found on HuggingFace Models Hub. For example, <code>obi/deid_roberta_i2b2</code></li> </ul> <p>The <code>ner_model_configuration</code> section contains the following parameters:</p> <ul> <li><code>labels_to_ignore</code>: A list of labels to ignore. For example, <code>O</code> (no entity) or entities you are not interested in returning.</li> <li><code>aggregation_strategy</code>: The strategy to use when aggregating the results of the transformers model.</li> <li><code>stride</code>: The value is the length of the window overlap in transformer tokenizer tokens.</li> <li><code>alignment_mode</code>: The strategy to use when aligning the results of the transformers model to the original text.</li> <li><code>model_to_presidio_entity_mapping</code>: A mapping between the transformers model labels and the Presidio entity types.</li> <li><code>low_confidence_score_multiplier</code>: A multiplier to apply to the score of entities with low confidence.</li> <li><code>low_score_entity_names</code>: A list of entity types to apply the low confidence score multiplier to.</li> </ul> <p>Defining the entity mapping</p> <p>To be able to create the <code>model_to_presidio_entity_mapping</code> dictionary, it is advised to check which classes the model is able to predict.  This can be found on the huggingface hub site for the model in some cases. In other, one can check the model's <code>config.json</code> uner <code>id2label</code>.  For example, for <code>bert-base-NER-uncased</code>, it can be found here: https://huggingface.co/dslim/bert-base-NER-uncased/blob/main/config.json.  Note that most NER models add a prefix to the class (e.g. <code>B-PER</code> for class <code>PER</code>). When creating the mapping, do not add the prefix.</p> <p>See more information on parameters on the spacy-huggingface-pipelines Github repo.</p> <p>Once created, see the NLP configuration documentation for more information.</p>"},{"location":"analyzer/nlp_engines/transformers/#training-your-own-model","title":"Training your own model","text":"<p>Note</p> <p>A labeled dataset containing text and labeled PII entities is required for training a new model.</p> <p>For more information on model training and evaluation for Presidio, see the Presidio-Research Github repository.</p> <p>To train your own model, see this tutorial: Train your own transformers model.</p>"},{"location":"analyzer/nlp_engines/transformers/#using-a-transformers-model-as-an-entityrecognizer","title":"Using a transformers model as an <code>EntityRecognizer</code>","text":"<p>In addition to the approach described in this document, one can decide to integrate a transformers model as a recognizer. We allow these two options, as a user might want to have multiple NER models running in parallel. In this case, one can create multiple <code>EntityRecognizer</code> instances, each serving a different model, instead of one model used in an <code>NlpEngine</code>. See this sample for more info on integrating a transformers model as a Presidio recognizer and not as a Presidio <code>NLPEngine</code>.</p>"},{"location":"anonymizer/","title":"Presidio Anonymizer","text":"<p>The Presidio anonymizer is a Python based module for anonymizing detected PII text entities with desired values. Presidio anonymizer supports both anonymization and deanonymization by applying different operators. Operators are built-in text manipulation classes which can be easily extended.</p> <p></p> <p>The Presidio-Anonymizer package contains both <code>Anonymizers</code> and <code>Deanonymizers</code>.</p> <ul> <li>Anonymizers are used to replace a PII entity text with some other value by applying a certain operator (e.g. replace, mask, redact, encrypt)</li> <li>Deanonymizers are used to revert the anonymization operation.   (e.g. to decrypt an encrypted text).</li> </ul>"},{"location":"anonymizer/#installation","title":"Installation","text":"<p>see Installing Presidio.</p>"},{"location":"anonymizer/#getting-started","title":"Getting started","text":"PythonAs an HTTP server <p>Simple example:</p> <pre><code>from presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import RecognizerResult, OperatorConfig\n\n# Initialize the engine:\nengine = AnonymizerEngine()\n\n# Invoke the anonymize function with the text, \n# analyzer results (potentially coming from presidio-analyzer) and\n# Operators to get the anonymization output:\nresult = engine.anonymize(\n    text=\"My name is Bond, James Bond\",\n    analyzer_results=[\n        RecognizerResult(entity_type=\"PERSON\", start=11, end=15, score=0.8),\n        RecognizerResult(entity_type=\"PERSON\", start=17, end=27, score=0.8),\n    ],\n    operators={\"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"BIP\"})},\n)\n\nprint(result)\n</code></pre> <p>This example takes the output of the <code>AnonymizerEngine</code>  containing an encrypted PII entity, and decrypts it back to the original text:</p> <pre><code>from presidio_anonymizer import DeanonymizeEngine\nfrom presidio_anonymizer.entities import OperatorResult, OperatorConfig\n\n# Initialize the engine:\nengine = DeanonymizeEngine()\n\n# Invoke the deanonymize function with the text, anonymizer results and\n# Operators to define the deanonymization type.\nresult = engine.deanonymize(\n    text=\"My name is S184CMt9Drj7QaKQ21JTrpYzghnboTF9pn/neN8JME0=\",\n    entities=[\n        OperatorResult(start=11, end=55, entity_type=\"PERSON\"),\n    ],\n    operators={\"DEFAULT\": OperatorConfig(\"decrypt\", {\"key\": \"WmZq4t7w!z%C&amp;F)J\"})},\n)\n\nprint(result)\n</code></pre> <p>You can run presidio anonymizer as an http server using either python runtime or using a docker container.</p>"},{"location":"anonymizer/#using-docker-container","title":"Using docker container","text":"<pre><code>cd presidio-anonymizer\ndocker run -p 5001:3000 presidio-anonymizer \n</code></pre>"},{"location":"anonymizer/#using-python-runtime","title":"Using python runtime","text":"<p>Note</p> <p>This requires the Presidio Github repository to be cloned.</p> <pre><code>cd presidio-anonymizer\npython app.py\n\nAnonymize:\n\ncurl -XPOST http://localhost:3000/anonymize -H \"Content-Type: application/json\" -d @payload\n\npayload example:\n{\n\"text\": \"hello world, my name is Jane Doe. My number is: 034453334\",\n\"anonymizers\": {\n    \"PHONE_NUMBER\": {\n        \"type\": \"mask\",\n        \"masking_char\": \"*\",\n        \"chars_to_mask\": 4,\n        \"from_end\": true\n    }\n},\n\"analyzer_results\": [\n    {\n        \"start\": 24,\n        \"end\": 32,\n        \"score\": 0.8,\n        \"entity_type\": \"NAME\"\n    },\n    {\n        \"start\": 24,\n        \"end\": 28,\n        \"score\": 0.8,\n        \"entity_type\": \"FIRST_NAME\"\n    },\n    {\n        \"start\": 29,\n        \"end\": 32,\n        \"score\": 0.6,\n        \"entity_type\": \"LAST_NAME\"\n    },\n    {\n        \"start\": 48,\n        \"end\": 57,\n        \"score\": 0.95,\n        \"entity_type\": \"PHONE_NUMBER\"\n    }\n]}\n\nDeanonymize:\n\ncurl -XPOST http://localhost:3000/deanonymize -H \"Content-Type: application/json\" -d @payload\n\npayload example:\n{\n\"text\": \"My name is S184CMt9Drj7QaKQ21JTrpYzghnboTF9pn/neN8JME0=\",\n\"deanonymizers\": {\n    \"PERSON\": {\n        \"type\": \"decrypt\",\n        \"key\": \"WmZq4t7w!z%C&amp;F)J\"\n    }\n},\n\"anonymizer_results\": [\n    {\n        \"start\": 11,\n        \"end\": 55,\n        \"entity_type\": \"PERSON\"\n    }\n]}\n</code></pre>"},{"location":"anonymizer/#built-in-operators","title":"Built-in operators","text":"Operator type Operator name Description Parameters Anonymize replace Replace the PII with desired value <code>new_value</code>: replaces existing text with the given value. If <code>new_value</code> is not supplied or empty, default behavior will be: &lt;entity_type&gt; e.g: &lt;PHONE_NUMBER&gt; Anonymize redact Remove the PII completely from text None Anonymize hash Hashes the PII text <code>hash_type</code>: sets the type of hashing. Can be either <code>sha256</code>, <code>sha512</code> or <code>md5</code>.  The default hash type is <code>sha256</code>. Anonymize mask Replace the PII with a given character <code>chars_to_mask</code>: the amount of characters out of the PII that should be replaced.  <code>masking_char</code>: the character to be replaced with.  <code>from_end</code>: Whether to mask the PII from it's end. Anonymize encrypt Encrypt the PII using a given key <code>key</code>: a cryptographic key used for the encryption. Anonymize custom Replace the PII with the result of the function executed on the PII <code>lambda</code>: lambda to execute on the PII data. The lambda return type must be a string. Anonymize keep Preserver the PII unmodified None Deanonymize decrypt Decrypt the encrypted PII in the text using the encryption key <code>key</code>: a cryptographic key used for the encryption is also used for the decryption. <p>Note</p> <p>When performing anonymization, if anonymizers map is empty or \"DEFAULT\" key is not stated, the default anonymization operator is \"replace\" for all entities. The replacing value will be the entity type e.g.: &lt;PHONE_NUMBER&gt;</p>"},{"location":"anonymizer/#handling-overlaps-between-entities","title":"Handling overlaps between entities","text":"<p>As the input text could potentially have overlapping PII entities, there are different anonymization scenarios:</p> <ul> <li>No overlap (single PII): When there is no overlap in spans of entities,     Presidio Anonymizer uses a given or default anonymization operator to anonymize     and replace the PII text entity.</li> <li>Full overlap of PII entitie spans: When entities have overlapping substrings,     the PII with the higher score will be taken.     Between PIIs with identical scores, the selection is arbitrary.</li> <li>One PII is contained in another: Presidio Anonymizer will use the PII with the larger text even if it's score is lower.</li> <li> <p>Partial intersection: Presidio Anonymizer will anonymize each individually and will return a concatenation of the anonymized text.     For example:     For the text</p> <pre><code>I'm George Washington Square Park.\n</code></pre> <p>Assuming one entity is <code>George Washington</code> and the other is <code>Washington State Park</code> and assuming we're using the default anonymizer, the result would be:</p> <pre><code>I'm &lt;PERSON&gt;&lt;LOCATION&gt;.\n</code></pre> </li> </ul>"},{"location":"anonymizer/#additional-examples-for-overlapping-pii-scenarios","title":"Additional examples for overlapping PII scenarios","text":"<p>Text:</p> <pre><code>My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is:\n03-232323.\n</code></pre> <p>Results:</p> <ul> <li> <p>No overlaps: Assuming only <code>Inigo</code> is recognized as NAME:</p> <pre><code>My name is &lt;NAME&gt; Montoya. You Killed my Father. Prepare to die. BTW my number is:\n03-232323.\n</code></pre> </li> <li> <p>Full overlap: Assuming the number is recognized as PHONE_NUMBER with score of 0.7 and as SSN     with score of 0.6, the higher score would count:</p> <pre><code>My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is: &lt;\nPHONE_NUMBER&gt;.\n</code></pre> </li> <li> <p>One PII is contained is another: Assuming Inigo is recognized as FIRST_NAME and Inigo Montoya     was recognized as NAME, the larger one will be used:</p> <pre><code>My name is &lt;NAME&gt;. You Killed my Father. Prepare to die. BTW my number is: 03-232323.\n</code></pre> </li> <li> <p>Partial intersection: Assuming the number 03-2323 is recognized as a PHONE_NUMBER but 232323     is recognized as SSN:</p> <pre><code>My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is: &lt;\nPHONE_NUMBER&gt;&lt;SSN&gt;.\n</code></pre> </li> </ul>"},{"location":"anonymizer/#creating-a-new-operator","title":"Creating a new <code>operator</code>","text":"<p>Presidio anonymizer can be easily extended to support additional operators. See this tutorial on adding new operators for more information.</p>"},{"location":"anonymizer/#api-reference","title":"API reference","text":"<p>Follow the API Spec for the Anonymizer REST API reference details and Anonymizer Python API for Python API reference.</p>"},{"location":"anonymizer/adding_operators/","title":"Supporting new types of PII operators","text":"<p>Operators are the presidio-anonymizer actions over the text.</p> <p>There are two types of operators: - Anonymize (hash, replace, redact, encrypt, mask) - Deanonymize (decrypt)</p> <p>Presidio anonymizer can be easily extended to support additional anonymization and deanonymization methods.</p>"},{"location":"anonymizer/adding_operators/#extending-presidio-anonymizer-for-additional-pii-operators","title":"Extending presidio-anonymizer for additional PII operators:","text":"<ol> <li>Under the path presidio_anonymizer/operators create new python class implementing the abstract Operator class</li> <li>Implement the methods:<ul> <li><code>operate</code> - gets the data and returns a new text expected to replace the old one.</li> <li><code>validate</code> - validate the parameters entered for the anonymizer exists and valid.</li> <li><code>operator_name</code> - this method helps to automatically load the existing anonymizers.</li> <li><code>operator_type</code> - either Anonymize or Deanonymize. Will be mapped to the proper engine.</li> </ul> </li> <li>Add the class to presidio_anonymizer/operators/init.py.</li> <li>Restart the anonymizer.</li> </ol> <p>Note</p> <p>The list of operators is being loaded dynamically each time Presidio Anonymizer is started.</p>"},{"location":"api/analyzer_python/","title":"Presidio Analyzer API Reference","text":"<p>Presidio analyzer package.</p>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalysisExplanation","title":"<code>AnalysisExplanation</code>","text":"<p>Hold tracing information to explain why PII entities were identified as such.</p> <p>Parameters:</p> Name Type Description Default <code>recognizer</code> <code>str</code> <p>name of recognizer that made the decision</p> required <code>original_score</code> <code>float</code> <p>recognizer's confidence in result</p> required <code>pattern_name</code> <code>str</code> <p>name of pattern (if decision was made by a PatternRecognizer)</p> <code>None</code> <code>pattern</code> <code>str</code> <p>regex pattern that was applied (if PatternRecognizer)</p> <code>None</code> <code>validation_result</code> <code>float</code> <p>result of a validation (e.g. checksum)</p> <code>None</code> <code>textual_explanation</code> <code>str</code> <p>Free text for describing a decision of a logic or model</p> <code>None</code> Source code in <code>presidio_analyzer/analysis_explanation.py</code> <pre><code>class AnalysisExplanation:\n    \"\"\"\n    Hold tracing information to explain why PII entities were identified as such.\n\n    :param recognizer: name of recognizer that made the decision\n    :param original_score: recognizer's confidence in result\n    :param pattern_name: name of pattern\n            (if decision was made by a PatternRecognizer)\n    :param pattern: regex pattern that was applied (if PatternRecognizer)\n    :param validation_result: result of a validation (e.g. checksum)\n    :param textual_explanation: Free text for describing\n            a decision of a logic or model\n    \"\"\"\n\n    def __init__(\n        self,\n        recognizer: str,\n        original_score: float,\n        pattern_name: str = None,\n        pattern: str = None,\n        validation_result: float = None,\n        textual_explanation: str = None,\n        regex_flags: int = None,\n    ):\n        self.recognizer = recognizer\n        self.pattern_name = pattern_name\n        self.pattern = pattern\n        self.original_score = original_score\n        self.score = original_score\n        self.textual_explanation = textual_explanation\n        self.score_context_improvement = 0\n        self.supportive_context_word = \"\"\n        self.validation_result = validation_result\n        self.regex_flags = regex_flags\n\n    def __repr__(self):\n        \"\"\"Create string representation of the object.\"\"\"\n        return str(self.__dict__)\n\n    def set_improved_score(self, score: float) -&gt; None:\n        \"\"\"Update the score and calculate the difference from the original score.\"\"\"\n        self.score = score\n        self.score_context_improvement = self.score - self.original_score\n\n    def set_supportive_context_word(self, word: str) -&gt; None:\n        \"\"\"Set the context word which helped increase the score.\"\"\"\n        self.supportive_context_word = word\n\n    def append_textual_explanation_line(self, text: str) -&gt; None:\n        \"\"\"Append a new line to textual_explanation field.\"\"\"\n        if self.textual_explanation is None:\n            self.textual_explanation = text\n        else:\n            self.textual_explanation = f\"{self.textual_explanation}\\n{text}\"\n\n    def to_dict(self) -&gt; Dict:\n        \"\"\"\n        Serialize self to dictionary.\n\n        :return: a dictionary\n        \"\"\"\n        return self.__dict__\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalysisExplanation.__repr__","title":"<code>__repr__()</code>","text":"<p>Create string representation of the object.</p> Source code in <code>presidio_analyzer/analysis_explanation.py</code> <pre><code>def __repr__(self):\n    \"\"\"Create string representation of the object.\"\"\"\n    return str(self.__dict__)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalysisExplanation.append_textual_explanation_line","title":"<code>append_textual_explanation_line(text)</code>","text":"<p>Append a new line to textual_explanation field.</p> Source code in <code>presidio_analyzer/analysis_explanation.py</code> <pre><code>def append_textual_explanation_line(self, text: str) -&gt; None:\n    \"\"\"Append a new line to textual_explanation field.\"\"\"\n    if self.textual_explanation is None:\n        self.textual_explanation = text\n    else:\n        self.textual_explanation = f\"{self.textual_explanation}\\n{text}\"\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalysisExplanation.set_improved_score","title":"<code>set_improved_score(score)</code>","text":"<p>Update the score and calculate the difference from the original score.</p> Source code in <code>presidio_analyzer/analysis_explanation.py</code> <pre><code>def set_improved_score(self, score: float) -&gt; None:\n    \"\"\"Update the score and calculate the difference from the original score.\"\"\"\n    self.score = score\n    self.score_context_improvement = self.score - self.original_score\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalysisExplanation.set_supportive_context_word","title":"<code>set_supportive_context_word(word)</code>","text":"<p>Set the context word which helped increase the score.</p> Source code in <code>presidio_analyzer/analysis_explanation.py</code> <pre><code>def set_supportive_context_word(self, word: str) -&gt; None:\n    \"\"\"Set the context word which helped increase the score.\"\"\"\n    self.supportive_context_word = word\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalysisExplanation.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize self to dictionary.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>a dictionary</p> Source code in <code>presidio_analyzer/analysis_explanation.py</code> <pre><code>def to_dict(self) -&gt; Dict:\n    \"\"\"\n    Serialize self to dictionary.\n\n    :return: a dictionary\n    \"\"\"\n    return self.__dict__\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine","title":"<code>AnalyzerEngine</code>","text":"<p>Entry point for Presidio Analyzer.</p> <p>Orchestrating the detection of PII entities and all related logic.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>RecognizerRegistry</code> <p>instance of type RecognizerRegistry</p> <code>None</code> <code>nlp_engine</code> <code>NlpEngine</code> <p>instance of type NlpEngine (for example SpacyNlpEngine)</p> <code>None</code> <code>app_tracer</code> <code>AppTracer</code> <p>instance of type AppTracer, used to trace the logic used during each request for interpretability reasons.</p> <code>None</code> <code>log_decision_process</code> <code>bool</code> <p>bool, defines whether the decision process within the analyzer should be logged or not.</p> <code>False</code> <code>default_score_threshold</code> <code>float</code> <p>Minimum confidence value for detected entities to be returned</p> <code>0</code> <code>supported_languages</code> <code>List[str]</code> <p>List of possible languages this engine could be run on. Used for loading the right NLP models and recognizers for these languages.</p> <code>None</code> <code>context_aware_enhancer</code> <code>Optional[ContextAwareEnhancer]</code> <p>instance of type ContextAwareEnhancer for enhancing confidence score based on context words, (LemmaContextAwareEnhancer will be created by default if None passed)</p> <code>None</code> Source code in <code>presidio_analyzer/analyzer_engine.py</code> <pre><code>class AnalyzerEngine:\n    \"\"\"\n    Entry point for Presidio Analyzer.\n\n    Orchestrating the detection of PII entities and all related logic.\n\n    :param registry: instance of type RecognizerRegistry\n    :param nlp_engine: instance of type NlpEngine\n    (for example SpacyNlpEngine)\n    :param app_tracer: instance of type AppTracer, used to trace the logic\n    used during each request for interpretability reasons.\n    :param log_decision_process: bool,\n    defines whether the decision process within the analyzer should be logged or not.\n    :param default_score_threshold: Minimum confidence value\n    for detected entities to be returned\n    :param supported_languages: List of possible languages this engine could be run on.\n    Used for loading the right NLP models and recognizers for these languages.\n    :param context_aware_enhancer: instance of type ContextAwareEnhancer for enhancing\n    confidence score based on context words, (LemmaContextAwareEnhancer will be created\n    by default if None passed)\n    \"\"\"\n\n    def __init__(\n        self,\n        registry: RecognizerRegistry = None,\n        nlp_engine: NlpEngine = None,\n        app_tracer: AppTracer = None,\n        log_decision_process: bool = False,\n        default_score_threshold: float = 0,\n        supported_languages: List[str] = None,\n        context_aware_enhancer: Optional[ContextAwareEnhancer] = None,\n    ):\n        if not supported_languages:\n            supported_languages = [\"en\"]\n\n        if not nlp_engine:\n            logger.info(\"nlp_engine not provided, creating default.\")\n            provider = NlpEngineProvider()\n            nlp_engine = provider.create_engine()\n\n        if not app_tracer:\n            app_tracer = AppTracer()\n        self.app_tracer = app_tracer\n\n        self.supported_languages = supported_languages\n\n        self.nlp_engine = nlp_engine\n        if not self.nlp_engine.is_loaded():\n            self.nlp_engine.load()\n\n        if not registry:\n            logger.info(\"registry not provided, creating default.\")\n            provider = RecognizerRegistryProvider(\n                registry_configuration={\"supported_languages\": self.supported_languages}\n            )\n            registry = provider.create_recognizer_registry()\n            registry.add_nlp_recognizer(nlp_engine=self.nlp_engine)\n        else:\n            if Counter(registry.supported_languages) != Counter(\n                self.supported_languages\n            ):\n                raise ValueError(\n                    f\"Misconfigured engine, supported languages have to be consistent\"\n                    f\"registry.supported_languages: {registry.supported_languages}, \"\n                    f\"analyzer_engine.supported_languages: {self.supported_languages}\"\n                )\n\n        # added to support the previous interface\n        if not registry.recognizers:\n            registry.load_predefined_recognizers(\n                nlp_engine=self.nlp_engine, languages=self.supported_languages\n            )\n\n        self.registry = registry\n\n        self.log_decision_process = log_decision_process\n        self.default_score_threshold = default_score_threshold\n\n        if not context_aware_enhancer:\n            logger.debug(\n                \"context aware enhancer not provided, creating default\"\n                + \" lemma based enhancer.\"\n            )\n            context_aware_enhancer = LemmaContextAwareEnhancer()\n\n        self.context_aware_enhancer = context_aware_enhancer\n\n    def get_recognizers(self, language: Optional[str] = None) -&gt; List[EntityRecognizer]:\n        \"\"\"\n        Return a list of PII recognizers currently loaded.\n\n        :param language: Return the recognizers supporting a given language.\n        :return: List of [Recognizer] as a RecognizersAllResponse\n        \"\"\"\n        if not language:\n            languages = self.supported_languages\n        else:\n            languages = [language]\n\n        recognizers = []\n        for language in languages:\n            logger.info(f\"Fetching all recognizers for language {language}\")\n            recognizers.extend(\n                self.registry.get_recognizers(language=language, all_fields=True)\n            )\n\n        return list(set(recognizers))\n\n    def get_supported_entities(self, language: Optional[str] = None) -&gt; List[str]:\n        \"\"\"\n        Return a list of the entities that can be detected.\n\n        :param language: Return only entities supported in a specific language.\n        :return: List of entity names\n        \"\"\"\n        recognizers = self.get_recognizers(language=language)\n        supported_entities = []\n        for recognizer in recognizers:\n            supported_entities.extend(recognizer.get_supported_entities())\n\n        return list(set(supported_entities))\n\n    def analyze(\n        self,\n        text: str,\n        language: str,\n        entities: Optional[List[str]] = None,\n        correlation_id: Optional[str] = None,\n        score_threshold: Optional[float] = None,\n        return_decision_process: Optional[bool] = False,\n        ad_hoc_recognizers: Optional[List[EntityRecognizer]] = None,\n        context: Optional[List[str]] = None,\n        allow_list: Optional[List[str]] = None,\n        allow_list_match: Optional[str] = \"exact\",\n        regex_flags: Optional[int] = re.DOTALL | re.MULTILINE | re.IGNORECASE,\n        nlp_artifacts: Optional[NlpArtifacts] = None,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Find PII entities in text using different PII recognizers for a given language.\n\n        :param text: the text to analyze\n        :param language: the language of the text\n        :param entities: List of PII entities that should be looked for in the text.\n        If entities=None then all entities are looked for.\n        :param correlation_id: cross call ID for this request\n        :param score_threshold: A minimum value for which\n        to return an identified entity\n        :param return_decision_process: Whether the analysis decision process steps\n        returned in the response.\n        :param ad_hoc_recognizers: List of recognizers which will be used only\n        for this specific request.\n        :param context: List of context words to enhance confidence score if matched\n        with the recognized entity's recognizer context\n        :param allow_list: List of words that the user defines as being allowed to keep\n        in the text\n        :param allow_list_match: How the allow_list should be interpreted; either as \"exact\" or as \"regex\".\n        - If `regex`, results which match with any regex condition in the allow_list would be allowed and not be returned as potential PII.\n        - if `exact`, results which exactly match any value in the allow_list would be allowed and not be returned as potential PII.\n        :param regex_flags: regex flags to be used for when allow_list_match is \"regex\"\n        :param nlp_artifacts: precomputed NlpArtifacts\n        :return: an array of the found entities in the text\n\n        :example:\n\n        &gt;&gt;&gt; from presidio_analyzer import AnalyzerEngine\n\n        &gt;&gt;&gt; # Set up the engine, loads the NLP module (spaCy model by default)\n        &gt;&gt;&gt; # and other PII recognizers\n        &gt;&gt;&gt; analyzer = AnalyzerEngine()\n\n        &gt;&gt;&gt; # Call analyzer to get results\n        &gt;&gt;&gt; results = analyzer.analyze(text='My phone number is 212-555-5555', entities=['PHONE_NUMBER'], language='en') # noqa D501\n        &gt;&gt;&gt; print(results)\n        [type: PHONE_NUMBER, start: 19, end: 31, score: 0.85]\n        \"\"\"  # noqa: E501\n\n        all_fields = not entities\n\n        recognizers = self.registry.get_recognizers(\n            language=language,\n            entities=entities,\n            all_fields=all_fields,\n            ad_hoc_recognizers=ad_hoc_recognizers,\n        )\n\n        if all_fields:\n            # Since all_fields=True, list all entities by iterating\n            # over all recognizers\n            entities = self.get_supported_entities(language=language)\n\n        # run the nlp pipeline over the given text, store the results in\n        # a NlpArtifacts instance\n        if not nlp_artifacts:\n            nlp_artifacts = self.nlp_engine.process_text(text, language)\n\n        if self.log_decision_process:\n            self.app_tracer.trace(\n                correlation_id, \"nlp artifacts:\" + nlp_artifacts.to_json()\n            )\n\n        results = []\n        for recognizer in recognizers:\n            # Lazy loading of the relevant recognizers\n            if not recognizer.is_loaded:\n                recognizer.load()\n                recognizer.is_loaded = True\n\n            # analyze using the current recognizer and append the results\n            current_results = recognizer.analyze(\n                text=text, entities=entities, nlp_artifacts=nlp_artifacts\n            )\n            if current_results:\n                # add recognizer name to recognition metadata inside results\n                # if not exists\n                self.__add_recognizer_id_if_not_exists(current_results, recognizer)\n                results.extend(current_results)\n\n        results = self._enhance_using_context(\n            text, results, nlp_artifacts, recognizers, context\n        )\n\n        if self.log_decision_process:\n            self.app_tracer.trace(\n                correlation_id,\n                json.dumps([str(result.to_dict()) for result in results]),\n            )\n\n        # Remove duplicates or low score results\n        results = EntityRecognizer.remove_duplicates(results)\n        results = self.__remove_low_scores(results, score_threshold)\n\n        if allow_list:\n            results = self._remove_allow_list(\n                results, allow_list, text, regex_flags, allow_list_match\n            )\n\n        if not return_decision_process:\n            results = self.__remove_decision_process(results)\n\n        return results\n\n    def _enhance_using_context(\n        self,\n        text: str,\n        raw_results: List[RecognizerResult],\n        nlp_artifacts: NlpArtifacts,\n        recognizers: List[EntityRecognizer],\n        context: Optional[List[str]] = None,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Enhance confidence score using context words.\n\n        :param text: The actual text that was analyzed\n        :param raw_results: Recognizer results which didn't take\n                            context into consideration\n        :param nlp_artifacts: The nlp artifacts contains elements\n                              such as lemmatized tokens for better\n                              accuracy of the context enhancement process\n        :param recognizers: the list of recognizers\n        :param context: list of context words\n        \"\"\"\n        results = []\n\n        for recognizer in recognizers:\n            recognizer_results = [\n                r\n                for r in raw_results\n                if r.recognition_metadata[RecognizerResult.RECOGNIZER_IDENTIFIER_KEY]\n                == recognizer.id\n            ]\n            other_recognizer_results = [\n                r\n                for r in raw_results\n                if r.recognition_metadata[RecognizerResult.RECOGNIZER_IDENTIFIER_KEY]\n                != recognizer.id\n            ]\n\n            # enhance score using context in recognizer level if implemented\n            recognizer_results = recognizer.enhance_using_context(\n                text=text,\n                # each recognizer will get access to all recognizer results\n                # to allow related entities contex enhancement\n                raw_recognizer_results=recognizer_results,\n                other_raw_recognizer_results=other_recognizer_results,\n                nlp_artifacts=nlp_artifacts,\n                context=context,\n            )\n\n            results.extend(recognizer_results)\n\n        # Update results in case surrounding words or external context are relevant to\n        # the context words.\n        results = self.context_aware_enhancer.enhance_using_context(\n            text=text,\n            raw_results=results,\n            nlp_artifacts=nlp_artifacts,\n            recognizers=recognizers,\n            context=context,\n        )\n\n        return results\n\n    def __remove_low_scores(\n        self, results: List[RecognizerResult], score_threshold: float = None\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Remove results for which the confidence is lower than the threshold.\n\n        :param results: List of RecognizerResult\n        :param score_threshold: float value for minimum possible confidence\n        :return: List[RecognizerResult]\n        \"\"\"\n        if score_threshold is None:\n            score_threshold = self.default_score_threshold\n\n        new_results = [result for result in results if result.score &gt;= score_threshold]\n        return new_results\n\n    @staticmethod\n    def _remove_allow_list(\n        results: List[RecognizerResult],\n        allow_list: List[str],\n        text: str,\n        regex_flags: Optional[int],\n        allow_list_match: str,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Remove results which are part of the allow list.\n\n        :param results: List of RecognizerResult\n        :param allow_list: list of allowed terms\n        :param text: the text to analyze\n        :param regex_flags: regex flags to be used for when allow_list_match is \"regex\"\n        :param allow_list_match: How the allow_list\n        should be interpreted; either as \"exact\" or as \"regex\"\n        :return: List[RecognizerResult]\n        \"\"\"\n        new_results = []\n        if allow_list_match == \"regex\":\n            pattern = \"|\".join(allow_list)\n            re_compiled = re.compile(pattern, flags=regex_flags)\n\n            for result in results:\n                word = text[result.start : result.end]\n\n                # if the word is not specified to be allowed, keep in the PII entities\n                if not re_compiled.search(word):\n                    new_results.append(result)\n        elif allow_list_match == \"exact\":\n            for result in results:\n                word = text[result.start : result.end]\n\n                # if the word is not specified to be allowed, keep in the PII entities\n                if word not in allow_list:\n                    new_results.append(result)\n        else:\n            raise ValueError(\n                \"allow_list_match must either be set to 'exact' or 'regex'.\"\n            )\n\n        return new_results\n\n    @staticmethod\n    def __add_recognizer_id_if_not_exists(\n        results: List[RecognizerResult], recognizer: EntityRecognizer\n    ) -&gt; None:\n        \"\"\"Ensure recognition metadata with recognizer id existence.\n\n        Ensure recognizer result list contains recognizer id inside recognition\n        metadata dictionary, and if not create it. recognizer_id is needed\n        for context aware enhancement.\n\n        :param results: List of RecognizerResult\n        :param recognizer: Entity recognizer\n        \"\"\"\n        for result in results:\n            if not result.recognition_metadata:\n                result.recognition_metadata = dict()\n            if (\n                RecognizerResult.RECOGNIZER_IDENTIFIER_KEY\n                not in result.recognition_metadata\n            ):\n                result.recognition_metadata[\n                    RecognizerResult.RECOGNIZER_IDENTIFIER_KEY\n                ] = recognizer.id\n            if RecognizerResult.RECOGNIZER_NAME_KEY not in result.recognition_metadata:\n                result.recognition_metadata[RecognizerResult.RECOGNIZER_NAME_KEY] = (\n                    recognizer.name\n                )\n\n    @staticmethod\n    def __remove_decision_process(\n        results: List[RecognizerResult],\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"Remove decision process / analysis explanation from response.\"\"\"\n\n        for result in results:\n            result.analysis_explanation = None\n\n        return results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.__add_recognizer_id_if_not_exists","title":"<code>__add_recognizer_id_if_not_exists(results, recognizer)</code>  <code>staticmethod</code>","text":"<p>Ensure recognition metadata with recognizer id existence.</p> <p>Ensure recognizer result list contains recognizer id inside recognition metadata dictionary, and if not create it. recognizer_id is needed for context aware enhancement.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>List[RecognizerResult]</code> <p>List of RecognizerResult</p> required <code>recognizer</code> <code>EntityRecognizer</code> <p>Entity recognizer</p> required Source code in <code>presidio_analyzer/analyzer_engine.py</code> <pre><code>@staticmethod\ndef __add_recognizer_id_if_not_exists(\n    results: List[RecognizerResult], recognizer: EntityRecognizer\n) -&gt; None:\n    \"\"\"Ensure recognition metadata with recognizer id existence.\n\n    Ensure recognizer result list contains recognizer id inside recognition\n    metadata dictionary, and if not create it. recognizer_id is needed\n    for context aware enhancement.\n\n    :param results: List of RecognizerResult\n    :param recognizer: Entity recognizer\n    \"\"\"\n    for result in results:\n        if not result.recognition_metadata:\n            result.recognition_metadata = dict()\n        if (\n            RecognizerResult.RECOGNIZER_IDENTIFIER_KEY\n            not in result.recognition_metadata\n        ):\n            result.recognition_metadata[\n                RecognizerResult.RECOGNIZER_IDENTIFIER_KEY\n            ] = recognizer.id\n        if RecognizerResult.RECOGNIZER_NAME_KEY not in result.recognition_metadata:\n            result.recognition_metadata[RecognizerResult.RECOGNIZER_NAME_KEY] = (\n                recognizer.name\n            )\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.__remove_decision_process","title":"<code>__remove_decision_process(results)</code>  <code>staticmethod</code>","text":"<p>Remove decision process / analysis explanation from response.</p> Source code in <code>presidio_analyzer/analyzer_engine.py</code> <pre><code>@staticmethod\ndef __remove_decision_process(\n    results: List[RecognizerResult],\n) -&gt; List[RecognizerResult]:\n    \"\"\"Remove decision process / analysis explanation from response.\"\"\"\n\n    for result in results:\n        result.analysis_explanation = None\n\n    return results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.__remove_low_scores","title":"<code>__remove_low_scores(results, score_threshold=None)</code>","text":"<p>Remove results for which the confidence is lower than the threshold.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>List[RecognizerResult]</code> <p>List of RecognizerResult</p> required <code>score_threshold</code> <code>float</code> <p>float value for minimum possible confidence</p> <code>None</code> <p>Returns:</p> Type Description <code>List[RecognizerResult]</code> <p>List[RecognizerResult]</p> Source code in <code>presidio_analyzer/analyzer_engine.py</code> <pre><code>def __remove_low_scores(\n    self, results: List[RecognizerResult], score_threshold: float = None\n) -&gt; List[RecognizerResult]:\n    \"\"\"\n    Remove results for which the confidence is lower than the threshold.\n\n    :param results: List of RecognizerResult\n    :param score_threshold: float value for minimum possible confidence\n    :return: List[RecognizerResult]\n    \"\"\"\n    if score_threshold is None:\n        score_threshold = self.default_score_threshold\n\n    new_results = [result for result in results if result.score &gt;= score_threshold]\n    return new_results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.analyze","title":"<code>analyze(text, language, entities=None, correlation_id=None, score_threshold=None, return_decision_process=False, ad_hoc_recognizers=None, context=None, allow_list=None, allow_list_match='exact', regex_flags=re.DOTALL | re.MULTILINE | re.IGNORECASE, nlp_artifacts=None)</code>","text":"<p>Find PII entities in text using different PII recognizers for a given language.</p> <p>:example:</p> <p>from presidio_analyzer import AnalyzerEngine</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>the text to analyze</p> required <code>language</code> <code>str</code> <p>the language of the text</p> required <code>entities</code> <code>Optional[List[str]]</code> <p>List of PII entities that should be looked for in the text. If entities=None then all entities are looked for.</p> <code>None</code> <code>correlation_id</code> <code>Optional[str]</code> <p>cross call ID for this request</p> <code>None</code> <code>score_threshold</code> <code>Optional[float]</code> <p>A minimum value for which to return an identified entity</p> <code>None</code> <code>return_decision_process</code> <code>Optional[bool]</code> <p>Whether the analysis decision process steps returned in the response.</p> <code>False</code> <code>ad_hoc_recognizers</code> <code>Optional[List[EntityRecognizer]]</code> <p>List of recognizers which will be used only for this specific request.</p> <code>None</code> <code>context</code> <code>Optional[List[str]]</code> <p>List of context words to enhance confidence score if matched with the recognized entity's recognizer context</p> <code>None</code> <code>allow_list</code> <code>Optional[List[str]]</code> <p>List of words that the user defines as being allowed to keep in the text</p> <code>None</code> <code>allow_list_match</code> <code>Optional[str]</code> <p>How the allow_list should be interpreted; either as \"exact\" or as \"regex\". - If <code>regex</code>, results which match with any regex condition in the allow_list would be allowed and not be returned as potential PII. - if <code>exact</code>, results which exactly match any value in the allow_list would be allowed and not be returned as potential PII.</p> <code>'exact'</code> <code>regex_flags</code> <code>Optional[int]</code> <p>regex flags to be used for when allow_list_match is \"regex\"</p> <code>DOTALL | MULTILINE | IGNORECASE</code> <code>nlp_artifacts</code> <code>Optional[NlpArtifacts]</code> <p>precomputed NlpArtifacts</p> <code>None</code> <p>Returns:</p> Type Description <code>List[RecognizerResult]</code> <p>an array of the found entities in the text</p> Source code in <code>presidio_analyzer/analyzer_engine.py</code> <pre><code>def analyze(\n    self,\n    text: str,\n    language: str,\n    entities: Optional[List[str]] = None,\n    correlation_id: Optional[str] = None,\n    score_threshold: Optional[float] = None,\n    return_decision_process: Optional[bool] = False,\n    ad_hoc_recognizers: Optional[List[EntityRecognizer]] = None,\n    context: Optional[List[str]] = None,\n    allow_list: Optional[List[str]] = None,\n    allow_list_match: Optional[str] = \"exact\",\n    regex_flags: Optional[int] = re.DOTALL | re.MULTILINE | re.IGNORECASE,\n    nlp_artifacts: Optional[NlpArtifacts] = None,\n) -&gt; List[RecognizerResult]:\n    \"\"\"\n    Find PII entities in text using different PII recognizers for a given language.\n\n    :param text: the text to analyze\n    :param language: the language of the text\n    :param entities: List of PII entities that should be looked for in the text.\n    If entities=None then all entities are looked for.\n    :param correlation_id: cross call ID for this request\n    :param score_threshold: A minimum value for which\n    to return an identified entity\n    :param return_decision_process: Whether the analysis decision process steps\n    returned in the response.\n    :param ad_hoc_recognizers: List of recognizers which will be used only\n    for this specific request.\n    :param context: List of context words to enhance confidence score if matched\n    with the recognized entity's recognizer context\n    :param allow_list: List of words that the user defines as being allowed to keep\n    in the text\n    :param allow_list_match: How the allow_list should be interpreted; either as \"exact\" or as \"regex\".\n    - If `regex`, results which match with any regex condition in the allow_list would be allowed and not be returned as potential PII.\n    - if `exact`, results which exactly match any value in the allow_list would be allowed and not be returned as potential PII.\n    :param regex_flags: regex flags to be used for when allow_list_match is \"regex\"\n    :param nlp_artifacts: precomputed NlpArtifacts\n    :return: an array of the found entities in the text\n\n    :example:\n\n    &gt;&gt;&gt; from presidio_analyzer import AnalyzerEngine\n\n    &gt;&gt;&gt; # Set up the engine, loads the NLP module (spaCy model by default)\n    &gt;&gt;&gt; # and other PII recognizers\n    &gt;&gt;&gt; analyzer = AnalyzerEngine()\n\n    &gt;&gt;&gt; # Call analyzer to get results\n    &gt;&gt;&gt; results = analyzer.analyze(text='My phone number is 212-555-5555', entities=['PHONE_NUMBER'], language='en') # noqa D501\n    &gt;&gt;&gt; print(results)\n    [type: PHONE_NUMBER, start: 19, end: 31, score: 0.85]\n    \"\"\"  # noqa: E501\n\n    all_fields = not entities\n\n    recognizers = self.registry.get_recognizers(\n        language=language,\n        entities=entities,\n        all_fields=all_fields,\n        ad_hoc_recognizers=ad_hoc_recognizers,\n    )\n\n    if all_fields:\n        # Since all_fields=True, list all entities by iterating\n        # over all recognizers\n        entities = self.get_supported_entities(language=language)\n\n    # run the nlp pipeline over the given text, store the results in\n    # a NlpArtifacts instance\n    if not nlp_artifacts:\n        nlp_artifacts = self.nlp_engine.process_text(text, language)\n\n    if self.log_decision_process:\n        self.app_tracer.trace(\n            correlation_id, \"nlp artifacts:\" + nlp_artifacts.to_json()\n        )\n\n    results = []\n    for recognizer in recognizers:\n        # Lazy loading of the relevant recognizers\n        if not recognizer.is_loaded:\n            recognizer.load()\n            recognizer.is_loaded = True\n\n        # analyze using the current recognizer and append the results\n        current_results = recognizer.analyze(\n            text=text, entities=entities, nlp_artifacts=nlp_artifacts\n        )\n        if current_results:\n            # add recognizer name to recognition metadata inside results\n            # if not exists\n            self.__add_recognizer_id_if_not_exists(current_results, recognizer)\n            results.extend(current_results)\n\n    results = self._enhance_using_context(\n        text, results, nlp_artifacts, recognizers, context\n    )\n\n    if self.log_decision_process:\n        self.app_tracer.trace(\n            correlation_id,\n            json.dumps([str(result.to_dict()) for result in results]),\n        )\n\n    # Remove duplicates or low score results\n    results = EntityRecognizer.remove_duplicates(results)\n    results = self.__remove_low_scores(results, score_threshold)\n\n    if allow_list:\n        results = self._remove_allow_list(\n            results, allow_list, text, regex_flags, allow_list_match\n        )\n\n    if not return_decision_process:\n        results = self.__remove_decision_process(results)\n\n    return results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.analyze--set-up-the-engine-loads-the-nlp-module-spacy-model-by-default","title":"Set up the engine, loads the NLP module (spaCy model by default)","text":""},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.analyze--and-other-pii-recognizers","title":"and other PII recognizers","text":"<p>analyzer = AnalyzerEngine()</p>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.analyze--call-analyzer-to-get-results","title":"Call analyzer to get results","text":"<p>results = analyzer.analyze(text='My phone number is 212-555-5555', entities=['PHONE_NUMBER'], language='en') # noqa D501 print(results) [type: PHONE_NUMBER, start: 19, end: 31, score: 0.85]</p>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.get_recognizers","title":"<code>get_recognizers(language=None)</code>","text":"<p>Return a list of PII recognizers currently loaded.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>Optional[str]</code> <p>Return the recognizers supporting a given language.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[EntityRecognizer]</code> <p>List of [Recognizer] as a RecognizersAllResponse</p> Source code in <code>presidio_analyzer/analyzer_engine.py</code> <pre><code>def get_recognizers(self, language: Optional[str] = None) -&gt; List[EntityRecognizer]:\n    \"\"\"\n    Return a list of PII recognizers currently loaded.\n\n    :param language: Return the recognizers supporting a given language.\n    :return: List of [Recognizer] as a RecognizersAllResponse\n    \"\"\"\n    if not language:\n        languages = self.supported_languages\n    else:\n        languages = [language]\n\n    recognizers = []\n    for language in languages:\n        logger.info(f\"Fetching all recognizers for language {language}\")\n        recognizers.extend(\n            self.registry.get_recognizers(language=language, all_fields=True)\n        )\n\n    return list(set(recognizers))\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngine.get_supported_entities","title":"<code>get_supported_entities(language=None)</code>","text":"<p>Return a list of the entities that can be detected.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>Optional[str]</code> <p>Return only entities supported in a specific language.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of entity names</p> Source code in <code>presidio_analyzer/analyzer_engine.py</code> <pre><code>def get_supported_entities(self, language: Optional[str] = None) -&gt; List[str]:\n    \"\"\"\n    Return a list of the entities that can be detected.\n\n    :param language: Return only entities supported in a specific language.\n    :return: List of entity names\n    \"\"\"\n    recognizers = self.get_recognizers(language=language)\n    supported_entities = []\n    for recognizer in recognizers:\n        supported_entities.extend(recognizer.get_supported_entities())\n\n    return list(set(supported_entities))\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngineProvider","title":"<code>AnalyzerEngineProvider</code>","text":"<p>Utility function for loading Presidio Analyzer.</p> <p>Use this class to load presidio analyzer engine from a yaml file</p> <p>Parameters:</p> Name Type Description Default <code>analyzer_engine_conf_file</code> <code>Optional[Union[Path, str]]</code> <p>the path to the analyzer configuration file</p> <code>None</code> <code>nlp_engine_conf_file</code> <code>Optional[Union[Path, str]]</code> <p>the path to the nlp engine configuration file</p> <code>None</code> <code>recognizer_registry_conf_file</code> <code>Optional[Union[Path, str]]</code> <p>the path to the recognizer registry configuration file</p> <code>None</code> Source code in <code>presidio_analyzer/analyzer_engine_provider.py</code> <pre><code>class AnalyzerEngineProvider:\n    \"\"\"\n    Utility function for loading Presidio Analyzer.\n\n    Use this class to load presidio analyzer engine from a yaml file\n\n    :param analyzer_engine_conf_file: the path to the analyzer configuration file\n    :param nlp_engine_conf_file: the path to the nlp engine configuration file\n    :param recognizer_registry_conf_file: the path to the recognizer\n    registry configuration file\n    \"\"\"\n\n    def __init__(\n        self,\n        analyzer_engine_conf_file: Optional[Union[Path, str]] = None,\n        nlp_engine_conf_file: Optional[Union[Path, str]] = None,\n        recognizer_registry_conf_file: Optional[Union[Path, str]] = None,\n    ):\n        self.configuration = self.get_configuration(conf_file=analyzer_engine_conf_file)\n        self.nlp_engine_conf_file = nlp_engine_conf_file\n        self.recognizer_registry_conf_file = recognizer_registry_conf_file\n\n    def get_configuration(\n        self, conf_file: Optional[Union[Path, str]]\n    ) -&gt; Union[Dict[str, Any]]:\n        \"\"\"Retrieve the analyzer engine configuration from the provided file.\"\"\"\n\n        if not conf_file:\n            default_conf_file = self._get_full_conf_path()\n            with open(default_conf_file) as file:\n                configuration = yaml.safe_load(file)\n            logger.info(\n                f\"Analyzer Engine configuration file \"\n                f\"not provided. Using {default_conf_file}.\"\n            )\n        else:\n            try:\n                logger.info(f\"Reading analyzer configuration from {conf_file}\")\n                with open(conf_file) as file:\n                    configuration = yaml.safe_load(file)\n            except OSError:\n                logger.warning(\n                    f\"configuration file {conf_file} not found.  \"\n                    f\"Using default config.\"\n                )\n                with open(self._get_full_conf_path()) as file:\n                    configuration = yaml.safe_load(file)\n            except Exception:\n                print(f\"Failed to parse file {conf_file}, resorting to default\")\n                with open(self._get_full_conf_path()) as file:\n                    configuration = yaml.safe_load(file)\n\n        return configuration\n\n    def create_engine(self) -&gt; AnalyzerEngine:\n        \"\"\"\n        Load Presidio Analyzer from yaml configuration file.\n\n        :return: analyzer engine initialized with yaml configuration\n        \"\"\"\n\n        nlp_engine = self._load_nlp_engine()\n        supported_languages = self.configuration.get(\"supported_languages\", [\"en\"])\n        default_score_threshold = self.configuration.get(\"default_score_threshold\", 0)\n\n        registry = self._load_recognizer_registry(\n            supported_languages=supported_languages, nlp_engine=nlp_engine\n        )\n\n        analyzer = AnalyzerEngine(\n            nlp_engine=nlp_engine,\n            registry=registry,\n            supported_languages=supported_languages,\n            default_score_threshold=default_score_threshold,\n        )\n\n        return analyzer\n\n    def _load_recognizer_registry(\n        self,\n        supported_languages: List[str],\n        nlp_engine: NlpEngine,\n    ) -&gt; RecognizerRegistry:\n        if self.recognizer_registry_conf_file:\n            logger.info(\n                f\"Reading recognizer registry \"\n                f\"configuration from {self.recognizer_registry_conf_file}\"\n            )\n            provider = RecognizerRegistryProvider(\n                conf_file=self.recognizer_registry_conf_file\n            )\n        elif \"recognizer_registry\" in self.configuration:\n            registry_configuration = self.configuration[\"recognizer_registry\"]\n            provider = RecognizerRegistryProvider(\n                registry_configuration={\n                    **registry_configuration,\n                    \"supported_languages\": supported_languages,\n                }\n            )\n        else:\n            logger.warning(\n                \"configuration file is missing for 'recognizer_registry'. \"\n                \"Using default configuration for recognizer registry\"\n            )\n            registry_configuration = self.configuration.get(\"recognizer_registry\", {})\n            provider = RecognizerRegistryProvider(\n                registry_configuration={\n                    **registry_configuration,\n                    \"supported_languages\": supported_languages,\n                }\n            )\n        registry = provider.create_recognizer_registry()\n        if nlp_engine:\n            registry.add_nlp_recognizer(nlp_engine)\n        return registry\n\n    def _load_nlp_engine(self) -&gt; NlpEngine:\n        if self.nlp_engine_conf_file:\n            logger.info(f\"Reading nlp configuration from {self.nlp_engine_conf_file}\")\n            provider = NlpEngineProvider(conf_file=self.nlp_engine_conf_file)\n        elif \"nlp_configuration\" in self.configuration:\n            nlp_configuration = self.configuration[\"nlp_configuration\"]\n            provider = NlpEngineProvider(nlp_configuration=nlp_configuration)\n        else:\n            logger.warning(\n                \"configuration file is missing for 'nlp_configuration'.\"\n                \"Using default configuration for nlp engine\"\n            )\n            provider = NlpEngineProvider()\n\n        return provider.create_engine()\n\n    @staticmethod\n    def _get_full_conf_path(\n        default_conf_file: Union[Path, str] = \"default_analyzer.yaml\",\n    ) -&gt; Path:\n        \"\"\"Return a Path to the default conf file.\"\"\"\n        return Path(Path(__file__).parent, \"conf\", default_conf_file)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngineProvider.create_engine","title":"<code>create_engine()</code>","text":"<p>Load Presidio Analyzer from yaml configuration file.</p> <p>Returns:</p> Type Description <code>AnalyzerEngine</code> <p>analyzer engine initialized with yaml configuration</p> Source code in <code>presidio_analyzer/analyzer_engine_provider.py</code> <pre><code>def create_engine(self) -&gt; AnalyzerEngine:\n    \"\"\"\n    Load Presidio Analyzer from yaml configuration file.\n\n    :return: analyzer engine initialized with yaml configuration\n    \"\"\"\n\n    nlp_engine = self._load_nlp_engine()\n    supported_languages = self.configuration.get(\"supported_languages\", [\"en\"])\n    default_score_threshold = self.configuration.get(\"default_score_threshold\", 0)\n\n    registry = self._load_recognizer_registry(\n        supported_languages=supported_languages, nlp_engine=nlp_engine\n    )\n\n    analyzer = AnalyzerEngine(\n        nlp_engine=nlp_engine,\n        registry=registry,\n        supported_languages=supported_languages,\n        default_score_threshold=default_score_threshold,\n    )\n\n    return analyzer\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerEngineProvider.get_configuration","title":"<code>get_configuration(conf_file)</code>","text":"<p>Retrieve the analyzer engine configuration from the provided file.</p> Source code in <code>presidio_analyzer/analyzer_engine_provider.py</code> <pre><code>def get_configuration(\n    self, conf_file: Optional[Union[Path, str]]\n) -&gt; Union[Dict[str, Any]]:\n    \"\"\"Retrieve the analyzer engine configuration from the provided file.\"\"\"\n\n    if not conf_file:\n        default_conf_file = self._get_full_conf_path()\n        with open(default_conf_file) as file:\n            configuration = yaml.safe_load(file)\n        logger.info(\n            f\"Analyzer Engine configuration file \"\n            f\"not provided. Using {default_conf_file}.\"\n        )\n    else:\n        try:\n            logger.info(f\"Reading analyzer configuration from {conf_file}\")\n            with open(conf_file) as file:\n                configuration = yaml.safe_load(file)\n        except OSError:\n            logger.warning(\n                f\"configuration file {conf_file} not found.  \"\n                f\"Using default config.\"\n            )\n            with open(self._get_full_conf_path()) as file:\n                configuration = yaml.safe_load(file)\n        except Exception:\n            print(f\"Failed to parse file {conf_file}, resorting to default\")\n            with open(self._get_full_conf_path()) as file:\n                configuration = yaml.safe_load(file)\n\n    return configuration\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.AnalyzerRequest","title":"<code>AnalyzerRequest</code>","text":"<p>Analyzer request data.</p> <p>Parameters:</p> Name Type Description Default <code>req_data</code> <code>Dict</code> <p>A request dictionary with the following fields: text: the text to analyze language: the language of the text entities: List of PII entities that should be looked for in the text. If entities=None then all entities are looked for. correlation_id: cross call ID for this request score_threshold: A minimum value for which to return an identified entity log_decision_process: Should the decision points within the analysis be logged return_decision_process: Should the decision points within the analysis returned as part of the response</p> required Source code in <code>presidio_analyzer/analyzer_request.py</code> <pre><code>class AnalyzerRequest:\n    \"\"\"\n    Analyzer request data.\n\n    :param req_data: A request dictionary with the following fields:\n        text: the text to analyze\n        language: the language of the text\n        entities: List of PII entities that should be looked for in the text.\n        If entities=None then all entities are looked for.\n        correlation_id: cross call ID for this request\n        score_threshold: A minimum value for which to return an identified entity\n        log_decision_process: Should the decision points within the analysis\n        be logged\n        return_decision_process: Should the decision points within the analysis\n        returned as part of the response\n    \"\"\"\n\n    def __init__(self, req_data: Dict):\n        self.text = req_data.get(\"text\")\n        self.language = req_data.get(\"language\")\n        self.entities = req_data.get(\"entities\")\n        self.correlation_id = req_data.get(\"correlation_id\")\n        self.score_threshold = req_data.get(\"score_threshold\")\n        self.return_decision_process = req_data.get(\"return_decision_process\")\n        ad_hoc_recognizers = req_data.get(\"ad_hoc_recognizers\")\n        self.ad_hoc_recognizers = []\n        if ad_hoc_recognizers:\n            self.ad_hoc_recognizers = [\n                PatternRecognizer.from_dict(rec) for rec in ad_hoc_recognizers\n            ]\n        self.context = req_data.get(\"context\")\n        self.allow_list = req_data.get(\"allow_list\")\n        self.allow_list_match = req_data.get(\"allow_list_match\", \"exact\")\n        self.regex_flags = req_data.get(\"regex_flags\",\n                                        re.DOTALL | re.MULTILINE | re.IGNORECASE)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.BatchAnalyzerEngine","title":"<code>BatchAnalyzerEngine</code>","text":"<p>Batch analysis of documents (tables, lists, dicts).</p> <p>Wrapper class to run Presidio Analyzer Engine on multiple values, either lists/iterators of strings, or dictionaries.</p> Source code in <code>presidio_analyzer/batch_analyzer_engine.py</code> <pre><code>class BatchAnalyzerEngine:\n    \"\"\"\n    Batch analysis of documents (tables, lists, dicts).\n\n    Wrapper class to run Presidio Analyzer Engine on multiple values,\n    either lists/iterators of strings, or dictionaries.\n\n    :param: analyzer_engine: AnalyzerEngine instance to use\n    for handling the values in those collections.\n    \"\"\"\n\n    def __init__(self, analyzer_engine: Optional[AnalyzerEngine] = None):\n        self.analyzer_engine = analyzer_engine\n        if not analyzer_engine:\n            self.analyzer_engine = AnalyzerEngine()\n\n    def analyze_iterator(\n        self,\n        texts: Iterable[Union[str, bool, float, int]],\n        language: str,\n        batch_size: Optional[int] = None,\n        **kwargs,\n    ) -&gt; List[List[RecognizerResult]]:\n        \"\"\"\n        Analyze an iterable of strings.\n\n        :param texts: An list containing strings to be analyzed.\n        :param language: Input language\n        :param batch_size: Batch size to process in a single iteration\n        :param kwargs: Additional parameters for the `AnalyzerEngine.analyze` method.\n        (default value depends on the nlp engine implementation)\n        \"\"\"\n\n        # validate types\n        texts = self._validate_types(texts)\n\n        # Process the texts as batch for improved performance\n        nlp_artifacts_batch: Iterator[Tuple[str, NlpArtifacts]] = (\n            self.analyzer_engine.nlp_engine.process_batch(\n                texts=texts, language=language, batch_size=batch_size\n            )\n        )\n\n        list_results = []\n        for text, nlp_artifacts in nlp_artifacts_batch:\n            results = self.analyzer_engine.analyze(\n                text=str(text), nlp_artifacts=nlp_artifacts, language=language, **kwargs\n            )\n\n            list_results.append(results)\n\n        return list_results\n\n    def analyze_dict(\n        self,\n        input_dict: Dict[str, Union[Any, Iterable[Any]]],\n        language: str,\n        keys_to_skip: Optional[List[str]] = None,\n        **kwargs,\n    ) -&gt; Iterator[DictAnalyzerResult]:\n        \"\"\"\n        Analyze a dictionary of keys (strings) and values/iterable of values.\n\n        Non-string values are returned as is.\n\n        :param input_dict: The input dictionary for analysis\n        :param language: Input language\n        :param keys_to_skip: Keys to ignore during analysis\n        :param kwargs: Additional keyword arguments\n        for the `AnalyzerEngine.analyze` method.\n        Use this to pass arguments to the analyze method,\n        such as `ad_hoc_recognizers`, `context`, `return_decision_process`.\n        See `AnalyzerEngine.analyze` for the full list.\n        \"\"\"\n\n        context = []\n        if \"context\" in kwargs:\n            context = kwargs[\"context\"]\n            del kwargs[\"context\"]\n\n        if not keys_to_skip:\n            keys_to_skip = []\n\n        for key, value in input_dict.items():\n            if not value or key in keys_to_skip:\n                yield DictAnalyzerResult(key=key, value=value, recognizer_results=[])\n                continue  # skip this key as requested\n\n            # Add the key as an additional context\n            specific_context = context[:]\n            specific_context.append(key)\n\n            if type(value) in (str, int, bool, float):\n                results: List[RecognizerResult] = self.analyzer_engine.analyze(\n                    text=str(value), language=language, context=[key], **kwargs\n                )\n            elif isinstance(value, dict):\n                new_keys_to_skip = self._get_nested_keys_to_skip(key, keys_to_skip)\n                results = self.analyze_dict(\n                    input_dict=value,\n                    language=language,\n                    context=specific_context,\n                    keys_to_skip=new_keys_to_skip,\n                    **kwargs,\n                )\n            elif isinstance(value, Iterable):\n                # Recursively iterate nested dicts\n\n                results: List[List[RecognizerResult]] = self.analyze_iterator(\n                    texts=value,\n                    language=language,\n                    context=specific_context,\n                    **kwargs,\n                )\n            else:\n                raise ValueError(f\"type {type(value)} is unsupported.\")\n\n            yield DictAnalyzerResult(key=key, value=value, recognizer_results=results)\n\n    @staticmethod\n    def _validate_types(value_iterator: Iterable[Any]) -&gt; Iterator[Any]:\n        for val in value_iterator:\n            if val and type(val) not in (int, float, bool, str):\n                err_msg = (\n                    \"Analyzer.analyze_iterator only works \"\n                    \"on primitive types (int, float, bool, str). \"\n                    \"Lists of objects are not yet supported.\"\n                )\n                logger.error(err_msg)\n                raise ValueError(err_msg)\n            yield val\n\n    @staticmethod\n    def _get_nested_keys_to_skip(key, keys_to_skip):\n        new_keys_to_skip = [\n            k.replace(f\"{key}.\", \"\") for k in keys_to_skip if k.startswith(key)\n        ]\n        return new_keys_to_skip\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.BatchAnalyzerEngine.analyze_dict","title":"<code>analyze_dict(input_dict, language, keys_to_skip=None, **kwargs)</code>","text":"<p>Analyze a dictionary of keys (strings) and values/iterable of values.</p> <p>Non-string values are returned as is.</p> <p>Parameters:</p> Name Type Description Default <code>input_dict</code> <code>Dict[str, Union[Any, Iterable[Any]]]</code> <p>The input dictionary for analysis</p> required <code>language</code> <code>str</code> <p>Input language</p> required <code>keys_to_skip</code> <code>Optional[List[str]]</code> <p>Keys to ignore during analysis</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments for the <code>AnalyzerEngine.analyze</code> method. Use this to pass arguments to the analyze method, such as <code>ad_hoc_recognizers</code>, <code>context</code>, <code>return_decision_process</code>. See <code>AnalyzerEngine.analyze</code> for the full list.</p> <code>{}</code> Source code in <code>presidio_analyzer/batch_analyzer_engine.py</code> <pre><code>def analyze_dict(\n    self,\n    input_dict: Dict[str, Union[Any, Iterable[Any]]],\n    language: str,\n    keys_to_skip: Optional[List[str]] = None,\n    **kwargs,\n) -&gt; Iterator[DictAnalyzerResult]:\n    \"\"\"\n    Analyze a dictionary of keys (strings) and values/iterable of values.\n\n    Non-string values are returned as is.\n\n    :param input_dict: The input dictionary for analysis\n    :param language: Input language\n    :param keys_to_skip: Keys to ignore during analysis\n    :param kwargs: Additional keyword arguments\n    for the `AnalyzerEngine.analyze` method.\n    Use this to pass arguments to the analyze method,\n    such as `ad_hoc_recognizers`, `context`, `return_decision_process`.\n    See `AnalyzerEngine.analyze` for the full list.\n    \"\"\"\n\n    context = []\n    if \"context\" in kwargs:\n        context = kwargs[\"context\"]\n        del kwargs[\"context\"]\n\n    if not keys_to_skip:\n        keys_to_skip = []\n\n    for key, value in input_dict.items():\n        if not value or key in keys_to_skip:\n            yield DictAnalyzerResult(key=key, value=value, recognizer_results=[])\n            continue  # skip this key as requested\n\n        # Add the key as an additional context\n        specific_context = context[:]\n        specific_context.append(key)\n\n        if type(value) in (str, int, bool, float):\n            results: List[RecognizerResult] = self.analyzer_engine.analyze(\n                text=str(value), language=language, context=[key], **kwargs\n            )\n        elif isinstance(value, dict):\n            new_keys_to_skip = self._get_nested_keys_to_skip(key, keys_to_skip)\n            results = self.analyze_dict(\n                input_dict=value,\n                language=language,\n                context=specific_context,\n                keys_to_skip=new_keys_to_skip,\n                **kwargs,\n            )\n        elif isinstance(value, Iterable):\n            # Recursively iterate nested dicts\n\n            results: List[List[RecognizerResult]] = self.analyze_iterator(\n                texts=value,\n                language=language,\n                context=specific_context,\n                **kwargs,\n            )\n        else:\n            raise ValueError(f\"type {type(value)} is unsupported.\")\n\n        yield DictAnalyzerResult(key=key, value=value, recognizer_results=results)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.BatchAnalyzerEngine.analyze_iterator","title":"<code>analyze_iterator(texts, language, batch_size=None, **kwargs)</code>","text":"<p>Analyze an iterable of strings.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>Iterable[Union[str, bool, float, int]]</code> <p>An list containing strings to be analyzed.</p> required <code>language</code> <code>str</code> <p>Input language</p> required <code>batch_size</code> <code>Optional[int]</code> <p>Batch size to process in a single iteration</p> <code>None</code> <code>kwargs</code> <p>Additional parameters for the <code>AnalyzerEngine.analyze</code> method. (default value depends on the nlp engine implementation)</p> <code>{}</code> Source code in <code>presidio_analyzer/batch_analyzer_engine.py</code> <pre><code>def analyze_iterator(\n    self,\n    texts: Iterable[Union[str, bool, float, int]],\n    language: str,\n    batch_size: Optional[int] = None,\n    **kwargs,\n) -&gt; List[List[RecognizerResult]]:\n    \"\"\"\n    Analyze an iterable of strings.\n\n    :param texts: An list containing strings to be analyzed.\n    :param language: Input language\n    :param batch_size: Batch size to process in a single iteration\n    :param kwargs: Additional parameters for the `AnalyzerEngine.analyze` method.\n    (default value depends on the nlp engine implementation)\n    \"\"\"\n\n    # validate types\n    texts = self._validate_types(texts)\n\n    # Process the texts as batch for improved performance\n    nlp_artifacts_batch: Iterator[Tuple[str, NlpArtifacts]] = (\n        self.analyzer_engine.nlp_engine.process_batch(\n            texts=texts, language=language, batch_size=batch_size\n        )\n    )\n\n    list_results = []\n    for text, nlp_artifacts in nlp_artifacts_batch:\n        results = self.analyzer_engine.analyze(\n            text=str(text), nlp_artifacts=nlp_artifacts, language=language, **kwargs\n        )\n\n        list_results.append(results)\n\n    return list_results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.ContextAwareEnhancer","title":"<code>ContextAwareEnhancer</code>","text":"<p>A class representing an abstract context aware enhancer.</p> <p>Context words might enhance confidence score of a recognized entity, ContextAwareEnhancer is an abstract class to be inherited by a context aware enhancer logic.</p> <p>Parameters:</p> Name Type Description Default <code>context_similarity_factor</code> <code>float</code> <p>How much to enhance confidence of match entity</p> required <code>min_score_with_context_similarity</code> <code>float</code> <p>Minimum confidence score</p> required <code>context_prefix_count</code> <code>int</code> <p>how many words before the entity to match context</p> required <code>context_suffix_count</code> <code>int</code> <p>how many words after the entity to match context</p> required Source code in <code>presidio_analyzer/context_aware_enhancers/context_aware_enhancer.py</code> <pre><code>class ContextAwareEnhancer:\n    \"\"\"\n    A class representing an abstract context aware enhancer.\n\n    Context words might enhance confidence score of a recognized entity,\n    ContextAwareEnhancer is an abstract class to be inherited by a context aware\n    enhancer logic.\n\n    :param context_similarity_factor: How much to enhance confidence of match entity\n    :param min_score_with_context_similarity: Minimum confidence score\n    :param context_prefix_count: how many words before the entity to match context\n    :param context_suffix_count: how many words after the entity to match context\n    \"\"\"\n\n    MIN_SCORE = 0\n    MAX_SCORE = 1.0\n\n    def __init__(\n        self,\n        context_similarity_factor: float,\n        min_score_with_context_similarity: float,\n        context_prefix_count: int,\n        context_suffix_count: int,\n    ):\n        self.context_similarity_factor = context_similarity_factor\n        self.min_score_with_context_similarity = min_score_with_context_similarity\n        self.context_prefix_count = context_prefix_count\n        self.context_suffix_count = context_suffix_count\n\n    @abstractmethod\n    def enhance_using_context(\n        self,\n        text: str,\n        raw_results: List[RecognizerResult],\n        nlp_artifacts: NlpArtifacts,\n        recognizers: List[EntityRecognizer],\n        context: Optional[List[str]] = None,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Update results in case surrounding words are relevant to the context words.\n\n        Using the surrounding words of the actual word matches, look\n        for specific strings that if found contribute to the score\n        of the result, improving the confidence that the match is\n        indeed of that PII entity type\n\n        :param text: The actual text that was analyzed\n        :param raw_results: Recognizer results which didn't take\n                            context into consideration\n        :param nlp_artifacts: The nlp artifacts contains elements\n                              such as lemmatized tokens for better\n                              accuracy of the context enhancement process\n        :param recognizers: the list of recognizers\n        :param context: list of context words\n        \"\"\"\n        return raw_results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.ContextAwareEnhancer.enhance_using_context","title":"<code>enhance_using_context(text, raw_results, nlp_artifacts, recognizers, context=None)</code>  <code>abstractmethod</code>","text":"<p>Update results in case surrounding words are relevant to the context words.</p> <p>Using the surrounding words of the actual word matches, look for specific strings that if found contribute to the score of the result, improving the confidence that the match is indeed of that PII entity type</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The actual text that was analyzed</p> required <code>raw_results</code> <code>List[RecognizerResult]</code> <p>Recognizer results which didn't take context into consideration</p> required <code>nlp_artifacts</code> <code>NlpArtifacts</code> <p>The nlp artifacts contains elements such as lemmatized tokens for better accuracy of the context enhancement process</p> required <code>recognizers</code> <code>List[EntityRecognizer]</code> <p>the list of recognizers</p> required <code>context</code> <code>Optional[List[str]]</code> <p>list of context words</p> <code>None</code> Source code in <code>presidio_analyzer/context_aware_enhancers/context_aware_enhancer.py</code> <pre><code>@abstractmethod\ndef enhance_using_context(\n    self,\n    text: str,\n    raw_results: List[RecognizerResult],\n    nlp_artifacts: NlpArtifacts,\n    recognizers: List[EntityRecognizer],\n    context: Optional[List[str]] = None,\n) -&gt; List[RecognizerResult]:\n    \"\"\"\n    Update results in case surrounding words are relevant to the context words.\n\n    Using the surrounding words of the actual word matches, look\n    for specific strings that if found contribute to the score\n    of the result, improving the confidence that the match is\n    indeed of that PII entity type\n\n    :param text: The actual text that was analyzed\n    :param raw_results: Recognizer results which didn't take\n                        context into consideration\n    :param nlp_artifacts: The nlp artifacts contains elements\n                          such as lemmatized tokens for better\n                          accuracy of the context enhancement process\n    :param recognizers: the list of recognizers\n    :param context: list of context words\n    \"\"\"\n    return raw_results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.DictAnalyzerResult","title":"<code>DictAnalyzerResult</code>  <code>dataclass</code>","text":"<p>Data class for holding the output of the Presidio Analyzer on dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>key in dictionary</p> required <code>value</code> <code>Union[str, List[str], dict]</code> <p>value to run analysis on (either string or list of strings)</p> required <code>recognizer_results</code> <code>Union[List[RecognizerResult], List[List[RecognizerResult]], Iterator[DictAnalyzerResult]]</code> <p>Analyzer output for one value. Could be either: - A list of recognizer results if the input is one string - A list of lists of recognizer results, if the input is a list of strings. - An iterator of a DictAnalyzerResult, if the input is a dictionary. In this case the recognizer_results would be the iterator of the DictAnalyzerResults next level in the dictionary.</p> required Source code in <code>presidio_analyzer/dict_analyzer_result.py</code> <pre><code>@dataclass\nclass DictAnalyzerResult:\n    \"\"\"\n    Data class for holding the output of the Presidio Analyzer on dictionaries.\n\n    :param key: key in dictionary\n    :param value: value to run analysis on (either string or list of strings)\n    :param recognizer_results: Analyzer output for one value.\n    Could be either:\n     - A list of recognizer results if the input is one string\n     - A list of lists of recognizer results, if the input is a list of strings.\n     - An iterator of a DictAnalyzerResult, if the input is a dictionary.\n     In this case the recognizer_results would be the iterator\n     of the DictAnalyzerResults next level in the dictionary.\n    \"\"\"\n\n    key: str\n    value: Union[str, List[str], dict]\n    recognizer_results: Union[\n        List[RecognizerResult],\n        List[List[RecognizerResult]],\n        Iterator[\"DictAnalyzerResult\"],\n    ]\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer","title":"<code>EntityRecognizer</code>","text":"<p>A class representing an abstract PII entity recognizer.</p> <p>EntityRecognizer is an abstract class to be inherited by Recognizers which hold the logic for recognizing specific PII entities.</p> <p>EntityRecognizer exposes a method called enhance_using_context which can be overridden in case a custom context aware enhancement is needed in derived class of a recognizer.</p> <p>Parameters:</p> Name Type Description Default <code>supported_entities</code> <code>List[str]</code> <p>the entities supported by this recognizer (for example, phone number, address, etc.)</p> required <code>supported_language</code> <code>str</code> <p>the language supported by this recognizer. The supported langauge code is iso6391Name</p> <code>'en'</code> <code>name</code> <code>str</code> <p>the name of this recognizer (optional)</p> <code>None</code> <code>version</code> <code>str</code> <p>the recognizer current version</p> <code>'0.0.1'</code> <code>context</code> <code>Optional[List[str]]</code> <p>a list of words which can help boost confidence score when they appear in context of the matched entity</p> <code>None</code> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>class EntityRecognizer:\n    \"\"\"\n    A class representing an abstract PII entity recognizer.\n\n    EntityRecognizer is an abstract class to be inherited by\n    Recognizers which hold the logic for recognizing specific PII entities.\n\n    EntityRecognizer exposes a method called enhance_using_context which\n    can be overridden in case a custom context aware enhancement is needed\n    in derived class of a recognizer.\n\n    :param supported_entities: the entities supported by this recognizer\n    (for example, phone number, address, etc.)\n    :param supported_language: the language supported by this recognizer.\n    The supported langauge code is iso6391Name\n    :param name: the name of this recognizer (optional)\n    :param version: the recognizer current version\n    :param context: a list of words which can help boost confidence score\n    when they appear in context of the matched entity\n    \"\"\"\n\n    MIN_SCORE = 0\n    MAX_SCORE = 1.0\n\n    def __init__(\n        self,\n        supported_entities: List[str],\n        name: str = None,\n        supported_language: str = \"en\",\n        version: str = \"0.0.1\",\n        context: Optional[List[str]] = None,\n    ):\n        self.supported_entities = supported_entities\n\n        if name is None:\n            self.name = self.__class__.__name__  # assign class name as name\n        else:\n            self.name = name\n\n        self._id = f\"{self.name}_{id(self)}\"\n\n        self.supported_language = supported_language\n        self.version = version\n        self.is_loaded = False\n        self.context = context if context else []\n\n        self.load()\n        logger.info(\"Loaded recognizer: %s\", self.name)\n        self.is_loaded = True\n\n    @property\n    def id(self):\n        \"\"\"Return a unique identifier of this recognizer.\"\"\"\n\n        return self._id\n\n    @abstractmethod\n    def load(self) -&gt; None:\n        \"\"\"\n        Initialize the recognizer assets if needed.\n\n        (e.g. machine learning models)\n        \"\"\"\n\n    @abstractmethod\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Analyze text to identify entities.\n\n        :param text: The text to be analyzed\n        :param entities: The list of entities this recognizer is able to detect\n        :param nlp_artifacts: A group of attributes which are the result of\n        an NLP process over the input text.\n        :return: List of results detected by this recognizer.\n        \"\"\"\n        return None\n\n    def enhance_using_context(\n        self,\n        text: str,\n        raw_recognizer_results: List[RecognizerResult],\n        other_raw_recognizer_results: List[RecognizerResult],\n        nlp_artifacts: NlpArtifacts,\n        context: Optional[List[str]] = None,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"Enhance confidence score using context of the entity.\n\n        Override this method in derived class in case a custom logic\n        is needed, otherwise return value will be equal to\n        raw_results.\n\n        in case a result score is boosted, derived class need to update\n        result.recognition_metadata[RecognizerResult.IS_SCORE_ENHANCED_BY_CONTEXT_KEY]\n\n        :param text: The actual text that was analyzed\n        :param raw_recognizer_results: This recognizer's results, to be updated\n        based on recognizer specific context.\n        :param other_raw_recognizer_results: Other recognizer results matched in\n        the given text to allow related entity context enhancement\n        :param nlp_artifacts: The nlp artifacts contains elements\n                              such as lemmatized tokens for better\n                              accuracy of the context enhancement process\n        :param context: list of context words\n        \"\"\"\n        return raw_recognizer_results\n\n    def get_supported_entities(self) -&gt; List[str]:\n        \"\"\"\n        Return the list of entities this recognizer can identify.\n\n        :return: A list of the supported entities by this recognizer\n        \"\"\"\n        return self.supported_entities\n\n    def get_supported_language(self) -&gt; str:\n        \"\"\"\n        Return the language this recognizer can support.\n\n        :return: A list of the supported language by this recognizer\n        \"\"\"\n        return self.supported_language\n\n    def get_version(self) -&gt; str:\n        \"\"\"\n        Return the version of this recognizer.\n\n        :return: The current version of this recognizer\n        \"\"\"\n        return self.version\n\n    def to_dict(self) -&gt; Dict:\n        \"\"\"\n        Serialize self to dictionary.\n\n        :return: a dictionary\n        \"\"\"\n        return_dict = {\n            \"supported_entities\": self.supported_entities,\n            \"supported_language\": self.supported_language,\n            \"name\": self.name,\n            \"version\": self.version,\n        }\n        return return_dict\n\n    @classmethod\n    def from_dict(cls, entity_recognizer_dict: Dict) -&gt; \"EntityRecognizer\":\n        \"\"\"\n        Create EntityRecognizer from a dict input.\n\n        :param entity_recognizer_dict: Dict containing keys and values for instantiation\n        \"\"\"\n        return cls(**entity_recognizer_dict)\n\n    @staticmethod\n    def remove_duplicates(results: List[RecognizerResult]) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Remove duplicate results.\n\n        Remove duplicates in case the two results\n        have identical start and ends and types.\n        :param results: List[RecognizerResult]\n        :return: List[RecognizerResult]\n        \"\"\"\n        results = list(set(results))\n        results = sorted(results, key=lambda x: (-x.score, x.start, -(x.end - x.start)))\n        filtered_results = []\n\n        for result in results:\n            if result.score == 0:\n                continue\n\n            to_keep = result not in filtered_results  # equals based comparison\n            if to_keep:\n                for filtered in filtered_results:\n                    # If result is contained in one of the other results\n                    if (\n                        result.contained_in(filtered)\n                        and result.entity_type == filtered.entity_type\n                    ):\n                        to_keep = False\n                        break\n\n            if to_keep:\n                filtered_results.append(result)\n\n        return filtered_results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.id","title":"<code>id</code>  <code>property</code>","text":"<p>Return a unique identifier of this recognizer.</p>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.analyze","title":"<code>analyze(text, entities, nlp_artifacts)</code>  <code>abstractmethod</code>","text":"<p>Analyze text to identify entities.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to be analyzed</p> required <code>entities</code> <code>List[str]</code> <p>The list of entities this recognizer is able to detect</p> required <code>nlp_artifacts</code> <code>NlpArtifacts</code> <p>A group of attributes which are the result of an NLP process over the input text.</p> required <p>Returns:</p> Type Description <code>List[RecognizerResult]</code> <p>List of results detected by this recognizer.</p> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>@abstractmethod\ndef analyze(\n    self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n) -&gt; List[RecognizerResult]:\n    \"\"\"\n    Analyze text to identify entities.\n\n    :param text: The text to be analyzed\n    :param entities: The list of entities this recognizer is able to detect\n    :param nlp_artifacts: A group of attributes which are the result of\n    an NLP process over the input text.\n    :return: List of results detected by this recognizer.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.enhance_using_context","title":"<code>enhance_using_context(text, raw_recognizer_results, other_raw_recognizer_results, nlp_artifacts, context=None)</code>","text":"<p>Enhance confidence score using context of the entity.</p> <p>Override this method in derived class in case a custom logic is needed, otherwise return value will be equal to raw_results.</p> <p>in case a result score is boosted, derived class need to update result.recognition_metadata[RecognizerResult.IS_SCORE_ENHANCED_BY_CONTEXT_KEY]</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The actual text that was analyzed</p> required <code>raw_recognizer_results</code> <code>List[RecognizerResult]</code> <p>This recognizer's results, to be updated based on recognizer specific context.</p> required <code>other_raw_recognizer_results</code> <code>List[RecognizerResult]</code> <p>Other recognizer results matched in the given text to allow related entity context enhancement</p> required <code>nlp_artifacts</code> <code>NlpArtifacts</code> <p>The nlp artifacts contains elements such as lemmatized tokens for better accuracy of the context enhancement process</p> required <code>context</code> <code>Optional[List[str]]</code> <p>list of context words</p> <code>None</code> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>def enhance_using_context(\n    self,\n    text: str,\n    raw_recognizer_results: List[RecognizerResult],\n    other_raw_recognizer_results: List[RecognizerResult],\n    nlp_artifacts: NlpArtifacts,\n    context: Optional[List[str]] = None,\n) -&gt; List[RecognizerResult]:\n    \"\"\"Enhance confidence score using context of the entity.\n\n    Override this method in derived class in case a custom logic\n    is needed, otherwise return value will be equal to\n    raw_results.\n\n    in case a result score is boosted, derived class need to update\n    result.recognition_metadata[RecognizerResult.IS_SCORE_ENHANCED_BY_CONTEXT_KEY]\n\n    :param text: The actual text that was analyzed\n    :param raw_recognizer_results: This recognizer's results, to be updated\n    based on recognizer specific context.\n    :param other_raw_recognizer_results: Other recognizer results matched in\n    the given text to allow related entity context enhancement\n    :param nlp_artifacts: The nlp artifacts contains elements\n                          such as lemmatized tokens for better\n                          accuracy of the context enhancement process\n    :param context: list of context words\n    \"\"\"\n    return raw_recognizer_results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.from_dict","title":"<code>from_dict(entity_recognizer_dict)</code>  <code>classmethod</code>","text":"<p>Create EntityRecognizer from a dict input.</p> <p>Parameters:</p> Name Type Description Default <code>entity_recognizer_dict</code> <code>Dict</code> <p>Dict containing keys and values for instantiation</p> required Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>@classmethod\ndef from_dict(cls, entity_recognizer_dict: Dict) -&gt; \"EntityRecognizer\":\n    \"\"\"\n    Create EntityRecognizer from a dict input.\n\n    :param entity_recognizer_dict: Dict containing keys and values for instantiation\n    \"\"\"\n    return cls(**entity_recognizer_dict)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.get_supported_entities","title":"<code>get_supported_entities()</code>","text":"<p>Return the list of entities this recognizer can identify.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of the supported entities by this recognizer</p> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>def get_supported_entities(self) -&gt; List[str]:\n    \"\"\"\n    Return the list of entities this recognizer can identify.\n\n    :return: A list of the supported entities by this recognizer\n    \"\"\"\n    return self.supported_entities\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.get_supported_language","title":"<code>get_supported_language()</code>","text":"<p>Return the language this recognizer can support.</p> <p>Returns:</p> Type Description <code>str</code> <p>A list of the supported language by this recognizer</p> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>def get_supported_language(self) -&gt; str:\n    \"\"\"\n    Return the language this recognizer can support.\n\n    :return: A list of the supported language by this recognizer\n    \"\"\"\n    return self.supported_language\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.get_version","title":"<code>get_version()</code>","text":"<p>Return the version of this recognizer.</p> <p>Returns:</p> Type Description <code>str</code> <p>The current version of this recognizer</p> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>def get_version(self) -&gt; str:\n    \"\"\"\n    Return the version of this recognizer.\n\n    :return: The current version of this recognizer\n    \"\"\"\n    return self.version\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.load","title":"<code>load()</code>  <code>abstractmethod</code>","text":"<p>Initialize the recognizer assets if needed.</p> <p>(e.g. machine learning models)</p> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>@abstractmethod\ndef load(self) -&gt; None:\n    \"\"\"\n    Initialize the recognizer assets if needed.\n\n    (e.g. machine learning models)\n    \"\"\"\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.remove_duplicates","title":"<code>remove_duplicates(results)</code>  <code>staticmethod</code>","text":"<p>Remove duplicate results.</p> <p>Remove duplicates in case the two results have identical start and ends and types.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>List[RecognizerResult]</code> <p>List[RecognizerResult]</p> required <p>Returns:</p> Type Description <code>List[RecognizerResult]</code> <p>List[RecognizerResult]</p> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>@staticmethod\ndef remove_duplicates(results: List[RecognizerResult]) -&gt; List[RecognizerResult]:\n    \"\"\"\n    Remove duplicate results.\n\n    Remove duplicates in case the two results\n    have identical start and ends and types.\n    :param results: List[RecognizerResult]\n    :return: List[RecognizerResult]\n    \"\"\"\n    results = list(set(results))\n    results = sorted(results, key=lambda x: (-x.score, x.start, -(x.end - x.start)))\n    filtered_results = []\n\n    for result in results:\n        if result.score == 0:\n            continue\n\n        to_keep = result not in filtered_results  # equals based comparison\n        if to_keep:\n            for filtered in filtered_results:\n                # If result is contained in one of the other results\n                if (\n                    result.contained_in(filtered)\n                    and result.entity_type == filtered.entity_type\n                ):\n                    to_keep = False\n                    break\n\n        if to_keep:\n            filtered_results.append(result)\n\n    return filtered_results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.EntityRecognizer.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize self to dictionary.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>a dictionary</p> Source code in <code>presidio_analyzer/entity_recognizer.py</code> <pre><code>def to_dict(self) -&gt; Dict:\n    \"\"\"\n    Serialize self to dictionary.\n\n    :return: a dictionary\n    \"\"\"\n    return_dict = {\n        \"supported_entities\": self.supported_entities,\n        \"supported_language\": self.supported_language,\n        \"name\": self.name,\n        \"version\": self.version,\n    }\n    return return_dict\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.LemmaContextAwareEnhancer","title":"<code>LemmaContextAwareEnhancer</code>","text":"<p>               Bases: <code>ContextAwareEnhancer</code></p> <p>A class representing a lemma based context aware enhancer logic.</p> <p>Context words might enhance confidence score of a recognized entity, LemmaContextAwareEnhancer is an implementation of Lemma based context aware logic, it compares spacy lemmas of each word in context of the matched entity to given context and the recognizer context words, if matched it enhance the recognized entity confidence score by a given factor.</p> <p>Parameters:</p> Name Type Description Default <code>context_similarity_factor</code> <code>float</code> <p>How much to enhance confidence of match entity</p> <code>0.35</code> <code>min_score_with_context_similarity</code> <code>float</code> <p>Minimum confidence score</p> <code>0.4</code> <code>context_prefix_count</code> <code>int</code> <p>how many words before the entity to match context</p> <code>5</code> <code>context_suffix_count</code> <code>int</code> <p>how many words after the entity to match context</p> <code>0</code> Source code in <code>presidio_analyzer/context_aware_enhancers/lemma_context_aware_enhancer.py</code> <pre><code>class LemmaContextAwareEnhancer(ContextAwareEnhancer):\n    \"\"\"\n    A class representing a lemma based context aware enhancer logic.\n\n    Context words might enhance confidence score of a recognized entity,\n    LemmaContextAwareEnhancer is an implementation of Lemma based context aware logic,\n    it compares spacy lemmas of each word in context of the matched entity to given\n    context and the recognizer context words,\n    if matched it enhance the recognized entity confidence score by a given factor.\n\n    :param context_similarity_factor: How much to enhance confidence of match entity\n    :param min_score_with_context_similarity: Minimum confidence score\n    :param context_prefix_count: how many words before the entity to match context\n    :param context_suffix_count: how many words after the entity to match context\n    \"\"\"\n\n    def __init__(\n        self,\n        context_similarity_factor: float = 0.35,\n        min_score_with_context_similarity: float = 0.4,\n        context_prefix_count: int = 5,\n        context_suffix_count: int = 0,\n    ):\n        super().__init__(\n            context_similarity_factor=context_similarity_factor,\n            min_score_with_context_similarity=min_score_with_context_similarity,\n            context_prefix_count=context_prefix_count,\n            context_suffix_count=context_suffix_count,\n        )\n\n    def enhance_using_context(\n        self,\n        text: str,\n        raw_results: List[RecognizerResult],\n        nlp_artifacts: NlpArtifacts,\n        recognizers: List[EntityRecognizer],\n        context: Optional[List[str]] = None,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Update results in case the lemmas of surrounding words or input context\n        words are identical to the context words.\n\n        Using the surrounding words of the actual word matches, look\n        for specific strings that if found contribute to the score\n        of the result, improving the confidence that the match is\n        indeed of that PII entity type\n\n        :param text: The actual text that was analyzed\n        :param raw_results: Recognizer results which didn't take\n                            context into consideration\n        :param nlp_artifacts: The nlp artifacts contains elements\n                              such as lemmatized tokens for better\n                              accuracy of the context enhancement process\n        :param recognizers: the list of recognizers\n        :param context: list of context words\n        \"\"\"  # noqa D205 D400\n\n        # create a deep copy of the results object, so we can manipulate it\n        results = copy.deepcopy(raw_results)\n\n        # create recognizer context dictionary\n        recognizers_dict = {recognizer.id: recognizer for recognizer in recognizers}\n\n        # Create empty list in None or lowercase all context words in the list\n        if not context:\n            context = []\n        else:\n            context = [word.lower() for word in context]\n\n        # Sanity\n        if nlp_artifacts is None:\n            logger.warning(\"NLP artifacts were not provided\")\n            return results\n\n        for result in results:\n            recognizer = None\n            # get recognizer matching the result, if found.\n            if (\n                result.recognition_metadata\n                and RecognizerResult.RECOGNIZER_IDENTIFIER_KEY\n                in result.recognition_metadata.keys()\n            ):\n                recognizer = recognizers_dict.get(\n                    result.recognition_metadata[\n                        RecognizerResult.RECOGNIZER_IDENTIFIER_KEY\n                    ]\n                )\n\n            if not recognizer:\n                logger.debug(\n                    \"Recognizer name not found as part of the \"\n                    \"recognition_metadata dict in the RecognizerResult. \"\n                )\n                continue\n\n            # skip recognizer result if the recognizer doesn't support\n            # context enhancement\n            if not recognizer.context:\n                logger.debug(\n                    \"recognizer '%s' does not support context enhancement\",\n                    recognizer.name,\n                )\n                continue\n\n            # skip context enhancement if already boosted by recognizer level\n            if result.recognition_metadata.get(\n                RecognizerResult.IS_SCORE_ENHANCED_BY_CONTEXT_KEY\n            ):\n                logger.debug(\"result score already boosted, skipping\")\n                continue\n\n            # extract lemmatized context from the surrounding of the match\n            word = text[result.start : result.end]\n\n            surrounding_words = self._extract_surrounding_words(\n                nlp_artifacts=nlp_artifacts, word=word, start=result.start\n            )\n\n            # combine other sources of context with surrounding words\n            surrounding_words.extend(context)\n\n            supportive_context_word = self._find_supportive_word_in_context(\n                surrounding_words, recognizer.context\n            )\n            if supportive_context_word != \"\":\n                result.score += self.context_similarity_factor\n                result.score = max(result.score, self.min_score_with_context_similarity)\n                result.score = min(result.score, ContextAwareEnhancer.MAX_SCORE)\n\n                # Update the explainability object with context information\n                # helped to improve the score\n                result.analysis_explanation.set_supportive_context_word(\n                    supportive_context_word\n                )\n                result.analysis_explanation.set_improved_score(result.score)\n        return results\n\n    @staticmethod\n    def _find_supportive_word_in_context(\n        context_list: List[str], recognizer_context_list: List[str]\n    ) -&gt; str:\n        \"\"\"\n        Find words in the text which are relevant for context evaluation.\n\n        A word is considered a supportive context word if there's exact match\n        between a keyword in context_text and any keyword in context_list.\n\n        :param context_list words before and after the matched entity within\n               a specified window size\n        :param recognizer_context_list a list of words considered as\n                context keywords manually specified by the recognizer's author\n        \"\"\"\n        word = \"\"\n        # If the context list is empty, no need to continue\n        if context_list is None or recognizer_context_list is None:\n            return word\n\n        for predefined_context_word in recognizer_context_list:\n            # result == true only if any of the predefined context words\n            # is found exactly or as a substring in any of the collected\n            # context words\n            result = next(\n                (\n                    True\n                    for keyword in context_list\n                    if predefined_context_word in keyword\n                ),\n                False,\n            )\n            if result:\n                logger.debug(\"Found context keyword '%s'\", predefined_context_word)\n                word = predefined_context_word\n                break\n\n        return word\n\n    def _extract_surrounding_words(\n        self, nlp_artifacts: NlpArtifacts, word: str, start: int\n    ) -&gt; List[str]:\n        \"\"\"Extract words surrounding another given word.\n\n        The text from which the context is extracted is given in the nlp\n        doc.\n\n        :param nlp_artifacts: An abstraction layer which holds different\n                              items which are the result of a NLP pipeline\n                              execution on a given text\n        :param word: The word to look for context around\n        :param start: The start index of the word in the original text\n        \"\"\"\n        if not nlp_artifacts.tokens:\n            logger.info(\"Skipping context extraction due to lack of NLP artifacts\")\n            # if there are no nlp artifacts, this is ok, we can\n            # extract context and we return a valid, yet empty\n            # context\n            return [\"\"]\n\n        # Get the already prepared words in the given text, in their\n        # LEMMATIZED version\n        lemmatized_keywords = nlp_artifacts.keywords\n\n        # since the list of tokens is not necessarily aligned\n        # with the actual index of the match, we look for the\n        # token index which corresponds to the match\n        token_index = self._find_index_of_match_token(\n            word, start, nlp_artifacts.tokens, nlp_artifacts.tokens_indices\n        )\n\n        # index i belongs to the PII entity, take the preceding n words\n        # and the successing m words into a context list\n\n        backward_context = self._add_n_words_backward(\n            token_index,\n            self.context_prefix_count,\n            nlp_artifacts.lemmas,\n            lemmatized_keywords,\n        )\n        forward_context = self._add_n_words_forward(\n            token_index,\n            self.context_suffix_count,\n            nlp_artifacts.lemmas,\n            lemmatized_keywords,\n        )\n\n        context_list = []\n        context_list.extend(backward_context)\n        context_list.extend(forward_context)\n        context_list = list(set(context_list))\n        logger.debug(\"Context list is: %s\", \" \".join(context_list))\n        return context_list\n\n    @staticmethod\n    def _find_index_of_match_token(\n        word: str,\n        start: int,\n        tokens,\n        tokens_indices: List[int],  # noqa ANN001\n    ) -&gt; int:\n        found = False\n        # we use the known start index of the original word to find the actual\n        # token at that index, we are not checking for equivilance since the\n        # token might be just a substring of that word (e.g. for phone number\n        # 555-124564 the first token might be just '555' or for a match like '\n        # rocket' the actual token will just be 'rocket' hence the misalignment\n        # of indices)\n        # Note: we are iterating over the original tokens (not the lemmatized)\n        i = -1\n        for i, token in enumerate(tokens, 0):\n            # Either we found a token with the exact location, or\n            # we take a token which its characters indices covers\n            # the index we are looking for.\n            if (tokens_indices[i] == start) or (start &lt; tokens_indices[i] + len(token)):\n                # found the interesting token, the one that around it\n                # we take n words, we save the matching lemma\n                found = True\n                break\n\n        if not found:\n            raise ValueError(\n                \"Did not find word '\" + word + \"' \"\n                \"in the list of tokens although it \"\n                \"is expected to be found\"\n            )\n        return i\n\n    @staticmethod\n    def _add_n_words(\n        index: int,\n        n_words: int,\n        lemmas: List[str],\n        lemmatized_filtered_keywords: List[str],\n        is_backward: bool,\n    ) -&gt; List[str]:\n        \"\"\"\n        Prepare a string of context words.\n\n        Return a list of words which surrounds a lemma at a given index.\n        The words will be collected only if exist in the filtered array\n\n        :param index: index of the lemma that its surrounding words we want\n        :param n_words: number of words to take\n        :param lemmas: array of lemmas\n        :param lemmatized_filtered_keywords: the array of filtered\n               lemmas from the original sentence,\n        :param is_backward: if true take the preceeding words, if false,\n                            take the successing words\n        \"\"\"\n        i = index\n        context_words = []\n        # The entity itself is no interest to us...however we want to\n        # consider it anyway for cases were it is attached with no spaces\n        # to an interesting context word, so we allow it and add 1 to\n        # the number of collected words\n\n        # collect at most n words (in lower case)\n        remaining = n_words + 1\n        while 0 &lt;= i &lt; len(lemmas) and remaining &gt; 0:\n            lower_lemma = lemmas[i].lower()\n            if lower_lemma in lemmatized_filtered_keywords:\n                context_words.append(lower_lemma)\n                remaining -= 1\n            i = i - 1 if is_backward else i + 1\n        return context_words\n\n    def _add_n_words_forward(\n        self,\n        index: int,\n        n_words: int,\n        lemmas: List[str],\n        lemmatized_filtered_keywords: List[str],\n    ) -&gt; List[str]:\n        return self._add_n_words(\n            index, n_words, lemmas, lemmatized_filtered_keywords, False\n        )\n\n    def _add_n_words_backward(\n        self,\n        index: int,\n        n_words: int,\n        lemmas: List[str],\n        lemmatized_filtered_keywords: List[str],\n    ) -&gt; List[str]:\n        return self._add_n_words(\n            index, n_words, lemmas, lemmatized_filtered_keywords, True\n        )\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.LemmaContextAwareEnhancer.enhance_using_context","title":"<code>enhance_using_context(text, raw_results, nlp_artifacts, recognizers, context=None)</code>","text":"<p>Update results in case the lemmas of surrounding words or input context words are identical to the context words.</p> <p>Using the surrounding words of the actual word matches, look for specific strings that if found contribute to the score of the result, improving the confidence that the match is indeed of that PII entity type</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The actual text that was analyzed</p> required <code>raw_results</code> <code>List[RecognizerResult]</code> <p>Recognizer results which didn't take context into consideration</p> required <code>nlp_artifacts</code> <code>NlpArtifacts</code> <p>The nlp artifacts contains elements such as lemmatized tokens for better accuracy of the context enhancement process</p> required <code>recognizers</code> <code>List[EntityRecognizer]</code> <p>the list of recognizers</p> required <code>context</code> <code>Optional[List[str]]</code> <p>list of context words</p> <code>None</code> Source code in <code>presidio_analyzer/context_aware_enhancers/lemma_context_aware_enhancer.py</code> <pre><code>def enhance_using_context(\n    self,\n    text: str,\n    raw_results: List[RecognizerResult],\n    nlp_artifacts: NlpArtifacts,\n    recognizers: List[EntityRecognizer],\n    context: Optional[List[str]] = None,\n) -&gt; List[RecognizerResult]:\n    \"\"\"\n    Update results in case the lemmas of surrounding words or input context\n    words are identical to the context words.\n\n    Using the surrounding words of the actual word matches, look\n    for specific strings that if found contribute to the score\n    of the result, improving the confidence that the match is\n    indeed of that PII entity type\n\n    :param text: The actual text that was analyzed\n    :param raw_results: Recognizer results which didn't take\n                        context into consideration\n    :param nlp_artifacts: The nlp artifacts contains elements\n                          such as lemmatized tokens for better\n                          accuracy of the context enhancement process\n    :param recognizers: the list of recognizers\n    :param context: list of context words\n    \"\"\"  # noqa D205 D400\n\n    # create a deep copy of the results object, so we can manipulate it\n    results = copy.deepcopy(raw_results)\n\n    # create recognizer context dictionary\n    recognizers_dict = {recognizer.id: recognizer for recognizer in recognizers}\n\n    # Create empty list in None or lowercase all context words in the list\n    if not context:\n        context = []\n    else:\n        context = [word.lower() for word in context]\n\n    # Sanity\n    if nlp_artifacts is None:\n        logger.warning(\"NLP artifacts were not provided\")\n        return results\n\n    for result in results:\n        recognizer = None\n        # get recognizer matching the result, if found.\n        if (\n            result.recognition_metadata\n            and RecognizerResult.RECOGNIZER_IDENTIFIER_KEY\n            in result.recognition_metadata.keys()\n        ):\n            recognizer = recognizers_dict.get(\n                result.recognition_metadata[\n                    RecognizerResult.RECOGNIZER_IDENTIFIER_KEY\n                ]\n            )\n\n        if not recognizer:\n            logger.debug(\n                \"Recognizer name not found as part of the \"\n                \"recognition_metadata dict in the RecognizerResult. \"\n            )\n            continue\n\n        # skip recognizer result if the recognizer doesn't support\n        # context enhancement\n        if not recognizer.context:\n            logger.debug(\n                \"recognizer '%s' does not support context enhancement\",\n                recognizer.name,\n            )\n            continue\n\n        # skip context enhancement if already boosted by recognizer level\n        if result.recognition_metadata.get(\n            RecognizerResult.IS_SCORE_ENHANCED_BY_CONTEXT_KEY\n        ):\n            logger.debug(\"result score already boosted, skipping\")\n            continue\n\n        # extract lemmatized context from the surrounding of the match\n        word = text[result.start : result.end]\n\n        surrounding_words = self._extract_surrounding_words(\n            nlp_artifacts=nlp_artifacts, word=word, start=result.start\n        )\n\n        # combine other sources of context with surrounding words\n        surrounding_words.extend(context)\n\n        supportive_context_word = self._find_supportive_word_in_context(\n            surrounding_words, recognizer.context\n        )\n        if supportive_context_word != \"\":\n            result.score += self.context_similarity_factor\n            result.score = max(result.score, self.min_score_with_context_similarity)\n            result.score = min(result.score, ContextAwareEnhancer.MAX_SCORE)\n\n            # Update the explainability object with context information\n            # helped to improve the score\n            result.analysis_explanation.set_supportive_context_word(\n                supportive_context_word\n            )\n            result.analysis_explanation.set_improved_score(result.score)\n    return results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.LocalRecognizer","title":"<code>LocalRecognizer</code>","text":"<p>               Bases: <code>ABC</code>, <code>EntityRecognizer</code></p> <p>PII entity recognizer which runs on the same process as the AnalyzerEngine.</p> Source code in <code>presidio_analyzer/local_recognizer.py</code> <pre><code>class LocalRecognizer(ABC, EntityRecognizer):\n    \"\"\"PII entity recognizer which runs on the same process as the AnalyzerEngine.\"\"\"\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.Pattern","title":"<code>Pattern</code>","text":"<p>A class that represents a regex pattern.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>the name of the pattern</p> required <code>regex</code> <code>str</code> <p>the regex pattern to detect</p> required <code>score</code> <code>float</code> <p>the pattern's strength (values varies 0-1)</p> required Source code in <code>presidio_analyzer/pattern.py</code> <pre><code>class Pattern:\n    \"\"\"\n    A class that represents a regex pattern.\n\n    :param name: the name of the pattern\n    :param regex: the regex pattern to detect\n    :param score: the pattern's strength (values varies 0-1)\n    \"\"\"\n\n    def __init__(self, name: str, regex: str, score: float):\n        self.name = name\n        self.regex = regex\n        self.score = score\n        self.compiled_regex = None\n        self.compiled_with_flags = None\n\n    def to_dict(self) -&gt; Dict:\n        \"\"\"\n        Turn this instance into a dictionary.\n\n        :return: a dictionary\n        \"\"\"\n        return_dict = {\"name\": self.name, \"score\": self.score, \"regex\": self.regex}\n        return return_dict\n\n    @classmethod\n    def from_dict(cls, pattern_dict: Dict) -&gt; \"Pattern\":\n        \"\"\"\n        Load an instance from a dictionary.\n\n        :param pattern_dict: a dictionary holding the pattern's parameters\n        :return: a Pattern instance\n        \"\"\"\n        return cls(**pattern_dict)\n\n    def __repr__(self):\n        \"\"\"Return string representation of instance.\"\"\"\n        return json.dumps(self.to_dict())\n\n    def __str__(self):\n        \"\"\"Return string representation of instance.\"\"\"\n        return json.dumps(self.to_dict())\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.Pattern.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation of instance.</p> Source code in <code>presidio_analyzer/pattern.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return string representation of instance.\"\"\"\n    return json.dumps(self.to_dict())\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.Pattern.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of instance.</p> Source code in <code>presidio_analyzer/pattern.py</code> <pre><code>def __str__(self):\n    \"\"\"Return string representation of instance.\"\"\"\n    return json.dumps(self.to_dict())\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.Pattern.from_dict","title":"<code>from_dict(pattern_dict)</code>  <code>classmethod</code>","text":"<p>Load an instance from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>pattern_dict</code> <code>Dict</code> <p>a dictionary holding the pattern's parameters</p> required <p>Returns:</p> Type Description <code>Pattern</code> <p>a Pattern instance</p> Source code in <code>presidio_analyzer/pattern.py</code> <pre><code>@classmethod\ndef from_dict(cls, pattern_dict: Dict) -&gt; \"Pattern\":\n    \"\"\"\n    Load an instance from a dictionary.\n\n    :param pattern_dict: a dictionary holding the pattern's parameters\n    :return: a Pattern instance\n    \"\"\"\n    return cls(**pattern_dict)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.Pattern.to_dict","title":"<code>to_dict()</code>","text":"<p>Turn this instance into a dictionary.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>a dictionary</p> Source code in <code>presidio_analyzer/pattern.py</code> <pre><code>def to_dict(self) -&gt; Dict:\n    \"\"\"\n    Turn this instance into a dictionary.\n\n    :return: a dictionary\n    \"\"\"\n    return_dict = {\"name\": self.name, \"score\": self.score, \"regex\": self.regex}\n    return return_dict\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PatternRecognizer","title":"<code>PatternRecognizer</code>","text":"<p>               Bases: <code>LocalRecognizer</code></p> <p>PII entity recognizer using regular expressions or deny-lists.</p> <p>Parameters:</p> Name Type Description Default <code>patterns</code> <code>List[Pattern]</code> <p>A list of patterns to detect</p> <code>None</code> <code>deny_list</code> <code>List[str]</code> <p>A list of words to detect, in case our recognizer uses a predefined list of words (deny list)</p> <code>None</code> <code>context</code> <code>List[str]</code> <p>list of context words</p> <code>None</code> <code>deny_list_score</code> <code>float</code> <p>confidence score for a term identified using a deny-list</p> <code>1.0</code> <code>global_regex_flags</code> <code>Optional[int]</code> <p>regex flags to be used in regex matching, including deny-lists.</p> <code>DOTALL | MULTILINE | IGNORECASE</code> Source code in <code>presidio_analyzer/pattern_recognizer.py</code> <pre><code>class PatternRecognizer(LocalRecognizer):\n    \"\"\"\n    PII entity recognizer using regular expressions or deny-lists.\n\n    :param patterns: A list of patterns to detect\n    :param deny_list: A list of words to detect,\n    in case our recognizer uses a predefined list of words (deny list)\n    :param context: list of context words\n    :param deny_list_score: confidence score for a term\n    identified using a deny-list\n    :param global_regex_flags: regex flags to be used in regex matching,\n    including deny-lists.\n    \"\"\"\n\n    def __init__(\n        self,\n        supported_entity: str,\n        name: str = None,\n        supported_language: str = \"en\",\n        patterns: List[Pattern] = None,\n        deny_list: List[str] = None,\n        context: List[str] = None,\n        deny_list_score: float = 1.0,\n        global_regex_flags: Optional[int] = re.DOTALL | re.MULTILINE | re.IGNORECASE,\n        version: str = \"0.0.1\",\n    ):\n        if not supported_entity:\n            raise ValueError(\"Pattern recognizer should be initialized with entity\")\n\n        if not patterns and not deny_list:\n            raise ValueError(\n                \"Pattern recognizer should be initialized with patterns\"\n                \" or with deny list\"\n            )\n\n        super().__init__(\n            supported_entities=[supported_entity],\n            supported_language=supported_language,\n            name=name,\n            version=version,\n        )\n        if patterns is None:\n            self.patterns = []\n        else:\n            self.patterns = patterns\n        self.context = context\n        self.deny_list_score = deny_list_score\n        self.global_regex_flags = global_regex_flags\n\n        if deny_list:\n            deny_list_pattern = self._deny_list_to_regex(deny_list)\n            self.patterns.append(deny_list_pattern)\n            self.deny_list = deny_list\n        else:\n            self.deny_list = []\n\n    def load(self):  # noqa D102\n        pass\n\n    def analyze(\n        self,\n        text: str,\n        entities: List[str],\n        nlp_artifacts: Optional[NlpArtifacts] = None,\n        regex_flags: Optional[int] = None,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Analyzes text to detect PII using regular expressions or deny-lists.\n\n        :param text: Text to be analyzed\n        :param entities: Entities this recognizer can detect\n        :param nlp_artifacts: Output values from the NLP engine\n        :param regex_flags: regex flags to be used in regex matching\n        :return:\n        \"\"\"\n        results = []\n\n        if self.patterns:\n            pattern_result = self.__analyze_patterns(text, regex_flags)\n            results.extend(pattern_result)\n\n        return results\n\n    def _deny_list_to_regex(self, deny_list: List[str]) -&gt; Pattern:\n        \"\"\"\n        Convert a list of words to a matching regex.\n\n        To be analyzed by the analyze method as any other regex patterns.\n\n        :param deny_list: the list of words to detect\n        :return:the regex of the words for detection\n        \"\"\"\n\n        # Escape deny list elements as preparation for regex\n        escaped_deny_list = [re.escape(element) for element in deny_list]\n        regex = r\"(?:^|(?&lt;=\\W))(\" + \"|\".join(escaped_deny_list) + r\")(?:(?=\\W)|$)\"\n        return Pattern(name=\"deny_list\", regex=regex, score=self.deny_list_score)\n\n    def validate_result(self, pattern_text: str) -&gt; Optional[bool]:\n        \"\"\"\n        Validate the pattern logic e.g., by running checksum on a detected pattern.\n\n        :param pattern_text: the text to validated.\n        Only the part in text that was detected by the regex engine\n        :return: A bool indicating whether the validation was successful.\n        \"\"\"\n        return None\n\n    def invalidate_result(self, pattern_text: str) -&gt; Optional[bool]:\n        \"\"\"\n        Logic to check for result invalidation by running pruning logic.\n\n        For example, each SSN number group should not consist of all the same digits.\n\n        :param pattern_text: the text to validated.\n        Only the part in text that was detected by the regex engine\n        :return: A bool indicating whether the result is invalidated\n        \"\"\"\n        return None\n\n    @staticmethod\n    def build_regex_explanation(\n        recognizer_name: str,\n        pattern_name: str,\n        pattern: str,\n        original_score: float,\n        validation_result: bool,\n        regex_flags: int,\n    ) -&gt; AnalysisExplanation:\n        \"\"\"\n        Construct an explanation for why this entity was detected.\n\n        :param recognizer_name: Name of recognizer detecting the entity\n        :param pattern_name: Regex pattern name which detected the entity\n        :param pattern: Regex pattern logic\n        :param original_score: Score given by the recognizer\n        :param validation_result: Whether validation was used and its result\n        :param regex_flags: Regex flags used in the regex matching\n        :return: Analysis explanation\n        \"\"\"\n        textual_explanation = (\n            f\"Detected by `{recognizer_name}` \" f\"using pattern `{pattern_name}`\"\n        )\n\n        explanation = AnalysisExplanation(\n            recognizer=recognizer_name,\n            original_score=original_score,\n            pattern_name=pattern_name,\n            pattern=pattern,\n            validation_result=validation_result,\n            regex_flags=regex_flags,\n            textual_explanation=textual_explanation,\n        )\n        return explanation\n\n    def __analyze_patterns(\n        self, text: str, flags: int = None\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Evaluate all patterns in the provided text.\n\n        Including words in the provided deny-list\n\n        :param text: text to analyze\n        :param flags: regex flags\n        :return: A list of RecognizerResult\n        \"\"\"\n        flags = flags if flags else self.global_regex_flags\n        results = []\n        for pattern in self.patterns:\n            match_start_time = datetime.datetime.now()\n\n            # Compile regex if flags differ from flags the regex was compiled with\n            if not pattern.compiled_regex or pattern.compiled_with_flags != flags:\n                pattern.compiled_with_flags = flags\n                pattern.compiled_regex = re.compile(pattern.regex, flags=flags)\n\n            matches = pattern.compiled_regex.finditer(text)\n            match_time = datetime.datetime.now() - match_start_time\n            logger.debug(\n                \"--- match_time[%s]: %.6f seconds\",\n                pattern.name,\n                match_time.total_seconds()\n            )\n\n            for match in matches:\n                start, end = match.span()\n                current_match = text[start:end]\n\n                # Skip empty results\n                if current_match == \"\":\n                    continue\n\n                score = pattern.score\n\n                validation_result = self.validate_result(current_match)\n                description = self.build_regex_explanation(\n                    self.name,\n                    pattern.name,\n                    pattern.regex,\n                    score,\n                    validation_result,\n                    flags,\n                )\n                pattern_result = RecognizerResult(\n                    entity_type=self.supported_entities[0],\n                    start=start,\n                    end=end,\n                    score=score,\n                    analysis_explanation=description,\n                    recognition_metadata={\n                        RecognizerResult.RECOGNIZER_NAME_KEY: self.name,\n                        RecognizerResult.RECOGNIZER_IDENTIFIER_KEY: self.id,\n                    },\n                )\n\n                if validation_result is not None:\n                    if validation_result:\n                        pattern_result.score = EntityRecognizer.MAX_SCORE\n                    else:\n                        pattern_result.score = EntityRecognizer.MIN_SCORE\n\n                invalidation_result = self.invalidate_result(current_match)\n                if invalidation_result is not None and invalidation_result:\n                    pattern_result.score = EntityRecognizer.MIN_SCORE\n\n                if pattern_result.score &gt; EntityRecognizer.MIN_SCORE:\n                    results.append(pattern_result)\n\n                # Update analysis explanation score following validation or invalidation\n                description.score = pattern_result.score\n\n        results = EntityRecognizer.remove_duplicates(results)\n        return results\n\n    def to_dict(self) -&gt; Dict:\n        \"\"\"Serialize instance into a dictionary.\"\"\"\n        return_dict = super().to_dict()\n\n        return_dict[\"patterns\"] = [pat.to_dict() for pat in self.patterns]\n        return_dict[\"deny_list\"] = self.deny_list\n        return_dict[\"context\"] = self.context\n        return_dict[\"supported_entity\"] = return_dict[\"supported_entities\"][0]\n        del return_dict[\"supported_entities\"]\n\n        return return_dict\n\n    @classmethod\n    def from_dict(cls, entity_recognizer_dict: Dict) -&gt; \"PatternRecognizer\":\n        \"\"\"Create instance from a serialized dict.\"\"\"\n        patterns = entity_recognizer_dict.get(\"patterns\")\n        if patterns:\n            patterns_list = [Pattern.from_dict(pat) for pat in patterns]\n            entity_recognizer_dict[\"patterns\"] = patterns_list\n\n        return cls(**entity_recognizer_dict)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PatternRecognizer.__analyze_patterns","title":"<code>__analyze_patterns(text, flags=None)</code>","text":"<p>Evaluate all patterns in the provided text.</p> <p>Including words in the provided deny-list</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>text to analyze</p> required <code>flags</code> <code>int</code> <p>regex flags</p> <code>None</code> <p>Returns:</p> Type Description <code>List[RecognizerResult]</code> <p>A list of RecognizerResult</p> Source code in <code>presidio_analyzer/pattern_recognizer.py</code> <pre><code>def __analyze_patterns(\n    self, text: str, flags: int = None\n) -&gt; List[RecognizerResult]:\n    \"\"\"\n    Evaluate all patterns in the provided text.\n\n    Including words in the provided deny-list\n\n    :param text: text to analyze\n    :param flags: regex flags\n    :return: A list of RecognizerResult\n    \"\"\"\n    flags = flags if flags else self.global_regex_flags\n    results = []\n    for pattern in self.patterns:\n        match_start_time = datetime.datetime.now()\n\n        # Compile regex if flags differ from flags the regex was compiled with\n        if not pattern.compiled_regex or pattern.compiled_with_flags != flags:\n            pattern.compiled_with_flags = flags\n            pattern.compiled_regex = re.compile(pattern.regex, flags=flags)\n\n        matches = pattern.compiled_regex.finditer(text)\n        match_time = datetime.datetime.now() - match_start_time\n        logger.debug(\n            \"--- match_time[%s]: %.6f seconds\",\n            pattern.name,\n            match_time.total_seconds()\n        )\n\n        for match in matches:\n            start, end = match.span()\n            current_match = text[start:end]\n\n            # Skip empty results\n            if current_match == \"\":\n                continue\n\n            score = pattern.score\n\n            validation_result = self.validate_result(current_match)\n            description = self.build_regex_explanation(\n                self.name,\n                pattern.name,\n                pattern.regex,\n                score,\n                validation_result,\n                flags,\n            )\n            pattern_result = RecognizerResult(\n                entity_type=self.supported_entities[0],\n                start=start,\n                end=end,\n                score=score,\n                analysis_explanation=description,\n                recognition_metadata={\n                    RecognizerResult.RECOGNIZER_NAME_KEY: self.name,\n                    RecognizerResult.RECOGNIZER_IDENTIFIER_KEY: self.id,\n                },\n            )\n\n            if validation_result is not None:\n                if validation_result:\n                    pattern_result.score = EntityRecognizer.MAX_SCORE\n                else:\n                    pattern_result.score = EntityRecognizer.MIN_SCORE\n\n            invalidation_result = self.invalidate_result(current_match)\n            if invalidation_result is not None and invalidation_result:\n                pattern_result.score = EntityRecognizer.MIN_SCORE\n\n            if pattern_result.score &gt; EntityRecognizer.MIN_SCORE:\n                results.append(pattern_result)\n\n            # Update analysis explanation score following validation or invalidation\n            description.score = pattern_result.score\n\n    results = EntityRecognizer.remove_duplicates(results)\n    return results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PatternRecognizer.analyze","title":"<code>analyze(text, entities, nlp_artifacts=None, regex_flags=None)</code>","text":"<p>Analyzes text to detect PII using regular expressions or deny-lists.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to be analyzed</p> required <code>entities</code> <code>List[str]</code> <p>Entities this recognizer can detect</p> required <code>nlp_artifacts</code> <code>Optional[NlpArtifacts]</code> <p>Output values from the NLP engine</p> <code>None</code> <code>regex_flags</code> <code>Optional[int]</code> <p>regex flags to be used in regex matching</p> <code>None</code> <p>Returns:</p> Type Description <code>List[RecognizerResult]</code> Source code in <code>presidio_analyzer/pattern_recognizer.py</code> <pre><code>def analyze(\n    self,\n    text: str,\n    entities: List[str],\n    nlp_artifacts: Optional[NlpArtifacts] = None,\n    regex_flags: Optional[int] = None,\n) -&gt; List[RecognizerResult]:\n    \"\"\"\n    Analyzes text to detect PII using regular expressions or deny-lists.\n\n    :param text: Text to be analyzed\n    :param entities: Entities this recognizer can detect\n    :param nlp_artifacts: Output values from the NLP engine\n    :param regex_flags: regex flags to be used in regex matching\n    :return:\n    \"\"\"\n    results = []\n\n    if self.patterns:\n        pattern_result = self.__analyze_patterns(text, regex_flags)\n        results.extend(pattern_result)\n\n    return results\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PatternRecognizer.build_regex_explanation","title":"<code>build_regex_explanation(recognizer_name, pattern_name, pattern, original_score, validation_result, regex_flags)</code>  <code>staticmethod</code>","text":"<p>Construct an explanation for why this entity was detected.</p> <p>Parameters:</p> Name Type Description Default <code>recognizer_name</code> <code>str</code> <p>Name of recognizer detecting the entity</p> required <code>pattern_name</code> <code>str</code> <p>Regex pattern name which detected the entity</p> required <code>pattern</code> <code>str</code> <p>Regex pattern logic</p> required <code>original_score</code> <code>float</code> <p>Score given by the recognizer</p> required <code>validation_result</code> <code>bool</code> <p>Whether validation was used and its result</p> required <code>regex_flags</code> <code>int</code> <p>Regex flags used in the regex matching</p> required <p>Returns:</p> Type Description <code>AnalysisExplanation</code> <p>Analysis explanation</p> Source code in <code>presidio_analyzer/pattern_recognizer.py</code> <pre><code>@staticmethod\ndef build_regex_explanation(\n    recognizer_name: str,\n    pattern_name: str,\n    pattern: str,\n    original_score: float,\n    validation_result: bool,\n    regex_flags: int,\n) -&gt; AnalysisExplanation:\n    \"\"\"\n    Construct an explanation for why this entity was detected.\n\n    :param recognizer_name: Name of recognizer detecting the entity\n    :param pattern_name: Regex pattern name which detected the entity\n    :param pattern: Regex pattern logic\n    :param original_score: Score given by the recognizer\n    :param validation_result: Whether validation was used and its result\n    :param regex_flags: Regex flags used in the regex matching\n    :return: Analysis explanation\n    \"\"\"\n    textual_explanation = (\n        f\"Detected by `{recognizer_name}` \" f\"using pattern `{pattern_name}`\"\n    )\n\n    explanation = AnalysisExplanation(\n        recognizer=recognizer_name,\n        original_score=original_score,\n        pattern_name=pattern_name,\n        pattern=pattern,\n        validation_result=validation_result,\n        regex_flags=regex_flags,\n        textual_explanation=textual_explanation,\n    )\n    return explanation\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PatternRecognizer.from_dict","title":"<code>from_dict(entity_recognizer_dict)</code>  <code>classmethod</code>","text":"<p>Create instance from a serialized dict.</p> Source code in <code>presidio_analyzer/pattern_recognizer.py</code> <pre><code>@classmethod\ndef from_dict(cls, entity_recognizer_dict: Dict) -&gt; \"PatternRecognizer\":\n    \"\"\"Create instance from a serialized dict.\"\"\"\n    patterns = entity_recognizer_dict.get(\"patterns\")\n    if patterns:\n        patterns_list = [Pattern.from_dict(pat) for pat in patterns]\n        entity_recognizer_dict[\"patterns\"] = patterns_list\n\n    return cls(**entity_recognizer_dict)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PatternRecognizer.invalidate_result","title":"<code>invalidate_result(pattern_text)</code>","text":"<p>Logic to check for result invalidation by running pruning logic.</p> <p>For example, each SSN number group should not consist of all the same digits.</p> <p>Parameters:</p> Name Type Description Default <code>pattern_text</code> <code>str</code> <p>the text to validated. Only the part in text that was detected by the regex engine</p> required <p>Returns:</p> Type Description <code>Optional[bool]</code> <p>A bool indicating whether the result is invalidated</p> Source code in <code>presidio_analyzer/pattern_recognizer.py</code> <pre><code>def invalidate_result(self, pattern_text: str) -&gt; Optional[bool]:\n    \"\"\"\n    Logic to check for result invalidation by running pruning logic.\n\n    For example, each SSN number group should not consist of all the same digits.\n\n    :param pattern_text: the text to validated.\n    Only the part in text that was detected by the regex engine\n    :return: A bool indicating whether the result is invalidated\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PatternRecognizer.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize instance into a dictionary.</p> Source code in <code>presidio_analyzer/pattern_recognizer.py</code> <pre><code>def to_dict(self) -&gt; Dict:\n    \"\"\"Serialize instance into a dictionary.\"\"\"\n    return_dict = super().to_dict()\n\n    return_dict[\"patterns\"] = [pat.to_dict() for pat in self.patterns]\n    return_dict[\"deny_list\"] = self.deny_list\n    return_dict[\"context\"] = self.context\n    return_dict[\"supported_entity\"] = return_dict[\"supported_entities\"][0]\n    del return_dict[\"supported_entities\"]\n\n    return return_dict\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PatternRecognizer.validate_result","title":"<code>validate_result(pattern_text)</code>","text":"<p>Validate the pattern logic e.g., by running checksum on a detected pattern.</p> <p>Parameters:</p> Name Type Description Default <code>pattern_text</code> <code>str</code> <p>the text to validated. Only the part in text that was detected by the regex engine</p> required <p>Returns:</p> Type Description <code>Optional[bool]</code> <p>A bool indicating whether the validation was successful.</p> Source code in <code>presidio_analyzer/pattern_recognizer.py</code> <pre><code>def validate_result(self, pattern_text: str) -&gt; Optional[bool]:\n    \"\"\"\n    Validate the pattern logic e.g., by running checksum on a detected pattern.\n\n    :param pattern_text: the text to validated.\n    Only the part in text that was detected by the regex engine\n    :return: A bool indicating whether the validation was successful.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PresidioAnalyzerUtils","title":"<code>PresidioAnalyzerUtils</code>","text":"<p>Utility functions for Presidio Analyzer.</p> <p>The class provides a bundle of utility functions that help centralizing the logic for re-usability and maintainability</p> Source code in <code>presidio_analyzer/analyzer_utils.py</code> <pre><code>class PresidioAnalyzerUtils:\n    \"\"\"\n    Utility functions for Presidio Analyzer.\n\n    The class provides a bundle of utility functions that help centralizing the\n    logic for re-usability and maintainability\n    \"\"\"\n\n    @staticmethod\n    def is_palindrome(text: str, case_insensitive: bool = False):\n        \"\"\"\n        Validate if input text is a true palindrome.\n\n        :param text: input text string to check for palindrome\n        :param case_insensitive: optional flag to check palindrome with no case\n        :return: True / False\n        \"\"\"\n        palindrome_text = text\n        if case_insensitive:\n            palindrome_text = palindrome_text.replace(\" \", \"\").lower()\n        return palindrome_text == palindrome_text[::-1]\n\n    @staticmethod\n    def sanitize_value(text: str, replacement_pairs: List[Tuple[str, str]]) -&gt; str:\n        \"\"\"\n        Cleanse the input string of the replacement pairs specified as argument.\n\n        :param text: input string\n        :param replacement_pairs: pairs of what has to be replaced with which value\n        :return: cleansed string\n        \"\"\"\n        for search_string, replacement_string in replacement_pairs:\n            text = text.replace(search_string, replacement_string)\n        return text\n\n    @staticmethod\n    def is_verhoeff_number(input_number: int):\n        \"\"\"\n        Check if the input number is a true verhoeff number.\n\n        :param input_number:\n        :return:\n        \"\"\"\n        __d__ = [\n            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n            [1, 2, 3, 4, 0, 6, 7, 8, 9, 5],\n            [2, 3, 4, 0, 1, 7, 8, 9, 5, 6],\n            [3, 4, 0, 1, 2, 8, 9, 5, 6, 7],\n            [4, 0, 1, 2, 3, 9, 5, 6, 7, 8],\n            [5, 9, 8, 7, 6, 0, 4, 3, 2, 1],\n            [6, 5, 9, 8, 7, 1, 0, 4, 3, 2],\n            [7, 6, 5, 9, 8, 2, 1, 0, 4, 3],\n            [8, 7, 6, 5, 9, 3, 2, 1, 0, 4],\n            [9, 8, 7, 6, 5, 4, 3, 2, 1, 0],\n        ]\n        __p__ = [\n            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n            [1, 5, 7, 6, 2, 8, 3, 0, 9, 4],\n            [5, 8, 0, 3, 7, 9, 6, 1, 4, 2],\n            [8, 9, 1, 6, 0, 4, 3, 5, 2, 7],\n            [9, 4, 5, 3, 1, 2, 6, 8, 7, 0],\n            [4, 2, 8, 6, 5, 7, 3, 9, 0, 1],\n            [2, 7, 9, 3, 8, 0, 6, 4, 1, 5],\n            [7, 0, 4, 6, 9, 1, 3, 2, 5, 8],\n        ]\n        __inv__ = [0, 4, 3, 2, 1, 5, 6, 7, 8, 9]\n\n        c = 0\n        inverted_number = list(map(int, reversed(str(input_number))))\n        for i in range(len(inverted_number)):\n            c = __d__[c][__p__[i % 8][inverted_number[i]]]\n        return __inv__[c] == 0\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PresidioAnalyzerUtils.is_palindrome","title":"<code>is_palindrome(text, case_insensitive=False)</code>  <code>staticmethod</code>","text":"<p>Validate if input text is a true palindrome.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>input text string to check for palindrome</p> required <code>case_insensitive</code> <code>bool</code> <p>optional flag to check palindrome with no case</p> <code>False</code> <p>Returns:</p> Type Description <p>True / False</p> Source code in <code>presidio_analyzer/analyzer_utils.py</code> <pre><code>@staticmethod\ndef is_palindrome(text: str, case_insensitive: bool = False):\n    \"\"\"\n    Validate if input text is a true palindrome.\n\n    :param text: input text string to check for palindrome\n    :param case_insensitive: optional flag to check palindrome with no case\n    :return: True / False\n    \"\"\"\n    palindrome_text = text\n    if case_insensitive:\n        palindrome_text = palindrome_text.replace(\" \", \"\").lower()\n    return palindrome_text == palindrome_text[::-1]\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PresidioAnalyzerUtils.is_verhoeff_number","title":"<code>is_verhoeff_number(input_number)</code>  <code>staticmethod</code>","text":"<p>Check if the input number is a true verhoeff number.</p> <p>Parameters:</p> Name Type Description Default <code>input_number</code> <code>int</code> required <p>Returns:</p> Type Description Source code in <code>presidio_analyzer/analyzer_utils.py</code> <pre><code>@staticmethod\ndef is_verhoeff_number(input_number: int):\n    \"\"\"\n    Check if the input number is a true verhoeff number.\n\n    :param input_number:\n    :return:\n    \"\"\"\n    __d__ = [\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [1, 2, 3, 4, 0, 6, 7, 8, 9, 5],\n        [2, 3, 4, 0, 1, 7, 8, 9, 5, 6],\n        [3, 4, 0, 1, 2, 8, 9, 5, 6, 7],\n        [4, 0, 1, 2, 3, 9, 5, 6, 7, 8],\n        [5, 9, 8, 7, 6, 0, 4, 3, 2, 1],\n        [6, 5, 9, 8, 7, 1, 0, 4, 3, 2],\n        [7, 6, 5, 9, 8, 2, 1, 0, 4, 3],\n        [8, 7, 6, 5, 9, 3, 2, 1, 0, 4],\n        [9, 8, 7, 6, 5, 4, 3, 2, 1, 0],\n    ]\n    __p__ = [\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        [1, 5, 7, 6, 2, 8, 3, 0, 9, 4],\n        [5, 8, 0, 3, 7, 9, 6, 1, 4, 2],\n        [8, 9, 1, 6, 0, 4, 3, 5, 2, 7],\n        [9, 4, 5, 3, 1, 2, 6, 8, 7, 0],\n        [4, 2, 8, 6, 5, 7, 3, 9, 0, 1],\n        [2, 7, 9, 3, 8, 0, 6, 4, 1, 5],\n        [7, 0, 4, 6, 9, 1, 3, 2, 5, 8],\n    ]\n    __inv__ = [0, 4, 3, 2, 1, 5, 6, 7, 8, 9]\n\n    c = 0\n    inverted_number = list(map(int, reversed(str(input_number))))\n    for i in range(len(inverted_number)):\n        c = __d__[c][__p__[i % 8][inverted_number[i]]]\n    return __inv__[c] == 0\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.PresidioAnalyzerUtils.sanitize_value","title":"<code>sanitize_value(text, replacement_pairs)</code>  <code>staticmethod</code>","text":"<p>Cleanse the input string of the replacement pairs specified as argument.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>input string</p> required <code>replacement_pairs</code> <code>List[Tuple[str, str]]</code> <p>pairs of what has to be replaced with which value</p> required <p>Returns:</p> Type Description <code>str</code> <p>cleansed string</p> Source code in <code>presidio_analyzer/analyzer_utils.py</code> <pre><code>@staticmethod\ndef sanitize_value(text: str, replacement_pairs: List[Tuple[str, str]]) -&gt; str:\n    \"\"\"\n    Cleanse the input string of the replacement pairs specified as argument.\n\n    :param text: input string\n    :param replacement_pairs: pairs of what has to be replaced with which value\n    :return: cleansed string\n    \"\"\"\n    for search_string, replacement_string in replacement_pairs:\n        text = text.replace(search_string, replacement_string)\n    return text\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry","title":"<code>RecognizerRegistry</code>","text":"<p>Detect, register and hold all recognizers to be used by the analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>recognizers</code> <code>Optional[Iterable[EntityRecognizer]]</code> <p>An optional list of recognizers, that will be available instead of the predefined recognizers</p> <code>None</code> <code></code> <code>global_regex_flags</code> <p>regex flags to be used in regex matching, including deny-lists</p> required Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>class RecognizerRegistry:\n    \"\"\"\n    Detect, register and hold all recognizers to be used by the analyzer.\n\n    :param recognizers: An optional list of recognizers,\n    that will be available instead of the predefined recognizers\n    :param global_regex_flags : regex flags to be used in regex matching,\n    including deny-lists\n\n    \"\"\"\n\n    def __init__(\n        self,\n        recognizers: Optional[Iterable[EntityRecognizer]] = None,\n        global_regex_flags: Optional[int] = re.DOTALL | re.MULTILINE | re.IGNORECASE,\n        supported_languages: Optional[List[str]] = None,\n    ):\n        if recognizers:\n            self.recognizers = recognizers\n        else:\n            self.recognizers = []\n        self.global_regex_flags = global_regex_flags\n        self.supported_languages = (\n            supported_languages if supported_languages else [\"en\"]\n        )\n\n    def _create_nlp_recognizer(\n        self, nlp_engine: NlpEngine = None, supported_language: str = None\n    ) -&gt; SpacyRecognizer:\n        nlp_recognizer = self._get_nlp_recognizer(nlp_engine)\n\n        if nlp_engine:\n            return nlp_recognizer(\n                supported_language=supported_language,\n                supported_entities=nlp_engine.get_supported_entities(),\n            )\n\n        return nlp_recognizer(supported_language=supported_language)\n\n    def add_nlp_recognizer(self, nlp_engine: NlpEngine) -&gt; None:\n        \"\"\"\n        Adding NLP recognizer in accordance with the nlp engine.\n\n        :param nlp_engine: The NLP engine.\n        :return: None\n        \"\"\"\n\n        if not nlp_engine:\n            supported_languages = self.supported_languages\n        else:\n            supported_languages = nlp_engine.get_supported_languages()\n\n        self.recognizers.extend(\n            [\n                self._create_nlp_recognizer(\n                    nlp_engine=nlp_engine, supported_language=supported_language\n                )\n                for supported_language in supported_languages\n            ]\n        )\n\n    def load_predefined_recognizers(\n        self, languages: Optional[List[str]] = None, nlp_engine: NlpEngine = None\n    ) -&gt; None:\n        \"\"\"\n        Load the existing recognizers into memory.\n\n        :param languages: List of languages for which to load recognizers\n        :param nlp_engine: The NLP engine to use.\n        :return: None\n        \"\"\"\n\n        registry_configuration = {\"global_regex_flags\": self.global_regex_flags}\n        if languages is not None:\n            registry_configuration[\"supported_languages\"] = languages\n\n        configuration = RecognizerConfigurationLoader.get(\n            registry_configuration=registry_configuration\n        )\n        recognizers = RecognizerListLoader.get(**configuration)\n\n        self.recognizers.extend(recognizers)\n        self.add_nlp_recognizer(nlp_engine=nlp_engine)\n\n    @staticmethod\n    def _get_nlp_recognizer(\n        nlp_engine: NlpEngine,\n    ) -&gt; Type[SpacyRecognizer]:\n        \"\"\"Return the recognizer leveraging the selected NLP Engine.\"\"\"\n\n        if isinstance(nlp_engine, StanzaNlpEngine):\n            return StanzaRecognizer\n        if isinstance(nlp_engine, TransformersNlpEngine):\n            return TransformersRecognizer\n        if not nlp_engine or isinstance(nlp_engine, SpacyNlpEngine):\n            return SpacyRecognizer\n        else:\n            logger.warning(\n                \"nlp engine should be either SpacyNlpEngine,\"\n                \"StanzaNlpEngine or TransformersNlpEngine\"\n            )\n            # Returning default\n            return SpacyRecognizer\n\n    def get_recognizers(\n        self,\n        language: str,\n        entities: Optional[List[str]] = None,\n        all_fields: bool = False,\n        ad_hoc_recognizers: Optional[List[EntityRecognizer]] = None,\n    ) -&gt; List[EntityRecognizer]:\n        \"\"\"\n        Return a list of recognizers which supports the specified name and language.\n\n        :param entities: the requested entities\n        :param language: the requested language\n        :param all_fields: a flag to return all fields of a requested language.\n        :param ad_hoc_recognizers: Additional recognizers provided by the user\n        as part of the request\n        :return: A list of the recognizers which supports the supplied entities\n        and language\n        \"\"\"\n        if language is None:\n            raise ValueError(\"No language provided\")\n\n        if entities is None and all_fields is False:\n            raise ValueError(\"No entities provided\")\n\n        all_possible_recognizers = copy.copy(self.recognizers)\n        if ad_hoc_recognizers:\n            all_possible_recognizers.extend(ad_hoc_recognizers)\n\n        # filter out unwanted recognizers\n        to_return = set()\n        if all_fields:\n            to_return = [\n                rec\n                for rec in all_possible_recognizers\n                if language == rec.supported_language\n            ]\n        else:\n            for entity in entities:\n                subset = [\n                    rec\n                    for rec in all_possible_recognizers\n                    if entity in rec.supported_entities\n                    and language == rec.supported_language\n                ]\n\n                if not subset:\n                    logger.warning(\n                        \"Entity %s doesn't have the corresponding\"\n                        \" recognizer in language : %s\",\n                        entity,\n                        language,\n                    )\n                else:\n                    to_return.update(set(subset))\n\n        logger.debug(\n            \"Returning a total of %s recognizers\",\n            str(len(to_return)),\n        )\n\n        if not to_return:\n            raise ValueError(\"No matching recognizers were found to serve the request.\")\n\n        return list(to_return)\n\n    def add_recognizer(self, recognizer: EntityRecognizer) -&gt; None:\n        \"\"\"\n        Add a new recognizer to the list of recognizers.\n\n        :param recognizer: Recognizer to add\n        \"\"\"\n        if not isinstance(recognizer, EntityRecognizer):\n            raise ValueError(\"Input is not of type EntityRecognizer\")\n\n        self.recognizers.append(recognizer)\n\n    def remove_recognizer(\n        self, recognizer_name: str, language: Optional[str] = None\n    ) -&gt; None:\n        \"\"\"\n        Remove a recognizer based on its name.\n\n        :param recognizer_name: Name of recognizer to remove\n        :param language: The supported language of the recognizer to be removed,\n        in case multiple recognizers with the same name are present,\n        and only one should be removed.\n        \"\"\"\n\n        if not language:\n            new_recognizers = [\n                rec for rec in self.recognizers if rec.name != recognizer_name\n            ]\n\n            logger.info(\n                \"Removed %s recognizers which had the name %s\",\n                str(len(self.recognizers) - len(new_recognizers)),\n                recognizer_name,\n            )\n\n        else:\n            new_recognizers = [\n                rec\n                for rec in self.recognizers\n                if rec.name != recognizer_name or rec.supported_language != language\n            ]\n\n            logger.info(\n                \"Removed %s recognizers which had the name %s and language %s\",\n                str(len(self.recognizers) - len(new_recognizers)),\n                recognizer_name,\n                language,\n            )\n\n        self.recognizers = new_recognizers\n\n    def add_pattern_recognizer_from_dict(self, recognizer_dict: Dict) -&gt; None:\n        \"\"\"\n        Load a pattern recognizer from a Dict into the recognizer registry.\n\n        :param recognizer_dict: Dict holding a serialization of an PatternRecognizer\n\n        :example:\n        &gt;&gt;&gt; registry = RecognizerRegistry()\n        &gt;&gt;&gt; recognizer = { \"name\": \"Titles Recognizer\", \"supported_language\": \"de\",\"supported_entity\": \"TITLE\", \"deny_list\": [\"Mr.\",\"Mrs.\"]}\n        &gt;&gt;&gt; registry.add_pattern_recognizer_from_dict(recognizer)\n        \"\"\"  # noqa: E501\n\n        recognizer = PatternRecognizer.from_dict(recognizer_dict)\n        self.add_recognizer(recognizer)\n\n    def add_recognizers_from_yaml(self, yml_path: Union[str, Path]) -&gt; None:\n        r\"\"\"\n        Read YAML file and load recognizers into the recognizer registry.\n\n        See example yaml file here:\n        https://github.com/microsoft/presidio/blob/main/presidio-analyzer/presidio_analyzer/conf/example_recognizers.yaml\n\n        :example:\n        &gt;&gt;&gt; yaml_file = \"recognizers.yaml\"\n        &gt;&gt;&gt; registry = RecognizerRegistry()\n        &gt;&gt;&gt; registry.add_recognizers_from_yaml(yaml_file)\n\n        \"\"\"\n\n        try:\n            with open(yml_path) as stream:\n                yaml_recognizers = yaml.safe_load(stream)\n\n            for yaml_recognizer in yaml_recognizers[\"recognizers\"]:\n                self.add_pattern_recognizer_from_dict(yaml_recognizer)\n        except OSError as io_error:\n            print(f\"Error reading file {yml_path}\")\n            raise io_error\n        except yaml.YAMLError as yaml_error:\n            print(f\"Failed to parse file {yml_path}\")\n            raise yaml_error\n        except TypeError as yaml_error:\n            print(f\"Failed to parse file {yml_path}\")\n            raise yaml_error\n\n    def __instantiate_recognizer(\n        self, recognizer_class: Type[EntityRecognizer], supported_language: str\n    ):\n        \"\"\"\n        Instantiate a recognizer class given type and input.\n\n        :param recognizer_class: Class object of the recognizer\n        :param supported_language: Language this recognizer should support\n        \"\"\"\n\n        inst = recognizer_class(supported_language=supported_language)\n        if isinstance(inst, PatternRecognizer):\n            inst.global_regex_flags = self.global_regex_flags\n        return inst\n\n    def _get_supported_languages(self) -&gt; List[str]:\n        languages = []\n        for rec in self.recognizers:\n            languages.append(rec.supported_language)\n\n        return list(set(languages))\n\n    def get_supported_entities(\n        self, languages: Optional[List[str]] = None\n    ) -&gt; List[str]:\n        \"\"\"\n        Return the supported entities by the set of recognizers loaded.\n\n        :param languages: The languages to get the supported entities for.\n        If languages=None, returns all entities for all languages.\n        \"\"\"\n        if not languages:\n            languages = self._get_supported_languages()\n\n        supported_entities = []\n        for language in languages:\n            recognizers = self.get_recognizers(language=language, all_fields=True)\n\n            for recognizer in recognizers:\n                supported_entities.extend(recognizer.get_supported_entities())\n\n        return list(set(supported_entities))\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.__instantiate_recognizer","title":"<code>__instantiate_recognizer(recognizer_class, supported_language)</code>","text":"<p>Instantiate a recognizer class given type and input.</p> <p>Parameters:</p> Name Type Description Default <code>recognizer_class</code> <code>Type[EntityRecognizer]</code> <p>Class object of the recognizer</p> required <code>supported_language</code> <code>str</code> <p>Language this recognizer should support</p> required Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def __instantiate_recognizer(\n    self, recognizer_class: Type[EntityRecognizer], supported_language: str\n):\n    \"\"\"\n    Instantiate a recognizer class given type and input.\n\n    :param recognizer_class: Class object of the recognizer\n    :param supported_language: Language this recognizer should support\n    \"\"\"\n\n    inst = recognizer_class(supported_language=supported_language)\n    if isinstance(inst, PatternRecognizer):\n        inst.global_regex_flags = self.global_regex_flags\n    return inst\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.add_nlp_recognizer","title":"<code>add_nlp_recognizer(nlp_engine)</code>","text":"<p>Adding NLP recognizer in accordance with the nlp engine.</p> <p>Parameters:</p> Name Type Description Default <code>nlp_engine</code> <code>NlpEngine</code> <p>The NLP engine.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def add_nlp_recognizer(self, nlp_engine: NlpEngine) -&gt; None:\n    \"\"\"\n    Adding NLP recognizer in accordance with the nlp engine.\n\n    :param nlp_engine: The NLP engine.\n    :return: None\n    \"\"\"\n\n    if not nlp_engine:\n        supported_languages = self.supported_languages\n    else:\n        supported_languages = nlp_engine.get_supported_languages()\n\n    self.recognizers.extend(\n        [\n            self._create_nlp_recognizer(\n                nlp_engine=nlp_engine, supported_language=supported_language\n            )\n            for supported_language in supported_languages\n        ]\n    )\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.add_pattern_recognizer_from_dict","title":"<code>add_pattern_recognizer_from_dict(recognizer_dict)</code>","text":"<p>Load a pattern recognizer from a Dict into the recognizer registry.</p> <p>:example:</p> <p>registry = RecognizerRegistry() recognizer = { \"name\": \"Titles Recognizer\", \"supported_language\": \"de\",\"supported_entity\": \"TITLE\", \"deny_list\": [\"Mr.\",\"Mrs.\"]} registry.add_pattern_recognizer_from_dict(recognizer)</p> <p>Parameters:</p> Name Type Description Default <code>recognizer_dict</code> <code>Dict</code> <p>Dict holding a serialization of an PatternRecognizer</p> required Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def add_pattern_recognizer_from_dict(self, recognizer_dict: Dict) -&gt; None:\n    \"\"\"\n    Load a pattern recognizer from a Dict into the recognizer registry.\n\n    :param recognizer_dict: Dict holding a serialization of an PatternRecognizer\n\n    :example:\n    &gt;&gt;&gt; registry = RecognizerRegistry()\n    &gt;&gt;&gt; recognizer = { \"name\": \"Titles Recognizer\", \"supported_language\": \"de\",\"supported_entity\": \"TITLE\", \"deny_list\": [\"Mr.\",\"Mrs.\"]}\n    &gt;&gt;&gt; registry.add_pattern_recognizer_from_dict(recognizer)\n    \"\"\"  # noqa: E501\n\n    recognizer = PatternRecognizer.from_dict(recognizer_dict)\n    self.add_recognizer(recognizer)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.add_recognizer","title":"<code>add_recognizer(recognizer)</code>","text":"<p>Add a new recognizer to the list of recognizers.</p> <p>Parameters:</p> Name Type Description Default <code>recognizer</code> <code>EntityRecognizer</code> <p>Recognizer to add</p> required Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def add_recognizer(self, recognizer: EntityRecognizer) -&gt; None:\n    \"\"\"\n    Add a new recognizer to the list of recognizers.\n\n    :param recognizer: Recognizer to add\n    \"\"\"\n    if not isinstance(recognizer, EntityRecognizer):\n        raise ValueError(\"Input is not of type EntityRecognizer\")\n\n    self.recognizers.append(recognizer)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.add_recognizers_from_yaml","title":"<code>add_recognizers_from_yaml(yml_path)</code>","text":"<p>Read YAML file and load recognizers into the recognizer registry.</p> <p>See example yaml file here: https://github.com/microsoft/presidio/blob/main/presidio-analyzer/presidio_analyzer/conf/example_recognizers.yaml</p> <p>:example:</p> <p>yaml_file = \"recognizers.yaml\" registry = RecognizerRegistry() registry.add_recognizers_from_yaml(yaml_file)</p> Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def add_recognizers_from_yaml(self, yml_path: Union[str, Path]) -&gt; None:\n    r\"\"\"\n    Read YAML file and load recognizers into the recognizer registry.\n\n    See example yaml file here:\n    https://github.com/microsoft/presidio/blob/main/presidio-analyzer/presidio_analyzer/conf/example_recognizers.yaml\n\n    :example:\n    &gt;&gt;&gt; yaml_file = \"recognizers.yaml\"\n    &gt;&gt;&gt; registry = RecognizerRegistry()\n    &gt;&gt;&gt; registry.add_recognizers_from_yaml(yaml_file)\n\n    \"\"\"\n\n    try:\n        with open(yml_path) as stream:\n            yaml_recognizers = yaml.safe_load(stream)\n\n        for yaml_recognizer in yaml_recognizers[\"recognizers\"]:\n            self.add_pattern_recognizer_from_dict(yaml_recognizer)\n    except OSError as io_error:\n        print(f\"Error reading file {yml_path}\")\n        raise io_error\n    except yaml.YAMLError as yaml_error:\n        print(f\"Failed to parse file {yml_path}\")\n        raise yaml_error\n    except TypeError as yaml_error:\n        print(f\"Failed to parse file {yml_path}\")\n        raise yaml_error\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.get_recognizers","title":"<code>get_recognizers(language, entities=None, all_fields=False, ad_hoc_recognizers=None)</code>","text":"<p>Return a list of recognizers which supports the specified name and language.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>Optional[List[str]]</code> <p>the requested entities</p> <code>None</code> <code>language</code> <code>str</code> <p>the requested language</p> required <code>all_fields</code> <code>bool</code> <p>a flag to return all fields of a requested language.</p> <code>False</code> <code>ad_hoc_recognizers</code> <code>Optional[List[EntityRecognizer]]</code> <p>Additional recognizers provided by the user as part of the request</p> <code>None</code> <p>Returns:</p> Type Description <code>List[EntityRecognizer]</code> <p>A list of the recognizers which supports the supplied entities and language</p> Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def get_recognizers(\n    self,\n    language: str,\n    entities: Optional[List[str]] = None,\n    all_fields: bool = False,\n    ad_hoc_recognizers: Optional[List[EntityRecognizer]] = None,\n) -&gt; List[EntityRecognizer]:\n    \"\"\"\n    Return a list of recognizers which supports the specified name and language.\n\n    :param entities: the requested entities\n    :param language: the requested language\n    :param all_fields: a flag to return all fields of a requested language.\n    :param ad_hoc_recognizers: Additional recognizers provided by the user\n    as part of the request\n    :return: A list of the recognizers which supports the supplied entities\n    and language\n    \"\"\"\n    if language is None:\n        raise ValueError(\"No language provided\")\n\n    if entities is None and all_fields is False:\n        raise ValueError(\"No entities provided\")\n\n    all_possible_recognizers = copy.copy(self.recognizers)\n    if ad_hoc_recognizers:\n        all_possible_recognizers.extend(ad_hoc_recognizers)\n\n    # filter out unwanted recognizers\n    to_return = set()\n    if all_fields:\n        to_return = [\n            rec\n            for rec in all_possible_recognizers\n            if language == rec.supported_language\n        ]\n    else:\n        for entity in entities:\n            subset = [\n                rec\n                for rec in all_possible_recognizers\n                if entity in rec.supported_entities\n                and language == rec.supported_language\n            ]\n\n            if not subset:\n                logger.warning(\n                    \"Entity %s doesn't have the corresponding\"\n                    \" recognizer in language : %s\",\n                    entity,\n                    language,\n                )\n            else:\n                to_return.update(set(subset))\n\n    logger.debug(\n        \"Returning a total of %s recognizers\",\n        str(len(to_return)),\n    )\n\n    if not to_return:\n        raise ValueError(\"No matching recognizers were found to serve the request.\")\n\n    return list(to_return)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.get_supported_entities","title":"<code>get_supported_entities(languages=None)</code>","text":"<p>Return the supported entities by the set of recognizers loaded.</p> <p>Parameters:</p> Name Type Description Default <code>languages</code> <code>Optional[List[str]]</code> <p>The languages to get the supported entities for. If languages=None, returns all entities for all languages.</p> <code>None</code> Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def get_supported_entities(\n    self, languages: Optional[List[str]] = None\n) -&gt; List[str]:\n    \"\"\"\n    Return the supported entities by the set of recognizers loaded.\n\n    :param languages: The languages to get the supported entities for.\n    If languages=None, returns all entities for all languages.\n    \"\"\"\n    if not languages:\n        languages = self._get_supported_languages()\n\n    supported_entities = []\n    for language in languages:\n        recognizers = self.get_recognizers(language=language, all_fields=True)\n\n        for recognizer in recognizers:\n            supported_entities.extend(recognizer.get_supported_entities())\n\n    return list(set(supported_entities))\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.load_predefined_recognizers","title":"<code>load_predefined_recognizers(languages=None, nlp_engine=None)</code>","text":"<p>Load the existing recognizers into memory.</p> <p>Parameters:</p> Name Type Description Default <code>languages</code> <code>Optional[List[str]]</code> <p>List of languages for which to load recognizers</p> <code>None</code> <code>nlp_engine</code> <code>NlpEngine</code> <p>The NLP engine to use.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def load_predefined_recognizers(\n    self, languages: Optional[List[str]] = None, nlp_engine: NlpEngine = None\n) -&gt; None:\n    \"\"\"\n    Load the existing recognizers into memory.\n\n    :param languages: List of languages for which to load recognizers\n    :param nlp_engine: The NLP engine to use.\n    :return: None\n    \"\"\"\n\n    registry_configuration = {\"global_regex_flags\": self.global_regex_flags}\n    if languages is not None:\n        registry_configuration[\"supported_languages\"] = languages\n\n    configuration = RecognizerConfigurationLoader.get(\n        registry_configuration=registry_configuration\n    )\n    recognizers = RecognizerListLoader.get(**configuration)\n\n    self.recognizers.extend(recognizers)\n    self.add_nlp_recognizer(nlp_engine=nlp_engine)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerRegistry.remove_recognizer","title":"<code>remove_recognizer(recognizer_name, language=None)</code>","text":"<p>Remove a recognizer based on its name.</p> <p>Parameters:</p> Name Type Description Default <code>recognizer_name</code> <code>str</code> <p>Name of recognizer to remove</p> required <code>language</code> <code>Optional[str]</code> <p>The supported language of the recognizer to be removed, in case multiple recognizers with the same name are present, and only one should be removed.</p> <code>None</code> Source code in <code>presidio_analyzer/recognizer_registry/recognizer_registry.py</code> <pre><code>def remove_recognizer(\n    self, recognizer_name: str, language: Optional[str] = None\n) -&gt; None:\n    \"\"\"\n    Remove a recognizer based on its name.\n\n    :param recognizer_name: Name of recognizer to remove\n    :param language: The supported language of the recognizer to be removed,\n    in case multiple recognizers with the same name are present,\n    and only one should be removed.\n    \"\"\"\n\n    if not language:\n        new_recognizers = [\n            rec for rec in self.recognizers if rec.name != recognizer_name\n        ]\n\n        logger.info(\n            \"Removed %s recognizers which had the name %s\",\n            str(len(self.recognizers) - len(new_recognizers)),\n            recognizer_name,\n        )\n\n    else:\n        new_recognizers = [\n            rec\n            for rec in self.recognizers\n            if rec.name != recognizer_name or rec.supported_language != language\n        ]\n\n        logger.info(\n            \"Removed %s recognizers which had the name %s and language %s\",\n            str(len(self.recognizers) - len(new_recognizers)),\n            recognizer_name,\n            language,\n        )\n\n    self.recognizers = new_recognizers\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult","title":"<code>RecognizerResult</code>","text":"<p>Recognizer Result represents the findings of the detected entity.</p> <p>Result of a recognizer analyzing the text.</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>the type of the entity</p> required <code>start</code> <code>int</code> <p>the start location of the detected entity</p> required <code>end</code> <code>int</code> <p>the end location of the detected entity</p> required <code>score</code> <code>float</code> <p>the score of the detection</p> required <code>analysis_explanation</code> <code>AnalysisExplanation</code> <p>contains the explanation of why this entity was identified</p> <code>None</code> <code>recognition_metadata</code> <code>Dict</code> <p>a dictionary of metadata to be used in recognizer specific cases, for example specific recognized context words and recognizer name</p> <code>None</code> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>class RecognizerResult:\n    \"\"\"\n    Recognizer Result represents the findings of the detected entity.\n\n    Result of a recognizer analyzing the text.\n\n    :param entity_type: the type of the entity\n    :param start: the start location of the detected entity\n    :param end: the end location of the detected entity\n    :param score: the score of the detection\n    :param analysis_explanation: contains the explanation of why this\n                                 entity was identified\n    :param recognition_metadata: a dictionary of metadata to be used in\n    recognizer specific cases, for example specific recognized context words\n    and recognizer name\n    \"\"\"\n\n    # Keys for recognizer metadata\n    RECOGNIZER_NAME_KEY = \"recognizer_name\"\n    RECOGNIZER_IDENTIFIER_KEY = \"recognizer_identifier\"\n\n    # Key of a flag inside recognition_metadata dictionary\n    # which is set to true if the result enhanced by context\n    IS_SCORE_ENHANCED_BY_CONTEXT_KEY = \"is_score_enhanced_by_context\"\n\n    logger = logging.getLogger(\"presidio-analyzer\")\n\n    def __init__(\n        self,\n        entity_type: str,\n        start: int,\n        end: int,\n        score: float,\n        analysis_explanation: AnalysisExplanation = None,\n        recognition_metadata: Dict = None,\n    ):\n        self.entity_type = entity_type\n        self.start = start\n        self.end = end\n        self.score = score\n        self.analysis_explanation = analysis_explanation\n\n        if not recognition_metadata:\n            self.logger.debug(\n                \"recognition_metadata should be passed, \"\n                \"containing a recognizer_name value\"\n            )\n\n        self.recognition_metadata = recognition_metadata\n\n    def append_analysis_explanation_text(self, text: str) -&gt; None:\n        \"\"\"Add text to the analysis explanation.\"\"\"\n        if self.analysis_explanation:\n            self.analysis_explanation.append_textual_explanation_line(text)\n\n    def to_dict(self) -&gt; Dict:\n        \"\"\"\n        Serialize self to dictionary.\n\n        :return: a dictionary\n        \"\"\"\n        return self.__dict__\n\n    @classmethod\n    def from_json(cls, data: Dict) -&gt; \"RecognizerResult\":\n        \"\"\"\n        Create RecognizerResult from json.\n\n        :param data: e.g. {\n            \"start\": 24,\n            \"end\": 32,\n            \"score\": 0.8,\n            \"entity_type\": \"NAME\"\n        }\n        :return: RecognizerResult\n        \"\"\"\n        score = data.get(\"score\")\n        entity_type = data.get(\"entity_type\")\n        start = data.get(\"start\")\n        end = data.get(\"end\")\n        return cls(entity_type, start, end, score)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the instance.\"\"\"\n        return self.__str__()\n\n    def intersects(self, other: \"RecognizerResult\") -&gt; int:\n        \"\"\"\n        Check if self intersects with a different RecognizerResult.\n\n        :return: If intersecting, returns the number of\n        intersecting characters.\n        If not, returns 0\n        \"\"\"\n        # if they do not overlap the intersection is 0\n        if self.end &lt; other.start or other.end &lt; self.start:\n            return 0\n\n        # otherwise the intersection is min(end) - max(start)\n        return min(self.end, other.end) - max(self.start, other.start)\n\n    def contained_in(self, other: \"RecognizerResult\") -&gt; bool:\n        \"\"\"\n        Check if self is contained in a different RecognizerResult.\n\n        :return: true if contained\n        \"\"\"\n        return self.start &gt;= other.start and self.end &lt;= other.end\n\n    def contains(self, other: \"RecognizerResult\") -&gt; bool:\n        \"\"\"\n        Check if one result is contained or equal to another result.\n\n        :param other: another RecognizerResult\n        :return: bool\n        \"\"\"\n        return self.start &lt;= other.start and self.end &gt;= other.end\n\n    def equal_indices(self, other: \"RecognizerResult\") -&gt; bool:\n        \"\"\"\n        Check if the indices are equal between two results.\n\n        :param other: another RecognizerResult\n        :return:\n        \"\"\"\n        return self.start == other.start and self.end == other.end\n\n    def __gt__(self, other: \"RecognizerResult\") -&gt; bool:\n        \"\"\"\n        Check if one result is greater by using the results indices in the text.\n\n        :param other: another RecognizerResult\n        :return: bool\n        \"\"\"\n        if self.start == other.start:\n            return self.end &gt; other.end\n        return self.start &gt; other.start\n\n    def __eq__(self, other: \"RecognizerResult\") -&gt; bool:\n        \"\"\"\n        Check two results are equal by using all class fields.\n\n        :param other: another RecognizerResult\n        :return: bool\n        \"\"\"\n        equal_type = self.entity_type == other.entity_type\n        equal_score = self.score == other.score\n        return self.equal_indices(other) and equal_type and equal_score\n\n    def __hash__(self):\n        \"\"\"\n        Hash the result data by using all class fields.\n\n        :return: int\n        \"\"\"\n        return hash(\n            f\"{str(self.start)} {str(self.end)} {str(self.score)} {self.entity_type}\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the instance.\"\"\"\n        return (\n            f\"type: {self.entity_type}, \"\n            f\"start: {self.start}, \"\n            f\"end: {self.end}, \"\n            f\"score: {self.score}\"\n        )\n\n    def has_conflict(self, other: \"RecognizerResult\") -&gt; bool:\n        \"\"\"\n        Check if two recognizer results are conflicted or not.\n\n        I have a conflict if:\n        1. My indices are the same as the other and my score is lower.\n        2. If my indices are contained in another.\n\n        :param other: RecognizerResult\n        :return:\n        \"\"\"\n        if self.equal_indices(other):\n            return self.score &lt;= other.score\n        return other.contains(self)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Check two results are equal by using all class fields.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>RecognizerResult</code> <p>another RecognizerResult</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def __eq__(self, other: \"RecognizerResult\") -&gt; bool:\n    \"\"\"\n    Check two results are equal by using all class fields.\n\n    :param other: another RecognizerResult\n    :return: bool\n    \"\"\"\n    equal_type = self.entity_type == other.entity_type\n    equal_score = self.score == other.score\n    return self.equal_indices(other) and equal_type and equal_score\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.__gt__","title":"<code>__gt__(other)</code>","text":"<p>Check if one result is greater by using the results indices in the text.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>RecognizerResult</code> <p>another RecognizerResult</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def __gt__(self, other: \"RecognizerResult\") -&gt; bool:\n    \"\"\"\n    Check if one result is greater by using the results indices in the text.\n\n    :param other: another RecognizerResult\n    :return: bool\n    \"\"\"\n    if self.start == other.start:\n        return self.end &gt; other.end\n    return self.start &gt; other.start\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.__hash__","title":"<code>__hash__()</code>","text":"<p>Hash the result data by using all class fields.</p> <p>Returns:</p> Type Description <p>int</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def __hash__(self):\n    \"\"\"\n    Hash the result data by using all class fields.\n\n    :return: int\n    \"\"\"\n    return hash(\n        f\"{str(self.start)} {str(self.end)} {str(self.score)} {self.entity_type}\"\n    )\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the instance.</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the instance.\"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the instance.</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the instance.\"\"\"\n    return (\n        f\"type: {self.entity_type}, \"\n        f\"start: {self.start}, \"\n        f\"end: {self.end}, \"\n        f\"score: {self.score}\"\n    )\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.append_analysis_explanation_text","title":"<code>append_analysis_explanation_text(text)</code>","text":"<p>Add text to the analysis explanation.</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def append_analysis_explanation_text(self, text: str) -&gt; None:\n    \"\"\"Add text to the analysis explanation.\"\"\"\n    if self.analysis_explanation:\n        self.analysis_explanation.append_textual_explanation_line(text)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.contained_in","title":"<code>contained_in(other)</code>","text":"<p>Check if self is contained in a different RecognizerResult.</p> <p>Returns:</p> Type Description <code>bool</code> <p>true if contained</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def contained_in(self, other: \"RecognizerResult\") -&gt; bool:\n    \"\"\"\n    Check if self is contained in a different RecognizerResult.\n\n    :return: true if contained\n    \"\"\"\n    return self.start &gt;= other.start and self.end &lt;= other.end\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.contains","title":"<code>contains(other)</code>","text":"<p>Check if one result is contained or equal to another result.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>RecognizerResult</code> <p>another RecognizerResult</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def contains(self, other: \"RecognizerResult\") -&gt; bool:\n    \"\"\"\n    Check if one result is contained or equal to another result.\n\n    :param other: another RecognizerResult\n    :return: bool\n    \"\"\"\n    return self.start &lt;= other.start and self.end &gt;= other.end\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.equal_indices","title":"<code>equal_indices(other)</code>","text":"<p>Check if the indices are equal between two results.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>RecognizerResult</code> <p>another RecognizerResult</p> required <p>Returns:</p> Type Description <code>bool</code> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def equal_indices(self, other: \"RecognizerResult\") -&gt; bool:\n    \"\"\"\n    Check if the indices are equal between two results.\n\n    :param other: another RecognizerResult\n    :return:\n    \"\"\"\n    return self.start == other.start and self.end == other.end\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.from_json","title":"<code>from_json(data)</code>  <code>classmethod</code>","text":"<p>Create RecognizerResult from json.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict</code> <p>e.g. { \"start\": 24, \"end\": 32, \"score\": 0.8, \"entity_type\": \"NAME\" }</p> required <p>Returns:</p> Type Description <code>RecognizerResult</code> <p>RecognizerResult</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>@classmethod\ndef from_json(cls, data: Dict) -&gt; \"RecognizerResult\":\n    \"\"\"\n    Create RecognizerResult from json.\n\n    :param data: e.g. {\n        \"start\": 24,\n        \"end\": 32,\n        \"score\": 0.8,\n        \"entity_type\": \"NAME\"\n    }\n    :return: RecognizerResult\n    \"\"\"\n    score = data.get(\"score\")\n    entity_type = data.get(\"entity_type\")\n    start = data.get(\"start\")\n    end = data.get(\"end\")\n    return cls(entity_type, start, end, score)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.has_conflict","title":"<code>has_conflict(other)</code>","text":"<p>Check if two recognizer results are conflicted or not.</p> <p>I have a conflict if: 1. My indices are the same as the other and my score is lower. 2. If my indices are contained in another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>RecognizerResult</code> <p>RecognizerResult</p> required <p>Returns:</p> Type Description <code>bool</code> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def has_conflict(self, other: \"RecognizerResult\") -&gt; bool:\n    \"\"\"\n    Check if two recognizer results are conflicted or not.\n\n    I have a conflict if:\n    1. My indices are the same as the other and my score is lower.\n    2. If my indices are contained in another.\n\n    :param other: RecognizerResult\n    :return:\n    \"\"\"\n    if self.equal_indices(other):\n        return self.score &lt;= other.score\n    return other.contains(self)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.intersects","title":"<code>intersects(other)</code>","text":"<p>Check if self intersects with a different RecognizerResult.</p> <p>Returns:</p> Type Description <code>int</code> <p>If intersecting, returns the number of intersecting characters. If not, returns 0</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def intersects(self, other: \"RecognizerResult\") -&gt; int:\n    \"\"\"\n    Check if self intersects with a different RecognizerResult.\n\n    :return: If intersecting, returns the number of\n    intersecting characters.\n    If not, returns 0\n    \"\"\"\n    # if they do not overlap the intersection is 0\n    if self.end &lt; other.start or other.end &lt; self.start:\n        return 0\n\n    # otherwise the intersection is min(end) - max(start)\n    return min(self.end, other.end) - max(self.start, other.start)\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RecognizerResult.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize self to dictionary.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>a dictionary</p> Source code in <code>presidio_analyzer/recognizer_result.py</code> <pre><code>def to_dict(self) -&gt; Dict:\n    \"\"\"\n    Serialize self to dictionary.\n\n    :return: a dictionary\n    \"\"\"\n    return self.__dict__\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RemoteRecognizer","title":"<code>RemoteRecognizer</code>","text":"<p>               Bases: <code>ABC</code>, <code>EntityRecognizer</code></p> <p>A configuration for a recognizer that runs on a different process / remote machine.</p> <p>Parameters:</p> Name Type Description Default <code>supported_entities</code> <code>List[str]</code> <p>A list of entities this recognizer can identify</p> required <code>name</code> <code>Optional[str]</code> <p>name of recognizer</p> required <code>supported_language</code> <code>str</code> <p>The language this recognizer can detect entities in</p> required <code>version</code> <code>str</code> <p>Version of this recognizer</p> required Source code in <code>presidio_analyzer/remote_recognizer.py</code> <pre><code>class RemoteRecognizer(ABC, EntityRecognizer):\n    \"\"\"\n    A configuration for a recognizer that runs on a different process / remote machine.\n\n    :param supported_entities: A list of entities this recognizer can identify\n    :param name: name of recognizer\n    :param supported_language: The language this recognizer can detect entities in\n    :param version: Version of this recognizer\n    \"\"\"\n\n    def __init__(\n        self,\n        supported_entities: List[str],\n        name: Optional[str],\n        supported_language: str,\n        version: str,\n        context: Optional[List[str]] = None,\n    ):\n        super().__init__(\n            supported_entities=supported_entities,\n            name=name,\n            supported_language=supported_language,\n            version=version,\n            context=context,\n        )\n\n    def load(self):  # noqa D102\n        pass\n\n    @abstractmethod\n    def analyze(self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts):  # noqa ANN201\n        \"\"\"\n        Call an external service for PII detection.\n\n        :param text: text to be analyzed\n        :param entities: Entities that should be looked for\n        :param nlp_artifacts: Additional metadata from the NLP engine\n        :return: List of identified PII entities\n        \"\"\"\n\n        # 1. Call the external service.\n        # 2. Translate results into List[RecognizerResult]\n        pass\n\n    @abstractmethod\n    def get_supported_entities(self) -&gt; List[str]:  # noqa D102\n        pass\n</code></pre>"},{"location":"api/analyzer_python/#presidio_analyzer.RemoteRecognizer.analyze","title":"<code>analyze(text, entities, nlp_artifacts)</code>  <code>abstractmethod</code>","text":"<p>Call an external service for PII detection.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>text to be analyzed</p> required <code>entities</code> <code>List[str]</code> <p>Entities that should be looked for</p> required <code>nlp_artifacts</code> <code>NlpArtifacts</code> <p>Additional metadata from the NLP engine</p> required <p>Returns:</p> Type Description <p>List of identified PII entities</p> Source code in <code>presidio_analyzer/remote_recognizer.py</code> <pre><code>@abstractmethod\ndef analyze(self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts):  # noqa ANN201\n    \"\"\"\n    Call an external service for PII detection.\n\n    :param text: text to be analyzed\n    :param entities: Entities that should be looked for\n    :param nlp_artifacts: Additional metadata from the NLP engine\n    :return: List of identified PII entities\n    \"\"\"\n\n    # 1. Call the external service.\n    # 2. Translate results into List[RecognizerResult]\n    pass\n</code></pre>"},{"location":"api/anonymizer_python/","title":"Presidio Anonymizer API Reference","text":"<p>Anonymizer root module.</p>"},{"location":"api/anonymizer_python/#presidio_anonymizer.AnonymizerEngine","title":"<code>AnonymizerEngine</code>","text":"<p>               Bases: <code>EngineBase</code></p> <p>AnonymizerEngine class.</p> <p>Handles the entire logic of the Presidio-anonymizer. Gets the original text and replaces the PII entities with the desired anonymizers.</p> Source code in <code>presidio_anonymizer/anonymizer_engine.py</code> <pre><code>class AnonymizerEngine(EngineBase):\n    \"\"\"\n    AnonymizerEngine class.\n\n    Handles the entire logic of the Presidio-anonymizer. Gets the original text\n    and replaces the PII entities with the desired anonymizers.\n    \"\"\"\n\n    def anonymize(\n        self,\n        text: str,\n        analyzer_results: List[RecognizerResult],\n        operators: Optional[Dict[str, OperatorConfig]] = None,\n        conflict_resolution: ConflictResolutionStrategy = (\n            ConflictResolutionStrategy.MERGE_SIMILAR_OR_CONTAINED\n        ),\n    ) -&gt; EngineResult:\n        \"\"\"Anonymize method to anonymize the given text.\n\n        :param text: the text we are anonymizing\n        :param analyzer_results: A list of RecognizerResult class -&gt; The results we\n        received from the analyzer\n        :param operators: The configuration of the anonymizers we would like\n        to use for each entity e.g.: {\"PHONE_NUMBER\":OperatorConfig(\"redact\", {})}\n        received from the analyzer\n        :param conflict_resolution: The configuration designed to handle conflicts\n        among entities\n        :return: the anonymized text and a list of information about the\n        anonymized entities.\n\n        :example:\n\n        &gt;&gt;&gt; from presidio_anonymizer import AnonymizerEngine\n        &gt;&gt;&gt; from presidio_anonymizer.entities import RecognizerResult, OperatorConfig\n\n        &gt;&gt;&gt; # Initialize the engine with logger.\n        &gt;&gt;&gt; engine = AnonymizerEngine()\n\n        &gt;&gt;&gt; # Invoke the anonymize function with the text, analyzer results and\n        &gt;&gt;&gt; # Operators to define the anonymization type.\n        &gt;&gt;&gt; result = engine.anonymize(\n        &gt;&gt;&gt;     text=\"My name is Bond, James Bond\",\n        &gt;&gt;&gt;     analyzer_results=[RecognizerResult(entity_type=\"PERSON\",\n        &gt;&gt;&gt;                                        start=11,\n        &gt;&gt;&gt;                                        end=15,\n        &gt;&gt;&gt;                                        score=0.8),\n        &gt;&gt;&gt;                       RecognizerResult(entity_type=\"PERSON\",\n        &gt;&gt;&gt;                                        start=17,\n        &gt;&gt;&gt;                                        end=27,\n        &gt;&gt;&gt;                                        score=0.8)],\n        &gt;&gt;&gt;     operators={\"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"BIP\"})}\n        &gt;&gt;&gt; )\n\n        &gt;&gt;&gt; print(result)\n        text: My name is BIP, BIP.\n        items:\n        [\n            {'start': 16, 'end': 19, 'entity_type': 'PERSON',\n             'text': 'BIP', 'operator': 'replace'},\n            {'start': 11, 'end': 14, 'entity_type': 'PERSON',\n             'text': 'BIP', 'operator': 'replace'}\n        ]\n\n\n        \"\"\"\n        analyzer_results = self._remove_conflicts_and_get_text_manipulation_data(\n            analyzer_results, conflict_resolution\n        )\n\n        merged_results = self._merge_entities_with_whitespace_between(\n            text, analyzer_results\n        )\n\n        operators = self.__check_or_add_default_operator(operators)\n\n        return self._operate(\n            text=text,\n            pii_entities=merged_results,\n            operators_metadata=operators,\n            operator_type=OperatorType.Anonymize,\n        )\n\n    def add_anonymizer(self, anonymizer_cls: Type[Operator]) -&gt; None:\n        \"\"\"\n        Add a new anonymizer to the engine.\n\n        anonymizer_cls: The anonymizer class to add to the engine.\n        \"\"\"\n        logger.info(f\"Added anonymizer {anonymizer_cls.__name__}\")\n        self.operators_factory.add_anonymize_operator(anonymizer_cls)\n\n    def remove_anonymizer(self, anonymizer_cls: Type[Operator]) -&gt; None:\n        \"\"\"\n        Remove an anonymizer from the engine.\n\n        anonymizer_cls: The anonymizer class to remove from the engine.\n        \"\"\"\n        logger.info(f\"Removed anonymizer {anonymizer_cls.__name__}\")\n        self.operators_factory.remove_anonymize_operator(anonymizer_cls)\n\n    def _remove_conflicts_and_get_text_manipulation_data(\n        self,\n        analyzer_results: List[RecognizerResult],\n        conflict_resolution: ConflictResolutionStrategy,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Iterate the list and create a sorted unique results list from it.\n\n        Only insert results which are:\n        1. Indices are not contained in other result.\n        2. Have the same indices as other results but with larger score.\n        :return: List\n        \"\"\"\n        tmp_analyzer_results = []\n        # This list contains all elements which we need to check a single result\n        # against. If a result is dropped, it can also be dropped from this list\n        # since it is intersecting with another result and we selected the other one.\n        other_elements = analyzer_results.copy()\n        for result in analyzer_results:\n            other_elements.remove(result)\n\n            is_merge_same_entity_type = False\n            for other_element in other_elements:\n                if other_element.entity_type != result.entity_type:\n                    continue\n                if result.intersects(other_element) == 0:\n                    continue\n\n                other_element.start = min(result.start, other_element.start)\n                other_element.end = max(result.end, other_element.end)\n                other_element.score = max(result.score, other_element.score)\n                is_merge_same_entity_type = True\n                break\n            if not is_merge_same_entity_type:\n                other_elements.append(result)\n                tmp_analyzer_results.append(result)\n            else:\n                self.logger.debug(\n                    f\"removing element {result} from \" f\"results list due to merge\"\n                )\n\n        unique_text_metadata_elements = []\n        # This list contains all elements which we need to check a single result\n        # against. If a result is dropped, it can also be dropped from this list\n        # since it is intersecting with another result and we selected the other one.\n        other_elements = tmp_analyzer_results.copy()\n        for result in tmp_analyzer_results:\n            other_elements.remove(result)\n            result_conflicted = self.__is_result_conflicted_with_other_elements(\n                other_elements, result\n            )\n            if not result_conflicted:\n                other_elements.append(result)\n                unique_text_metadata_elements.append(result)\n            else:\n                self.logger.debug(\n                    f\"removing element {result} from results list due to conflict\"\n                )\n\n        # This further improves the quality of handling the conflict between the\n        # various entities overlapping. This will not drop the results insted\n        # it adjust the start and end positions of overlapping results and removes\n        # All types of conflicts among entities as well as text.\n        if conflict_resolution == ConflictResolutionStrategy.REMOVE_INTERSECTIONS:\n            unique_text_metadata_elements.sort(key=lambda element: element.start)\n            elements_length = len(unique_text_metadata_elements)\n            index = 0\n            while index &lt; elements_length - 1:\n                current_entity = unique_text_metadata_elements[index]\n                next_entity = unique_text_metadata_elements[index + 1]\n                if current_entity.end &lt;= next_entity.start:\n                    index += 1\n                else:\n                    if current_entity.score &gt;= next_entity.score:\n                        next_entity.start = current_entity.end\n                    else:\n                        current_entity.end = next_entity.start\n                    unique_text_metadata_elements.sort(\n                        key=lambda element: element.start\n                    )\n            unique_text_metadata_elements = [\n                element\n                for element in unique_text_metadata_elements\n                if element.start &lt;= element.end\n            ]\n        return unique_text_metadata_elements\n\n    def _merge_entities_with_whitespace_between(\n        self, text: str, analyzer_results: List[RecognizerResult]\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"Merge adjacent entities of the same type separated by whitespace.\"\"\"\n        merged_results = []\n        prev_result = None\n        for result in analyzer_results:\n            if prev_result is not None:\n                if prev_result.entity_type == result.entity_type:\n                    if re.search(r\"^( )+$\", text[prev_result.end : result.start]):\n                        merged_results.remove(prev_result)\n                        result.start = prev_result.start\n            merged_results.append(result)\n            prev_result = result\n        return merged_results\n\n    def get_anonymizers(self) -&gt; List[str]:\n        \"\"\"Return a list of supported anonymizers.\"\"\"\n        names = [p for p in self.operators_factory.get_anonymizers().keys()]\n        return names\n\n    @staticmethod\n    def __is_result_conflicted_with_other_elements(other_elements, result):\n        return any(\n            [result.has_conflict(other_element) for other_element in other_elements]\n        )\n\n    @staticmethod\n    def __check_or_add_default_operator(\n        operators: Dict[str, OperatorConfig],\n    ) -&gt; Dict[str, OperatorConfig]:\n        default_operator = OperatorConfig(DEFAULT)\n        if not operators:\n            return {\"DEFAULT\": default_operator}\n        if not operators.get(\"DEFAULT\"):\n            operators[\"DEFAULT\"] = default_operator\n        return operators\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.AnonymizerEngine.add_anonymizer","title":"<code>add_anonymizer(anonymizer_cls)</code>","text":"<p>Add a new anonymizer to the engine.</p> <p>anonymizer_cls: The anonymizer class to add to the engine.</p> Source code in <code>presidio_anonymizer/anonymizer_engine.py</code> <pre><code>def add_anonymizer(self, anonymizer_cls: Type[Operator]) -&gt; None:\n    \"\"\"\n    Add a new anonymizer to the engine.\n\n    anonymizer_cls: The anonymizer class to add to the engine.\n    \"\"\"\n    logger.info(f\"Added anonymizer {anonymizer_cls.__name__}\")\n    self.operators_factory.add_anonymize_operator(anonymizer_cls)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.AnonymizerEngine.anonymize","title":"<code>anonymize(text, analyzer_results, operators=None, conflict_resolution=ConflictResolutionStrategy.MERGE_SIMILAR_OR_CONTAINED)</code>","text":"<p>Anonymize method to anonymize the given text.</p> <p>:example:</p> <p>from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import RecognizerResult, OperatorConfig</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>the text we are anonymizing</p> required <code>analyzer_results</code> <code>List[RecognizerResult]</code> <p>A list of RecognizerResult class -&gt; The results we received from the analyzer</p> required <code>operators</code> <code>Optional[Dict[str, OperatorConfig]]</code> <p>The configuration of the anonymizers we would like to use for each entity e.g.: {\"PHONE_NUMBER\":OperatorConfig(\"redact\", {})} received from the analyzer</p> <code>None</code> <code>conflict_resolution</code> <code>ConflictResolutionStrategy</code> <p>The configuration designed to handle conflicts among entities</p> <code>MERGE_SIMILAR_OR_CONTAINED</code> <p>Returns:</p> Type Description <code>EngineResult</code> <p>the anonymized text and a list of information about the anonymized entities.</p> Source code in <code>presidio_anonymizer/anonymizer_engine.py</code> <pre><code>def anonymize(\n    self,\n    text: str,\n    analyzer_results: List[RecognizerResult],\n    operators: Optional[Dict[str, OperatorConfig]] = None,\n    conflict_resolution: ConflictResolutionStrategy = (\n        ConflictResolutionStrategy.MERGE_SIMILAR_OR_CONTAINED\n    ),\n) -&gt; EngineResult:\n    \"\"\"Anonymize method to anonymize the given text.\n\n    :param text: the text we are anonymizing\n    :param analyzer_results: A list of RecognizerResult class -&gt; The results we\n    received from the analyzer\n    :param operators: The configuration of the anonymizers we would like\n    to use for each entity e.g.: {\"PHONE_NUMBER\":OperatorConfig(\"redact\", {})}\n    received from the analyzer\n    :param conflict_resolution: The configuration designed to handle conflicts\n    among entities\n    :return: the anonymized text and a list of information about the\n    anonymized entities.\n\n    :example:\n\n    &gt;&gt;&gt; from presidio_anonymizer import AnonymizerEngine\n    &gt;&gt;&gt; from presidio_anonymizer.entities import RecognizerResult, OperatorConfig\n\n    &gt;&gt;&gt; # Initialize the engine with logger.\n    &gt;&gt;&gt; engine = AnonymizerEngine()\n\n    &gt;&gt;&gt; # Invoke the anonymize function with the text, analyzer results and\n    &gt;&gt;&gt; # Operators to define the anonymization type.\n    &gt;&gt;&gt; result = engine.anonymize(\n    &gt;&gt;&gt;     text=\"My name is Bond, James Bond\",\n    &gt;&gt;&gt;     analyzer_results=[RecognizerResult(entity_type=\"PERSON\",\n    &gt;&gt;&gt;                                        start=11,\n    &gt;&gt;&gt;                                        end=15,\n    &gt;&gt;&gt;                                        score=0.8),\n    &gt;&gt;&gt;                       RecognizerResult(entity_type=\"PERSON\",\n    &gt;&gt;&gt;                                        start=17,\n    &gt;&gt;&gt;                                        end=27,\n    &gt;&gt;&gt;                                        score=0.8)],\n    &gt;&gt;&gt;     operators={\"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"BIP\"})}\n    &gt;&gt;&gt; )\n\n    &gt;&gt;&gt; print(result)\n    text: My name is BIP, BIP.\n    items:\n    [\n        {'start': 16, 'end': 19, 'entity_type': 'PERSON',\n         'text': 'BIP', 'operator': 'replace'},\n        {'start': 11, 'end': 14, 'entity_type': 'PERSON',\n         'text': 'BIP', 'operator': 'replace'}\n    ]\n\n\n    \"\"\"\n    analyzer_results = self._remove_conflicts_and_get_text_manipulation_data(\n        analyzer_results, conflict_resolution\n    )\n\n    merged_results = self._merge_entities_with_whitespace_between(\n        text, analyzer_results\n    )\n\n    operators = self.__check_or_add_default_operator(operators)\n\n    return self._operate(\n        text=text,\n        pii_entities=merged_results,\n        operators_metadata=operators,\n        operator_type=OperatorType.Anonymize,\n    )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.AnonymizerEngine.anonymize--initialize-the-engine-with-logger","title":"Initialize the engine with logger.","text":"<p>engine = AnonymizerEngine()</p>"},{"location":"api/anonymizer_python/#presidio_anonymizer.AnonymizerEngine.anonymize--invoke-the-anonymize-function-with-the-text-analyzer-results-and","title":"Invoke the anonymize function with the text, analyzer results and","text":""},{"location":"api/anonymizer_python/#presidio_anonymizer.AnonymizerEngine.anonymize--operators-to-define-the-anonymization-type","title":"Operators to define the anonymization type.","text":"<p>result = engine.anonymize(     text=\"My name is Bond, James Bond\",     analyzer_results=[RecognizerResult(entity_type=\"PERSON\",                                        start=11,                                        end=15,                                        score=0.8),                       RecognizerResult(entity_type=\"PERSON\",                                        start=17,                                        end=27,                                        score=0.8)],     operators={\"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"BIP\"})} )</p> <p>print(result) text: My name is BIP, BIP. items: [     {'start': 16, 'end': 19, 'entity_type': 'PERSON',      'text': 'BIP', 'operator': 'replace'},     {'start': 11, 'end': 14, 'entity_type': 'PERSON',      'text': 'BIP', 'operator': 'replace'} ]</p>"},{"location":"api/anonymizer_python/#presidio_anonymizer.AnonymizerEngine.get_anonymizers","title":"<code>get_anonymizers()</code>","text":"<p>Return a list of supported anonymizers.</p> Source code in <code>presidio_anonymizer/anonymizer_engine.py</code> <pre><code>def get_anonymizers(self) -&gt; List[str]:\n    \"\"\"Return a list of supported anonymizers.\"\"\"\n    names = [p for p in self.operators_factory.get_anonymizers().keys()]\n    return names\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.AnonymizerEngine.remove_anonymizer","title":"<code>remove_anonymizer(anonymizer_cls)</code>","text":"<p>Remove an anonymizer from the engine.</p> <p>anonymizer_cls: The anonymizer class to remove from the engine.</p> Source code in <code>presidio_anonymizer/anonymizer_engine.py</code> <pre><code>def remove_anonymizer(self, anonymizer_cls: Type[Operator]) -&gt; None:\n    \"\"\"\n    Remove an anonymizer from the engine.\n\n    anonymizer_cls: The anonymizer class to remove from the engine.\n    \"\"\"\n    logger.info(f\"Removed anonymizer {anonymizer_cls.__name__}\")\n    self.operators_factory.remove_anonymize_operator(anonymizer_cls)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.BatchAnonymizerEngine","title":"<code>BatchAnonymizerEngine</code>","text":"<p>BatchAnonymizerEngine class.</p> <p>A class that provides functionality to anonymize in batches.</p> <p>Parameters:</p> Name Type Description Default <code>anonymizer_engine</code> <code>Optional[AnonymizerEngine]</code> <p>An instance of the AnonymizerEngine class.</p> <code>None</code> Source code in <code>presidio_anonymizer/batch_anonymizer_engine.py</code> <pre><code>class BatchAnonymizerEngine:\n    \"\"\"\n    BatchAnonymizerEngine class.\n\n    A class that provides functionality to anonymize in batches.\n    :param anonymizer_engine: An instance of the AnonymizerEngine class.\n    \"\"\"\n\n    def __init__(self, anonymizer_engine: Optional[AnonymizerEngine] = None):\n        self.anonymizer_engine = anonymizer_engine or AnonymizerEngine()\n\n    def anonymize_list(\n        self,\n        texts: List[Optional[Union[str, bool, int, float]]],\n        recognizer_results_list: List[List[RecognizerResult]],\n        **kwargs,\n    ) -&gt; List[Union[str, Any]]:\n        \"\"\"\n        Anonymize a list of strings.\n\n        :param texts: List containing the texts to be anonymized (original texts).\n            Items with a `type` not in `(str, bool, int, float)` will not be anonymized.\n        :param recognizer_results_list: A list of lists of RecognizerResult,\n        the output of the AnalyzerEngine on each text in the list.\n        :param kwargs: Additional kwargs for the `AnonymizerEngine.anonymize` method\n        \"\"\"\n        return_list = []\n        if not recognizer_results_list:\n            recognizer_results_list = [[] for _ in range(len(texts))]\n        for text, recognizer_results in zip(texts, recognizer_results_list):\n            if type(text) in (str, bool, int, float):\n                res = self.anonymizer_engine.anonymize(\n                    text=str(text), analyzer_results=recognizer_results, **kwargs\n                )\n                return_list.append(res.text)\n            else:\n                return_list.append(text)\n\n        return return_list\n\n    def anonymize_dict(\n        self, analyzer_results: Iterable[DictRecognizerResult], **kwargs\n    ) -&gt; Dict[str, str]:\n        \"\"\"\n        Anonymize values in a dictionary.\n\n        :param analyzer_results: Iterator of `DictRecognizerResult`\n        containing the output of the AnalyzerEngine.analyze_dict on the input text.\n        :param kwargs: Additional kwargs for the `AnonymizerEngine.anonymize` method\n        \"\"\"\n\n        return_dict = {}\n        for result in analyzer_results:\n            if isinstance(result.value, dict):\n                resp = self.anonymize_dict(\n                    analyzer_results=result.recognizer_results, **kwargs\n                )\n                return_dict[result.key] = resp\n\n            elif isinstance(result.value, str):\n                resp = self.anonymizer_engine.anonymize(\n                    text=result.value,\n                    analyzer_results=result.recognizer_results,\n                    **kwargs,\n                )\n                return_dict[result.key] = resp.text\n\n            elif isinstance(result.value, collections.abc.Iterable):\n                anonymize_response = self.anonymize_list(\n                    texts=result.value,\n                    recognizer_results_list=result.recognizer_results,\n                    **kwargs,\n                )\n                return_dict[result.key] = anonymize_response\n            else:\n                return_dict[result.key] = result.value\n        return return_dict\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.BatchAnonymizerEngine.anonymize_dict","title":"<code>anonymize_dict(analyzer_results, **kwargs)</code>","text":"<p>Anonymize values in a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer_results</code> <code>Iterable[DictRecognizerResult]</code> <p>Iterator of <code>DictRecognizerResult</code> containing the output of the AnalyzerEngine.analyze_dict on the input text.</p> required <code>kwargs</code> <p>Additional kwargs for the <code>AnonymizerEngine.anonymize</code> method</p> <code>{}</code> Source code in <code>presidio_anonymizer/batch_anonymizer_engine.py</code> <pre><code>def anonymize_dict(\n    self, analyzer_results: Iterable[DictRecognizerResult], **kwargs\n) -&gt; Dict[str, str]:\n    \"\"\"\n    Anonymize values in a dictionary.\n\n    :param analyzer_results: Iterator of `DictRecognizerResult`\n    containing the output of the AnalyzerEngine.analyze_dict on the input text.\n    :param kwargs: Additional kwargs for the `AnonymizerEngine.anonymize` method\n    \"\"\"\n\n    return_dict = {}\n    for result in analyzer_results:\n        if isinstance(result.value, dict):\n            resp = self.anonymize_dict(\n                analyzer_results=result.recognizer_results, **kwargs\n            )\n            return_dict[result.key] = resp\n\n        elif isinstance(result.value, str):\n            resp = self.anonymizer_engine.anonymize(\n                text=result.value,\n                analyzer_results=result.recognizer_results,\n                **kwargs,\n            )\n            return_dict[result.key] = resp.text\n\n        elif isinstance(result.value, collections.abc.Iterable):\n            anonymize_response = self.anonymize_list(\n                texts=result.value,\n                recognizer_results_list=result.recognizer_results,\n                **kwargs,\n            )\n            return_dict[result.key] = anonymize_response\n        else:\n            return_dict[result.key] = result.value\n    return return_dict\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.BatchAnonymizerEngine.anonymize_list","title":"<code>anonymize_list(texts, recognizer_results_list, **kwargs)</code>","text":"<p>Anonymize a list of strings.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>List[Optional[Union[str, bool, int, float]]]</code> <p>List containing the texts to be anonymized (original texts). Items with a <code>type</code> not in <code>(str, bool, int, float)</code> will not be anonymized.</p> required <code>recognizer_results_list</code> <code>List[List[RecognizerResult]]</code> <p>A list of lists of RecognizerResult, the output of the AnalyzerEngine on each text in the list.</p> required <code>kwargs</code> <p>Additional kwargs for the <code>AnonymizerEngine.anonymize</code> method</p> <code>{}</code> Source code in <code>presidio_anonymizer/batch_anonymizer_engine.py</code> <pre><code>def anonymize_list(\n    self,\n    texts: List[Optional[Union[str, bool, int, float]]],\n    recognizer_results_list: List[List[RecognizerResult]],\n    **kwargs,\n) -&gt; List[Union[str, Any]]:\n    \"\"\"\n    Anonymize a list of strings.\n\n    :param texts: List containing the texts to be anonymized (original texts).\n        Items with a `type` not in `(str, bool, int, float)` will not be anonymized.\n    :param recognizer_results_list: A list of lists of RecognizerResult,\n    the output of the AnalyzerEngine on each text in the list.\n    :param kwargs: Additional kwargs for the `AnonymizerEngine.anonymize` method\n    \"\"\"\n    return_list = []\n    if not recognizer_results_list:\n        recognizer_results_list = [[] for _ in range(len(texts))]\n    for text, recognizer_results in zip(texts, recognizer_results_list):\n        if type(text) in (str, bool, int, float):\n            res = self.anonymizer_engine.anonymize(\n                text=str(text), analyzer_results=recognizer_results, **kwargs\n            )\n            return_list.append(res.text)\n        else:\n            return_list.append(text)\n\n    return return_list\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.ConflictResolutionStrategy","title":"<code>ConflictResolutionStrategy</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Conflict resolution strategy.</p> <p>The strategy to use when there is a conflict between two entities.</p> <p>MERGE_SIMILAR_OR_CONTAINED: This default strategy resolves conflicts between similar or contained entities. REMOVE_INTERSECTIONS: Effectively resolves both intersection conflicts among entities and default strategy conflicts. NONE: No conflict resolution will be performed.</p> Source code in <code>presidio_anonymizer/entities/conflict_resolution_strategy.py</code> <pre><code>class ConflictResolutionStrategy(Enum):\n    \"\"\"Conflict resolution strategy.\n\n    The strategy to use when there is a conflict between two entities.\n\n    MERGE_SIMILAR_OR_CONTAINED: This default strategy resolves conflicts\n    between similar or contained entities.\n    REMOVE_INTERSECTIONS: Effectively resolves both intersection conflicts\n    among entities and default strategy conflicts.\n    NONE: No conflict resolution will be performed.\n    \"\"\"\n\n    MERGE_SIMILAR_OR_CONTAINED = \"merge_similar_or_contained\"\n    REMOVE_INTERSECTIONS = \"remove_intersections\"\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.DeanonymizeEngine","title":"<code>DeanonymizeEngine</code>","text":"<p>               Bases: <code>EngineBase</code></p> <p>Deanonymize text that was previously anonymized.</p> Source code in <code>presidio_anonymizer/deanonymize_engine.py</code> <pre><code>class DeanonymizeEngine(EngineBase):\n    \"\"\"Deanonymize text that was previously anonymized.\"\"\"\n\n    def deanonymize(\n        self,\n        text: str,\n        entities: List[OperatorResult],\n        operators: Dict[str, OperatorConfig],\n    ) -&gt; EngineResult:\n        \"\"\"\n        Receive the text, entities and operators to perform deanonymization over.\n\n        :param operators: the operators to apply on the anonymizer result entities\n        :param text: the full text with the encrypted entities\n        :param entities: list of encrypted entities\n        :return: EngineResult - the new text and data about the deanonymized entities.\n        \"\"\"\n        return self._operate(text, entities, operators, OperatorType.Deanonymize)\n\n    def get_deanonymizers(self) -&gt; List[str]:\n        \"\"\"Return a list of supported deanonymizers.\"\"\"\n        names = [p for p in self.operators_factory.get_deanonymizers().keys()]\n        return names\n\n    def add_deanonymizer(self, deanonymizer_cls: Type[Operator]) -&gt; None:\n        \"\"\"\n        Add a new deanonymizer to the engine.\n\n        anonymizer_cls: The deanonymizer class to add to the engine.\n        \"\"\"\n        logger.info(f\"Added deanonymizer {deanonymizer_cls.__name__}\")\n        self.operators_factory.add_deanonymize_operator(deanonymizer_cls)\n\n    def remove_deanonymizer(self, deanonymizer_cls: Type[Operator]) -&gt; None:\n        \"\"\"\n        Remove a deanonymizer from the engine.\n\n        deanonymizer_cls: The deanonymizer class to remove from the engine.\n        \"\"\"\n        logger.info(f\"Removed deanonymizer {deanonymizer_cls.__name__}\")\n        self.operators_factory.remove_deanonymize_operator(deanonymizer_cls)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.DeanonymizeEngine.add_deanonymizer","title":"<code>add_deanonymizer(deanonymizer_cls)</code>","text":"<p>Add a new deanonymizer to the engine.</p> <p>anonymizer_cls: The deanonymizer class to add to the engine.</p> Source code in <code>presidio_anonymizer/deanonymize_engine.py</code> <pre><code>def add_deanonymizer(self, deanonymizer_cls: Type[Operator]) -&gt; None:\n    \"\"\"\n    Add a new deanonymizer to the engine.\n\n    anonymizer_cls: The deanonymizer class to add to the engine.\n    \"\"\"\n    logger.info(f\"Added deanonymizer {deanonymizer_cls.__name__}\")\n    self.operators_factory.add_deanonymize_operator(deanonymizer_cls)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.DeanonymizeEngine.deanonymize","title":"<code>deanonymize(text, entities, operators)</code>","text":"<p>Receive the text, entities and operators to perform deanonymization over.</p> <p>Parameters:</p> Name Type Description Default <code>operators</code> <code>Dict[str, OperatorConfig]</code> <p>the operators to apply on the anonymizer result entities</p> required <code>text</code> <code>str</code> <p>the full text with the encrypted entities</p> required <code>entities</code> <code>List[OperatorResult]</code> <p>list of encrypted entities</p> required <p>Returns:</p> Type Description <code>EngineResult</code> <p>EngineResult - the new text and data about the deanonymized entities.</p> Source code in <code>presidio_anonymizer/deanonymize_engine.py</code> <pre><code>def deanonymize(\n    self,\n    text: str,\n    entities: List[OperatorResult],\n    operators: Dict[str, OperatorConfig],\n) -&gt; EngineResult:\n    \"\"\"\n    Receive the text, entities and operators to perform deanonymization over.\n\n    :param operators: the operators to apply on the anonymizer result entities\n    :param text: the full text with the encrypted entities\n    :param entities: list of encrypted entities\n    :return: EngineResult - the new text and data about the deanonymized entities.\n    \"\"\"\n    return self._operate(text, entities, operators, OperatorType.Deanonymize)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.DeanonymizeEngine.get_deanonymizers","title":"<code>get_deanonymizers()</code>","text":"<p>Return a list of supported deanonymizers.</p> Source code in <code>presidio_anonymizer/deanonymize_engine.py</code> <pre><code>def get_deanonymizers(self) -&gt; List[str]:\n    \"\"\"Return a list of supported deanonymizers.\"\"\"\n    names = [p for p in self.operators_factory.get_deanonymizers().keys()]\n    return names\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.DeanonymizeEngine.remove_deanonymizer","title":"<code>remove_deanonymizer(deanonymizer_cls)</code>","text":"<p>Remove a deanonymizer from the engine.</p> <p>deanonymizer_cls: The deanonymizer class to remove from the engine.</p> Source code in <code>presidio_anonymizer/deanonymize_engine.py</code> <pre><code>def remove_deanonymizer(self, deanonymizer_cls: Type[Operator]) -&gt; None:\n    \"\"\"\n    Remove a deanonymizer from the engine.\n\n    deanonymizer_cls: The deanonymizer class to remove from the engine.\n    \"\"\"\n    logger.info(f\"Removed deanonymizer {deanonymizer_cls.__name__}\")\n    self.operators_factory.remove_deanonymize_operator(deanonymizer_cls)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.DictRecognizerResult","title":"<code>DictRecognizerResult</code>  <code>dataclass</code>","text":"<p>Data class for holding the output of the Presidio Analyzer on dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>key in dictionary</p> required <code>value</code> <code>Union[str, List[str], dict]</code> <p>value to run analysis on (either string or list of strings)</p> required <code>recognizer_results</code> <code>Union[List[RecognizerResult], List[List[RecognizerResult]], Iterator[DictRecognizerResult]]</code> <p>Analyzer output for one value. Could be either: - A list of recognizer results if the input is one string - A list of lists of recognizer results, if the input is a list of strings. - An iterator of a DictRecognizerResult, if the input is a dictionary. In this case the recognizer_results would be the iterator of the DictRecognizerResult next level in the dictionary.</p> required Source code in <code>presidio_anonymizer/entities/engine/dict_recognizer_result.py</code> <pre><code>@dataclass\nclass DictRecognizerResult:\n    \"\"\"\n    Data class for holding the output of the Presidio Analyzer on dictionaries.\n\n    :param key: key in dictionary\n    :param value: value to run analysis on (either string or list of strings)\n    :param recognizer_results: Analyzer output for one value.\n    Could be either:\n     - A list of recognizer results if the input is one string\n     - A list of lists of recognizer results, if the input is a list of strings.\n     - An iterator of a DictRecognizerResult, if the input is a dictionary.\n     In this case the recognizer_results would be the iterator\n     of the DictRecognizerResult next level in the dictionary.\n    \"\"\"\n\n    key: str\n    value: Union[str, List[str], dict]\n    recognizer_results: Union[\n        List[RecognizerResult],\n        List[List[RecognizerResult]],\n        Iterator[\"DictRecognizerResult\"],\n    ]\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.EngineResult","title":"<code>EngineResult</code>","text":"<p>Engine result.</p> Source code in <code>presidio_anonymizer/entities/engine/result/engine_result.py</code> <pre><code>class EngineResult:\n    \"\"\"Engine result.\"\"\"\n\n    def __init__(self, text: str = None, items: List[OperatorResult] = None):\n        \"\"\"Create EngineResult entity.\n\n        :param text: The anonymized text.\n        :param items: List of PII entities and the indices\n         of their replacements in the anonymized text.\n        \"\"\"\n        if items is None:\n            items = []\n        self.text = text\n        self.items = items\n\n    def set_text(self, text: str):\n        \"\"\"Set a text.\"\"\"\n        self.text = text\n\n    def add_item(self, item: OperatorResult):\n        \"\"\"Add an item.\n\n        :param item: an item to add to the list.\n        \"\"\"\n        self.items.append(item)\n\n    def normalize_item_indexes(self):\n        \"\"\"Normalize the indexes to be index from start.\"\"\"\n        text_len = len(self.text)\n        for result_item in self.items:\n            result_item.start = text_len - result_item.end\n            result_item.end = result_item.start + len(result_item.text)\n\n    def to_json(self) -&gt; str:\n        \"\"\"Return a json string serializing this instance.\"\"\"\n        return json.dumps(self, default=lambda x: x.__dict__)\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the object.\"\"\"\n\n        items_repr = (\n            \",\\n    \".join([str(item) for item in self.items]) if self.items else \"\"\n        )\n        return f\"text: {self.text}\\nitems:\\n[\\n    {items_repr}\\n]\\n\"\n\n    def __eq__(self, other) -&gt; bool:\n        \"\"\"Verify two instances are equal.\n\n        Returns true if the two instances are equal, false otherwise.\n        \"\"\"\n        return self.text == other.text and all(\n            map(lambda x, y: x == y, self.items, other.items)\n        )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.EngineResult.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Verify two instances are equal.</p> <p>Returns true if the two instances are equal, false otherwise.</p> Source code in <code>presidio_anonymizer/entities/engine/result/engine_result.py</code> <pre><code>def __eq__(self, other) -&gt; bool:\n    \"\"\"Verify two instances are equal.\n\n    Returns true if the two instances are equal, false otherwise.\n    \"\"\"\n    return self.text == other.text and all(\n        map(lambda x, y: x == y, self.items, other.items)\n    )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.EngineResult.__init__","title":"<code>__init__(text=None, items=None)</code>","text":"<p>Create EngineResult entity.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The anonymized text.</p> <code>None</code> <code>items</code> <code>List[OperatorResult]</code> <p>List of PII entities and the indices of their replacements in the anonymized text.</p> <code>None</code> Source code in <code>presidio_anonymizer/entities/engine/result/engine_result.py</code> <pre><code>def __init__(self, text: str = None, items: List[OperatorResult] = None):\n    \"\"\"Create EngineResult entity.\n\n    :param text: The anonymized text.\n    :param items: List of PII entities and the indices\n     of their replacements in the anonymized text.\n    \"\"\"\n    if items is None:\n        items = []\n    self.text = text\n    self.items = items\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.EngineResult.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the object.</p> Source code in <code>presidio_anonymizer/entities/engine/result/engine_result.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a string representation of the object.\"\"\"\n\n    items_repr = (\n        \",\\n    \".join([str(item) for item in self.items]) if self.items else \"\"\n    )\n    return f\"text: {self.text}\\nitems:\\n[\\n    {items_repr}\\n]\\n\"\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.EngineResult.add_item","title":"<code>add_item(item)</code>","text":"<p>Add an item.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>OperatorResult</code> <p>an item to add to the list.</p> required Source code in <code>presidio_anonymizer/entities/engine/result/engine_result.py</code> <pre><code>def add_item(self, item: OperatorResult):\n    \"\"\"Add an item.\n\n    :param item: an item to add to the list.\n    \"\"\"\n    self.items.append(item)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.EngineResult.normalize_item_indexes","title":"<code>normalize_item_indexes()</code>","text":"<p>Normalize the indexes to be index from start.</p> Source code in <code>presidio_anonymizer/entities/engine/result/engine_result.py</code> <pre><code>def normalize_item_indexes(self):\n    \"\"\"Normalize the indexes to be index from start.\"\"\"\n    text_len = len(self.text)\n    for result_item in self.items:\n        result_item.start = text_len - result_item.end\n        result_item.end = result_item.start + len(result_item.text)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.EngineResult.set_text","title":"<code>set_text(text)</code>","text":"<p>Set a text.</p> Source code in <code>presidio_anonymizer/entities/engine/result/engine_result.py</code> <pre><code>def set_text(self, text: str):\n    \"\"\"Set a text.\"\"\"\n    self.text = text\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.EngineResult.to_json","title":"<code>to_json()</code>","text":"<p>Return a json string serializing this instance.</p> Source code in <code>presidio_anonymizer/entities/engine/result/engine_result.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Return a json string serializing this instance.\"\"\"\n    return json.dumps(self, default=lambda x: x.__dict__)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.InvalidParamError","title":"<code>InvalidParamError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Throw exception with error when user input is not valid.</p> <p>param msg: Message to be added to the exception</p> Source code in <code>presidio_anonymizer/entities/invalid_exception.py</code> <pre><code>class InvalidParamError(Exception):\n    \"\"\"Throw exception with error when user input is not valid.\n\n    param msg: Message to be added to the exception\n    \"\"\"\n\n    def __init__(self, msg: str):\n        self.err_msg = msg\n        super().__init__(self.err_msg)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorConfig","title":"<code>OperatorConfig</code>","text":"<p>Hold the data of the required operator.</p> Source code in <code>presidio_anonymizer/entities/engine/operator_config.py</code> <pre><code>class OperatorConfig:\n    \"\"\"Hold the data of the required operator.\"\"\"\n\n    def __init__(self, operator_name: str, params: Dict = None):\n        \"\"\"\n        Create an operator config instance.\n\n        :param operator_name: the name of the operator we want to work with\n        :param params: the parameters the operator needs in order to work\n        \"\"\"\n        self.operator_name = operator_name\n        if not params:\n            params = {}\n        self.params = params\n        self.__validate_fields()\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the object.\"\"\"\n        return f\"operator_name: {self.operator_name}, params: {self.params}\"\n\n    @classmethod\n    def from_json(cls, params: Dict) -&gt; \"OperatorConfig\":\n        \"\"\"\n        Create OperatorConfig from json.\n\n        :param params: json e.g.: {\n            \"type\": \"mask\",\n            \"masking_char\": \"*\",\n            \"chars_to_mask\": 4,\n            \"from_end\": true\n            }\n        :return: OperatorConfig\n        \"\"\"\n        operator_name = params.get(\"type\")\n        if operator_name:\n            params.pop(\"type\")\n        return cls(operator_name, params)\n\n    def __eq__(self, other: \"OperatorConfig\"):\n        \"\"\"Verify two OperatorConfigs are equal.\"\"\"\n        operator_name = self.operator_name == other.operator_name\n        return self.params == other.params and operator_name\n\n    def __validate_fields(self):\n        validate_parameter_not_empty(\n            self.operator_name, \"operator config\", \"operator_name\"\n        )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorConfig.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Verify two OperatorConfigs are equal.</p> Source code in <code>presidio_anonymizer/entities/engine/operator_config.py</code> <pre><code>def __eq__(self, other: \"OperatorConfig\"):\n    \"\"\"Verify two OperatorConfigs are equal.\"\"\"\n    operator_name = self.operator_name == other.operator_name\n    return self.params == other.params and operator_name\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorConfig.__init__","title":"<code>__init__(operator_name, params=None)</code>","text":"<p>Create an operator config instance.</p> <p>Parameters:</p> Name Type Description Default <code>operator_name</code> <code>str</code> <p>the name of the operator we want to work with</p> required <code>params</code> <code>Dict</code> <p>the parameters the operator needs in order to work</p> <code>None</code> Source code in <code>presidio_anonymizer/entities/engine/operator_config.py</code> <pre><code>def __init__(self, operator_name: str, params: Dict = None):\n    \"\"\"\n    Create an operator config instance.\n\n    :param operator_name: the name of the operator we want to work with\n    :param params: the parameters the operator needs in order to work\n    \"\"\"\n    self.operator_name = operator_name\n    if not params:\n        params = {}\n    self.params = params\n    self.__validate_fields()\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorConfig.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the object.</p> Source code in <code>presidio_anonymizer/entities/engine/operator_config.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a string representation of the object.\"\"\"\n    return f\"operator_name: {self.operator_name}, params: {self.params}\"\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorConfig.from_json","title":"<code>from_json(params)</code>  <code>classmethod</code>","text":"<p>Create OperatorConfig from json.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Dict</code> <p>json e.g.: { \"type\": \"mask\", \"masking_char\": \"*\", \"chars_to_mask\": 4, \"from_end\": true }</p> required <p>Returns:</p> Type Description <code>OperatorConfig</code> <p>OperatorConfig</p> Source code in <code>presidio_anonymizer/entities/engine/operator_config.py</code> <pre><code>@classmethod\ndef from_json(cls, params: Dict) -&gt; \"OperatorConfig\":\n    \"\"\"\n    Create OperatorConfig from json.\n\n    :param params: json e.g.: {\n        \"type\": \"mask\",\n        \"masking_char\": \"*\",\n        \"chars_to_mask\": 4,\n        \"from_end\": true\n        }\n    :return: OperatorConfig\n    \"\"\"\n    operator_name = params.get(\"type\")\n    if operator_name:\n        params.pop(\"type\")\n    return cls(operator_name, params)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorResult","title":"<code>OperatorResult</code>","text":"<p>               Bases: <code>PIIEntity</code></p> <p>A class to hold data for engines results either anonymize or deanonymize.</p> Source code in <code>presidio_anonymizer/entities/engine/result/operator_result.py</code> <pre><code>class OperatorResult(PIIEntity):\n    \"\"\"A class to hold data for engines results either anonymize or deanonymize.\"\"\"\n\n    def __init__(\n        self,\n        start: int,\n        end: int,\n        entity_type: str,\n        text: str = None,\n        operator: str = None,\n    ):\n        PIIEntity.__init__(self, start, end, entity_type)\n        self.text = text\n        self.operator = operator\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the object.\"\"\"\n        return str(self.to_dict())\n\n    def to_dict(self) -&gt; Dict:\n        \"\"\"Return object as Dict.\"\"\"\n        return self.__dict__\n\n    def __str__(self):\n        \"\"\"Return a string representation of the object.\"\"\"\n        return str(self.to_dict())\n\n    def __eq__(self, other: \"OperatorResult\") -&gt; bool:\n        \"\"\"\n        Verify two OperatorResults are equal.\n\n        :param other: OperatorResult\n        :return: bool\n        \"\"\"\n        return (\n            self.start == other.start\n            and self.end == other.end\n            and self.entity_type == other.entity_type\n            and self.operator == other.operator\n            and self.text == other.text\n        )\n\n    @classmethod\n    def from_json(cls, json: Dict) -&gt; \"OperatorResult\":\n        \"\"\"\n        Create OperatorResult from user json.\n\n        :param json: json representation for this operator result. For example:\n        {\n            \"start\": 0,\n            \"end\": 10,\n            \"key\": \"1111111111111111\",\n            \"entity_type\":\"PERSON\",\n            \"text\":\"resulted_text\",\n            \"operator\":\"encrypt\",\n        }\n        \"\"\"\n        start = json.get(\"start\")\n        end = json.get(\"end\")\n        entity_type = json.get(\"entity_type\")\n        text = json.get(\"text\")\n        operator = json.get(\"operator\")\n        return cls(\n            start=start,\n            end=end,\n            entity_type=entity_type,\n            text=text,\n            operator=operator,\n        )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorResult.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Verify two OperatorResults are equal.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>OperatorResult</code> <p>OperatorResult</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool</p> Source code in <code>presidio_anonymizer/entities/engine/result/operator_result.py</code> <pre><code>def __eq__(self, other: \"OperatorResult\") -&gt; bool:\n    \"\"\"\n    Verify two OperatorResults are equal.\n\n    :param other: OperatorResult\n    :return: bool\n    \"\"\"\n    return (\n        self.start == other.start\n        and self.end == other.end\n        and self.entity_type == other.entity_type\n        and self.operator == other.operator\n        and self.text == other.text\n    )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorResult.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the object.</p> Source code in <code>presidio_anonymizer/entities/engine/result/operator_result.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a string representation of the object.\"\"\"\n    return str(self.to_dict())\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorResult.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the object.</p> Source code in <code>presidio_anonymizer/entities/engine/result/operator_result.py</code> <pre><code>def __str__(self):\n    \"\"\"Return a string representation of the object.\"\"\"\n    return str(self.to_dict())\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorResult.from_json","title":"<code>from_json(json)</code>  <code>classmethod</code>","text":"<p>Create OperatorResult from user json.</p> <p>Parameters:</p> Name Type Description Default <code>json</code> <code>Dict</code> <p>json representation for this operator result. For example: { \"start\": 0, \"end\": 10, \"key\": \"1111111111111111\", \"entity_type\":\"PERSON\", \"text\":\"resulted_text\", \"operator\":\"encrypt\", }</p> required Source code in <code>presidio_anonymizer/entities/engine/result/operator_result.py</code> <pre><code>@classmethod\ndef from_json(cls, json: Dict) -&gt; \"OperatorResult\":\n    \"\"\"\n    Create OperatorResult from user json.\n\n    :param json: json representation for this operator result. For example:\n    {\n        \"start\": 0,\n        \"end\": 10,\n        \"key\": \"1111111111111111\",\n        \"entity_type\":\"PERSON\",\n        \"text\":\"resulted_text\",\n        \"operator\":\"encrypt\",\n    }\n    \"\"\"\n    start = json.get(\"start\")\n    end = json.get(\"end\")\n    entity_type = json.get(\"entity_type\")\n    text = json.get(\"text\")\n    operator = json.get(\"operator\")\n    return cls(\n        start=start,\n        end=end,\n        entity_type=entity_type,\n        text=text,\n        operator=operator,\n    )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.OperatorResult.to_dict","title":"<code>to_dict()</code>","text":"<p>Return object as Dict.</p> Source code in <code>presidio_anonymizer/entities/engine/result/operator_result.py</code> <pre><code>def to_dict(self) -&gt; Dict:\n    \"\"\"Return object as Dict.\"\"\"\n    return self.__dict__\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.PIIEntity","title":"<code>PIIEntity</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract class to hold the text we are going to operate on metadata.</p> Source code in <code>presidio_anonymizer/entities/engine/pii_entity.py</code> <pre><code>class PIIEntity(ABC):\n    \"\"\"Abstract class to hold the text we are going to operate on metadata.\"\"\"\n\n    logger = logging.getLogger(\"presidio-anonymizer\")\n\n    def __init__(self, start: int, end: int, entity_type: str):\n        self.start = start\n        self.end = end\n        self.entity_type = entity_type\n        self.__validate_fields()\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the object.\"\"\"\n        return (\n            f\"start: {self.start}\"\n            f\"end: {self.end},\"\n            f\"entity_type: {self.entity_type}\"\n        )\n\n    def __gt__(self, other):\n        \"\"\"Check one entity is greater then other by the text end index.\"\"\"\n        return self.start &gt; other.start\n\n    def __eq__(self, other):\n        \"\"\"Check two text metadata entities are equal.\"\"\"\n        return (\n            self.start == other.start\n            and self.end == other.end\n            and self.entity_type == other.entity_type\n        )\n\n    def __validate_fields(self):\n        validate_parameter_exists(self.start, \"result\", \"start\")\n        validate_type(self.start, \"start\", int)\n        validate_parameter_exists(self.end, \"result\", \"end\")\n        validate_type(self.end, \"end\", int)\n        validate_parameter_not_empty(self.entity_type, \"result\", \"entity_type\")\n        if self.start &lt; 0 or self.end &lt; 0:\n            raise InvalidParamError(\n                \"Invalid input, result start and end must be positive\"\n            )\n        if self.start &gt; self.end:\n            raise InvalidParamError(\n                f\"Invalid input, start index '{self.start}' \"\n                f\"must be smaller than end index '{self.end}'\"\n            )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.PIIEntity.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Check two text metadata entities are equal.</p> Source code in <code>presidio_anonymizer/entities/engine/pii_entity.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"Check two text metadata entities are equal.\"\"\"\n    return (\n        self.start == other.start\n        and self.end == other.end\n        and self.entity_type == other.entity_type\n    )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.PIIEntity.__gt__","title":"<code>__gt__(other)</code>","text":"<p>Check one entity is greater then other by the text end index.</p> Source code in <code>presidio_anonymizer/entities/engine/pii_entity.py</code> <pre><code>def __gt__(self, other):\n    \"\"\"Check one entity is greater then other by the text end index.\"\"\"\n    return self.start &gt; other.start\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.PIIEntity.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the object.</p> Source code in <code>presidio_anonymizer/entities/engine/pii_entity.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a string representation of the object.\"\"\"\n    return (\n        f\"start: {self.start}\"\n        f\"end: {self.end},\"\n        f\"entity_type: {self.entity_type}\"\n    )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult","title":"<code>RecognizerResult</code>","text":"<p>               Bases: <code>PIIEntity</code></p> <p>Recognizer Result represents the findings of the detected entity.</p> <p>Result of a recognizer analyzing the text.</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>the type of the entity</p> required <code>start</code> <code>int</code> <p>the start location of the detected entity</p> required <code>end</code> <code>int</code> <p>the end location of the detected entity</p> required <code>score</code> <code>float</code> <p>the score of the detection</p> required Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>class RecognizerResult(PIIEntity):\n    \"\"\"\n    Recognizer Result represents the findings of the detected entity.\n\n    Result of a recognizer analyzing the text.\n\n    :param entity_type: the type of the entity\n    :param start: the start location of the detected entity\n    :param end: the end location of the detected entity\n    :param score: the score of the detection\n    \"\"\"\n\n    logger = logging.getLogger(\"presidio-anonymizer\")\n\n    def __init__(self, entity_type: str, start: int, end: int, score: float):\n        PIIEntity.__init__(self, start, end, entity_type)\n        self.score = score\n        validate_parameter_exists(score, \"analyzer result\", \"score\")\n\n    @classmethod\n    def from_json(cls, data: Dict):\n        \"\"\"\n        Create RecognizerResult from json.\n\n        :param data: e.g. {\n            \"start\": 24,\n            \"end\": 32,\n            \"score\": 0.8,\n            \"entity_type\": \"NAME\"\n        }\n        :return: RecognizerResult\n        \"\"\"\n        score = data.get(\"score\")\n        entity_type = data.get(\"entity_type\")\n        start = data.get(\"start\")\n        end = data.get(\"end\")\n        return cls(entity_type, start, end, score)\n\n    def __gt__(self, other):\n        \"\"\"\n        Check if one result is greater by using the results indices in the text.\n\n        :param other: another RecognizerResult\n        :return: bool\n        \"\"\"\n        if self.start == other.start:\n            return self.end &gt; other.end\n        return self.start &gt; other.start\n\n    def __eq__(self, other):\n        \"\"\"\n        Check two results are equal by using all class fields.\n\n        :param other: another RecognizerResult\n        :return: bool\n        \"\"\"\n        equal_type = self.entity_type == other.entity_type\n        equal_score = self.score == other.score\n        return self.equal_indices(other) and equal_type and equal_score\n\n    def __hash__(self):\n        \"\"\"\n        Hash the result data by using all class fields.\n\n        :return: int\n        \"\"\"\n        return hash(\n            f\"{str(self.start)} {str(self.end)} {str(self.score)} {self.entity_type}\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the instance.\"\"\"\n        return (\n            f\"type: {self.entity_type}, \"\n            f\"start: {self.start}, \"\n            f\"end: {self.end}, \"\n            f\"score: {self.score}\"\n        )\n\n    def has_conflict(self, other):\n        \"\"\"\n        Check if two recognizer results are conflicted or not.\n\n        I have a conflict if:\n        1. My indices are the same as the other and my score is lower.\n        2. If my indices are contained in another.\n\n        :param other: RecognizerResult\n        :return:\n        \"\"\"\n        if self.equal_indices(other):\n            return self.score &lt;= other.score\n        return other.contains(self)\n\n    def contains(self, other):\n        \"\"\"\n        Check if one result is contained or equal to another result.\n\n        :param other: another RecognizerResult\n        :return: bool\n        \"\"\"\n        return self.start &lt;= other.start and self.end &gt;= other.end\n\n    def equal_indices(self, other):\n        \"\"\"\n        Check if the indices are equal between two results.\n\n        :param other: another RecognizerResult\n        :return:\n        \"\"\"\n        return self.start == other.start and self.end == other.end\n\n    def intersects(self, other) -&gt; int:\n        \"\"\"\n        Check if self intersects with a different RecognizerResult.\n\n        :return: If intersecting, returns the number of\n        intersecting characters.\n        If not, returns 0\n        \"\"\"\n        # if they do not overlap the intersection is 0\n        if self.end &lt; other.start or other.end &lt; self.start:\n            return 0\n\n        # otherwise the intersection is min(end) - max(start)\n        return min(self.end, other.end) - max(self.start, other.start)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Check two results are equal by using all class fields.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>another RecognizerResult</p> required <p>Returns:</p> Type Description <p>bool</p> Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"\n    Check two results are equal by using all class fields.\n\n    :param other: another RecognizerResult\n    :return: bool\n    \"\"\"\n    equal_type = self.entity_type == other.entity_type\n    equal_score = self.score == other.score\n    return self.equal_indices(other) and equal_type and equal_score\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.__gt__","title":"<code>__gt__(other)</code>","text":"<p>Check if one result is greater by using the results indices in the text.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>another RecognizerResult</p> required <p>Returns:</p> Type Description <p>bool</p> Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>def __gt__(self, other):\n    \"\"\"\n    Check if one result is greater by using the results indices in the text.\n\n    :param other: another RecognizerResult\n    :return: bool\n    \"\"\"\n    if self.start == other.start:\n        return self.end &gt; other.end\n    return self.start &gt; other.start\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.__hash__","title":"<code>__hash__()</code>","text":"<p>Hash the result data by using all class fields.</p> <p>Returns:</p> Type Description <p>int</p> Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>def __hash__(self):\n    \"\"\"\n    Hash the result data by using all class fields.\n\n    :return: int\n    \"\"\"\n    return hash(\n        f\"{str(self.start)} {str(self.end)} {str(self.score)} {self.entity_type}\"\n    )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the instance.</p> Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the instance.\"\"\"\n    return (\n        f\"type: {self.entity_type}, \"\n        f\"start: {self.start}, \"\n        f\"end: {self.end}, \"\n        f\"score: {self.score}\"\n    )\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.contains","title":"<code>contains(other)</code>","text":"<p>Check if one result is contained or equal to another result.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>another RecognizerResult</p> required <p>Returns:</p> Type Description <p>bool</p> Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>def contains(self, other):\n    \"\"\"\n    Check if one result is contained or equal to another result.\n\n    :param other: another RecognizerResult\n    :return: bool\n    \"\"\"\n    return self.start &lt;= other.start and self.end &gt;= other.end\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.equal_indices","title":"<code>equal_indices(other)</code>","text":"<p>Check if the indices are equal between two results.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>another RecognizerResult</p> required <p>Returns:</p> Type Description Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>def equal_indices(self, other):\n    \"\"\"\n    Check if the indices are equal between two results.\n\n    :param other: another RecognizerResult\n    :return:\n    \"\"\"\n    return self.start == other.start and self.end == other.end\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.from_json","title":"<code>from_json(data)</code>  <code>classmethod</code>","text":"<p>Create RecognizerResult from json.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict</code> <p>e.g. { \"start\": 24, \"end\": 32, \"score\": 0.8, \"entity_type\": \"NAME\" }</p> required <p>Returns:</p> Type Description <p>RecognizerResult</p> Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>@classmethod\ndef from_json(cls, data: Dict):\n    \"\"\"\n    Create RecognizerResult from json.\n\n    :param data: e.g. {\n        \"start\": 24,\n        \"end\": 32,\n        \"score\": 0.8,\n        \"entity_type\": \"NAME\"\n    }\n    :return: RecognizerResult\n    \"\"\"\n    score = data.get(\"score\")\n    entity_type = data.get(\"entity_type\")\n    start = data.get(\"start\")\n    end = data.get(\"end\")\n    return cls(entity_type, start, end, score)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.has_conflict","title":"<code>has_conflict(other)</code>","text":"<p>Check if two recognizer results are conflicted or not.</p> <p>I have a conflict if: 1. My indices are the same as the other and my score is lower. 2. If my indices are contained in another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>RecognizerResult</p> required <p>Returns:</p> Type Description Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>def has_conflict(self, other):\n    \"\"\"\n    Check if two recognizer results are conflicted or not.\n\n    I have a conflict if:\n    1. My indices are the same as the other and my score is lower.\n    2. If my indices are contained in another.\n\n    :param other: RecognizerResult\n    :return:\n    \"\"\"\n    if self.equal_indices(other):\n        return self.score &lt;= other.score\n    return other.contains(self)\n</code></pre>"},{"location":"api/anonymizer_python/#presidio_anonymizer.RecognizerResult.intersects","title":"<code>intersects(other)</code>","text":"<p>Check if self intersects with a different RecognizerResult.</p> <p>Returns:</p> Type Description <code>int</code> <p>If intersecting, returns the number of intersecting characters. If not, returns 0</p> Source code in <code>presidio_anonymizer/entities/engine/recognizer_result.py</code> <pre><code>def intersects(self, other) -&gt; int:\n    \"\"\"\n    Check if self intersects with a different RecognizerResult.\n\n    :return: If intersecting, returns the number of\n    intersecting characters.\n    If not, returns 0\n    \"\"\"\n    # if they do not overlap the intersection is 0\n    if self.end &lt; other.start or other.end &lt; self.start:\n        return 0\n\n    # otherwise the intersection is min(end) - max(start)\n    return min(self.end, other.end) - max(self.start, other.start)\n</code></pre>"},{"location":"api/image_redactor_python/","title":"Presidio Image Redactor API Reference","text":"<p>Image Redactor root module.</p>"},{"location":"api/image_redactor_python/#presidio_image_redactor.BboxProcessor","title":"<code>BboxProcessor</code>","text":"<p>Common module for general bounding box operators.</p> Source code in <code>presidio_image_redactor/bbox.py</code> <pre><code>class BboxProcessor:\n    \"\"\"Common module for general bounding box operators.\"\"\"\n\n    @staticmethod\n    def get_bboxes_from_ocr_results(\n        ocr_results: Dict[str, List[Union[int, str]]],\n    ) -&gt; List[Dict[str, Union[int, float, str]]]:\n        \"\"\"Get bounding boxes on padded image for all detected words from ocr_results.\n\n        :param ocr_results: Raw results from OCR.\n        :return: Bounding box information per word.\n        \"\"\"\n        bboxes = []\n        for i in range(len(ocr_results[\"text\"])):\n            detected_text = ocr_results[\"text\"][i]\n            if detected_text:\n                bbox = {\n                    \"left\": ocr_results[\"left\"][i],\n                    \"top\": ocr_results[\"top\"][i],\n                    \"width\": ocr_results[\"width\"][i],\n                    \"height\": ocr_results[\"height\"][i],\n                    \"conf\": float(ocr_results[\"conf\"][i]),\n                    \"label\": detected_text,\n                }\n                bboxes.append(bbox)\n\n        return bboxes\n\n    @staticmethod\n    def get_bboxes_from_analyzer_results(\n        analyzer_results: List[ImageRecognizerResult],\n    ) -&gt; List[Dict[str, Union[str, float, int]]]:\n        \"\"\"Organize bounding box info from analyzer results.\n\n        :param analyzer_results: Results from using ImageAnalyzerEngine.\n\n        :return: Bounding box info organized.\n        \"\"\"\n        bboxes = []\n        for i in range(len(analyzer_results)):\n            result = analyzer_results[i].to_dict()\n\n            bbox_item = {\n                \"entity_type\": result[\"entity_type\"],\n                \"score\": result[\"score\"],\n                \"left\": result[\"left\"],\n                \"top\": result[\"top\"],\n                \"width\": result[\"width\"],\n                \"height\": result[\"height\"],\n            }\n            bboxes.append(bbox_item)\n\n        return bboxes\n\n    @staticmethod\n    def remove_bbox_padding(\n        analyzer_bboxes: List[Dict[str, Union[str, float, int]]],\n        padding_width: int,\n    ) -&gt; List[Dict[str, int]]:\n        \"\"\"Remove added padding in bounding box coordinates.\n\n        :param analyzer_bboxes: The bounding boxes from analyzer results.\n        :param padding_width: Pixel width used for padding (0 if no padding).\n\n        :return: Bounding box information per word.\n        \"\"\"\n        if padding_width &lt; 0:\n            raise ValueError(\"Padding width must be a non-negative integer.\")\n\n        if len(analyzer_bboxes) &gt; 0:\n            # Get fields\n            has_label = False\n            has_entity_type = False\n            try:\n                _ = analyzer_bboxes[0][\"label\"]\n                has_label = True\n            except KeyError:\n                has_label = False\n            try:\n                _ = analyzer_bboxes[0][\"entity_type\"]\n                has_entity_type = True\n            except KeyError:\n                has_entity_type = False\n\n            # Remove padding from all bounding boxes\n            if has_label is True and has_entity_type is True:\n                bboxes = [\n                    {\n                        \"left\": max(0, bbox[\"left\"] - padding_width),\n                        \"top\": max(0, bbox[\"top\"] - padding_width),\n                        \"width\": bbox[\"width\"],\n                        \"height\": bbox[\"height\"],\n                        \"label\": bbox[\"label\"],\n                        \"entity_type\": bbox[\"entity_type\"],\n                    }\n                    for bbox in analyzer_bboxes\n                ]\n            elif has_label is True and has_entity_type is False:\n                bboxes = [\n                    {\n                        \"left\": max(0, bbox[\"left\"] - padding_width),\n                        \"top\": max(0, bbox[\"top\"] - padding_width),\n                        \"width\": bbox[\"width\"],\n                        \"height\": bbox[\"height\"],\n                        \"label\": bbox[\"label\"],\n                    }\n                    for bbox in analyzer_bboxes\n                ]\n            elif has_label is False and has_entity_type is True:\n                bboxes = [\n                    {\n                        \"left\": max(0, bbox[\"left\"] - padding_width),\n                        \"top\": max(0, bbox[\"top\"] - padding_width),\n                        \"width\": bbox[\"width\"],\n                        \"height\": bbox[\"height\"],\n                        \"entity_type\": bbox[\"entity_type\"],\n                    }\n                    for bbox in analyzer_bboxes\n                ]\n            elif has_label is False and has_entity_type is False:\n                bboxes = [\n                    {\n                        \"left\": max(0, bbox[\"left\"] - padding_width),\n                        \"top\": max(0, bbox[\"top\"] - padding_width),\n                        \"width\": bbox[\"width\"],\n                        \"height\": bbox[\"height\"],\n                    }\n                    for bbox in analyzer_bboxes\n                ]\n        else:\n            bboxes = analyzer_bboxes\n\n        return bboxes\n\n    @staticmethod\n    def match_with_source(\n        all_pos: List[Dict[str, Union[str, int, float]]],\n        pii_source_dict: List[Dict[str, Union[str, int, float]]],\n        detected_pii: Dict[str, Union[str, float, int]],\n        tolerance: int = 50,\n    ) -&gt; Tuple[List[Dict[str, Union[str, int, float]]], bool]:\n        \"\"\"Match returned redacted PII bbox data with some source of truth for PII.\n\n        :param all_pos: Dictionary storing all positives.\n        :param pii_source_dict: List of PII labels for this instance.\n        :param detected_pii: Detected PII (single entity from analyzer_results).\n        :param tolerance: Tolerance for exact coordinates and size data.\n        :return: List of all positive with PII mapped back as possible\n        and whether a match was found.\n        \"\"\"\n        all_pos_match = all_pos.copy()\n\n        # Get info from detected PII (positive)\n        results_left = detected_pii[\"left\"]\n        results_top = detected_pii[\"top\"]\n        results_width = detected_pii[\"width\"]\n        results_height = detected_pii[\"height\"]\n        try:\n            results_score = detected_pii[\"score\"]\n        except KeyError:\n            # Handle matching when no score available\n            results_score = 0\n        match_found = False\n\n        # See what in the ground truth this positive matches\n        for label in pii_source_dict:\n            source_left = label[\"left\"]\n            source_top = label[\"top\"]\n            source_width = label[\"width\"]\n            source_height = label[\"height\"]\n\n            match_left = abs(source_left - results_left) &lt;= tolerance\n            match_top = abs(source_top - results_top) &lt;= tolerance\n            match_width = abs(source_width - results_width) &lt;= tolerance\n            match_height = abs(source_height - results_height) &lt;= tolerance\n            matching = [match_left, match_top, match_width, match_height]\n\n            if False not in matching:\n                # If match is found, carry over ground truth info\n                positive = label\n                positive[\"score\"] = results_score\n                all_pos_match.append(positive)\n                match_found = True\n\n        return all_pos_match, match_found\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.BboxProcessor.get_bboxes_from_analyzer_results","title":"<code>get_bboxes_from_analyzer_results(analyzer_results)</code>  <code>staticmethod</code>","text":"<p>Organize bounding box info from analyzer results.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer_results</code> <code>List[ImageRecognizerResult]</code> <p>Results from using ImageAnalyzerEngine.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Union[str, float, int]]]</code> <p>Bounding box info organized.</p> Source code in <code>presidio_image_redactor/bbox.py</code> <pre><code>@staticmethod\ndef get_bboxes_from_analyzer_results(\n    analyzer_results: List[ImageRecognizerResult],\n) -&gt; List[Dict[str, Union[str, float, int]]]:\n    \"\"\"Organize bounding box info from analyzer results.\n\n    :param analyzer_results: Results from using ImageAnalyzerEngine.\n\n    :return: Bounding box info organized.\n    \"\"\"\n    bboxes = []\n    for i in range(len(analyzer_results)):\n        result = analyzer_results[i].to_dict()\n\n        bbox_item = {\n            \"entity_type\": result[\"entity_type\"],\n            \"score\": result[\"score\"],\n            \"left\": result[\"left\"],\n            \"top\": result[\"top\"],\n            \"width\": result[\"width\"],\n            \"height\": result[\"height\"],\n        }\n        bboxes.append(bbox_item)\n\n    return bboxes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.BboxProcessor.get_bboxes_from_ocr_results","title":"<code>get_bboxes_from_ocr_results(ocr_results)</code>  <code>staticmethod</code>","text":"<p>Get bounding boxes on padded image for all detected words from ocr_results.</p> <p>Parameters:</p> Name Type Description Default <code>ocr_results</code> <code>Dict[str, List[Union[int, str]]]</code> <p>Raw results from OCR.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Union[int, float, str]]]</code> <p>Bounding box information per word.</p> Source code in <code>presidio_image_redactor/bbox.py</code> <pre><code>@staticmethod\ndef get_bboxes_from_ocr_results(\n    ocr_results: Dict[str, List[Union[int, str]]],\n) -&gt; List[Dict[str, Union[int, float, str]]]:\n    \"\"\"Get bounding boxes on padded image for all detected words from ocr_results.\n\n    :param ocr_results: Raw results from OCR.\n    :return: Bounding box information per word.\n    \"\"\"\n    bboxes = []\n    for i in range(len(ocr_results[\"text\"])):\n        detected_text = ocr_results[\"text\"][i]\n        if detected_text:\n            bbox = {\n                \"left\": ocr_results[\"left\"][i],\n                \"top\": ocr_results[\"top\"][i],\n                \"width\": ocr_results[\"width\"][i],\n                \"height\": ocr_results[\"height\"][i],\n                \"conf\": float(ocr_results[\"conf\"][i]),\n                \"label\": detected_text,\n            }\n            bboxes.append(bbox)\n\n    return bboxes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.BboxProcessor.match_with_source","title":"<code>match_with_source(all_pos, pii_source_dict, detected_pii, tolerance=50)</code>  <code>staticmethod</code>","text":"<p>Match returned redacted PII bbox data with some source of truth for PII.</p> <p>Parameters:</p> Name Type Description Default <code>all_pos</code> <code>List[Dict[str, Union[str, int, float]]]</code> <p>Dictionary storing all positives.</p> required <code>pii_source_dict</code> <code>List[Dict[str, Union[str, int, float]]]</code> <p>List of PII labels for this instance.</p> required <code>detected_pii</code> <code>Dict[str, Union[str, float, int]]</code> <p>Detected PII (single entity from analyzer_results).</p> required <code>tolerance</code> <code>int</code> <p>Tolerance for exact coordinates and size data.</p> <code>50</code> <p>Returns:</p> Type Description <code>Tuple[List[Dict[str, Union[str, int, float]]], bool]</code> <p>List of all positive with PII mapped back as possible and whether a match was found.</p> Source code in <code>presidio_image_redactor/bbox.py</code> <pre><code>@staticmethod\ndef match_with_source(\n    all_pos: List[Dict[str, Union[str, int, float]]],\n    pii_source_dict: List[Dict[str, Union[str, int, float]]],\n    detected_pii: Dict[str, Union[str, float, int]],\n    tolerance: int = 50,\n) -&gt; Tuple[List[Dict[str, Union[str, int, float]]], bool]:\n    \"\"\"Match returned redacted PII bbox data with some source of truth for PII.\n\n    :param all_pos: Dictionary storing all positives.\n    :param pii_source_dict: List of PII labels for this instance.\n    :param detected_pii: Detected PII (single entity from analyzer_results).\n    :param tolerance: Tolerance for exact coordinates and size data.\n    :return: List of all positive with PII mapped back as possible\n    and whether a match was found.\n    \"\"\"\n    all_pos_match = all_pos.copy()\n\n    # Get info from detected PII (positive)\n    results_left = detected_pii[\"left\"]\n    results_top = detected_pii[\"top\"]\n    results_width = detected_pii[\"width\"]\n    results_height = detected_pii[\"height\"]\n    try:\n        results_score = detected_pii[\"score\"]\n    except KeyError:\n        # Handle matching when no score available\n        results_score = 0\n    match_found = False\n\n    # See what in the ground truth this positive matches\n    for label in pii_source_dict:\n        source_left = label[\"left\"]\n        source_top = label[\"top\"]\n        source_width = label[\"width\"]\n        source_height = label[\"height\"]\n\n        match_left = abs(source_left - results_left) &lt;= tolerance\n        match_top = abs(source_top - results_top) &lt;= tolerance\n        match_width = abs(source_width - results_width) &lt;= tolerance\n        match_height = abs(source_height - results_height) &lt;= tolerance\n        matching = [match_left, match_top, match_width, match_height]\n\n        if False not in matching:\n            # If match is found, carry over ground truth info\n            positive = label\n            positive[\"score\"] = results_score\n            all_pos_match.append(positive)\n            match_found = True\n\n    return all_pos_match, match_found\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.BboxProcessor.remove_bbox_padding","title":"<code>remove_bbox_padding(analyzer_bboxes, padding_width)</code>  <code>staticmethod</code>","text":"<p>Remove added padding in bounding box coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer_bboxes</code> <code>List[Dict[str, Union[str, float, int]]]</code> <p>The bounding boxes from analyzer results.</p> required <code>padding_width</code> <code>int</code> <p>Pixel width used for padding (0 if no padding).</p> required <p>Returns:</p> Type Description <code>List[Dict[str, int]]</code> <p>Bounding box information per word.</p> Source code in <code>presidio_image_redactor/bbox.py</code> <pre><code>@staticmethod\ndef remove_bbox_padding(\n    analyzer_bboxes: List[Dict[str, Union[str, float, int]]],\n    padding_width: int,\n) -&gt; List[Dict[str, int]]:\n    \"\"\"Remove added padding in bounding box coordinates.\n\n    :param analyzer_bboxes: The bounding boxes from analyzer results.\n    :param padding_width: Pixel width used for padding (0 if no padding).\n\n    :return: Bounding box information per word.\n    \"\"\"\n    if padding_width &lt; 0:\n        raise ValueError(\"Padding width must be a non-negative integer.\")\n\n    if len(analyzer_bboxes) &gt; 0:\n        # Get fields\n        has_label = False\n        has_entity_type = False\n        try:\n            _ = analyzer_bboxes[0][\"label\"]\n            has_label = True\n        except KeyError:\n            has_label = False\n        try:\n            _ = analyzer_bboxes[0][\"entity_type\"]\n            has_entity_type = True\n        except KeyError:\n            has_entity_type = False\n\n        # Remove padding from all bounding boxes\n        if has_label is True and has_entity_type is True:\n            bboxes = [\n                {\n                    \"left\": max(0, bbox[\"left\"] - padding_width),\n                    \"top\": max(0, bbox[\"top\"] - padding_width),\n                    \"width\": bbox[\"width\"],\n                    \"height\": bbox[\"height\"],\n                    \"label\": bbox[\"label\"],\n                    \"entity_type\": bbox[\"entity_type\"],\n                }\n                for bbox in analyzer_bboxes\n            ]\n        elif has_label is True and has_entity_type is False:\n            bboxes = [\n                {\n                    \"left\": max(0, bbox[\"left\"] - padding_width),\n                    \"top\": max(0, bbox[\"top\"] - padding_width),\n                    \"width\": bbox[\"width\"],\n                    \"height\": bbox[\"height\"],\n                    \"label\": bbox[\"label\"],\n                }\n                for bbox in analyzer_bboxes\n            ]\n        elif has_label is False and has_entity_type is True:\n            bboxes = [\n                {\n                    \"left\": max(0, bbox[\"left\"] - padding_width),\n                    \"top\": max(0, bbox[\"top\"] - padding_width),\n                    \"width\": bbox[\"width\"],\n                    \"height\": bbox[\"height\"],\n                    \"entity_type\": bbox[\"entity_type\"],\n                }\n                for bbox in analyzer_bboxes\n            ]\n        elif has_label is False and has_entity_type is False:\n            bboxes = [\n                {\n                    \"left\": max(0, bbox[\"left\"] - padding_width),\n                    \"top\": max(0, bbox[\"top\"] - padding_width),\n                    \"width\": bbox[\"width\"],\n                    \"height\": bbox[\"height\"],\n                }\n                for bbox in analyzer_bboxes\n            ]\n    else:\n        bboxes = analyzer_bboxes\n\n    return bboxes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.BilateralFilter","title":"<code>BilateralFilter</code>","text":"<p>               Bases: <code>ImagePreprocessor</code></p> <p>BilateralFilter class.</p> <p>The class applies bilateral filtering to an image. and returns the filtered   image and metadata.</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>class BilateralFilter(ImagePreprocessor):\n    \"\"\"BilateralFilter class.\n\n    The class applies bilateral filtering to an image. and returns the filtered\n      image and metadata.\n    \"\"\"\n\n    def __init__(\n        self, diameter: int = 3, sigma_color: int = 40, sigma_space: int = 40\n    ) -&gt; None:\n        \"\"\"Initialize the BilateralFilter class.\n\n        :param diameter: Diameter of each pixel neighborhood.\n        :param sigma_color: value of sigma in the color space.\n        :param sigma_space: value of sigma in the coordinate space.\n        \"\"\"\n        super().__init__(use_greyscale=True)\n\n        self.diameter = diameter\n        self.sigma_color = sigma_color\n        self.sigma_space = sigma_space\n\n    def preprocess_image(self, image: Image.Image) -&gt; Tuple[Image.Image, dict]:\n        \"\"\"Preprocess the image to be analyzed.\n\n        :param image: Loaded PIL image.\n\n        :return: The processed image and metadata (diameter, sigma_color, sigma_space).\n        \"\"\"\n        image = self.convert_image_to_array(image)\n\n        # Apply bilateral filtering\n        filtered_image = cv2.bilateralFilter(\n            image,\n            self.diameter,\n            self.sigma_color,\n            self.sigma_space,\n        )\n\n        metadata = {\n            \"diameter\": self.diameter,\n            \"sigma_color\": self.sigma_color,\n            \"sigma_space\": self.sigma_space,\n        }\n\n        return Image.fromarray(filtered_image), metadata\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.BilateralFilter.__init__","title":"<code>__init__(diameter=3, sigma_color=40, sigma_space=40)</code>","text":"<p>Initialize the BilateralFilter class.</p> <p>Parameters:</p> Name Type Description Default <code>diameter</code> <code>int</code> <p>Diameter of each pixel neighborhood.</p> <code>3</code> <code>sigma_color</code> <code>int</code> <p>value of sigma in the color space.</p> <code>40</code> <code>sigma_space</code> <code>int</code> <p>value of sigma in the coordinate space.</p> <code>40</code> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def __init__(\n    self, diameter: int = 3, sigma_color: int = 40, sigma_space: int = 40\n) -&gt; None:\n    \"\"\"Initialize the BilateralFilter class.\n\n    :param diameter: Diameter of each pixel neighborhood.\n    :param sigma_color: value of sigma in the color space.\n    :param sigma_space: value of sigma in the coordinate space.\n    \"\"\"\n    super().__init__(use_greyscale=True)\n\n    self.diameter = diameter\n    self.sigma_color = sigma_color\n    self.sigma_space = sigma_space\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.BilateralFilter.preprocess_image","title":"<code>preprocess_image(image)</code>","text":"<p>Preprocess the image to be analyzed.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Loaded PIL image.</p> required <p>Returns:</p> Type Description <code>Tuple[Image, dict]</code> <p>The processed image and metadata (diameter, sigma_color, sigma_space).</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def preprocess_image(self, image: Image.Image) -&gt; Tuple[Image.Image, dict]:\n    \"\"\"Preprocess the image to be analyzed.\n\n    :param image: Loaded PIL image.\n\n    :return: The processed image and metadata (diameter, sigma_color, sigma_space).\n    \"\"\"\n    image = self.convert_image_to_array(image)\n\n    # Apply bilateral filtering\n    filtered_image = cv2.bilateralFilter(\n        image,\n        self.diameter,\n        self.sigma_color,\n        self.sigma_space,\n    )\n\n    metadata = {\n        \"diameter\": self.diameter,\n        \"sigma_color\": self.sigma_color,\n        \"sigma_space\": self.sigma_space,\n    }\n\n    return Image.fromarray(filtered_image), metadata\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ContrastSegmentedImageEnhancer","title":"<code>ContrastSegmentedImageEnhancer</code>","text":"<p>               Bases: <code>ImagePreprocessor</code></p> <p>Class containing all logic to perform contrastive segmentation.</p> <p>Contrastive segmentation is a preprocessing step that aims to enhance the text in an image by increasing the contrast between the text and the background. The parameters used to run the preprocessing are selected based on the contrast level of the image.</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>class ContrastSegmentedImageEnhancer(ImagePreprocessor):\n    \"\"\"Class containing all logic to perform contrastive segmentation.\n\n    Contrastive segmentation is a preprocessing step that aims to enhance the\n    text in an image by increasing the contrast between the text and the\n    background. The parameters used to run the preprocessing are selected based\n    on the contrast level of the image.\n    \"\"\"\n\n    def __init__(\n        self,\n        bilateral_filter: Optional[BilateralFilter] = None,\n        adaptive_threshold: Optional[SegmentedAdaptiveThreshold] = None,\n        image_rescaling: Optional[ImageRescaling] = None,\n        low_contrast_threshold: int = 40,\n    ) -&gt; None:\n        \"\"\"Initialize the class.\n\n        :param bilateral_filter: Optional BilateralFilter instance.\n        :param adaptive_threshold: Optional AdaptiveThreshold instance.\n        :param image_rescaling: Optional ImageRescaling instance.\n        :param low_contrast_threshold: Threshold for low contrast images.\n        \"\"\"\n\n        super().__init__(use_greyscale=True)\n        if not bilateral_filter:\n            self.bilateral_filter = BilateralFilter()\n        else:\n            self.bilateral_filter = bilateral_filter\n\n        if not adaptive_threshold:\n            self.adaptive_threshold = SegmentedAdaptiveThreshold()\n        else:\n            self.adaptive_threshold = adaptive_threshold\n\n        if not image_rescaling:\n            self.image_rescaling = ImageRescaling()\n        else:\n            self.image_rescaling = image_rescaling\n\n        self.low_contrast_threshold = low_contrast_threshold\n\n    def preprocess_image(self, image: Image.Image) -&gt; Tuple[Image.Image, dict]:\n        \"\"\"Preprocess the image to be analyzed.\n\n        :param image: Loaded PIL image.\n\n        :return: The processed image and metadata (background color, scale percentage,\n             contrast level, and C value).\n        \"\"\"\n        image = self.convert_image_to_array(image)\n\n        # Apply bilateral filtering\n        filtered_image, _ = self.bilateral_filter.preprocess_image(image)\n\n        # Convert to grayscale\n        pil_filtered_image = Image.fromarray(np.uint8(filtered_image))\n        pil_grayscale_image = pil_filtered_image.convert(\"L\")\n        grayscale_image = np.asarray(pil_grayscale_image)\n\n        # Improve contrast\n        adjusted_image, _, adjusted_contrast = self._improve_contrast(grayscale_image)\n\n        # Adaptive Thresholding\n        adaptive_threshold_image, _ = self.adaptive_threshold.preprocess_image(\n            adjusted_image\n        )\n        # Increase contrast\n        _, threshold_image = cv2.threshold(\n            np.asarray(adaptive_threshold_image),\n            0,\n            255,\n            cv2.THRESH_BINARY | cv2.THRESH_OTSU,\n        )\n\n        # Rescale image\n        rescaled_image, scale_metadata = self.image_rescaling.preprocess_image(\n            threshold_image\n        )\n\n        return rescaled_image, scale_metadata\n\n    def _improve_contrast(self, image: np.ndarray) -&gt; Tuple[np.ndarray, str, str]:\n        \"\"\"Improve the contrast of an image based on its initial contrast level.\n\n        :param image: Input image.\n\n        :return: A tuple containing the improved image, the initial contrast level,\n             and the adjusted contrast level.\n        \"\"\"\n        contrast, mean_intensity = self._get_image_contrast(image)\n\n        if contrast &lt;= self.low_contrast_threshold:\n            alpha = 1.5\n            beta = -mean_intensity * alpha\n            adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n            adjusted_contrast, _ = self._get_image_contrast(adjusted_image)\n        else:\n            adjusted_image = image\n            adjusted_contrast = contrast\n        return adjusted_image, contrast, adjusted_contrast\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ContrastSegmentedImageEnhancer.__init__","title":"<code>__init__(bilateral_filter=None, adaptive_threshold=None, image_rescaling=None, low_contrast_threshold=40)</code>","text":"<p>Initialize the class.</p> <p>Parameters:</p> Name Type Description Default <code>bilateral_filter</code> <code>Optional[BilateralFilter]</code> <p>Optional BilateralFilter instance.</p> <code>None</code> <code>adaptive_threshold</code> <code>Optional[SegmentedAdaptiveThreshold]</code> <p>Optional AdaptiveThreshold instance.</p> <code>None</code> <code>image_rescaling</code> <code>Optional[ImageRescaling]</code> <p>Optional ImageRescaling instance.</p> <code>None</code> <code>low_contrast_threshold</code> <code>int</code> <p>Threshold for low contrast images.</p> <code>40</code> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def __init__(\n    self,\n    bilateral_filter: Optional[BilateralFilter] = None,\n    adaptive_threshold: Optional[SegmentedAdaptiveThreshold] = None,\n    image_rescaling: Optional[ImageRescaling] = None,\n    low_contrast_threshold: int = 40,\n) -&gt; None:\n    \"\"\"Initialize the class.\n\n    :param bilateral_filter: Optional BilateralFilter instance.\n    :param adaptive_threshold: Optional AdaptiveThreshold instance.\n    :param image_rescaling: Optional ImageRescaling instance.\n    :param low_contrast_threshold: Threshold for low contrast images.\n    \"\"\"\n\n    super().__init__(use_greyscale=True)\n    if not bilateral_filter:\n        self.bilateral_filter = BilateralFilter()\n    else:\n        self.bilateral_filter = bilateral_filter\n\n    if not adaptive_threshold:\n        self.adaptive_threshold = SegmentedAdaptiveThreshold()\n    else:\n        self.adaptive_threshold = adaptive_threshold\n\n    if not image_rescaling:\n        self.image_rescaling = ImageRescaling()\n    else:\n        self.image_rescaling = image_rescaling\n\n    self.low_contrast_threshold = low_contrast_threshold\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ContrastSegmentedImageEnhancer.preprocess_image","title":"<code>preprocess_image(image)</code>","text":"<p>Preprocess the image to be analyzed.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Loaded PIL image.</p> required <p>Returns:</p> Type Description <code>Tuple[Image, dict]</code> <p>The processed image and metadata (background color, scale percentage, contrast level, and C value).</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def preprocess_image(self, image: Image.Image) -&gt; Tuple[Image.Image, dict]:\n    \"\"\"Preprocess the image to be analyzed.\n\n    :param image: Loaded PIL image.\n\n    :return: The processed image and metadata (background color, scale percentage,\n         contrast level, and C value).\n    \"\"\"\n    image = self.convert_image_to_array(image)\n\n    # Apply bilateral filtering\n    filtered_image, _ = self.bilateral_filter.preprocess_image(image)\n\n    # Convert to grayscale\n    pil_filtered_image = Image.fromarray(np.uint8(filtered_image))\n    pil_grayscale_image = pil_filtered_image.convert(\"L\")\n    grayscale_image = np.asarray(pil_grayscale_image)\n\n    # Improve contrast\n    adjusted_image, _, adjusted_contrast = self._improve_contrast(grayscale_image)\n\n    # Adaptive Thresholding\n    adaptive_threshold_image, _ = self.adaptive_threshold.preprocess_image(\n        adjusted_image\n    )\n    # Increase contrast\n    _, threshold_image = cv2.threshold(\n        np.asarray(adaptive_threshold_image),\n        0,\n        255,\n        cv2.THRESH_BINARY | cv2.THRESH_OTSU,\n    )\n\n    # Rescale image\n    rescaled_image, scale_metadata = self.image_rescaling.preprocess_image(\n        threshold_image\n    )\n\n    return rescaled_image, scale_metadata\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImagePiiVerifyEngine","title":"<code>DicomImagePiiVerifyEngine</code>","text":"<p>               Bases: <code>ImagePiiVerifyEngine</code>, <code>DicomImageRedactorEngine</code></p> <p>Class to handle verification and evaluation for DICOM de-identification.</p> Source code in <code>presidio_image_redactor/dicom_image_pii_verify_engine.py</code> <pre><code>class DicomImagePiiVerifyEngine(ImagePiiVerifyEngine, DicomImageRedactorEngine):\n    \"\"\"Class to handle verification and evaluation for DICOM de-identification.\"\"\"\n\n    def __init__(\n        self,\n        ocr_engine: Optional[OCR] = None,\n        image_analyzer_engine: Optional[ImageAnalyzerEngine] = None,\n    ):\n        \"\"\"Initialize DicomImagePiiVerifyEngine object.\n\n        :param ocr_engine: OCR engine to use.\n        :param image_analyzer_engine: Image analyzer engine to use.\n        \"\"\"\n        # Initialize OCR engine\n        if not ocr_engine:\n            self.ocr_engine = TesseractOCR()\n        else:\n            self.ocr_engine = ocr_engine\n\n        # Initialize image analyzer engine\n        if not image_analyzer_engine:\n            self.image_analyzer_engine = ImageAnalyzerEngine()\n        else:\n            self.image_analyzer_engine = image_analyzer_engine\n\n        # Initialize bbox processor\n        self.bbox_processor = BboxProcessor()\n\n    def verify_dicom_instance(\n        self,\n        instance: pydicom.dataset.FileDataset,\n        padding_width: int = 25,\n        display_image: bool = True,\n        show_text_annotation: bool = True,\n        use_metadata: bool = True,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; Tuple[Optional[PIL.Image.Image], dict, list]:\n        \"\"\"Verify PII on a single DICOM instance.\n\n        :param instance: Loaded DICOM instance including pixel data and metadata.\n        :param padding_width: Padding width to use when running OCR.\n        :param display_image: If the verificationimage is displayed and returned.\n        :param show_text_annotation: True to display entity type when displaying\n        image with bounding boxes.\n        :param use_metadata: Whether to redact text in the image that\n        are present in the metadata.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in ImageAnalyzerEngine.\n\n        :return: Image with boxes identifying PHI, OCR results,\n        and analyzer results.\n        \"\"\"\n        instance_copy = deepcopy(instance)\n\n        try:\n            instance_copy.PixelData\n        except AttributeError:\n            raise AttributeError(\"Provided DICOM instance lacks pixel data.\")\n\n        # Load image for processing\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Convert DICOM to PNG and add padding for OCR (during analysis)\n            is_greyscale = self._check_if_greyscale(instance_copy)\n            image = self._rescale_dcm_pixel_array(instance_copy, is_greyscale)\n            self._save_pixel_array_as_png(image, is_greyscale, \"tmp_dcm\", tmpdirname)\n\n            png_filepath = f\"{tmpdirname}/tmp_dcm.png\"\n            loaded_image = Image.open(png_filepath)\n            image = self._add_padding(loaded_image, is_greyscale, padding_width)\n\n        # Get OCR results\n        perform_ocr_kwargs, ocr_threshold = (\n            self.image_analyzer_engine._parse_ocr_kwargs(ocr_kwargs)\n        )  # noqa: E501\n        ocr_results = self.ocr_engine.perform_ocr(image, **perform_ocr_kwargs)\n        if ocr_threshold:\n            ocr_results = self.image_analyzer_engine.threshold_ocr_result(\n                ocr_results, ocr_threshold\n            )\n        ocr_bboxes = self.bbox_processor.get_bboxes_from_ocr_results(ocr_results)\n\n        # Get analyzer results\n        analyzer_results = self._get_analyzer_results(\n            image,\n            instance,\n            use_metadata,\n            ocr_kwargs,\n            ad_hoc_recognizers,\n            **text_analyzer_kwargs,\n        )\n        analyzer_bboxes = self.bbox_processor.get_bboxes_from_analyzer_results(\n            analyzer_results\n        )\n\n        # Prepare for plotting\n        pii_bboxes = self.image_analyzer_engine.get_pii_bboxes(\n            ocr_bboxes, analyzer_bboxes\n        )\n        if is_greyscale:\n            use_greyscale_cmap = True\n        else:\n            use_greyscale_cmap = False\n\n        # Get image with verification boxes\n        verify_image = (\n            self.image_analyzer_engine.add_custom_bboxes(\n                image, pii_bboxes, show_text_annotation, use_greyscale_cmap\n            )\n            if display_image\n            else None\n        )\n\n        return verify_image, ocr_bboxes, analyzer_bboxes\n\n    def eval_dicom_instance(\n        self,\n        instance: pydicom.dataset.FileDataset,\n        ground_truth: dict,\n        padding_width: int = 25,\n        tolerance: int = 50,\n        display_image: bool = False,\n        use_metadata: bool = True,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; Tuple[Optional[PIL.Image.Image], dict]:\n        \"\"\"Evaluate performance for a single DICOM instance.\n\n        :param instance: Loaded DICOM instance including pixel data and metadata.\n        :param ground_truth: Dictionary containing ground truth labels for the instance.\n        :param padding_width: Padding width to use when running OCR.\n        :param tolerance: Pixel distance tolerance for matching to ground truth.\n        :param display_image: If the verificationimage is displayed and returned.\n        :param use_metadata: Whether to redact text in the image that\n        are present in the metadata.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in ImageAnalyzerEngine.\n\n        :return: Evaluation comparing redactor engine results vs ground truth.\n        \"\"\"\n        # Verify detected PHI\n        verify_image, ocr_results, analyzer_results = self.verify_dicom_instance(\n            instance,\n            padding_width,\n            display_image,\n            use_metadata,\n            ocr_kwargs=ocr_kwargs,\n            ad_hoc_recognizers=ad_hoc_recognizers,\n            **text_analyzer_kwargs,\n        )\n        formatted_ocr_results = self.bbox_processor.get_bboxes_from_ocr_results(\n            ocr_results\n        )\n        detected_phi = self.bbox_processor.get_bboxes_from_analyzer_results(\n            analyzer_results\n        )\n\n        # Remove duplicate entities in results\n        detected_phi = self._remove_duplicate_entities(detected_phi)\n\n        # Get correct PHI text (all TP and FP)\n        all_pos = self._label_all_positives(\n            ground_truth, formatted_ocr_results, detected_phi, tolerance\n        )\n\n        # Calculate evaluation metrics\n        precision = self.calculate_precision(ground_truth, all_pos)\n        recall = self.calculate_recall(ground_truth, all_pos)\n\n        eval_results = {\n            \"all_positives\": all_pos,\n            \"ground_truth\": ground_truth,\n            \"precision\": precision,\n            \"recall\": recall,\n        }\n\n        return verify_image, eval_results\n\n    @staticmethod\n    def _remove_duplicate_entities(\n        results: List[dict], dup_pix_tolerance: int = 5\n    ) -&gt; List[dict]:\n        \"\"\"Handle when a word is detected multiple times as different types of entities.\n\n        :param results: List of detected PHI with bbox info.\n        :param dup_pix_tolerance: Pixel difference tolerance for identifying duplicates.\n        :return: Detected PHI with no duplicate entities.\n        \"\"\"\n        dups = []\n        sorted(results, key=lambda x: x[\"score\"], reverse=True)\n        results_no_dups = []\n        dims = [\"left\", \"top\", \"width\", \"height\"]\n\n        # Check for duplicates\n        for i in range(len(results) - 1):\n            i_dims = {dim: results[i][dim] for dim in dims}\n\n            # Ignore if we've already detected this dup combination\n            for other in range(i + 1, len(results)):\n                if i not in results_no_dups:\n                    other_dims = {dim: results[other][dim] for dim in dims}\n                    matching_dims = {\n                        dim: abs(i_dims[dim] - other_dims[dim]) &lt;= dup_pix_tolerance\n                        for dim in dims\n                    }\n                    matching = list(matching_dims.values())\n\n                    if all(matching):\n                        lower_scored_index = (\n                            other\n                            if results[other][\"score\"] &lt; results[i][\"score\"]\n                            else i\n                        )\n                        dups.append(lower_scored_index)\n\n        # Remove duplicates\n        for i in range(len(results)):\n            if i not in dups:\n                results_no_dups.append(results[i])\n\n        return results_no_dups\n\n    def _label_all_positives(\n        self,\n        gt_labels_dict: dict,\n        ocr_results: List[dict],\n        detected_phi: List[dict],\n        tolerance: int = 50,\n    ) -&gt; List[dict]:\n        \"\"\"Label all entities detected as PHI by using ground truth and OCR results.\n\n        All positives (detected_phi) do not contain PHI labels and are thus\n        difficult to work with intuitively. This method maps back to the\n        actual PHI to each detected sensitive entity.\n\n        :param gt_labels_dict: Dictionary with ground truth labels for a\n        single DICOM instance.\n        :param ocr_results: All detected text.\n        :param detected_phi: Formatted analyzer_results.\n        :param tolerance: Tolerance for exact coordinates and size data.\n        :return: List of all positives, labeled.\n        \"\"\"\n        all_pos = []\n\n        # Cycle through each positive (TP or FP)\n        for analyzer_result in detected_phi:\n            # See if there are any ground truth matches\n            all_pos, gt_match_found = self.bbox_processor.match_with_source(\n                all_pos, gt_labels_dict, analyzer_result, tolerance\n            )\n\n            # If not, check back with OCR\n            if not gt_match_found:\n                all_pos, _ = self.bbox_processor.match_with_source(\n                    all_pos, ocr_results, analyzer_result, tolerance\n                )\n\n        # Remove any duplicates\n        all_pos = self._remove_duplicate_entities(all_pos)\n\n        return all_pos\n\n    @staticmethod\n    def calculate_precision(gt: List[dict], all_pos: List[dict]) -&gt; float:\n        \"\"\"Calculate precision.\n\n        :param gt: List of ground truth labels.\n        :param all_pos: All Detected PHI (mapped back to have actual PHI text).\n        :return: Precision value.\n        \"\"\"\n        # Find True Positive (TP) and precision\n        tp = [i for i in all_pos if i in gt]\n        try:\n            precision = len(tp) / len(all_pos)\n        except ZeroDivisionError:\n            precision = 0\n\n        return precision\n\n    @staticmethod\n    def calculate_recall(gt: List[dict], all_pos: List[dict]) -&gt; float:\n        \"\"\"Calculate recall.\n\n        :param gt: List of ground truth labels.\n        :param all_pos: All Detected PHI (mapped back to have actual PHI text).\n        :return: Recall value.\n        \"\"\"\n        # Find True Positive (TP) and precision\n        tp = [i for i in all_pos if i in gt]\n        try:\n            recall = len(tp) / len(gt)\n        except ZeroDivisionError:\n            recall = 0\n\n        return recall\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImagePiiVerifyEngine.__init__","title":"<code>__init__(ocr_engine=None, image_analyzer_engine=None)</code>","text":"<p>Initialize DicomImagePiiVerifyEngine object.</p> <p>Parameters:</p> Name Type Description Default <code>ocr_engine</code> <code>Optional[OCR]</code> <p>OCR engine to use.</p> <code>None</code> <code>image_analyzer_engine</code> <code>Optional[ImageAnalyzerEngine]</code> <p>Image analyzer engine to use.</p> <code>None</code> Source code in <code>presidio_image_redactor/dicom_image_pii_verify_engine.py</code> <pre><code>def __init__(\n    self,\n    ocr_engine: Optional[OCR] = None,\n    image_analyzer_engine: Optional[ImageAnalyzerEngine] = None,\n):\n    \"\"\"Initialize DicomImagePiiVerifyEngine object.\n\n    :param ocr_engine: OCR engine to use.\n    :param image_analyzer_engine: Image analyzer engine to use.\n    \"\"\"\n    # Initialize OCR engine\n    if not ocr_engine:\n        self.ocr_engine = TesseractOCR()\n    else:\n        self.ocr_engine = ocr_engine\n\n    # Initialize image analyzer engine\n    if not image_analyzer_engine:\n        self.image_analyzer_engine = ImageAnalyzerEngine()\n    else:\n        self.image_analyzer_engine = image_analyzer_engine\n\n    # Initialize bbox processor\n    self.bbox_processor = BboxProcessor()\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImagePiiVerifyEngine.calculate_precision","title":"<code>calculate_precision(gt, all_pos)</code>  <code>staticmethod</code>","text":"<p>Calculate precision.</p> <p>Parameters:</p> Name Type Description Default <code>gt</code> <code>List[dict]</code> <p>List of ground truth labels.</p> required <code>all_pos</code> <code>List[dict]</code> <p>All Detected PHI (mapped back to have actual PHI text).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Precision value.</p> Source code in <code>presidio_image_redactor/dicom_image_pii_verify_engine.py</code> <pre><code>@staticmethod\ndef calculate_precision(gt: List[dict], all_pos: List[dict]) -&gt; float:\n    \"\"\"Calculate precision.\n\n    :param gt: List of ground truth labels.\n    :param all_pos: All Detected PHI (mapped back to have actual PHI text).\n    :return: Precision value.\n    \"\"\"\n    # Find True Positive (TP) and precision\n    tp = [i for i in all_pos if i in gt]\n    try:\n        precision = len(tp) / len(all_pos)\n    except ZeroDivisionError:\n        precision = 0\n\n    return precision\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImagePiiVerifyEngine.calculate_recall","title":"<code>calculate_recall(gt, all_pos)</code>  <code>staticmethod</code>","text":"<p>Calculate recall.</p> <p>Parameters:</p> Name Type Description Default <code>gt</code> <code>List[dict]</code> <p>List of ground truth labels.</p> required <code>all_pos</code> <code>List[dict]</code> <p>All Detected PHI (mapped back to have actual PHI text).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Recall value.</p> Source code in <code>presidio_image_redactor/dicom_image_pii_verify_engine.py</code> <pre><code>@staticmethod\ndef calculate_recall(gt: List[dict], all_pos: List[dict]) -&gt; float:\n    \"\"\"Calculate recall.\n\n    :param gt: List of ground truth labels.\n    :param all_pos: All Detected PHI (mapped back to have actual PHI text).\n    :return: Recall value.\n    \"\"\"\n    # Find True Positive (TP) and precision\n    tp = [i for i in all_pos if i in gt]\n    try:\n        recall = len(tp) / len(gt)\n    except ZeroDivisionError:\n        recall = 0\n\n    return recall\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImagePiiVerifyEngine.eval_dicom_instance","title":"<code>eval_dicom_instance(instance, ground_truth, padding_width=25, tolerance=50, display_image=False, use_metadata=True, ocr_kwargs=None, ad_hoc_recognizers=None, **text_analyzer_kwargs)</code>","text":"<p>Evaluate performance for a single DICOM instance.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>FileDataset</code> <p>Loaded DICOM instance including pixel data and metadata.</p> required <code>ground_truth</code> <code>dict</code> <p>Dictionary containing ground truth labels for the instance.</p> required <code>padding_width</code> <code>int</code> <p>Padding width to use when running OCR.</p> <code>25</code> <code>tolerance</code> <code>int</code> <p>Pixel distance tolerance for matching to ground truth.</p> <code>50</code> <code>display_image</code> <code>bool</code> <p>If the verificationimage is displayed and returned.</p> <code>False</code> <code>use_metadata</code> <code>bool</code> <p>Whether to redact text in the image that are present in the metadata.</p> <code>True</code> <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>ad_hoc_recognizers</code> <code>Optional[List[PatternRecognizer]]</code> <p>List of PatternRecognizer objects to use for ad-hoc recognizer.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in ImageAnalyzerEngine.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Optional[Image], dict]</code> <p>Evaluation comparing redactor engine results vs ground truth.</p> Source code in <code>presidio_image_redactor/dicom_image_pii_verify_engine.py</code> <pre><code>def eval_dicom_instance(\n    self,\n    instance: pydicom.dataset.FileDataset,\n    ground_truth: dict,\n    padding_width: int = 25,\n    tolerance: int = 50,\n    display_image: bool = False,\n    use_metadata: bool = True,\n    ocr_kwargs: Optional[dict] = None,\n    ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    **text_analyzer_kwargs,\n) -&gt; Tuple[Optional[PIL.Image.Image], dict]:\n    \"\"\"Evaluate performance for a single DICOM instance.\n\n    :param instance: Loaded DICOM instance including pixel data and metadata.\n    :param ground_truth: Dictionary containing ground truth labels for the instance.\n    :param padding_width: Padding width to use when running OCR.\n    :param tolerance: Pixel distance tolerance for matching to ground truth.\n    :param display_image: If the verificationimage is displayed and returned.\n    :param use_metadata: Whether to redact text in the image that\n    are present in the metadata.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n    for ad-hoc recognizer.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in ImageAnalyzerEngine.\n\n    :return: Evaluation comparing redactor engine results vs ground truth.\n    \"\"\"\n    # Verify detected PHI\n    verify_image, ocr_results, analyzer_results = self.verify_dicom_instance(\n        instance,\n        padding_width,\n        display_image,\n        use_metadata,\n        ocr_kwargs=ocr_kwargs,\n        ad_hoc_recognizers=ad_hoc_recognizers,\n        **text_analyzer_kwargs,\n    )\n    formatted_ocr_results = self.bbox_processor.get_bboxes_from_ocr_results(\n        ocr_results\n    )\n    detected_phi = self.bbox_processor.get_bboxes_from_analyzer_results(\n        analyzer_results\n    )\n\n    # Remove duplicate entities in results\n    detected_phi = self._remove_duplicate_entities(detected_phi)\n\n    # Get correct PHI text (all TP and FP)\n    all_pos = self._label_all_positives(\n        ground_truth, formatted_ocr_results, detected_phi, tolerance\n    )\n\n    # Calculate evaluation metrics\n    precision = self.calculate_precision(ground_truth, all_pos)\n    recall = self.calculate_recall(ground_truth, all_pos)\n\n    eval_results = {\n        \"all_positives\": all_pos,\n        \"ground_truth\": ground_truth,\n        \"precision\": precision,\n        \"recall\": recall,\n    }\n\n    return verify_image, eval_results\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImagePiiVerifyEngine.verify_dicom_instance","title":"<code>verify_dicom_instance(instance, padding_width=25, display_image=True, show_text_annotation=True, use_metadata=True, ocr_kwargs=None, ad_hoc_recognizers=None, **text_analyzer_kwargs)</code>","text":"<p>Verify PII on a single DICOM instance.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>FileDataset</code> <p>Loaded DICOM instance including pixel data and metadata.</p> required <code>padding_width</code> <code>int</code> <p>Padding width to use when running OCR.</p> <code>25</code> <code>display_image</code> <code>bool</code> <p>If the verificationimage is displayed and returned.</p> <code>True</code> <code>show_text_annotation</code> <code>bool</code> <p>True to display entity type when displaying image with bounding boxes.</p> <code>True</code> <code>use_metadata</code> <code>bool</code> <p>Whether to redact text in the image that are present in the metadata.</p> <code>True</code> <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>ad_hoc_recognizers</code> <code>Optional[List[PatternRecognizer]]</code> <p>List of PatternRecognizer objects to use for ad-hoc recognizer.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in ImageAnalyzerEngine.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Optional[Image], dict, list]</code> <p>Image with boxes identifying PHI, OCR results, and analyzer results.</p> Source code in <code>presidio_image_redactor/dicom_image_pii_verify_engine.py</code> <pre><code>def verify_dicom_instance(\n    self,\n    instance: pydicom.dataset.FileDataset,\n    padding_width: int = 25,\n    display_image: bool = True,\n    show_text_annotation: bool = True,\n    use_metadata: bool = True,\n    ocr_kwargs: Optional[dict] = None,\n    ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    **text_analyzer_kwargs,\n) -&gt; Tuple[Optional[PIL.Image.Image], dict, list]:\n    \"\"\"Verify PII on a single DICOM instance.\n\n    :param instance: Loaded DICOM instance including pixel data and metadata.\n    :param padding_width: Padding width to use when running OCR.\n    :param display_image: If the verificationimage is displayed and returned.\n    :param show_text_annotation: True to display entity type when displaying\n    image with bounding boxes.\n    :param use_metadata: Whether to redact text in the image that\n    are present in the metadata.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n    for ad-hoc recognizer.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in ImageAnalyzerEngine.\n\n    :return: Image with boxes identifying PHI, OCR results,\n    and analyzer results.\n    \"\"\"\n    instance_copy = deepcopy(instance)\n\n    try:\n        instance_copy.PixelData\n    except AttributeError:\n        raise AttributeError(\"Provided DICOM instance lacks pixel data.\")\n\n    # Load image for processing\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        # Convert DICOM to PNG and add padding for OCR (during analysis)\n        is_greyscale = self._check_if_greyscale(instance_copy)\n        image = self._rescale_dcm_pixel_array(instance_copy, is_greyscale)\n        self._save_pixel_array_as_png(image, is_greyscale, \"tmp_dcm\", tmpdirname)\n\n        png_filepath = f\"{tmpdirname}/tmp_dcm.png\"\n        loaded_image = Image.open(png_filepath)\n        image = self._add_padding(loaded_image, is_greyscale, padding_width)\n\n    # Get OCR results\n    perform_ocr_kwargs, ocr_threshold = (\n        self.image_analyzer_engine._parse_ocr_kwargs(ocr_kwargs)\n    )  # noqa: E501\n    ocr_results = self.ocr_engine.perform_ocr(image, **perform_ocr_kwargs)\n    if ocr_threshold:\n        ocr_results = self.image_analyzer_engine.threshold_ocr_result(\n            ocr_results, ocr_threshold\n        )\n    ocr_bboxes = self.bbox_processor.get_bboxes_from_ocr_results(ocr_results)\n\n    # Get analyzer results\n    analyzer_results = self._get_analyzer_results(\n        image,\n        instance,\n        use_metadata,\n        ocr_kwargs,\n        ad_hoc_recognizers,\n        **text_analyzer_kwargs,\n    )\n    analyzer_bboxes = self.bbox_processor.get_bboxes_from_analyzer_results(\n        analyzer_results\n    )\n\n    # Prepare for plotting\n    pii_bboxes = self.image_analyzer_engine.get_pii_bboxes(\n        ocr_bboxes, analyzer_bboxes\n    )\n    if is_greyscale:\n        use_greyscale_cmap = True\n    else:\n        use_greyscale_cmap = False\n\n    # Get image with verification boxes\n    verify_image = (\n        self.image_analyzer_engine.add_custom_bboxes(\n            image, pii_bboxes, show_text_annotation, use_greyscale_cmap\n        )\n        if display_image\n        else None\n    )\n\n    return verify_image, ocr_bboxes, analyzer_bboxes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImageRedactorEngine","title":"<code>DicomImageRedactorEngine</code>","text":"<p>               Bases: <code>ImageRedactorEngine</code></p> <p>Performs OCR + PII detection + bounding box redaction.</p> <p>Parameters:</p> Name Type Description Default <code>image_analyzer_engine</code> <code>ImageAnalyzerEngine</code> <p>Engine which performs OCR + PII detection.</p> <code>None</code> Source code in <code>presidio_image_redactor/dicom_image_redactor_engine.py</code> <pre><code>class DicomImageRedactorEngine(ImageRedactorEngine):\n    \"\"\"Performs OCR + PII detection + bounding box redaction.\n\n    :param image_analyzer_engine: Engine which performs OCR + PII detection.\n    \"\"\"\n\n    def redact_and_return_bbox(\n        self,\n        image: pydicom.dataset.FileDataset,\n        fill: str = \"contrast\",\n        padding_width: int = 25,\n        crop_ratio: float = 0.75,\n        use_metadata: bool = True,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; Tuple[pydicom.dataset.FileDataset, List[Dict[str, int]]]:\n        \"\"\"Redact method to redact the given DICOM image and return redacted bboxes.\n\n        Please note, this method duplicates the image, creates a\n        new instance and manipulates it.\n\n        :param image: Loaded DICOM instance including pixel data and metadata.\n        :param fill: Fill setting to use for redaction box (\"contrast\" or \"background\").\n        :param padding_width: Padding width to use when running OCR.\n        :param crop_ratio: Portion of image to consider when selecting\n        most common pixel value as the background color value.\n        :param use_metadata: Whether to redact text in the image that\n        are present in the metadata.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine.\n\n        :return: DICOM instance with redacted pixel data.\n        \"\"\"\n        # Check input\n        if type(image) not in [pydicom.dataset.FileDataset, pydicom.dataset.Dataset]:\n            raise TypeError(\"The provided image must be a loaded DICOM instance.\")\n        try:\n            image.PixelData\n        except AttributeError as e:\n            raise AttributeError(f\"Provided DICOM instance lacks pixel data: {e}\")\n        except PermissionError as e:\n            raise PermissionError(f\"Unable to access pixel data (may not exist): {e}\")\n        except IsADirectoryError as e:\n            raise IsADirectoryError(f\"DICOM instance is a directory: {e}\")\n\n        instance = deepcopy(image)\n\n        # Load image for processing\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Convert DICOM to PNG and add padding for OCR (during analysis)\n            is_greyscale = self._check_if_greyscale(instance)\n            image = self._rescale_dcm_pixel_array(instance, is_greyscale)\n            image_name = str(uuid.uuid4())\n            self._save_pixel_array_as_png(image, is_greyscale, image_name, tmpdirname)\n\n            png_filepath = f\"{tmpdirname}/{image_name}.png\"\n            loaded_image = Image.open(png_filepath)\n            image = self._add_padding(loaded_image, is_greyscale, padding_width)\n\n        # Detect PII\n        analyzer_results = self._get_analyzer_results(\n            image,\n            instance,\n            use_metadata,\n            ocr_kwargs,\n            ad_hoc_recognizers,\n            **text_analyzer_kwargs,\n        )\n\n        # Redact all bounding boxes from DICOM file\n        analyzer_bboxes = self.bbox_processor.get_bboxes_from_analyzer_results(\n            analyzer_results\n        )\n        bboxes = self.bbox_processor.remove_bbox_padding(analyzer_bboxes, padding_width)\n        redacted_image = self._add_redact_box(instance, bboxes, crop_ratio, fill)\n\n        return redacted_image, bboxes\n\n    def redact(\n        self,\n        image: pydicom.dataset.FileDataset,\n        fill: str = \"contrast\",\n        padding_width: int = 25,\n        crop_ratio: float = 0.75,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; pydicom.dataset.FileDataset:\n        \"\"\"Redact method to redact the given DICOM image.\n\n        Please note, this method duplicates the image, creates a\n        new instance and manipulates it.\n\n        :param image: Loaded DICOM instance including pixel data and metadata.\n        :param fill: Fill setting to use for redaction box (\"contrast\" or \"background\").\n        :param padding_width: Padding width to use when running OCR.\n        :param crop_ratio: Portion of image to consider when selecting\n        most common pixel value as the background color value.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine.\n\n        :return: DICOM instance with redacted pixel data.\n        \"\"\"\n        redacted_image, _ = self.redact_and_return_bbox(\n            image=image,\n            fill=fill,\n            padding_width=padding_width,\n            crop_ratio=crop_ratio,\n            ocr_kwargs=ocr_kwargs,\n            ad_hoc_recognizers=ad_hoc_recognizers,\n            **text_analyzer_kwargs,\n        )\n\n        return redacted_image\n\n    def redact_from_file(\n        self,\n        input_dicom_path: str,\n        output_dir: str,\n        padding_width: int = 25,\n        crop_ratio: float = 0.75,\n        fill: str = \"contrast\",\n        use_metadata: bool = True,\n        save_bboxes: bool = False,\n        verbose: bool = True,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; None:\n        \"\"\"Redact method to redact from a given file.\n\n        Please notice, this method duplicates the file, creates\n        new instance and manipulate them.\n\n        :param input_dicom_path: String path to DICOM image.\n        :param output_dir: String path to parent output directory.\n        :param padding_width : Padding width to use when running OCR.\n        :param fill: Color setting to use for redaction box\n        (\"contrast\" or \"background\").\n        :param use_metadata: Whether to redact text in the image that\n        are present in the metadata.\n        :param save_bboxes: True if we want to save boundings boxes.\n        :param verbose: True to print where redacted file was written to.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine.\n        \"\"\"\n        # Verify the given paths\n        if Path(input_dicom_path).is_dir() is True:\n            raise TypeError(\"input_dicom_path must be file (not dir)\")\n        if Path(input_dicom_path).is_file() is False:\n            raise TypeError(\"input_dicom_path must be a valid file\")\n        if Path(output_dir).is_file() is True:\n            raise TypeError(\n                \"output_dir must be a directory (does not need to exist yet)\"\n            )\n\n        # Create duplicate\n        dst_path = self._copy_files_for_processing(input_dicom_path, output_dir)\n\n        # Process DICOM file\n        output_location = self._redact_single_dicom_image(\n            dcm_path=dst_path,\n            crop_ratio=crop_ratio,\n            fill=fill,\n            padding_width=padding_width,\n            use_metadata=use_metadata,\n            overwrite=True,\n            dst_parent_dir=\".\",\n            save_bboxes=save_bboxes,\n            ocr_kwargs=ocr_kwargs,\n            ad_hoc_recognizers=ad_hoc_recognizers,\n            **text_analyzer_kwargs,\n        )\n\n        if verbose:\n            print(f\"Output written to {output_location}\")\n\n        return None\n\n    def redact_from_directory(\n        self,\n        input_dicom_path: str,\n        output_dir: str,\n        padding_width: int = 25,\n        crop_ratio: float = 0.75,\n        fill: str = \"contrast\",\n        use_metadata: bool = True,\n        save_bboxes: bool = False,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; None:\n        \"\"\"Redact method to redact from a directory of files.\n\n        Please notice, this method duplicates the files, creates\n        new instances and manipulate them.\n\n        :param input_dicom_path: String path to directory of DICOM images.\n        :param output_dir: String path to parent output directory.\n        :param padding_width : Padding width to use when running OCR.\n        :param crop_ratio: Portion of image to consider when selecting\n        most common pixel value as the background color value.\n        :param fill: Color setting to use for redaction box\n        (\"contrast\" or \"background\").\n        :param use_metadata: Whether to redact text in the image that\n        are present in the metadata.\n        :param save_bboxes: True if we want to save boundings boxes.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine.\n        \"\"\"\n        # Verify the given paths\n        if Path(input_dicom_path).is_dir() is False:\n            raise TypeError(\"input_dicom_path must be a valid directory\")\n        if Path(input_dicom_path).is_file() is True:\n            raise TypeError(\"input_dicom_path must be a directory (not file)\")\n        if Path(output_dir).is_file() is True:\n            raise TypeError(\n                \"output_dir must be a directory (does not need to exist yet)\"\n            )\n\n        # Create duplicates\n        dst_path = self._copy_files_for_processing(input_dicom_path, output_dir)\n\n        # Process DICOM files\n        output_location = self._redact_multiple_dicom_images(\n            dcm_dir=dst_path,\n            crop_ratio=crop_ratio,\n            fill=fill,\n            padding_width=padding_width,\n            use_metadata=use_metadata,\n            ad_hoc_recognizers=ad_hoc_recognizers,\n            overwrite=True,\n            dst_parent_dir=\".\",\n            save_bboxes=save_bboxes,\n            ocr_kwargs=ocr_kwargs,\n            **text_analyzer_kwargs,\n        )\n\n        print(f\"Output written to {output_location}\")\n\n        return None\n\n    @staticmethod\n    def _get_all_dcm_files(dcm_dir: Path) -&gt; List[Path]:\n        \"\"\"Return paths to all DICOM files in a directory and its sub-directories.\n\n        :param dcm_dir: pathlib Path to a directory containing at least one .dcm file.\n\n        :return: List of pathlib Path objects.\n        \"\"\"\n        # Define applicable extensions\n        extensions = [\"[dD][cC][mM]\", \"[dD][iI][cC][oO][mM]\"]\n\n        # Get all files with any applicable extension\n        all_files = []\n        for extension in extensions:\n            p = dcm_dir.glob(f\"**/*.{extension}\")\n            files = [x for x in p if x.is_file()]\n            all_files += files\n\n        return all_files\n\n    @staticmethod\n    def _check_if_greyscale(instance: pydicom.dataset.FileDataset) -&gt; bool:\n        \"\"\"Check if a DICOM image is in greyscale.\n\n        :param instance: A single DICOM instance.\n\n        :return: FALSE if the Photometric Interpretation is RGB.\n        \"\"\"\n        # Check if image is grayscale using the Photometric Interpretation element\n        try:\n            color_scale = instance.PhotometricInterpretation\n        except AttributeError:\n            color_scale = None\n        is_greyscale = color_scale in [\"MONOCHROME1\", \"MONOCHROME2\"]\n\n        return is_greyscale\n\n    @staticmethod\n    def _rescale_dcm_pixel_array(\n        instance: pydicom.dataset.FileDataset, is_greyscale: bool\n    ) -&gt; np.ndarray:\n        \"\"\"Rescale DICOM pixel_array.\n\n        :param instance: A singe DICOM instance.\n        :param is_greyscale: FALSE if the Photometric Interpretation is RGB.\n\n        :return: Rescaled DICOM pixel_array.\n        \"\"\"\n        # Normalize contrast\n        if \"WindowWidth\" in instance:\n            if is_greyscale:\n                image_2d = apply_voi_lut(instance.pixel_array, instance)\n            else:\n                image_2d = instance.pixel_array\n        else:\n            image_2d = instance.pixel_array\n\n        # Convert to float to avoid overflow or underflow losses.\n        image_2d_float = image_2d.astype(float)\n\n        if not is_greyscale:\n            image_2d_scaled = image_2d_float\n        else:\n            # Rescaling grey scale between 0-255\n            image_2d_scaled = (\n                (image_2d_float.max() - image_2d_float)\n                / (image_2d_float.max() - image_2d_float.min())\n            ) * 255.0\n\n        # Convert to uint\n        image_2d_scaled = np.uint8(image_2d_scaled)\n\n        return image_2d_scaled\n\n    @staticmethod\n    def _save_pixel_array_as_png(\n        pixel_array: np.array,\n        is_greyscale: bool,\n        output_file_name: str = \"example\",\n        output_dir: str = \"temp_dir\",\n    ) -&gt; None:\n        \"\"\"Save the pixel data from a loaded DICOM instance as PNG.\n\n        :param pixel_array: Pixel data from the instance.\n        :param is_greyscale: True if image is greyscale.\n        :param output_file_name: Name of output file (no file extension).\n        :param output_dir: String path to output directory.\n        \"\"\"\n        shape = pixel_array.shape\n\n        # Write the PNG file\n        os.makedirs(output_dir, exist_ok=True)\n        if is_greyscale:\n            with open(f\"{output_dir}/{output_file_name}.png\", \"wb\") as png_file:\n                w = png.Writer(shape[1], shape[0], greyscale=True)\n                w.write(png_file, pixel_array)\n        else:\n            with open(f\"{output_dir}/{output_file_name}.png\", \"wb\") as png_file:\n                w = png.Writer(shape[1], shape[0], greyscale=False)\n                # Semi-flatten the pixel array to RGB representation in 2D\n                pixel_array = np.reshape(pixel_array, (shape[0], shape[1] * 3))\n                w.write(png_file, pixel_array)\n\n        return None\n\n    @classmethod\n    def _convert_dcm_to_png(cls, filepath: Path, output_dir: str = \"temp_dir\") -&gt; tuple:\n        \"\"\"Convert DICOM image to PNG file.\n\n        :param filepath: pathlib Path to a single dcm file.\n        :param output_dir: String path to output directory.\n\n        :return: Shape of pixel array and if image mode is greyscale.\n        \"\"\"\n        ds = pydicom.dcmread(filepath)\n\n        # Check if image is grayscale using the Photometric Interpretation element\n        is_greyscale = cls._check_if_greyscale(ds)\n\n        # Rescale pixel array\n        image = cls._rescale_dcm_pixel_array(ds, is_greyscale)\n        shape = image.shape\n\n        # Write to PNG file\n        cls._save_pixel_array_as_png(image, is_greyscale, filepath.stem, output_dir)\n\n        return shape, is_greyscale\n\n    @staticmethod\n    def _get_bg_color(\n        image: Image.Image, is_greyscale: bool, invert: bool = False\n    ) -&gt; Union[int, Tuple[int, int, int]]:\n        \"\"\"Select most common color as background color.\n\n        :param image: Loaded PIL image.\n        :param colorscale: Colorscale of image (e.g., 'grayscale', 'RGB')\n        :param invert: TRUE if you want to get the inverse of the bg color.\n\n        :return: Background color.\n        \"\"\"\n        # Invert colors if invert flag is True\n        if invert:\n            if image.mode == \"RGBA\":\n                # Handle transparency as needed\n                r, g, b, a = image.split()\n                rgb_image = Image.merge(\"RGB\", (r, g, b))\n                inverted_image = ImageOps.invert(rgb_image)\n                r2, g2, b2 = inverted_image.split()\n\n                image = Image.merge(\"RGBA\", (r2, g2, b2, a))\n\n            else:\n                image = ImageOps.invert(image)\n\n        # Get background color\n        if is_greyscale:\n            # Select most common color as color\n            bg_color = int(np.bincount(list(image.getdata())).argmax())\n        else:\n            # Reduce size of image to 1 pixel to get dominant color\n            tmp_image = image.copy()\n            tmp_image = tmp_image.resize((1, 1), resample=0)\n            bg_color = tmp_image.getpixel((0, 0))\n\n        return bg_color\n\n    @staticmethod\n    def _get_array_corners(pixel_array: np.ndarray, crop_ratio: float) -&gt; np.ndarray:\n        \"\"\"Crop a pixel array to just return the corners in a single array.\n\n        :param pixel_array: Numpy array containing the pixel data.\n        :param crop_ratio: Portion of image to consider when selecting\n        most common pixel value as the background color value.\n\n        :return: Cropped input array.\n        \"\"\"\n        if crop_ratio &gt;= 1.0 or crop_ratio &lt;= 0:\n            raise ValueError(\"crop_ratio must be between 0 and 1\")\n\n        # Set dimensions\n        width = pixel_array.shape[0]\n        height = pixel_array.shape[1]\n        crop_width = int(np.floor(width * crop_ratio / 2))\n        crop_height = int(np.floor(height * crop_ratio / 2))\n\n        # Get coordinates for corners\n        # (left, top, right, bottom)\n        box_top_left = (0, 0, crop_width, crop_height)\n        box_top_right = (width - crop_width, 0, width, crop_height)\n        box_bottom_left = (0, height - crop_height, crop_width, height)\n        box_bottom_right = (width - crop_width, height - crop_height, width, height)\n        boxes = [box_top_left, box_top_right, box_bottom_left, box_bottom_right]\n\n        # Only keep box pixels\n        cropped_pixel_arrays = [\n            pixel_array[box[0] : box[2], box[1] : box[3]] for box in boxes\n        ]\n\n        # Combine the cropped pixel arrays\n        cropped_array = np.vstack(cropped_pixel_arrays)\n\n        return cropped_array\n\n    @classmethod\n    def _get_most_common_pixel_value(\n        cls,\n        instance: pydicom.dataset.FileDataset,\n        crop_ratio: float,\n        fill: str = \"contrast\",\n    ) -&gt; Union[int, Tuple[int, int, int]]:\n        \"\"\"Find the most common pixel value.\n\n        :param instance: A singe DICOM instance.\n        :param crop_ratio: Portion of image to consider when selecting\n        most common pixel value as the background color value.\n        :param fill: Determines how box color is selected.\n        'contrast' - Masks stand out relative to background.\n        'background' - Masks are same color as background.\n\n        :return: Most or least common pixel value (depending on fill).\n        \"\"\"\n        # Crop down to just only look at image corners\n        cropped_array = cls._get_array_corners(instance.pixel_array, crop_ratio)\n\n        # Get flattened pixel array\n        flat_pixel_array = np.array(cropped_array).flatten()\n\n        is_greyscale = cls._check_if_greyscale(instance)\n        if is_greyscale:\n            # Get most common value\n            values, counts = np.unique(flat_pixel_array, return_counts=True)\n            flat_pixel_array = np.array(flat_pixel_array)\n            common_value = values[np.argmax(counts)]\n        else:\n            raise TypeError(\n                \"Most common pixel value retrieval is only supported for greyscale images at this point.\"  # noqa: E501\n            )\n\n        # Invert color as necessary\n        if fill.lower() in [\"contrast\", \"invert\", \"inverted\", \"inverse\"]:\n            pixel_value = np.max(flat_pixel_array) - common_value\n        elif fill.lower() in [\"background\", \"bg\"]:\n            pixel_value = common_value\n\n        return pixel_value\n\n    @classmethod\n    def _add_padding(\n        cls,\n        image: Image.Image,\n        is_greyscale: bool,\n        padding_width: int,\n    ) -&gt; Image.Image:\n        \"\"\"Add border to image using most common color.\n\n        :param image: Loaded PIL image.\n        :param is_greyscale: Whether image is in grayscale or not.\n        :param padding_width: Pixel width of padding (uniform).\n\n        :return: PIL image with padding.\n        \"\"\"\n        # Check padding width value\n        if padding_width &lt;= 0:\n            raise ValueError(\"Enter a positive value for padding\")\n        elif padding_width &gt;= 100:\n            raise ValueError(\n                \"Excessive padding width entered. Please use a width under 100 pixels.\"  # noqa: E501\n            )\n\n        # Select most common color as border color\n        border_color = cls._get_bg_color(image, is_greyscale)\n\n        # Add padding\n        right = padding_width\n        left = padding_width\n        top = padding_width\n        bottom = padding_width\n\n        width, height = image.size\n\n        new_width = width + right + left\n        new_height = height + top + bottom\n\n        image_with_padding = Image.new(\n            image.mode, (new_width, new_height), border_color\n        )\n        image_with_padding.paste(image, (left, top))\n\n        return image_with_padding\n\n    @staticmethod\n    def _copy_files_for_processing(src_path: str, dst_parent_dir: str) -&gt; Path:\n        \"\"\"Copy DICOM files. All processing should be done on the copies.\n\n        :param src_path: String path to DICOM file or directory containing DICOM files.\n        :param dst_parent_dir: String path to parent directory of output location.\n\n        :return: Output location of the file(s).\n        \"\"\"\n        # Identify output path\n        tail = list(Path(src_path).parts)[-1]\n        dst_path = Path(dst_parent_dir, tail)\n\n        # Copy file(s)\n        if Path(src_path).is_dir() is True:\n            try:\n                shutil.copytree(src_path, dst_path)\n            except FileExistsError:\n                raise FileExistsError(\n                    \"Destination files already exist. Please clear the destination files or specify a different dst_parent_dir.\"  # noqa: E501\n                )\n        elif Path(src_path).is_file() is True:\n            # Create the output dir manually if working with a single file\n            os.makedirs(Path(dst_path).parent, exist_ok=True)\n            shutil.copyfile(src_path, dst_path)\n        else:\n            raise FileNotFoundError(f\"{src_path} does not exist\")\n\n        return dst_path\n\n    @staticmethod\n    def _get_text_metadata(\n        instance: pydicom.dataset.FileDataset,\n    ) -&gt; Tuple[list, list, list]:\n        \"\"\"Retrieve all text metadata from the DICOM image.\n\n        :param instance: Loaded DICOM instance.\n\n        :return: List of all the instance's element values (excluding pixel data),\n        bool for if the element is specified as being a name,\n        bool for if the element is specified as being related to the patient.\n        \"\"\"\n        metadata_text = list()\n        is_name = list()\n        is_patient = list()\n\n        for element in instance:\n            # Save all metadata except the DICOM image itself\n            if element.name != \"Pixel Data\":\n                # Save the metadata\n                metadata_text.append(element.value)\n\n                # Track whether this particular element is a name\n                if \"name\" in element.name.lower():\n                    is_name.append(True)\n                else:\n                    is_name.append(False)\n\n                # Track whether this particular element is directly tied to the patient\n                if \"patient\" in element.name.lower():\n                    is_patient.append(True)\n                else:\n                    is_patient.append(False)\n            else:\n                metadata_text.append(\"\")\n                is_name.append(False)\n                is_patient.append(False)\n\n        return metadata_text, is_name, is_patient\n\n    @staticmethod\n    def augment_word(word: str, case_sensitive: bool = False) -&gt; list:\n        \"\"\"Apply multiple types of casing to the provided string.\n\n        :param words: String containing the word or term of interest.\n        :param case_sensitive: True if we want to preserve casing.\n\n        :return: List of the same string with different casings and spacing.\n        \"\"\"\n        word_list = []\n        if word != \"\":\n            # Replacing separator character with space, if any\n            text_no_separator = word.replace(\"^\", \" \")\n            text_no_separator = text_no_separator.replace(\"-\", \" \")\n            text_no_separator = \" \".join(text_no_separator.split())\n\n            if case_sensitive:\n                word_list.append(text_no_separator)\n                word_list.extend(\n                    [\n                        text_no_separator.split(\" \"),\n                    ]\n                )\n            else:\n                # Capitalize all characters in string\n                text_upper = text_no_separator.upper()\n\n                # Lowercase all characters in string\n                text_lower = text_no_separator.lower()\n\n                # Capitalize first letter in each part of string\n                text_title = text_no_separator.title()\n\n                # Append iterations\n                word_list.extend(\n                    [text_no_separator, text_upper, text_lower, text_title]\n                )\n\n                # Adding each term as a separate item in the list\n                word_list.extend(\n                    [\n                        text_no_separator.split(\" \"),\n                        text_upper.split(\" \"),\n                        text_lower.split(\" \"),\n                        text_title.split(\" \"),\n                    ]\n                )\n\n            # Flatten list\n            flat_list = []\n            for item in word_list:\n                if isinstance(item, list):\n                    flat_list.extend(item)\n                else:\n                    flat_list.append(item)\n\n            # Remove any duplicates and empty strings\n            word_list = list(set(flat_list))\n            word_list = list(filter(None, word_list))\n\n        return word_list\n\n    @classmethod\n    def _process_names(cls, text_metadata: list, is_name: list) -&gt; list:\n        \"\"\"Process names to have multiple iterations in our PHI list.\n\n        :param metadata_text: List of all the instance's element values\n        (excluding pixel data).\n        :param is_name: True if the element is specified as being a name.\n\n        :return: Metadata text with additional name iterations appended.\n        \"\"\"\n        phi_list = text_metadata.copy()\n\n        for i in range(0, len(text_metadata)):\n            if is_name[i] is True:\n                original_text = str(text_metadata[i])\n                phi_list += cls.augment_word(original_text)\n\n        return phi_list\n\n    @staticmethod\n    def _add_known_generic_phi(phi_list: list) -&gt; list:\n        \"\"\"Add known potential generic PHI values.\n\n        :param phi_list: List of PHI to use with Presidio ad-hoc recognizer.\n\n        :return: Same list with added known values.\n        \"\"\"\n        known_generic_phi = [\"[M]\", \"[F]\", \"[X]\", \"[U]\", \"M\", \"F\", \"X\", \"U\"]\n        phi_list.extend(known_generic_phi)\n\n        return phi_list\n\n    @classmethod\n    def _make_phi_list(\n        cls,\n        original_metadata: List[Union[pydicom.multival.MultiValue, list, tuple]],\n        is_name: List[bool],\n        is_patient: List[bool],\n    ) -&gt; list:\n        \"\"\"Make the list of PHI to use in Presidio ad-hoc recognizer.\n\n        :param original_metadata: List of all the instance's element values\n        (excluding pixel data).\n        :param is_name: True if the element is specified as being a name.\n        :param is_patient: True if the element is specified as being\n        related to the patient.\n\n        :return: List of PHI (str) to use with Presidio ad-hoc recognizer.\n        \"\"\"\n        # Process names\n        phi_list = cls._process_names(original_metadata, is_name)\n\n        # Add known potential phi values\n        phi_list = cls._add_known_generic_phi(phi_list)\n\n        # Flatten any nested lists\n        for phi in phi_list:\n            if type(phi) in [pydicom.multival.MultiValue, list, tuple]:\n                for item in phi:\n                    phi_list.append(item)\n                phi_list.remove(phi)\n\n        # Convert all items to strings\n        phi_str_list = [str(phi) for phi in phi_list]\n\n        # Remove duplicates\n        phi_str_list = list(set(phi_str_list))\n\n        return phi_str_list\n\n    @classmethod\n    def _set_bbox_color(\n        cls, instance: pydicom.dataset.FileDataset, fill: str\n    ) -&gt; Union[int, Tuple[int, int, int]]:\n        \"\"\"Set the bounding box color.\n\n        :param instance: A single DICOM instance.\n        :param fill: Determines how box color is selected.\n        'contrast' - Masks stand out relative to background.\n        'background' - Masks are same color as background.\n\n        :return: int or tuple of int values determining masking box color.\n        \"\"\"\n        # Check if we want the box color to contrast with the background\n        if fill.lower() in [\"contrast\", \"invert\", \"inverted\", \"inverse\"]:\n            invert_flag = True\n        elif fill.lower() in [\"background\", \"bg\"]:\n            invert_flag = False\n        else:\n            raise ValueError(\"fill must be 'contrast' or 'background'\")\n\n        # Temporarily save as PNG to get color\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            dst_path = Path(f\"{tmpdirname}/temp.dcm\")\n            instance.save_as(dst_path)\n            _, is_greyscale = cls._convert_dcm_to_png(dst_path, output_dir=tmpdirname)\n\n            png_filepath = f\"{tmpdirname}/{dst_path.stem}.png\"\n            loaded_image = Image.open(png_filepath)\n            box_color = cls._get_bg_color(loaded_image, is_greyscale, invert_flag)\n\n        return box_color\n\n    @staticmethod\n    def _check_if_compressed(instance: pydicom.dataset.FileDataset) -&gt; bool:\n        \"\"\"Check if the pixel data is compressed.\n\n        :param instance: DICOM instance.\n\n        :return: Boolean for whether the pixel data is compressed.\n        \"\"\"\n        # Calculate expected bytes\n        rows = instance.Rows\n        columns = instance.Columns\n        samples_per_pixel = instance.SamplesPerPixel\n        bits_allocated = instance.BitsAllocated\n        try:\n            number_of_frames = instance[0x0028, 0x0008].value\n        except KeyError:\n            number_of_frames = 1\n        expected_num_bytes = (\n            rows * columns * number_of_frames * samples_per_pixel * (bits_allocated / 8)\n        )\n\n        # Compare expected vs actual\n        is_compressed = (int(expected_num_bytes)) &gt; len(instance.PixelData)\n\n        return is_compressed\n\n    @staticmethod\n    def _compress_pixel_data(\n        instance: pydicom.dataset.FileDataset,\n    ) -&gt; pydicom.dataset.FileDataset:\n        \"\"\"Recompress pixel data that was decompressed during redaction.\n\n        :param instance: Loaded DICOM instance.\n\n        :return: Instance with compressed pixel data.\n        \"\"\"\n        compression_method = pydicom.uid.RLELossless\n\n        # Temporarily change syntax to an \"uncompressed\" method\n        instance.file_meta.TransferSyntaxUID = pydicom.uid.UID(\"1.2.840.10008.1.2\")\n\n        # Compress and update syntax\n        instance.compress(compression_method, encoding_plugin=\"gdcm\")\n        instance.file_meta.TransferSyntaxUID = compression_method\n\n        return instance\n\n    @staticmethod\n    def _check_if_has_image_icon_sequence(\n        instance: pydicom.dataset.FileDataset,\n    ) -&gt; bool:\n        \"\"\"Check if there is an image icon sequence tag in the metadata.\n\n        This leads to pixel data being present in multiple locations.\n\n        :param instance: DICOM instance.\n\n        :return: Boolean for whether the instance has an image icon sequence tag.\n        \"\"\"\n        has_image_icon_sequence = False\n        try:\n            _ = instance[0x0088, 0x0200]\n            has_image_icon_sequence = True\n        except KeyError:\n            has_image_icon_sequence = False\n\n        return has_image_icon_sequence\n\n    @classmethod\n    def _add_redact_box(\n        cls,\n        instance: pydicom.dataset.FileDataset,\n        bounding_boxes_coordinates: list,\n        crop_ratio: float,\n        fill: str = \"contrast\",\n    ) -&gt; pydicom.dataset.FileDataset:\n        \"\"\"Add redaction bounding boxes on a DICOM instance.\n\n        :param instance: A single DICOM instance.\n        :param bounding_boxes_coordinates: Bounding box coordinates.\n        :param crop_ratio: Portion of image to consider when selecting\n        most common pixel value as the background color value.\n        :param fill: Determines how box color is selected.\n        'contrast' - Masks stand out relative to background.\n        'background' - Masks are same color as background.\n\n        :return: A new dicom instance with redaction bounding boxes.\n        \"\"\"\n        # Copy instance\n        redacted_instance = deepcopy(instance)\n        is_compressed = cls._check_if_compressed(redacted_instance)\n        has_image_icon_sequence = cls._check_if_has_image_icon_sequence(\n            redacted_instance\n        )\n\n        # Select masking box color\n        is_greyscale = cls._check_if_greyscale(instance)\n        if is_greyscale:\n            box_color = cls._get_most_common_pixel_value(instance, crop_ratio, fill)\n        else:\n            box_color = cls._set_bbox_color(redacted_instance, fill)\n\n        # Apply mask\n        for i in range(0, len(bounding_boxes_coordinates)):\n            bbox = bounding_boxes_coordinates[i]\n            top = bbox[\"top\"]\n            left = bbox[\"left\"]\n            width = bbox[\"width\"]\n            height = bbox[\"height\"]\n            redacted_instance.pixel_array[top : top + height, left : left + width] = (\n                box_color\n            )\n\n        redacted_instance.PixelData = redacted_instance.pixel_array.tobytes()\n\n        # If original pixel data is compressed, recompress after redaction\n        if is_compressed or has_image_icon_sequence:\n            # Temporary \"fix\" to manually set all YBR photometric interp as YBR_FULL\n            if \"YBR\" in redacted_instance.PhotometricInterpretation:\n                redacted_instance.PhotometricInterpretation = \"YBR_FULL\"\n            redacted_instance = cls._compress_pixel_data(redacted_instance)\n\n        return redacted_instance\n\n    def _get_analyzer_results(\n        self,\n        image: Image.Image,\n        instance: pydicom.dataset.FileDataset,\n        use_metadata: bool,\n        ocr_kwargs: Optional[dict],\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]],\n        **text_analyzer_kwargs,\n    ) -&gt; List[ImageRecognizerResult]:\n        \"\"\"Analyze image with selected redaction approach.\n\n        :param image: DICOM pixel data as PIL image.\n        :param instance: DICOM instance (with metadata).\n        :param use_metadata: Whether to redact text in the image that\n        are present in the metadata.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine (e.g., allow_list).\n\n        :return: Analyzer results.\n        \"\"\"\n        # Check the ad-hoc recognizers list\n        self._check_ad_hoc_recognizer_list(ad_hoc_recognizers)\n\n        # Create custom recognizer using DICOM metadata\n        if use_metadata:\n            original_metadata, is_name, is_patient = self._get_text_metadata(instance)\n            phi_list = self._make_phi_list(original_metadata, is_name, is_patient)\n            deny_list_recognizer = PatternRecognizer(\n                supported_entity=\"PERSON\", deny_list=phi_list\n            )\n\n            if ad_hoc_recognizers is None:\n                ad_hoc_recognizers = [deny_list_recognizer]\n            elif isinstance(ad_hoc_recognizers, list):\n                ad_hoc_recognizers.append(deny_list_recognizer)\n\n        # Detect PII\n        if ad_hoc_recognizers is None:\n            analyzer_results = self.image_analyzer_engine.analyze(\n                image,\n                ocr_kwargs=ocr_kwargs,\n                **text_analyzer_kwargs,\n            )\n        else:\n            analyzer_results = self.image_analyzer_engine.analyze(\n                image,\n                ocr_kwargs=ocr_kwargs,\n                ad_hoc_recognizers=ad_hoc_recognizers,\n                **text_analyzer_kwargs,\n            )\n\n        return analyzer_results\n\n    @staticmethod\n    def _save_bbox_json(output_dcm_path: str, bboxes: List[Dict[str, int]]) -&gt; None:\n        \"\"\"Save the redacted bounding box info as a json file.\n\n        :param output_dcm_path: Path to the redacted DICOM file.\n\n        :param bboxes: Bounding boxes used in redaction.\n        \"\"\"\n        output_json_path = Path(output_dcm_path).with_suffix(\".json\")\n\n        with open(output_json_path, \"w\") as write_file:\n            json.dump(bboxes, write_file, indent=4)\n\n    def _redact_single_dicom_image(\n        self,\n        dcm_path: str,\n        crop_ratio: float,\n        fill: str,\n        padding_width: int,\n        use_metadata: bool,\n        overwrite: bool,\n        dst_parent_dir: str,\n        save_bboxes: bool,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; str:\n        \"\"\"Redact text PHI present on a DICOM image.\n\n        :param dcm_path: String path to the DICOM file.\n        :param crop_ratio: Portion of image to consider when selecting\n        most common pixel value as the background color value.\n        :param fill: Color setting to use for bounding boxes\n        (\"contrast\" or \"background\").\n        :param padding_width: Pixel width of padding (uniform).\n        :param use_metadata: Whether to redact text in the image that\n        are present in the metadata.\n        :param overwrite: Only set to True if you are providing the\n        duplicated DICOM path in dcm_path.\n        :param dst_parent_dir: String path to parent directory of where to store copies.\n        :param save_bboxes: True if we want to save boundings boxes.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine.\n\n        :return: Path to the output DICOM file.\n        \"\"\"\n        # Ensure we are working on a single file\n        if Path(dcm_path).is_dir():\n            raise FileNotFoundError(\"Please ensure dcm_path is a single file\")\n        elif Path(dcm_path).is_file() is False:\n            raise FileNotFoundError(f\"{dcm_path} does not exist\")\n\n        # Copy file before processing if overwrite==False\n        if overwrite is False:\n            dst_path = self._copy_files_for_processing(dcm_path, dst_parent_dir)\n        else:\n            dst_path = dcm_path\n\n        # Load instance\n        instance = pydicom.dcmread(dst_path)\n\n        try:\n            instance.PixelData\n        except AttributeError:\n            raise AttributeError(\"Provided DICOM file lacks pixel data.\")\n\n        # Load image for processing\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Convert DICOM to PNG and add padding for OCR (during analysis)\n            _, is_greyscale = self._convert_dcm_to_png(dst_path, output_dir=tmpdirname)\n            png_filepath = f\"{tmpdirname}/{dst_path.stem}.png\"\n            loaded_image = Image.open(png_filepath)\n            image = self._add_padding(loaded_image, is_greyscale, padding_width)\n\n        # Detect PII\n        analyzer_results = self._get_analyzer_results(\n            image,\n            instance,\n            use_metadata,\n            ocr_kwargs,\n            ad_hoc_recognizers,\n            **text_analyzer_kwargs,\n        )\n\n        # Redact all bounding boxes from DICOM file\n        analyzer_bboxes = self.bbox_processor.get_bboxes_from_analyzer_results(\n            analyzer_results\n        )\n        bboxes = self.bbox_processor.remove_bbox_padding(analyzer_bboxes, padding_width)\n        redacted_dicom_instance = self._add_redact_box(\n            instance, bboxes, crop_ratio, fill\n        )\n        redacted_dicom_instance.save_as(dst_path)\n\n        # Save redacted bboxes\n        if save_bboxes:\n            self._save_bbox_json(dst_path, bboxes)\n\n        return dst_path\n\n    def _redact_multiple_dicom_images(\n        self,\n        dcm_dir: str,\n        crop_ratio: float,\n        fill: str,\n        padding_width: int,\n        use_metadata: bool,\n        overwrite: bool,\n        dst_parent_dir: str,\n        save_bboxes: bool,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; str:\n        \"\"\"Redact text PHI present on all DICOM images in a directory.\n\n        :param dcm_dir: String path to directory containing DICOM files (can be nested).\n        :param crop_ratio: Portion of image to consider when selecting\n        most common pixel value as the background color value.\n        :param fill: Color setting to use for bounding boxes\n        (\"contrast\" or \"background\").\n        :param padding_width: Pixel width of padding (uniform).\n        :param use_metadata: Whether to redact text in the image that\n        are present in the metadata.\n        :param overwrite: Only set to True if you are providing\n        the duplicated DICOM dir in dcm_dir.\n        :param dst_parent_dir: String path to parent directory of where to store copies.\n        :param save_bboxes: True if we want to save boundings boxes.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine.\n\n        Return:\n            dst_dir (str): Path to the output DICOM directory.\n        \"\"\"\n        # Ensure we are working on a directory (can have sub-directories)\n        if Path(dcm_dir).is_file():\n            raise FileNotFoundError(\"Please ensure dcm_path is a directory\")\n        elif Path(dcm_dir).is_dir() is False:\n            raise FileNotFoundError(f\"{dcm_dir} does not exist\")\n\n        # List of files to process directly\n        if overwrite is False:\n            dst_dir = self._copy_files_for_processing(dcm_dir, dst_parent_dir)\n        else:\n            dst_dir = dcm_dir\n\n        # Process each DICOM file directly\n        all_dcm_files = self._get_all_dcm_files(Path(dst_dir))\n        for dst_path in all_dcm_files:\n            self._redact_single_dicom_image(\n                dst_path,\n                crop_ratio,\n                fill,\n                padding_width,\n                use_metadata,\n                overwrite,\n                dst_parent_dir,\n                save_bboxes,\n                ocr_kwargs=ocr_kwargs,\n                ad_hoc_recognizers=ad_hoc_recognizers,\n                **text_analyzer_kwargs,\n            )\n\n        return dst_dir\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImageRedactorEngine.augment_word","title":"<code>augment_word(word, case_sensitive=False)</code>  <code>staticmethod</code>","text":"<p>Apply multiple types of casing to the provided string.</p> <p>Parameters:</p> Name Type Description Default <code>words</code> <p>String containing the word or term of interest.</p> required <code>case_sensitive</code> <code>bool</code> <p>True if we want to preserve casing.</p> <code>False</code> <p>Returns:</p> Type Description <code>list</code> <p>List of the same string with different casings and spacing.</p> Source code in <code>presidio_image_redactor/dicom_image_redactor_engine.py</code> <pre><code>@staticmethod\ndef augment_word(word: str, case_sensitive: bool = False) -&gt; list:\n    \"\"\"Apply multiple types of casing to the provided string.\n\n    :param words: String containing the word or term of interest.\n    :param case_sensitive: True if we want to preserve casing.\n\n    :return: List of the same string with different casings and spacing.\n    \"\"\"\n    word_list = []\n    if word != \"\":\n        # Replacing separator character with space, if any\n        text_no_separator = word.replace(\"^\", \" \")\n        text_no_separator = text_no_separator.replace(\"-\", \" \")\n        text_no_separator = \" \".join(text_no_separator.split())\n\n        if case_sensitive:\n            word_list.append(text_no_separator)\n            word_list.extend(\n                [\n                    text_no_separator.split(\" \"),\n                ]\n            )\n        else:\n            # Capitalize all characters in string\n            text_upper = text_no_separator.upper()\n\n            # Lowercase all characters in string\n            text_lower = text_no_separator.lower()\n\n            # Capitalize first letter in each part of string\n            text_title = text_no_separator.title()\n\n            # Append iterations\n            word_list.extend(\n                [text_no_separator, text_upper, text_lower, text_title]\n            )\n\n            # Adding each term as a separate item in the list\n            word_list.extend(\n                [\n                    text_no_separator.split(\" \"),\n                    text_upper.split(\" \"),\n                    text_lower.split(\" \"),\n                    text_title.split(\" \"),\n                ]\n            )\n\n        # Flatten list\n        flat_list = []\n        for item in word_list:\n            if isinstance(item, list):\n                flat_list.extend(item)\n            else:\n                flat_list.append(item)\n\n        # Remove any duplicates and empty strings\n        word_list = list(set(flat_list))\n        word_list = list(filter(None, word_list))\n\n    return word_list\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImageRedactorEngine.redact","title":"<code>redact(image, fill='contrast', padding_width=25, crop_ratio=0.75, ocr_kwargs=None, ad_hoc_recognizers=None, **text_analyzer_kwargs)</code>","text":"<p>Redact method to redact the given DICOM image.</p> <p>Please note, this method duplicates the image, creates a new instance and manipulates it.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileDataset</code> <p>Loaded DICOM instance including pixel data and metadata.</p> required <code>fill</code> <code>str</code> <p>Fill setting to use for redaction box (\"contrast\" or \"background\").</p> <code>'contrast'</code> <code>padding_width</code> <code>int</code> <p>Padding width to use when running OCR.</p> <code>25</code> <code>crop_ratio</code> <code>float</code> <p>Portion of image to consider when selecting most common pixel value as the background color value.</p> <code>0.75</code> <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>ad_hoc_recognizers</code> <code>Optional[List[PatternRecognizer]]</code> <p>List of PatternRecognizer objects to use for ad-hoc recognizer.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in AnalyzerEngine.</p> <code>{}</code> <p>Returns:</p> Type Description <code>FileDataset</code> <p>DICOM instance with redacted pixel data.</p> Source code in <code>presidio_image_redactor/dicom_image_redactor_engine.py</code> <pre><code>def redact(\n    self,\n    image: pydicom.dataset.FileDataset,\n    fill: str = \"contrast\",\n    padding_width: int = 25,\n    crop_ratio: float = 0.75,\n    ocr_kwargs: Optional[dict] = None,\n    ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    **text_analyzer_kwargs,\n) -&gt; pydicom.dataset.FileDataset:\n    \"\"\"Redact method to redact the given DICOM image.\n\n    Please note, this method duplicates the image, creates a\n    new instance and manipulates it.\n\n    :param image: Loaded DICOM instance including pixel data and metadata.\n    :param fill: Fill setting to use for redaction box (\"contrast\" or \"background\").\n    :param padding_width: Padding width to use when running OCR.\n    :param crop_ratio: Portion of image to consider when selecting\n    most common pixel value as the background color value.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n    for ad-hoc recognizer.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in AnalyzerEngine.\n\n    :return: DICOM instance with redacted pixel data.\n    \"\"\"\n    redacted_image, _ = self.redact_and_return_bbox(\n        image=image,\n        fill=fill,\n        padding_width=padding_width,\n        crop_ratio=crop_ratio,\n        ocr_kwargs=ocr_kwargs,\n        ad_hoc_recognizers=ad_hoc_recognizers,\n        **text_analyzer_kwargs,\n    )\n\n    return redacted_image\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImageRedactorEngine.redact_and_return_bbox","title":"<code>redact_and_return_bbox(image, fill='contrast', padding_width=25, crop_ratio=0.75, use_metadata=True, ocr_kwargs=None, ad_hoc_recognizers=None, **text_analyzer_kwargs)</code>","text":"<p>Redact method to redact the given DICOM image and return redacted bboxes.</p> <p>Please note, this method duplicates the image, creates a new instance and manipulates it.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>FileDataset</code> <p>Loaded DICOM instance including pixel data and metadata.</p> required <code>fill</code> <code>str</code> <p>Fill setting to use for redaction box (\"contrast\" or \"background\").</p> <code>'contrast'</code> <code>padding_width</code> <code>int</code> <p>Padding width to use when running OCR.</p> <code>25</code> <code>crop_ratio</code> <code>float</code> <p>Portion of image to consider when selecting most common pixel value as the background color value.</p> <code>0.75</code> <code>use_metadata</code> <code>bool</code> <p>Whether to redact text in the image that are present in the metadata.</p> <code>True</code> <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>ad_hoc_recognizers</code> <code>Optional[List[PatternRecognizer]]</code> <p>List of PatternRecognizer objects to use for ad-hoc recognizer.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in AnalyzerEngine.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[FileDataset, List[Dict[str, int]]]</code> <p>DICOM instance with redacted pixel data.</p> Source code in <code>presidio_image_redactor/dicom_image_redactor_engine.py</code> <pre><code>def redact_and_return_bbox(\n    self,\n    image: pydicom.dataset.FileDataset,\n    fill: str = \"contrast\",\n    padding_width: int = 25,\n    crop_ratio: float = 0.75,\n    use_metadata: bool = True,\n    ocr_kwargs: Optional[dict] = None,\n    ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    **text_analyzer_kwargs,\n) -&gt; Tuple[pydicom.dataset.FileDataset, List[Dict[str, int]]]:\n    \"\"\"Redact method to redact the given DICOM image and return redacted bboxes.\n\n    Please note, this method duplicates the image, creates a\n    new instance and manipulates it.\n\n    :param image: Loaded DICOM instance including pixel data and metadata.\n    :param fill: Fill setting to use for redaction box (\"contrast\" or \"background\").\n    :param padding_width: Padding width to use when running OCR.\n    :param crop_ratio: Portion of image to consider when selecting\n    most common pixel value as the background color value.\n    :param use_metadata: Whether to redact text in the image that\n    are present in the metadata.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n    for ad-hoc recognizer.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in AnalyzerEngine.\n\n    :return: DICOM instance with redacted pixel data.\n    \"\"\"\n    # Check input\n    if type(image) not in [pydicom.dataset.FileDataset, pydicom.dataset.Dataset]:\n        raise TypeError(\"The provided image must be a loaded DICOM instance.\")\n    try:\n        image.PixelData\n    except AttributeError as e:\n        raise AttributeError(f\"Provided DICOM instance lacks pixel data: {e}\")\n    except PermissionError as e:\n        raise PermissionError(f\"Unable to access pixel data (may not exist): {e}\")\n    except IsADirectoryError as e:\n        raise IsADirectoryError(f\"DICOM instance is a directory: {e}\")\n\n    instance = deepcopy(image)\n\n    # Load image for processing\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        # Convert DICOM to PNG and add padding for OCR (during analysis)\n        is_greyscale = self._check_if_greyscale(instance)\n        image = self._rescale_dcm_pixel_array(instance, is_greyscale)\n        image_name = str(uuid.uuid4())\n        self._save_pixel_array_as_png(image, is_greyscale, image_name, tmpdirname)\n\n        png_filepath = f\"{tmpdirname}/{image_name}.png\"\n        loaded_image = Image.open(png_filepath)\n        image = self._add_padding(loaded_image, is_greyscale, padding_width)\n\n    # Detect PII\n    analyzer_results = self._get_analyzer_results(\n        image,\n        instance,\n        use_metadata,\n        ocr_kwargs,\n        ad_hoc_recognizers,\n        **text_analyzer_kwargs,\n    )\n\n    # Redact all bounding boxes from DICOM file\n    analyzer_bboxes = self.bbox_processor.get_bboxes_from_analyzer_results(\n        analyzer_results\n    )\n    bboxes = self.bbox_processor.remove_bbox_padding(analyzer_bboxes, padding_width)\n    redacted_image = self._add_redact_box(instance, bboxes, crop_ratio, fill)\n\n    return redacted_image, bboxes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImageRedactorEngine.redact_from_directory","title":"<code>redact_from_directory(input_dicom_path, output_dir, padding_width=25, crop_ratio=0.75, fill='contrast', use_metadata=True, save_bboxes=False, ocr_kwargs=None, ad_hoc_recognizers=None, **text_analyzer_kwargs)</code>","text":"<p>Redact method to redact from a directory of files.</p> <p>Please notice, this method duplicates the files, creates new instances and manipulate them.</p> <p>Parameters:</p> Name Type Description Default <code>input_dicom_path</code> <code>str</code> <p>String path to directory of DICOM images.</p> required <code>output_dir</code> <code>str</code> <p>String path to parent output directory.</p> required <code></code> <code>padding_width</code> <p>Padding width to use when running OCR.</p> required <code>crop_ratio</code> <code>float</code> <p>Portion of image to consider when selecting most common pixel value as the background color value.</p> <code>0.75</code> <code>fill</code> <code>str</code> <p>Color setting to use for redaction box (\"contrast\" or \"background\").</p> <code>'contrast'</code> <code>use_metadata</code> <code>bool</code> <p>Whether to redact text in the image that are present in the metadata.</p> <code>True</code> <code>save_bboxes</code> <code>bool</code> <p>True if we want to save boundings boxes.</p> <code>False</code> <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>ad_hoc_recognizers</code> <code>Optional[List[PatternRecognizer]]</code> <p>List of PatternRecognizer objects to use for ad-hoc recognizer.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in AnalyzerEngine.</p> <code>{}</code> Source code in <code>presidio_image_redactor/dicom_image_redactor_engine.py</code> <pre><code>def redact_from_directory(\n    self,\n    input_dicom_path: str,\n    output_dir: str,\n    padding_width: int = 25,\n    crop_ratio: float = 0.75,\n    fill: str = \"contrast\",\n    use_metadata: bool = True,\n    save_bboxes: bool = False,\n    ocr_kwargs: Optional[dict] = None,\n    ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    **text_analyzer_kwargs,\n) -&gt; None:\n    \"\"\"Redact method to redact from a directory of files.\n\n    Please notice, this method duplicates the files, creates\n    new instances and manipulate them.\n\n    :param input_dicom_path: String path to directory of DICOM images.\n    :param output_dir: String path to parent output directory.\n    :param padding_width : Padding width to use when running OCR.\n    :param crop_ratio: Portion of image to consider when selecting\n    most common pixel value as the background color value.\n    :param fill: Color setting to use for redaction box\n    (\"contrast\" or \"background\").\n    :param use_metadata: Whether to redact text in the image that\n    are present in the metadata.\n    :param save_bboxes: True if we want to save boundings boxes.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n    for ad-hoc recognizer.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in AnalyzerEngine.\n    \"\"\"\n    # Verify the given paths\n    if Path(input_dicom_path).is_dir() is False:\n        raise TypeError(\"input_dicom_path must be a valid directory\")\n    if Path(input_dicom_path).is_file() is True:\n        raise TypeError(\"input_dicom_path must be a directory (not file)\")\n    if Path(output_dir).is_file() is True:\n        raise TypeError(\n            \"output_dir must be a directory (does not need to exist yet)\"\n        )\n\n    # Create duplicates\n    dst_path = self._copy_files_for_processing(input_dicom_path, output_dir)\n\n    # Process DICOM files\n    output_location = self._redact_multiple_dicom_images(\n        dcm_dir=dst_path,\n        crop_ratio=crop_ratio,\n        fill=fill,\n        padding_width=padding_width,\n        use_metadata=use_metadata,\n        ad_hoc_recognizers=ad_hoc_recognizers,\n        overwrite=True,\n        dst_parent_dir=\".\",\n        save_bboxes=save_bboxes,\n        ocr_kwargs=ocr_kwargs,\n        **text_analyzer_kwargs,\n    )\n\n    print(f\"Output written to {output_location}\")\n\n    return None\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DicomImageRedactorEngine.redact_from_file","title":"<code>redact_from_file(input_dicom_path, output_dir, padding_width=25, crop_ratio=0.75, fill='contrast', use_metadata=True, save_bboxes=False, verbose=True, ocr_kwargs=None, ad_hoc_recognizers=None, **text_analyzer_kwargs)</code>","text":"<p>Redact method to redact from a given file.</p> <p>Please notice, this method duplicates the file, creates new instance and manipulate them.</p> <p>Parameters:</p> Name Type Description Default <code>input_dicom_path</code> <code>str</code> <p>String path to DICOM image.</p> required <code>output_dir</code> <code>str</code> <p>String path to parent output directory.</p> required <code></code> <code>padding_width</code> <p>Padding width to use when running OCR.</p> required <code>fill</code> <code>str</code> <p>Color setting to use for redaction box (\"contrast\" or \"background\").</p> <code>'contrast'</code> <code>use_metadata</code> <code>bool</code> <p>Whether to redact text in the image that are present in the metadata.</p> <code>True</code> <code>save_bboxes</code> <code>bool</code> <p>True if we want to save boundings boxes.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>True to print where redacted file was written to.</p> <code>True</code> <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>ad_hoc_recognizers</code> <code>Optional[List[PatternRecognizer]]</code> <p>List of PatternRecognizer objects to use for ad-hoc recognizer.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in AnalyzerEngine.</p> <code>{}</code> Source code in <code>presidio_image_redactor/dicom_image_redactor_engine.py</code> <pre><code>def redact_from_file(\n    self,\n    input_dicom_path: str,\n    output_dir: str,\n    padding_width: int = 25,\n    crop_ratio: float = 0.75,\n    fill: str = \"contrast\",\n    use_metadata: bool = True,\n    save_bboxes: bool = False,\n    verbose: bool = True,\n    ocr_kwargs: Optional[dict] = None,\n    ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    **text_analyzer_kwargs,\n) -&gt; None:\n    \"\"\"Redact method to redact from a given file.\n\n    Please notice, this method duplicates the file, creates\n    new instance and manipulate them.\n\n    :param input_dicom_path: String path to DICOM image.\n    :param output_dir: String path to parent output directory.\n    :param padding_width : Padding width to use when running OCR.\n    :param fill: Color setting to use for redaction box\n    (\"contrast\" or \"background\").\n    :param use_metadata: Whether to redact text in the image that\n    are present in the metadata.\n    :param save_bboxes: True if we want to save boundings boxes.\n    :param verbose: True to print where redacted file was written to.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n    for ad-hoc recognizer.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in AnalyzerEngine.\n    \"\"\"\n    # Verify the given paths\n    if Path(input_dicom_path).is_dir() is True:\n        raise TypeError(\"input_dicom_path must be file (not dir)\")\n    if Path(input_dicom_path).is_file() is False:\n        raise TypeError(\"input_dicom_path must be a valid file\")\n    if Path(output_dir).is_file() is True:\n        raise TypeError(\n            \"output_dir must be a directory (does not need to exist yet)\"\n        )\n\n    # Create duplicate\n    dst_path = self._copy_files_for_processing(input_dicom_path, output_dir)\n\n    # Process DICOM file\n    output_location = self._redact_single_dicom_image(\n        dcm_path=dst_path,\n        crop_ratio=crop_ratio,\n        fill=fill,\n        padding_width=padding_width,\n        use_metadata=use_metadata,\n        overwrite=True,\n        dst_parent_dir=\".\",\n        save_bboxes=save_bboxes,\n        ocr_kwargs=ocr_kwargs,\n        ad_hoc_recognizers=ad_hoc_recognizers,\n        **text_analyzer_kwargs,\n    )\n\n    if verbose:\n        print(f\"Output written to {output_location}\")\n\n    return None\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DocumentIntelligenceOCR","title":"<code>DocumentIntelligenceOCR</code>","text":"<p>               Bases: <code>OCR</code></p> <p>OCR class that uses Azure AI Document Intelligence OCR engine.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Optional[str]</code> <p>The API key</p> <code>None</code> <code>endpoint</code> <code>Optional[str]</code> <p>The API endpoint</p> <code>None</code> <code>model_id</code> <code>Optional[str]</code> <p>Which model to use  For details, see https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/</p> <code>'prebuilt-document'</code> Source code in <code>presidio_image_redactor/document_intelligence_ocr.py</code> <pre><code>class DocumentIntelligenceOCR(OCR):\n    \"\"\"OCR class that uses Azure AI Document Intelligence OCR engine.\n\n    :param key: The API key\n    :param endpoint: The API endpoint\n    :param model_id: Which model to use\n\n    For details, see\n    https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/\n    \"\"\"\n\n    SUPPORTED_MODELS = [\n        \"prebuilt-document\",\n        \"prebuilt-read\",\n        \"prebuilt-layout\",\n        \"prebuilt-contract\",\n        \"prebuilt-healthInsuranceCard.us\",\n        \"prebuilt-invoice\",\n        \"prebuilt-receipt\",\n        \"prebuilt-idDocument\",\n        \"prebuilt-businessCard\",\n    ]\n\n    def __init__(\n        self,\n        endpoint: Optional[str] = None,\n        key: Optional[str] = None,\n        model_id: Optional[str] = \"prebuilt-document\",\n    ):\n        if model_id not in DocumentIntelligenceOCR.SUPPORTED_MODELS:\n            raise ValueError(\"Unsupported model id: %s\" % model_id)\n\n        # If endpoint and/or key are not passed, attempt to get from environment\n        # variables\n        if not endpoint:\n            endpoint = os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\")\n\n        if not key:\n            key = os.getenv(\"DOCUMENT_INTELLIGENCE_KEY\")\n\n        if not key or not endpoint:\n            raise ValueError(\"Endpoint and key must be specified\")\n\n        self.client = DocumentAnalysisClient(\n            endpoint=endpoint, credential=AzureKeyCredential(key)\n        )\n        self.model_id = model_id\n\n    @staticmethod\n    def _polygon_to_bbox(polygon: Sequence[Point]) -&gt; tuple:\n        \"\"\"Convert polygon to a tuple of left/top/width/height.\n\n        The returned bounding box should entirely cover the passed polygon.\n\n        :param polygon: A sequence of points\n\n        :return a tuple of left/top/width/height in pixel dimensions\n\n        \"\"\"\n        # We need at least two points for a valid bounding box.\n        if len(polygon) &lt; 2:\n            return (0, 0, 0, 0)\n\n        left = min([int(p.x) for p in polygon])\n        top = min([int(p.y) for p in polygon])\n        right = max([int(p.x) for p in polygon])\n        bottom = max([int(p.y) for p in polygon])\n        width = right - left\n        height = bottom - top\n        return (left, top, width, height)\n\n    @staticmethod\n    def _page_to_bboxes(page: DocumentPage) -&gt; dict:\n        \"\"\"Convert bounding boxes to uniform format.\n\n        Presidio supports tesseract format of output only, so we format in the same\n        way.\n        Expected format looks like:\n        {\n            \"left\": [123, 345],\n            \"top\": [0, 15],\n            \"width\": [100, 75],\n            \"height\": [25, 30],\n            \"conf\": [\"1\", \"0.87\"],\n            \"text\": [\"JOHN\", \"DOE\"],\n        }\n\n        :param page: The documentpage object from the DI client library\n\n        :return dictionary in the expected format for presidio\n        \"\"\"\n        bounds = [\n            DocumentIntelligenceOCR._polygon_to_bbox(word.polygon)\n            for word in page.words\n        ]\n\n        return {\n            \"left\": [box[0] for box in bounds],\n            \"top\": [box[1] for box in bounds],\n            \"width\": [box[2] for box in bounds],\n            \"height\": [box[3] for box in bounds],\n            \"conf\": [w.confidence for w in page.words],\n            \"text\": [w.content for w in page.words],\n        }\n\n    def get_imgbytes(self, image: Union[bytes, np.ndarray, Image.Image]) -&gt; bytes:\n        \"\"\"Retrieve the image bytes from the image object.\n\n        :param image:  Any of bytes/numpy array /PIL image object\n\n        :return raw image bytes\n        \"\"\"\n        if isinstance(image, bytes):\n            return image\n        if isinstance(image, np.ndarray):\n            image = Image.fromarray(image)\n            # Fallthrough to process PIL image\n        if isinstance(image, Image.Image):\n            # Image is a PIL image, write to bytes stream\n            ostream = BytesIO()\n            image.save(ostream, \"PNG\")\n            imgbytes = ostream.getvalue()\n        elif isinstance(image, str):\n            # image is a filename\n            imgbytes = open(image, \"rb\")\n        else:\n            raise ValueError(\"Unsupported image type: %s\" % type(image))\n        return imgbytes\n\n    def analyze_document(self, imgbytes: bytes, **kwargs) -&gt; AnalyzedDocument:\n        \"\"\"Analyze the document and return the result.\n\n        :param imgbytes: The bytes to send to the API endpoint\n        :param kwargs: additional arguments for begin_analyze_document\n\n        :return the result of the poller, an AnalyzedDocument object.\n        \"\"\"\n        poller = self.client.begin_analyze_document(self.model_id, imgbytes, **kwargs)\n        return poller.result()\n\n    def perform_ocr(self, image: object, **kwargs) -&gt; dict:\n        \"\"\"Perform OCR on the image.\n\n        :param image: PIL Image/numpy array or file path(str) to be processed\n        :param kwargs: Additional values for begin_analyze_document\n\n        :return: results dictionary containing bboxes and text for each detected word\n        \"\"\"\n        imgbytes = self.get_imgbytes(image)\n        result = self.analyze_document(imgbytes, **kwargs)\n\n        # Currently cannot handle more than one page.\n        if not (len(result.pages) == 1):\n            raise ValueError(\"DocumentIntelligenceOCR only supports 1 page documents\")\n\n        return DocumentIntelligenceOCR._page_to_bboxes(result.pages[0])\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DocumentIntelligenceOCR.analyze_document","title":"<code>analyze_document(imgbytes, **kwargs)</code>","text":"<p>Analyze the document and return the result.</p> <p>Parameters:</p> Name Type Description Default <code>imgbytes</code> <code>bytes</code> <p>The bytes to send to the API endpoint</p> required <code>kwargs</code> <p>additional arguments for begin_analyze_document</p> <code>{}</code> Source code in <code>presidio_image_redactor/document_intelligence_ocr.py</code> <pre><code>def analyze_document(self, imgbytes: bytes, **kwargs) -&gt; AnalyzedDocument:\n    \"\"\"Analyze the document and return the result.\n\n    :param imgbytes: The bytes to send to the API endpoint\n    :param kwargs: additional arguments for begin_analyze_document\n\n    :return the result of the poller, an AnalyzedDocument object.\n    \"\"\"\n    poller = self.client.begin_analyze_document(self.model_id, imgbytes, **kwargs)\n    return poller.result()\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DocumentIntelligenceOCR.get_imgbytes","title":"<code>get_imgbytes(image)</code>","text":"<p>Retrieve the image bytes from the image object.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Union[bytes, ndarray, Image]</code> <p>Any of bytes/numpy array /PIL image object</p> required Source code in <code>presidio_image_redactor/document_intelligence_ocr.py</code> <pre><code>def get_imgbytes(self, image: Union[bytes, np.ndarray, Image.Image]) -&gt; bytes:\n    \"\"\"Retrieve the image bytes from the image object.\n\n    :param image:  Any of bytes/numpy array /PIL image object\n\n    :return raw image bytes\n    \"\"\"\n    if isinstance(image, bytes):\n        return image\n    if isinstance(image, np.ndarray):\n        image = Image.fromarray(image)\n        # Fallthrough to process PIL image\n    if isinstance(image, Image.Image):\n        # Image is a PIL image, write to bytes stream\n        ostream = BytesIO()\n        image.save(ostream, \"PNG\")\n        imgbytes = ostream.getvalue()\n    elif isinstance(image, str):\n        # image is a filename\n        imgbytes = open(image, \"rb\")\n    else:\n        raise ValueError(\"Unsupported image type: %s\" % type(image))\n    return imgbytes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.DocumentIntelligenceOCR.perform_ocr","title":"<code>perform_ocr(image, **kwargs)</code>","text":"<p>Perform OCR on the image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>object</code> <p>PIL Image/numpy array or file path(str) to be processed</p> required <code>kwargs</code> <p>Additional values for begin_analyze_document</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>results dictionary containing bboxes and text for each detected word</p> Source code in <code>presidio_image_redactor/document_intelligence_ocr.py</code> <pre><code>def perform_ocr(self, image: object, **kwargs) -&gt; dict:\n    \"\"\"Perform OCR on the image.\n\n    :param image: PIL Image/numpy array or file path(str) to be processed\n    :param kwargs: Additional values for begin_analyze_document\n\n    :return: results dictionary containing bboxes and text for each detected word\n    \"\"\"\n    imgbytes = self.get_imgbytes(image)\n    result = self.analyze_document(imgbytes, **kwargs)\n\n    # Currently cannot handle more than one page.\n    if not (len(result.pages) == 1):\n        raise ValueError(\"DocumentIntelligenceOCR only supports 1 page documents\")\n\n    return DocumentIntelligenceOCR._page_to_bboxes(result.pages[0])\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageAnalyzerEngine","title":"<code>ImageAnalyzerEngine</code>","text":"<p>ImageAnalyzerEngine class.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer_engine</code> <code>Optional[AnalyzerEngine]</code> <p>The Presidio AnalyzerEngine instance to be used to detect PII in text</p> <code>None</code> <code>ocr</code> <code>Optional[OCR]</code> <p>the OCR object to be used to detect text in images.</p> <code>None</code> <code>image_preprocessor</code> <code>Optional[ImagePreprocessor]</code> <p>The ImagePreprocessor object to be used to preprocess the image</p> <code>None</code> Source code in <code>presidio_image_redactor/image_analyzer_engine.py</code> <pre><code>class ImageAnalyzerEngine:\n    \"\"\"ImageAnalyzerEngine class.\n\n    :param analyzer_engine: The Presidio AnalyzerEngine instance\n        to be used to detect PII in text\n    :param ocr: the OCR object to be used to detect text in images.\n    :param image_preprocessor: The ImagePreprocessor object to be\n        used to preprocess the image\n    \"\"\"\n\n    def __init__(\n        self,\n        analyzer_engine: Optional[AnalyzerEngine] = None,\n        ocr: Optional[OCR] = None,\n        image_preprocessor: Optional[ImagePreprocessor] = None,\n    ):\n        if not analyzer_engine:\n            analyzer_engine = AnalyzerEngine()\n        self.analyzer_engine = analyzer_engine\n\n        if not ocr:\n            ocr = TesseractOCR()\n        self.ocr = ocr\n\n        if not image_preprocessor:\n            image_preprocessor = ImagePreprocessor()\n        self.image_preprocessor = image_preprocessor\n\n    def analyze(\n        self, image: object, ocr_kwargs: Optional[dict] = None, **text_analyzer_kwargs\n    ) -&gt; List[ImageRecognizerResult]:\n        \"\"\"Analyse method to analyse the given image.\n\n        :param image: PIL Image/numpy array or file path(str) to be processed.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine.\n\n        :return: List of the extract entities with image bounding boxes.\n        \"\"\"\n        # Perform OCR\n        perform_ocr_kwargs, ocr_threshold = self._parse_ocr_kwargs(ocr_kwargs)\n        image, preprocessing_metadata = self.image_preprocessor.preprocess_image(image)\n        ocr_result = self.ocr.perform_ocr(image, **perform_ocr_kwargs)\n        ocr_result = self.remove_space_boxes(ocr_result)\n\n        if preprocessing_metadata and (\"scale_factor\" in preprocessing_metadata):\n            ocr_result = self._scale_bbox_results(\n                ocr_result, preprocessing_metadata[\"scale_factor\"]\n            )\n\n        # Apply OCR confidence threshold if it is passed in\n        if ocr_threshold:\n            ocr_result = self.threshold_ocr_result(ocr_result, ocr_threshold)\n\n        # Analyze text\n        text = self.ocr.get_text_from_ocr_dict(ocr_result)\n\n        # Difines English as default language, if not specified\n        if \"language\" not in text_analyzer_kwargs:\n            text_analyzer_kwargs[\"language\"] = \"en\"\n        analyzer_result = self.analyzer_engine.analyze(\n            text=text, **text_analyzer_kwargs\n        )\n        allow_list = self._check_for_allow_list(text_analyzer_kwargs)\n        bboxes = self.map_analyzer_results_to_bounding_boxes(\n            analyzer_result, ocr_result, text, allow_list\n        )\n\n        return bboxes\n\n    @staticmethod\n    def threshold_ocr_result(ocr_result: dict, ocr_threshold: float) -&gt; dict:\n        \"\"\"Filter out OCR results below confidence threshold.\n\n        :param ocr_result: OCR results (raw).\n        :param ocr_threshold: Threshold value between -1 and 100.\n\n        :return: OCR results with low confidence items removed.\n        \"\"\"\n        if ocr_threshold &lt; -1 or ocr_threshold &gt; 100:\n            raise ValueError(\"ocr_threshold must be between -1 and 100\")\n\n        # Get indices of items above threshold\n        idx = list()\n        for i, val in enumerate(ocr_result[\"conf\"]):\n            if float(val) &gt;= ocr_threshold:\n                idx.append(i)\n\n        # Only retain high confidence items\n        filtered_ocr_result = {}\n        for key in list(ocr_result.keys()):\n            filtered_ocr_result[key] = [ocr_result[key][i] for i in idx]\n\n        return filtered_ocr_result\n\n    @staticmethod\n    def remove_space_boxes(ocr_result: dict) -&gt; dict:\n        \"\"\"Remove OCR bboxes that are for spaces.\n\n        :param ocr_result: OCR results (raw or thresholded).\n        :return: OCR results with empty words removed.\n        \"\"\"\n        # Get indices of items with no text\n        idx = list()\n        for i, text in enumerate(ocr_result[\"text\"]):\n            is_not_space = text.isspace() is False\n            if text != \"\" and is_not_space:\n                idx.append(i)\n\n        # Only retain items with text\n        filtered_ocr_result = {}\n        for key in list(ocr_result.keys()):\n            filtered_ocr_result[key] = [ocr_result[key][i] for i in idx]\n\n        return filtered_ocr_result\n\n    @staticmethod\n    def map_analyzer_results_to_bounding_boxes(\n        text_analyzer_results: List[RecognizerResult],\n        ocr_result: dict,\n        text: str,\n        allow_list: List[str],\n    ) -&gt; List[ImageRecognizerResult]:\n        \"\"\"Map extracted PII entities to image bounding boxes.\n\n        Matching is based on the position of the recognized entity from analyzer\n        and word (in ocr dict) in the text.\n\n        :param text_analyzer_results: PII entities recognized by presidio analyzer\n        :param ocr_result: dict results with words and bboxes from OCR\n        :param text: text the results are based on\n        :param allow_list: List of words to not redact\n\n        return: list of extracted entities with image bounding boxes\n        \"\"\"\n        if (not ocr_result) or (not text_analyzer_results):\n            return []\n\n        bboxes = []\n        proc_indexes = 0\n        indexes = len(text_analyzer_results)\n\n        pos = 0\n        iter_ocr = enumerate(ocr_result[\"text\"])\n        for index, word in iter_ocr:\n            if not word:\n                pos += 1\n            else:\n                for element in text_analyzer_results:\n                    text_element = text[element.start : element.end]\n                    # check position and text of ocr word matches recognized entity\n                    if (\n                        max(pos, element.start) &lt; min(element.end, pos + len(word))\n                    ) and ((text_element in word) or (word in text_element)):\n                        yes_make_bbox_for_word = (\n                            (word is not None)\n                            and (word != \"\")\n                            and (word.isspace() is False)\n                            and (word not in allow_list)\n                        )\n                        # Do not add bbox for standalone spaces / empty strings\n                        if yes_make_bbox_for_word:\n                            bboxes.append(\n                                ImageRecognizerResult(\n                                    element.entity_type,\n                                    element.start,\n                                    element.end,\n                                    element.score,\n                                    ocr_result[\"left\"][index],\n                                    ocr_result[\"top\"][index],\n                                    ocr_result[\"width\"][index],\n                                    ocr_result[\"height\"][index],\n                                )\n                            )\n\n                            # add bounding boxes for all words in ocr dict\n                            # contained within the text of recognized entity\n                            # based on relative position in the full text\n                            while pos + len(word) &lt; element.end:\n                                prev_word = word\n                                index, word = next(iter_ocr)\n                                yes_make_bbox_for_word = (\n                                    (word is not None)\n                                    and (word != \"\")\n                                    and (word.isspace() is False)\n                                    and (word not in allow_list)\n                                )\n                                if yes_make_bbox_for_word:\n                                    bboxes.append(\n                                        ImageRecognizerResult(\n                                            element.entity_type,\n                                            element.start,\n                                            element.end,\n                                            element.score,\n                                            ocr_result[\"left\"][index],\n                                            ocr_result[\"top\"][index],\n                                            ocr_result[\"width\"][index],\n                                            ocr_result[\"height\"][index],\n                                        )\n                                    )\n                                pos += len(prev_word) + 1\n                            proc_indexes += 1\n\n                if proc_indexes == indexes:\n                    break\n                pos += len(word) + 1\n\n        return bboxes\n\n    @staticmethod\n    def _scale_bbox_results(\n        ocr_result: Dict[str, List[Union[int, str]]], scale_factor: float\n    ) -&gt; Dict[str, float]:\n        \"\"\"Scale down the bounding box results based on a scale percentage.\n\n        :param ocr_result: OCR results (raw).\n        :param scale_percent: Scale percentage for resizing the bounding box.\n\n        :return: OCR results (scaled).\n        \"\"\"\n        scaled_results = deepcopy(ocr_result)\n        coordinate_keys = [\"left\", \"top\"]\n        dimension_keys = [\"width\", \"height\"]\n\n        for coord_key in coordinate_keys:\n            scaled_results[coord_key] = [\n                int(np.ceil((x) / (scale_factor))) for x in scaled_results[coord_key]\n            ]\n\n        for dim_key in dimension_keys:\n            scaled_results[dim_key] = [\n                max(1, int(np.ceil(x / (scale_factor))))\n                for x in scaled_results[dim_key]\n            ]\n        return scaled_results\n\n    @staticmethod\n    def _remove_bbox_padding(\n        analyzer_bboxes: List[Dict[str, Union[str, float, int]]],\n        padding_width: int,\n    ) -&gt; List[Dict[str, int]]:\n        \"\"\"Remove added padding in bounding box coordinates.\n\n        :param analyzer_bboxes: The bounding boxes from analyzer results.\n        :param padding_width: Pixel width used for padding (0 if no padding).\n\n        :return: Bounding box information per word.\n        \"\"\"\n\n        unpadded_results = deepcopy(analyzer_bboxes)\n        if padding_width &lt; 0:\n            raise ValueError(\"Padding width must be a non-negative integer.\")\n\n        coordinate_keys = [\"left\", \"top\"]\n        for coord_key in coordinate_keys:\n            unpadded_results[coord_key] = [\n                max(0, x - padding_width) for x in unpadded_results[coord_key]\n            ]\n\n        return unpadded_results\n\n    @staticmethod\n    def _parse_ocr_kwargs(ocr_kwargs: dict) -&gt; Tuple[dict, float]:\n        \"\"\"Parse the OCR-related kwargs.\n\n        :param ocr_kwargs: Parameters for OCR operations.\n\n        :return: Params for ocr.perform_ocr and ocr_threshold\n        \"\"\"\n        ocr_threshold = None\n        if ocr_kwargs is not None:\n            if \"ocr_threshold\" in ocr_kwargs:\n                ocr_threshold = ocr_kwargs[\"ocr_threshold\"]\n                ocr_kwargs = {\n                    key: value\n                    for key, value in ocr_kwargs.items()\n                    if key != \"ocr_threshold\"\n                }\n        else:\n            ocr_kwargs = {}\n\n        return ocr_kwargs, ocr_threshold\n\n    @staticmethod\n    def _check_for_allow_list(text_analyzer_kwargs: dict) -&gt; List[str]:\n        \"\"\"Check the text_analyzer_kwargs for an allow_list.\n\n        :param text_analyzer_kwargs: Text analyzer kwargs.\n        :return: The allow list if it exists.\n        \"\"\"\n        allow_list = []\n        if text_analyzer_kwargs is not None:\n            if \"allow_list\" in text_analyzer_kwargs:\n                allow_list = text_analyzer_kwargs[\"allow_list\"]\n\n        return allow_list\n\n    @staticmethod\n    def fig2img(fig: matplotlib.figure.Figure) -&gt; Image:\n        \"\"\"Convert a Matplotlib figure to a PIL Image and return it.\n\n        :param fig: Matplotlib figure.\n\n        :return: Image of figure.\n        \"\"\"\n        buf = io.BytesIO()\n        fig.savefig(buf)\n        buf.seek(0)\n        img = Image.open(buf)\n\n        return img\n\n    @staticmethod\n    def get_pii_bboxes(\n        ocr_bboxes: List[dict], analyzer_bboxes: List[dict]\n    ) -&gt; List[dict]:\n        \"\"\"Get a list of bboxes with is_PII property.\n\n        :param ocr_bboxes: Bboxes from OCR results.\n        :param analyzer_bboxes: Bboxes from analyzer results.\n\n        :return: All bboxes with appropriate label for whether it is PHI or not.\n        \"\"\"\n        bboxes = []\n        for ocr_bbox in ocr_bboxes:\n            has_match = False\n\n            # Check if we have the same bbox in analyzer results\n            for analyzer_bbox in analyzer_bboxes:\n                has_same_position = (\n                    ocr_bbox[\"left\"] == analyzer_bbox[\"left\"]\n                    and ocr_bbox[\"top\"] == analyzer_bbox[\"top\"]\n                )  # noqa: E501\n                has_same_dimension = (\n                    ocr_bbox[\"width\"] == analyzer_bbox[\"width\"]\n                    and ocr_bbox[\"height\"] == analyzer_bbox[\"height\"]\n                )  # noqa: E501\n                is_same = has_same_position is True and has_same_dimension is True\n\n                if is_same is True:\n                    current_bbox = analyzer_bbox\n                    current_bbox[\"is_PII\"] = True\n                    has_match = True\n                    break\n\n            if has_match is False:\n                current_bbox = ocr_bbox\n                current_bbox[\"is_PII\"] = False\n\n            bboxes.append(current_bbox)\n\n        return bboxes\n\n    @classmethod\n    def add_custom_bboxes(\n        cls,\n        image: Image,\n        bboxes: List[dict],\n        show_text_annotation: bool = True,\n        use_greyscale_cmap: bool = False,\n    ) -&gt; Image:\n        \"\"\"Add custom bounding boxes to image.\n\n        :param image: Standard image of DICOM pixels.\n        :param bboxes: List of bounding boxes to display (with is_PII field).\n        :param gt_bboxes: Ground truth bboxes (list of dictionaries).\n        :param show_text_annotation: True if you want text annotation for\n        PHI status to display.\n        :param use_greyscale_cmap: Use greyscale color map.\n        :return: Image with bounding boxes drawn on.\n        \"\"\"\n        image_custom = ImageChops.duplicate(image)\n        image_x, image_y = image_custom.size\n\n        fig, ax = plt.subplots()\n        image_r = 70\n        fig.set_size_inches(image_x / image_r, image_y / image_r)\n\n        if len(bboxes) == 0:\n            ax.imshow(image_custom)\n            return image_custom\n        else:\n            for box in bboxes:\n                try:\n                    entity_type = box[\"entity_type\"]\n                except KeyError:\n                    entity_type = \"UNKNOWN\"\n\n                try:\n                    if box[\"is_PII\"]:\n                        bbox_color = \"r\"\n                    else:\n                        bbox_color = \"b\"\n                except KeyError:\n                    bbox_color = \"b\"\n\n                # Get coordinates and dimensions\n                x0 = box[\"left\"]\n                y0 = box[\"top\"]\n                x1 = x0 + box[\"width\"]\n                y1 = y0 + box[\"height\"]\n                rect = matplotlib.patches.Rectangle(\n                    (x0, y0), x1 - x0, y1 - y0, edgecolor=bbox_color, facecolor=\"none\"\n                )\n                ax.add_patch(rect)\n                if show_text_annotation:\n                    ax.annotate(\n                        entity_type,\n                        xy=(x0 - 3, y0 - 3),\n                        xycoords=\"data\",\n                        bbox=dict(boxstyle=\"round4,pad=.5\", fc=\"0.9\"),\n                    )\n            if use_greyscale_cmap:\n                ax.imshow(image_custom, cmap=\"gray\")\n            else:\n                ax.imshow(image_custom)\n            im_from_fig = cls.fig2img(fig)\n            im_resized = im_from_fig.resize((image_x, image_y))\n\n        return im_resized\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageAnalyzerEngine.add_custom_bboxes","title":"<code>add_custom_bboxes(image, bboxes, show_text_annotation=True, use_greyscale_cmap=False)</code>  <code>classmethod</code>","text":"<p>Add custom bounding boxes to image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Standard image of DICOM pixels.</p> required <code>bboxes</code> <code>List[dict]</code> <p>List of bounding boxes to display (with is_PII field).</p> required <code>gt_bboxes</code> <p>Ground truth bboxes (list of dictionaries).</p> required <code>show_text_annotation</code> <code>bool</code> <p>True if you want text annotation for PHI status to display.</p> <code>True</code> <code>use_greyscale_cmap</code> <code>bool</code> <p>Use greyscale color map.</p> <code>False</code> <p>Returns:</p> Type Description <code>Image</code> <p>Image with bounding boxes drawn on.</p> Source code in <code>presidio_image_redactor/image_analyzer_engine.py</code> <pre><code>@classmethod\ndef add_custom_bboxes(\n    cls,\n    image: Image,\n    bboxes: List[dict],\n    show_text_annotation: bool = True,\n    use_greyscale_cmap: bool = False,\n) -&gt; Image:\n    \"\"\"Add custom bounding boxes to image.\n\n    :param image: Standard image of DICOM pixels.\n    :param bboxes: List of bounding boxes to display (with is_PII field).\n    :param gt_bboxes: Ground truth bboxes (list of dictionaries).\n    :param show_text_annotation: True if you want text annotation for\n    PHI status to display.\n    :param use_greyscale_cmap: Use greyscale color map.\n    :return: Image with bounding boxes drawn on.\n    \"\"\"\n    image_custom = ImageChops.duplicate(image)\n    image_x, image_y = image_custom.size\n\n    fig, ax = plt.subplots()\n    image_r = 70\n    fig.set_size_inches(image_x / image_r, image_y / image_r)\n\n    if len(bboxes) == 0:\n        ax.imshow(image_custom)\n        return image_custom\n    else:\n        for box in bboxes:\n            try:\n                entity_type = box[\"entity_type\"]\n            except KeyError:\n                entity_type = \"UNKNOWN\"\n\n            try:\n                if box[\"is_PII\"]:\n                    bbox_color = \"r\"\n                else:\n                    bbox_color = \"b\"\n            except KeyError:\n                bbox_color = \"b\"\n\n            # Get coordinates and dimensions\n            x0 = box[\"left\"]\n            y0 = box[\"top\"]\n            x1 = x0 + box[\"width\"]\n            y1 = y0 + box[\"height\"]\n            rect = matplotlib.patches.Rectangle(\n                (x0, y0), x1 - x0, y1 - y0, edgecolor=bbox_color, facecolor=\"none\"\n            )\n            ax.add_patch(rect)\n            if show_text_annotation:\n                ax.annotate(\n                    entity_type,\n                    xy=(x0 - 3, y0 - 3),\n                    xycoords=\"data\",\n                    bbox=dict(boxstyle=\"round4,pad=.5\", fc=\"0.9\"),\n                )\n        if use_greyscale_cmap:\n            ax.imshow(image_custom, cmap=\"gray\")\n        else:\n            ax.imshow(image_custom)\n        im_from_fig = cls.fig2img(fig)\n        im_resized = im_from_fig.resize((image_x, image_y))\n\n    return im_resized\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageAnalyzerEngine.analyze","title":"<code>analyze(image, ocr_kwargs=None, **text_analyzer_kwargs)</code>","text":"<p>Analyse method to analyse the given image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>object</code> <p>PIL Image/numpy array or file path(str) to be processed.</p> required <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in AnalyzerEngine.</p> <code>{}</code> <p>Returns:</p> Type Description <code>List[ImageRecognizerResult]</code> <p>List of the extract entities with image bounding boxes.</p> Source code in <code>presidio_image_redactor/image_analyzer_engine.py</code> <pre><code>def analyze(\n    self, image: object, ocr_kwargs: Optional[dict] = None, **text_analyzer_kwargs\n) -&gt; List[ImageRecognizerResult]:\n    \"\"\"Analyse method to analyse the given image.\n\n    :param image: PIL Image/numpy array or file path(str) to be processed.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in AnalyzerEngine.\n\n    :return: List of the extract entities with image bounding boxes.\n    \"\"\"\n    # Perform OCR\n    perform_ocr_kwargs, ocr_threshold = self._parse_ocr_kwargs(ocr_kwargs)\n    image, preprocessing_metadata = self.image_preprocessor.preprocess_image(image)\n    ocr_result = self.ocr.perform_ocr(image, **perform_ocr_kwargs)\n    ocr_result = self.remove_space_boxes(ocr_result)\n\n    if preprocessing_metadata and (\"scale_factor\" in preprocessing_metadata):\n        ocr_result = self._scale_bbox_results(\n            ocr_result, preprocessing_metadata[\"scale_factor\"]\n        )\n\n    # Apply OCR confidence threshold if it is passed in\n    if ocr_threshold:\n        ocr_result = self.threshold_ocr_result(ocr_result, ocr_threshold)\n\n    # Analyze text\n    text = self.ocr.get_text_from_ocr_dict(ocr_result)\n\n    # Difines English as default language, if not specified\n    if \"language\" not in text_analyzer_kwargs:\n        text_analyzer_kwargs[\"language\"] = \"en\"\n    analyzer_result = self.analyzer_engine.analyze(\n        text=text, **text_analyzer_kwargs\n    )\n    allow_list = self._check_for_allow_list(text_analyzer_kwargs)\n    bboxes = self.map_analyzer_results_to_bounding_boxes(\n        analyzer_result, ocr_result, text, allow_list\n    )\n\n    return bboxes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageAnalyzerEngine.fig2img","title":"<code>fig2img(fig)</code>  <code>staticmethod</code>","text":"<p>Convert a Matplotlib figure to a PIL Image and return it.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>Matplotlib figure.</p> required <p>Returns:</p> Type Description <code>Image</code> <p>Image of figure.</p> Source code in <code>presidio_image_redactor/image_analyzer_engine.py</code> <pre><code>@staticmethod\ndef fig2img(fig: matplotlib.figure.Figure) -&gt; Image:\n    \"\"\"Convert a Matplotlib figure to a PIL Image and return it.\n\n    :param fig: Matplotlib figure.\n\n    :return: Image of figure.\n    \"\"\"\n    buf = io.BytesIO()\n    fig.savefig(buf)\n    buf.seek(0)\n    img = Image.open(buf)\n\n    return img\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageAnalyzerEngine.get_pii_bboxes","title":"<code>get_pii_bboxes(ocr_bboxes, analyzer_bboxes)</code>  <code>staticmethod</code>","text":"<p>Get a list of bboxes with is_PII property.</p> <p>Parameters:</p> Name Type Description Default <code>ocr_bboxes</code> <code>List[dict]</code> <p>Bboxes from OCR results.</p> required <code>analyzer_bboxes</code> <code>List[dict]</code> <p>Bboxes from analyzer results.</p> required <p>Returns:</p> Type Description <code>List[dict]</code> <p>All bboxes with appropriate label for whether it is PHI or not.</p> Source code in <code>presidio_image_redactor/image_analyzer_engine.py</code> <pre><code>@staticmethod\ndef get_pii_bboxes(\n    ocr_bboxes: List[dict], analyzer_bboxes: List[dict]\n) -&gt; List[dict]:\n    \"\"\"Get a list of bboxes with is_PII property.\n\n    :param ocr_bboxes: Bboxes from OCR results.\n    :param analyzer_bboxes: Bboxes from analyzer results.\n\n    :return: All bboxes with appropriate label for whether it is PHI or not.\n    \"\"\"\n    bboxes = []\n    for ocr_bbox in ocr_bboxes:\n        has_match = False\n\n        # Check if we have the same bbox in analyzer results\n        for analyzer_bbox in analyzer_bboxes:\n            has_same_position = (\n                ocr_bbox[\"left\"] == analyzer_bbox[\"left\"]\n                and ocr_bbox[\"top\"] == analyzer_bbox[\"top\"]\n            )  # noqa: E501\n            has_same_dimension = (\n                ocr_bbox[\"width\"] == analyzer_bbox[\"width\"]\n                and ocr_bbox[\"height\"] == analyzer_bbox[\"height\"]\n            )  # noqa: E501\n            is_same = has_same_position is True and has_same_dimension is True\n\n            if is_same is True:\n                current_bbox = analyzer_bbox\n                current_bbox[\"is_PII\"] = True\n                has_match = True\n                break\n\n        if has_match is False:\n            current_bbox = ocr_bbox\n            current_bbox[\"is_PII\"] = False\n\n        bboxes.append(current_bbox)\n\n    return bboxes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageAnalyzerEngine.map_analyzer_results_to_bounding_boxes","title":"<code>map_analyzer_results_to_bounding_boxes(text_analyzer_results, ocr_result, text, allow_list)</code>  <code>staticmethod</code>","text":"<p>Map extracted PII entities to image bounding boxes.</p> <p>Matching is based on the position of the recognized entity from analyzer and word (in ocr dict) in the text.</p> <p>Parameters:</p> Name Type Description Default <code>text_analyzer_results</code> <code>List[RecognizerResult]</code> <p>PII entities recognized by presidio analyzer</p> required <code>ocr_result</code> <code>dict</code> <p>dict results with words and bboxes from OCR</p> required <code>text</code> <code>str</code> <p>text the results are based on</p> required <code>allow_list</code> <code>List[str]</code> <p>List of words to not redact  return: list of extracted entities with image bounding boxes</p> required Source code in <code>presidio_image_redactor/image_analyzer_engine.py</code> <pre><code>@staticmethod\ndef map_analyzer_results_to_bounding_boxes(\n    text_analyzer_results: List[RecognizerResult],\n    ocr_result: dict,\n    text: str,\n    allow_list: List[str],\n) -&gt; List[ImageRecognizerResult]:\n    \"\"\"Map extracted PII entities to image bounding boxes.\n\n    Matching is based on the position of the recognized entity from analyzer\n    and word (in ocr dict) in the text.\n\n    :param text_analyzer_results: PII entities recognized by presidio analyzer\n    :param ocr_result: dict results with words and bboxes from OCR\n    :param text: text the results are based on\n    :param allow_list: List of words to not redact\n\n    return: list of extracted entities with image bounding boxes\n    \"\"\"\n    if (not ocr_result) or (not text_analyzer_results):\n        return []\n\n    bboxes = []\n    proc_indexes = 0\n    indexes = len(text_analyzer_results)\n\n    pos = 0\n    iter_ocr = enumerate(ocr_result[\"text\"])\n    for index, word in iter_ocr:\n        if not word:\n            pos += 1\n        else:\n            for element in text_analyzer_results:\n                text_element = text[element.start : element.end]\n                # check position and text of ocr word matches recognized entity\n                if (\n                    max(pos, element.start) &lt; min(element.end, pos + len(word))\n                ) and ((text_element in word) or (word in text_element)):\n                    yes_make_bbox_for_word = (\n                        (word is not None)\n                        and (word != \"\")\n                        and (word.isspace() is False)\n                        and (word not in allow_list)\n                    )\n                    # Do not add bbox for standalone spaces / empty strings\n                    if yes_make_bbox_for_word:\n                        bboxes.append(\n                            ImageRecognizerResult(\n                                element.entity_type,\n                                element.start,\n                                element.end,\n                                element.score,\n                                ocr_result[\"left\"][index],\n                                ocr_result[\"top\"][index],\n                                ocr_result[\"width\"][index],\n                                ocr_result[\"height\"][index],\n                            )\n                        )\n\n                        # add bounding boxes for all words in ocr dict\n                        # contained within the text of recognized entity\n                        # based on relative position in the full text\n                        while pos + len(word) &lt; element.end:\n                            prev_word = word\n                            index, word = next(iter_ocr)\n                            yes_make_bbox_for_word = (\n                                (word is not None)\n                                and (word != \"\")\n                                and (word.isspace() is False)\n                                and (word not in allow_list)\n                            )\n                            if yes_make_bbox_for_word:\n                                bboxes.append(\n                                    ImageRecognizerResult(\n                                        element.entity_type,\n                                        element.start,\n                                        element.end,\n                                        element.score,\n                                        ocr_result[\"left\"][index],\n                                        ocr_result[\"top\"][index],\n                                        ocr_result[\"width\"][index],\n                                        ocr_result[\"height\"][index],\n                                    )\n                                )\n                            pos += len(prev_word) + 1\n                        proc_indexes += 1\n\n            if proc_indexes == indexes:\n                break\n            pos += len(word) + 1\n\n    return bboxes\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageAnalyzerEngine.remove_space_boxes","title":"<code>remove_space_boxes(ocr_result)</code>  <code>staticmethod</code>","text":"<p>Remove OCR bboxes that are for spaces.</p> <p>Parameters:</p> Name Type Description Default <code>ocr_result</code> <code>dict</code> <p>OCR results (raw or thresholded).</p> required <p>Returns:</p> Type Description <code>dict</code> <p>OCR results with empty words removed.</p> Source code in <code>presidio_image_redactor/image_analyzer_engine.py</code> <pre><code>@staticmethod\ndef remove_space_boxes(ocr_result: dict) -&gt; dict:\n    \"\"\"Remove OCR bboxes that are for spaces.\n\n    :param ocr_result: OCR results (raw or thresholded).\n    :return: OCR results with empty words removed.\n    \"\"\"\n    # Get indices of items with no text\n    idx = list()\n    for i, text in enumerate(ocr_result[\"text\"]):\n        is_not_space = text.isspace() is False\n        if text != \"\" and is_not_space:\n            idx.append(i)\n\n    # Only retain items with text\n    filtered_ocr_result = {}\n    for key in list(ocr_result.keys()):\n        filtered_ocr_result[key] = [ocr_result[key][i] for i in idx]\n\n    return filtered_ocr_result\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageAnalyzerEngine.threshold_ocr_result","title":"<code>threshold_ocr_result(ocr_result, ocr_threshold)</code>  <code>staticmethod</code>","text":"<p>Filter out OCR results below confidence threshold.</p> <p>Parameters:</p> Name Type Description Default <code>ocr_result</code> <code>dict</code> <p>OCR results (raw).</p> required <code>ocr_threshold</code> <code>float</code> <p>Threshold value between -1 and 100.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>OCR results with low confidence items removed.</p> Source code in <code>presidio_image_redactor/image_analyzer_engine.py</code> <pre><code>@staticmethod\ndef threshold_ocr_result(ocr_result: dict, ocr_threshold: float) -&gt; dict:\n    \"\"\"Filter out OCR results below confidence threshold.\n\n    :param ocr_result: OCR results (raw).\n    :param ocr_threshold: Threshold value between -1 and 100.\n\n    :return: OCR results with low confidence items removed.\n    \"\"\"\n    if ocr_threshold &lt; -1 or ocr_threshold &gt; 100:\n        raise ValueError(\"ocr_threshold must be between -1 and 100\")\n\n    # Get indices of items above threshold\n    idx = list()\n    for i, val in enumerate(ocr_result[\"conf\"]):\n        if float(val) &gt;= ocr_threshold:\n            idx.append(i)\n\n    # Only retain high confidence items\n    filtered_ocr_result = {}\n    for key in list(ocr_result.keys()):\n        filtered_ocr_result[key] = [ocr_result[key][i] for i in idx]\n\n    return filtered_ocr_result\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImagePiiVerifyEngine","title":"<code>ImagePiiVerifyEngine</code>","text":"<p>               Bases: <code>ImageRedactorEngine</code></p> <p>ImagePiiVerifyEngine class only supporting Pii verification currently.</p> Source code in <code>presidio_image_redactor/image_pii_verify_engine.py</code> <pre><code>class ImagePiiVerifyEngine(ImageRedactorEngine):\n    \"\"\"ImagePiiVerifyEngine class only supporting Pii verification currently.\"\"\"\n\n    def verify(\n        self,\n        image: Image,\n        is_greyscale: bool = False,\n        display_image: bool = True,\n        show_text_annotation: bool = True,\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; Image:\n        \"\"\"Annotate image with the detect PII entity.\n\n        Please notice, this method duplicates the image, creates a\n        new instance and manipulate it.\n\n        :param image: PIL Image to be processed.\n        :param is_greyscale: Whether the image is greyscale or not.\n        :param display_image: If the verificationimage is displayed and returned.\n        :param show_text_annotation: True to display entity type when displaying\n        image with bounding boxes.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in ImageAnalyzerEngine.\n\n        :return: the annotated image\n        \"\"\"\n        image = ImageChops.duplicate(image)\n\n        # Check the ad-hoc recognizers list\n        self._check_ad_hoc_recognizer_list(ad_hoc_recognizers)\n\n        # Detect text\n        perform_ocr_kwargs, ocr_threshold = (\n            self.image_analyzer_engine._parse_ocr_kwargs(ocr_kwargs)\n        )  # noqa: E501\n        ocr_results = self.image_analyzer_engine.ocr.perform_ocr(\n            image, **perform_ocr_kwargs\n        )\n        if ocr_threshold:\n            ocr_results = self.image_analyzer_engine.threshold_ocr_result(\n                ocr_results, ocr_threshold\n            )\n        ocr_bboxes = self.bbox_processor.get_bboxes_from_ocr_results(ocr_results)\n\n        # Detect PII\n        if ad_hoc_recognizers is None:\n            analyzer_results = self.image_analyzer_engine.analyze(\n                image,\n                ocr_kwargs=ocr_kwargs,\n                **text_analyzer_kwargs,\n            )\n        else:\n            analyzer_results = self.image_analyzer_engine.analyze(\n                image,\n                ocr_kwargs=ocr_kwargs,\n                ad_hoc_recognizers=ad_hoc_recognizers,\n                **text_analyzer_kwargs,\n            )\n        analyzer_bboxes = self.bbox_processor.get_bboxes_from_analyzer_results(\n            analyzer_results\n        )\n\n        # Prepare for plotting\n        pii_bboxes = self.image_analyzer_engine.get_pii_bboxes(\n            ocr_bboxes, analyzer_bboxes\n        )\n        if is_greyscale:\n            use_greyscale_cmap = True\n        else:\n            use_greyscale_cmap = False\n\n        # Get image with verification boxes\n        verify_image = (\n            self.image_analyzer_engine.add_custom_bboxes(\n                image, pii_bboxes, show_text_annotation, use_greyscale_cmap\n            )\n            if display_image\n            else None\n        )\n\n        return verify_image\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImagePiiVerifyEngine.verify","title":"<code>verify(image, is_greyscale=False, display_image=True, show_text_annotation=True, ocr_kwargs=None, ad_hoc_recognizers=None, **text_analyzer_kwargs)</code>","text":"<p>Annotate image with the detect PII entity.</p> <p>Please notice, this method duplicates the image, creates a new instance and manipulate it.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>PIL Image to be processed.</p> required <code>is_greyscale</code> <code>bool</code> <p>Whether the image is greyscale or not.</p> <code>False</code> <code>display_image</code> <code>bool</code> <p>If the verificationimage is displayed and returned.</p> <code>True</code> <code>show_text_annotation</code> <code>bool</code> <p>True to display entity type when displaying image with bounding boxes.</p> <code>True</code> <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>ad_hoc_recognizers</code> <code>Optional[List[PatternRecognizer]]</code> <p>List of PatternRecognizer objects to use for ad-hoc recognizer.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in ImageAnalyzerEngine.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Image</code> <p>the annotated image</p> Source code in <code>presidio_image_redactor/image_pii_verify_engine.py</code> <pre><code>def verify(\n    self,\n    image: Image,\n    is_greyscale: bool = False,\n    display_image: bool = True,\n    show_text_annotation: bool = True,\n    ocr_kwargs: Optional[dict] = None,\n    ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    **text_analyzer_kwargs,\n) -&gt; Image:\n    \"\"\"Annotate image with the detect PII entity.\n\n    Please notice, this method duplicates the image, creates a\n    new instance and manipulate it.\n\n    :param image: PIL Image to be processed.\n    :param is_greyscale: Whether the image is greyscale or not.\n    :param display_image: If the verificationimage is displayed and returned.\n    :param show_text_annotation: True to display entity type when displaying\n    image with bounding boxes.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n    for ad-hoc recognizer.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in ImageAnalyzerEngine.\n\n    :return: the annotated image\n    \"\"\"\n    image = ImageChops.duplicate(image)\n\n    # Check the ad-hoc recognizers list\n    self._check_ad_hoc_recognizer_list(ad_hoc_recognizers)\n\n    # Detect text\n    perform_ocr_kwargs, ocr_threshold = (\n        self.image_analyzer_engine._parse_ocr_kwargs(ocr_kwargs)\n    )  # noqa: E501\n    ocr_results = self.image_analyzer_engine.ocr.perform_ocr(\n        image, **perform_ocr_kwargs\n    )\n    if ocr_threshold:\n        ocr_results = self.image_analyzer_engine.threshold_ocr_result(\n            ocr_results, ocr_threshold\n        )\n    ocr_bboxes = self.bbox_processor.get_bboxes_from_ocr_results(ocr_results)\n\n    # Detect PII\n    if ad_hoc_recognizers is None:\n        analyzer_results = self.image_analyzer_engine.analyze(\n            image,\n            ocr_kwargs=ocr_kwargs,\n            **text_analyzer_kwargs,\n        )\n    else:\n        analyzer_results = self.image_analyzer_engine.analyze(\n            image,\n            ocr_kwargs=ocr_kwargs,\n            ad_hoc_recognizers=ad_hoc_recognizers,\n            **text_analyzer_kwargs,\n        )\n    analyzer_bboxes = self.bbox_processor.get_bboxes_from_analyzer_results(\n        analyzer_results\n    )\n\n    # Prepare for plotting\n    pii_bboxes = self.image_analyzer_engine.get_pii_bboxes(\n        ocr_bboxes, analyzer_bboxes\n    )\n    if is_greyscale:\n        use_greyscale_cmap = True\n    else:\n        use_greyscale_cmap = False\n\n    # Get image with verification boxes\n    verify_image = (\n        self.image_analyzer_engine.add_custom_bboxes(\n            image, pii_bboxes, show_text_annotation, use_greyscale_cmap\n        )\n        if display_image\n        else None\n    )\n\n    return verify_image\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImagePreprocessor","title":"<code>ImagePreprocessor</code>","text":"<p>ImagePreprocessor class.</p> <p>Parent class for image preprocessing objects.</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>class ImagePreprocessor:\n    \"\"\"ImagePreprocessor class.\n\n    Parent class for image preprocessing objects.\n    \"\"\"\n\n    def __init__(self, use_greyscale: bool = True) -&gt; None:\n        \"\"\"Initialize the ImagePreprocessor class.\n\n        :param use_greyscale: Whether to convert the image to greyscale.\n        \"\"\"\n        self.use_greyscale = use_greyscale\n\n    def preprocess_image(self, image: Image.Image) -&gt; Tuple[Image.Image, dict]:\n        \"\"\"Preprocess the image to be analyzed.\n\n        :param image: Loaded PIL image.\n\n        :return: The processed image and any metadata regarding the\n             preprocessing approach.\n        \"\"\"\n        return image, {}\n\n    def convert_image_to_array(self, image: Image.Image) -&gt; np.ndarray:\n        \"\"\"Convert PIL image to numpy array.\n\n        :param image: Loaded PIL image.\n        :param convert_to_greyscale: Whether to convert the image to greyscale.\n\n        :return: image pixels as a numpy array.\n\n        \"\"\"\n\n        if isinstance(image, np.ndarray):\n            img = image\n        else:\n            if self.use_greyscale:\n                image = image.convert(\"L\")\n            img = np.asarray(image)\n        return img\n\n    @staticmethod\n    def _get_bg_color(\n        image: Image.Image, is_greyscale: bool, invert: bool = False\n    ) -&gt; Union[int, Tuple[int, int, int]]:\n        \"\"\"Select most common color as background color.\n\n        :param image: Loaded PIL image.\n        :param is_greyscale: Whether the image is greyscale.\n        :param invert: TRUE if you want to get the inverse of the bg color.\n\n        :return: Background color.\n        \"\"\"\n        # Invert colors if invert flag is True\n        if invert:\n            if image.mode == \"RGBA\":\n                # Handle transparency as needed\n                r, g, b, a = image.split()\n                rgb_image = Image.merge(\"RGB\", (r, g, b))\n                inverted_image = PIL.ImageOps.invert(rgb_image)\n                r2, g2, b2 = inverted_image.split()\n\n                image = Image.merge(\"RGBA\", (r2, g2, b2, a))\n\n            else:\n                image = PIL.ImageOps.invert(image)\n\n        # Get background color\n        if is_greyscale:\n            # Select most common color as color\n            bg_color = int(np.bincount(image.flatten()).argmax())\n        else:\n            # Reduce size of image to 1 pixel to get dominant color\n            tmp_image = image.copy()\n            tmp_image = tmp_image.resize((1, 1), resample=0)\n            bg_color = tmp_image.getpixel((0, 0))\n\n        return bg_color\n\n    @staticmethod\n    def _get_image_contrast(image: np.ndarray) -&gt; Tuple[float, float]:\n        \"\"\"Compute the contrast level and mean intensity of an image.\n\n        :param image: Input image pixels (as a numpy array).\n\n        :return: A tuple containing the contrast level and mean intensity of the image.\n        \"\"\"\n        contrast = np.std(image)\n        mean_intensity = np.mean(image)\n        return contrast, mean_intensity\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImagePreprocessor.__init__","title":"<code>__init__(use_greyscale=True)</code>","text":"<p>Initialize the ImagePreprocessor class.</p> <p>Parameters:</p> Name Type Description Default <code>use_greyscale</code> <code>bool</code> <p>Whether to convert the image to greyscale.</p> <code>True</code> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def __init__(self, use_greyscale: bool = True) -&gt; None:\n    \"\"\"Initialize the ImagePreprocessor class.\n\n    :param use_greyscale: Whether to convert the image to greyscale.\n    \"\"\"\n    self.use_greyscale = use_greyscale\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImagePreprocessor.convert_image_to_array","title":"<code>convert_image_to_array(image)</code>","text":"<p>Convert PIL image to numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Loaded PIL image.</p> required <code>convert_to_greyscale</code> <p>Whether to convert the image to greyscale.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>image pixels as a numpy array.</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def convert_image_to_array(self, image: Image.Image) -&gt; np.ndarray:\n    \"\"\"Convert PIL image to numpy array.\n\n    :param image: Loaded PIL image.\n    :param convert_to_greyscale: Whether to convert the image to greyscale.\n\n    :return: image pixels as a numpy array.\n\n    \"\"\"\n\n    if isinstance(image, np.ndarray):\n        img = image\n    else:\n        if self.use_greyscale:\n            image = image.convert(\"L\")\n        img = np.asarray(image)\n    return img\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImagePreprocessor.preprocess_image","title":"<code>preprocess_image(image)</code>","text":"<p>Preprocess the image to be analyzed.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Loaded PIL image.</p> required <p>Returns:</p> Type Description <code>Tuple[Image, dict]</code> <p>The processed image and any metadata regarding the preprocessing approach.</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def preprocess_image(self, image: Image.Image) -&gt; Tuple[Image.Image, dict]:\n    \"\"\"Preprocess the image to be analyzed.\n\n    :param image: Loaded PIL image.\n\n    :return: The processed image and any metadata regarding the\n         preprocessing approach.\n    \"\"\"\n    return image, {}\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageRedactorEngine","title":"<code>ImageRedactorEngine</code>","text":"<p>ImageRedactorEngine performs OCR + PII detection + bounding box redaction.</p> <p>Parameters:</p> Name Type Description Default <code>image_analyzer_engine</code> <code>ImageAnalyzerEngine</code> <p>Engine which performs OCR + PII detection.</p> <code>None</code> Source code in <code>presidio_image_redactor/image_redactor_engine.py</code> <pre><code>class ImageRedactorEngine:\n    \"\"\"ImageRedactorEngine performs OCR + PII detection + bounding box redaction.\n\n    :param image_analyzer_engine: Engine which performs OCR + PII detection.\n    \"\"\"\n\n    def __init__(\n        self,\n        image_analyzer_engine: ImageAnalyzerEngine = None,\n    ):\n        if not image_analyzer_engine:\n            self.image_analyzer_engine = ImageAnalyzerEngine()\n        else:\n            self.image_analyzer_engine = image_analyzer_engine\n\n        self.bbox_processor = BboxProcessor()\n\n    def redact(\n        self,\n        image: Image,\n        fill: Union[int, Tuple[int, int, int]] = (0, 0, 0),\n        ocr_kwargs: Optional[dict] = None,\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n        **text_analyzer_kwargs,\n    ) -&gt; Image:\n        \"\"\"Redact method to redact the given image.\n\n        Please notice, this method duplicates the image, creates a new instance and\n        manipulate it.\n        :param image: PIL Image to be processed.\n        :param fill: colour to fill the shape - int (0-255) for\n        grayscale or Tuple(R, G, B) for RGB.\n        :param ocr_kwargs: Additional params for OCR methods.\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        :param text_analyzer_kwargs: Additional values for the analyze method\n        in AnalyzerEngine.\n\n        :return: the redacted image\n        \"\"\"\n\n        image = ImageChops.duplicate(image)\n\n        # Check the ad-hoc recognizers list\n        self._check_ad_hoc_recognizer_list(ad_hoc_recognizers)\n\n        # Detect PII\n        if ad_hoc_recognizers is None:\n            bboxes = self.image_analyzer_engine.analyze(\n                image,\n                ocr_kwargs=ocr_kwargs,\n                **text_analyzer_kwargs,\n            )\n        else:\n            bboxes = self.image_analyzer_engine.analyze(\n                image,\n                ocr_kwargs=ocr_kwargs,\n                ad_hoc_recognizers=ad_hoc_recognizers,\n                **text_analyzer_kwargs,\n            )\n\n        draw = ImageDraw.Draw(image)\n\n        for box in bboxes:\n            x0 = box.left\n            y0 = box.top\n            x1 = x0 + box.width\n            y1 = y0 + box.height\n            draw.rectangle([x0, y0, x1, y1], fill=fill)\n\n        return image\n\n    @staticmethod\n    def _check_ad_hoc_recognizer_list(\n        ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    ):\n        \"\"\"Check if the provided ad-hoc recognizer list is valid.\n\n        :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n        for ad-hoc recognizer.\n        \"\"\"\n        if isinstance(ad_hoc_recognizers, (list, type(None))):\n            if isinstance(ad_hoc_recognizers, list):\n                if len(ad_hoc_recognizers) &gt;= 1:\n                    are_recognizers = all(\n                        isinstance(\n                            x, presidio_analyzer.pattern_recognizer.PatternRecognizer\n                        )\n                        for x in ad_hoc_recognizers\n                    )\n                    if are_recognizers is False:\n                        raise TypeError(\n                            \"\"\"All items in ad_hoc_recognizers list must be\n                            PatternRecognizer objects\"\"\"\n                        )\n                else:\n                    raise TypeError(\n                        \"ad_hoc_recognizers must be None or list of PatternRecognizer\"\n                    )\n        else:\n            raise TypeError(\n                \"ad_hoc_recognizers must be None or list of PatternRecognizer\"\n            )\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageRedactorEngine.redact","title":"<code>redact(image, fill=(0, 0, 0), ocr_kwargs=None, ad_hoc_recognizers=None, **text_analyzer_kwargs)</code>","text":"<p>Redact method to redact the given image.</p> <p>Please notice, this method duplicates the image, creates a new instance and manipulate it.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>PIL Image to be processed.</p> required <code>fill</code> <code>Union[int, Tuple[int, int, int]]</code> <p>colour to fill the shape - int (0-255) for grayscale or Tuple(R, G, B) for RGB.</p> <code>(0, 0, 0)</code> <code>ocr_kwargs</code> <code>Optional[dict]</code> <p>Additional params for OCR methods.</p> <code>None</code> <code>ad_hoc_recognizers</code> <code>Optional[List[PatternRecognizer]]</code> <p>List of PatternRecognizer objects to use for ad-hoc recognizer.</p> <code>None</code> <code>text_analyzer_kwargs</code> <p>Additional values for the analyze method in AnalyzerEngine.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Image</code> <p>the redacted image</p> Source code in <code>presidio_image_redactor/image_redactor_engine.py</code> <pre><code>def redact(\n    self,\n    image: Image,\n    fill: Union[int, Tuple[int, int, int]] = (0, 0, 0),\n    ocr_kwargs: Optional[dict] = None,\n    ad_hoc_recognizers: Optional[List[PatternRecognizer]] = None,\n    **text_analyzer_kwargs,\n) -&gt; Image:\n    \"\"\"Redact method to redact the given image.\n\n    Please notice, this method duplicates the image, creates a new instance and\n    manipulate it.\n    :param image: PIL Image to be processed.\n    :param fill: colour to fill the shape - int (0-255) for\n    grayscale or Tuple(R, G, B) for RGB.\n    :param ocr_kwargs: Additional params for OCR methods.\n    :param ad_hoc_recognizers: List of PatternRecognizer objects to use\n    for ad-hoc recognizer.\n    :param text_analyzer_kwargs: Additional values for the analyze method\n    in AnalyzerEngine.\n\n    :return: the redacted image\n    \"\"\"\n\n    image = ImageChops.duplicate(image)\n\n    # Check the ad-hoc recognizers list\n    self._check_ad_hoc_recognizer_list(ad_hoc_recognizers)\n\n    # Detect PII\n    if ad_hoc_recognizers is None:\n        bboxes = self.image_analyzer_engine.analyze(\n            image,\n            ocr_kwargs=ocr_kwargs,\n            **text_analyzer_kwargs,\n        )\n    else:\n        bboxes = self.image_analyzer_engine.analyze(\n            image,\n            ocr_kwargs=ocr_kwargs,\n            ad_hoc_recognizers=ad_hoc_recognizers,\n            **text_analyzer_kwargs,\n        )\n\n    draw = ImageDraw.Draw(image)\n\n    for box in bboxes:\n        x0 = box.left\n        y0 = box.top\n        x1 = x0 + box.width\n        y1 = y0 + box.height\n        draw.rectangle([x0, y0, x1, y1], fill=fill)\n\n    return image\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageRescaling","title":"<code>ImageRescaling</code>","text":"<p>               Bases: <code>ImagePreprocessor</code></p> <p>ImageRescaling class. Rescales images based on their size.</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>class ImageRescaling(ImagePreprocessor):\n    \"\"\"ImageRescaling class. Rescales images based on their size.\"\"\"\n\n    def __init__(\n        self,\n        small_size: int = 1048576,\n        large_size: int = 4000000,\n        factor: int = 2,\n        interpolation: int = cv2.INTER_AREA,\n    ) -&gt; None:\n        \"\"\"Initialize the ImageRescaling class.\n\n        :param small_size: Threshold for small image size.\n        :param large_size: Threshold for large image size.\n        :param factor: Scaling factor for resizing.\n        :param interpolation: Interpolation method for resizing.\n        \"\"\"\n        super().__init__(use_greyscale=True)\n\n        self.small_size = small_size\n        self.large_size = large_size\n        self.factor = factor\n        self.interpolation = interpolation\n\n    def preprocess_image(self, image: Image.Image) -&gt; Tuple[Image.Image, dict]:\n        \"\"\"Preprocess the image to be analyzed.\n\n        :param image: Loaded PIL image.\n\n        :return: The processed image and metadata (scale_factor).\n        \"\"\"\n\n        scale_factor = 1\n        if image.size &lt; self.small_size:\n            scale_factor = self.factor\n        elif image.size &gt; self.large_size:\n            scale_factor = 1 / self.factor\n\n        width = int(image.shape[1] * scale_factor)\n        height = int(image.shape[0] * scale_factor)\n        dimensions = (width, height)\n\n        # resize image\n        rescaled_image = cv2.resize(image, dimensions, interpolation=self.interpolation)\n        metadata = {\"scale_factor\": scale_factor}\n        return Image.fromarray(rescaled_image), metadata\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageRescaling.__init__","title":"<code>__init__(small_size=1048576, large_size=4000000, factor=2, interpolation=cv2.INTER_AREA)</code>","text":"<p>Initialize the ImageRescaling class.</p> <p>Parameters:</p> Name Type Description Default <code>small_size</code> <code>int</code> <p>Threshold for small image size.</p> <code>1048576</code> <code>large_size</code> <code>int</code> <p>Threshold for large image size.</p> <code>4000000</code> <code>factor</code> <code>int</code> <p>Scaling factor for resizing.</p> <code>2</code> <code>interpolation</code> <code>int</code> <p>Interpolation method for resizing.</p> <code>INTER_AREA</code> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def __init__(\n    self,\n    small_size: int = 1048576,\n    large_size: int = 4000000,\n    factor: int = 2,\n    interpolation: int = cv2.INTER_AREA,\n) -&gt; None:\n    \"\"\"Initialize the ImageRescaling class.\n\n    :param small_size: Threshold for small image size.\n    :param large_size: Threshold for large image size.\n    :param factor: Scaling factor for resizing.\n    :param interpolation: Interpolation method for resizing.\n    \"\"\"\n    super().__init__(use_greyscale=True)\n\n    self.small_size = small_size\n    self.large_size = large_size\n    self.factor = factor\n    self.interpolation = interpolation\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.ImageRescaling.preprocess_image","title":"<code>preprocess_image(image)</code>","text":"<p>Preprocess the image to be analyzed.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Loaded PIL image.</p> required <p>Returns:</p> Type Description <code>Tuple[Image, dict]</code> <p>The processed image and metadata (scale_factor).</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def preprocess_image(self, image: Image.Image) -&gt; Tuple[Image.Image, dict]:\n    \"\"\"Preprocess the image to be analyzed.\n\n    :param image: Loaded PIL image.\n\n    :return: The processed image and metadata (scale_factor).\n    \"\"\"\n\n    scale_factor = 1\n    if image.size &lt; self.small_size:\n        scale_factor = self.factor\n    elif image.size &gt; self.large_size:\n        scale_factor = 1 / self.factor\n\n    width = int(image.shape[1] * scale_factor)\n    height = int(image.shape[0] * scale_factor)\n    dimensions = (width, height)\n\n    # resize image\n    rescaled_image = cv2.resize(image, dimensions, interpolation=self.interpolation)\n    metadata = {\"scale_factor\": scale_factor}\n    return Image.fromarray(rescaled_image), metadata\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.OCR","title":"<code>OCR</code>","text":"<p>               Bases: <code>ABC</code></p> <p>OCR class that performs OCR on a given image.</p> Source code in <code>presidio_image_redactor/ocr.py</code> <pre><code>class OCR(ABC):\n    \"\"\"OCR class that performs OCR on a given image.\"\"\"\n\n    @abstractmethod\n    def perform_ocr(self, image: object, **kwargs) -&gt; dict:\n        \"\"\"Perform OCR on a given image.\n\n        :param image: PIL Image/numpy array or file path(str) to be processed\n        :param kwargs: Additional values for perform OCR method\n\n        :return: results dictionary containing bboxes and text for each detected word\n        \"\"\"\n        pass\n\n    @staticmethod\n    def get_text_from_ocr_dict(ocr_result: dict, separator: str = \" \") -&gt; str:\n        \"\"\"Combine the text from the OCR dict to full text.\n\n        :param ocr_result: dictionary containing the ocr results per word\n        :param separator: separator to use when joining the words\n\n        return: str containing the full extracted text as string\n        \"\"\"\n        if not ocr_result:\n            return \"\"\n        else:\n            return separator.join(ocr_result[\"text\"])\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.OCR.get_text_from_ocr_dict","title":"<code>get_text_from_ocr_dict(ocr_result, separator=' ')</code>  <code>staticmethod</code>","text":"<p>Combine the text from the OCR dict to full text.</p> <p>Parameters:</p> Name Type Description Default <code>ocr_result</code> <code>dict</code> <p>dictionary containing the ocr results per word</p> required <code>separator</code> <code>str</code> <p>separator to use when joining the words  return: str containing the full extracted text as string</p> <code>' '</code> Source code in <code>presidio_image_redactor/ocr.py</code> <pre><code>@staticmethod\ndef get_text_from_ocr_dict(ocr_result: dict, separator: str = \" \") -&gt; str:\n    \"\"\"Combine the text from the OCR dict to full text.\n\n    :param ocr_result: dictionary containing the ocr results per word\n    :param separator: separator to use when joining the words\n\n    return: str containing the full extracted text as string\n    \"\"\"\n    if not ocr_result:\n        return \"\"\n    else:\n        return separator.join(ocr_result[\"text\"])\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.OCR.perform_ocr","title":"<code>perform_ocr(image, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Perform OCR on a given image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>object</code> <p>PIL Image/numpy array or file path(str) to be processed</p> required <code>kwargs</code> <p>Additional values for perform OCR method</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>results dictionary containing bboxes and text for each detected word</p> Source code in <code>presidio_image_redactor/ocr.py</code> <pre><code>@abstractmethod\ndef perform_ocr(self, image: object, **kwargs) -&gt; dict:\n    \"\"\"Perform OCR on a given image.\n\n    :param image: PIL Image/numpy array or file path(str) to be processed\n    :param kwargs: Additional values for perform OCR method\n\n    :return: results dictionary containing bboxes and text for each detected word\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.SegmentedAdaptiveThreshold","title":"<code>SegmentedAdaptiveThreshold</code>","text":"<p>               Bases: <code>ImagePreprocessor</code></p> <p>SegmentedAdaptiveThreshold class.</p> <p>The class applies adaptive thresholding to an image and returns the thresholded image and metadata. The parameters used to run the adaptivethresholding are selected based on the contrast level of the image.</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>class SegmentedAdaptiveThreshold(ImagePreprocessor):\n    \"\"\"SegmentedAdaptiveThreshold class.\n\n    The class applies adaptive thresholding to an image\n    and returns the thresholded image and metadata.\n    The parameters used to run the adaptivethresholding are selected based on\n    the contrast level of the image.\n    \"\"\"\n\n    def __init__(\n        self,\n        block_size: int = 5,\n        contrast_threshold: int = 40,\n        c_low_contrast: int = 10,\n        c_high_contrast: int = 40,\n        bg_threshold: int = 122,\n    ) -&gt; None:\n        \"\"\"Initialize the SegmentedAdaptiveThreshold class.\n\n        :param block_size: Size of the neighborhood area for threshold calculation.\n        :param contrast_threshold: Threshold for low contrast images.\n        :param C_low_contrast: Constant added to the mean for low contrast images.\n        :param C_high_contrast: Constant added to the mean for high contrast images.\n        :param bg_threshold: Threshold for background color.\n        \"\"\"\n\n        super().__init__(use_greyscale=True)\n        self.block_size = block_size\n        self.c_low_contrast = c_low_contrast\n        self.c_high_contrast = c_high_contrast\n        self.bg_threshold = bg_threshold\n        self.contrast_threshold = contrast_threshold\n\n    def preprocess_image(\n        self, image: Union[Image.Image, np.ndarray]\n    ) -&gt; Tuple[Image.Image, dict]:\n        \"\"\"Preprocess the image.\n\n        :param image: Loaded PIL image.\n\n        :return: The processed image and metadata (C, background_color, contrast).\n        \"\"\"\n        if not isinstance(image, np.ndarray):\n            image = self.convert_image_to_array(image)\n\n        # Determine background color\n        background_color = self._get_bg_color(image, True)\n        contrast, _ = self._get_image_contrast(image)\n\n        c = (\n            self.c_low_contrast\n            if contrast &lt;= self.contrast_threshold\n            else self.c_high_contrast\n        )\n\n        if background_color &lt; self.bg_threshold:\n            adaptive_threshold_image = cv2.adaptiveThreshold(\n                image,\n                255,\n                cv2.ADAPTIVE_THRESH_MEAN_C,\n                cv2.THRESH_BINARY_INV,\n                self.block_size,\n                -c,\n            )\n        else:\n            adaptive_threshold_image = cv2.adaptiveThreshold(\n                image,\n                255,\n                cv2.ADAPTIVE_THRESH_MEAN_C,\n                cv2.THRESH_BINARY,\n                self.block_size,\n                c,\n            )\n\n        metadata = {\"C\": c, \"background_color\": background_color, \"contrast\": contrast}\n        return Image.fromarray(adaptive_threshold_image), metadata\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.SegmentedAdaptiveThreshold.__init__","title":"<code>__init__(block_size=5, contrast_threshold=40, c_low_contrast=10, c_high_contrast=40, bg_threshold=122)</code>","text":"<p>Initialize the SegmentedAdaptiveThreshold class.</p> <p>Parameters:</p> Name Type Description Default <code>block_size</code> <code>int</code> <p>Size of the neighborhood area for threshold calculation.</p> <code>5</code> <code>contrast_threshold</code> <code>int</code> <p>Threshold for low contrast images.</p> <code>40</code> <code>C_low_contrast</code> <p>Constant added to the mean for low contrast images.</p> required <code>C_high_contrast</code> <p>Constant added to the mean for high contrast images.</p> required <code>bg_threshold</code> <code>int</code> <p>Threshold for background color.</p> <code>122</code> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def __init__(\n    self,\n    block_size: int = 5,\n    contrast_threshold: int = 40,\n    c_low_contrast: int = 10,\n    c_high_contrast: int = 40,\n    bg_threshold: int = 122,\n) -&gt; None:\n    \"\"\"Initialize the SegmentedAdaptiveThreshold class.\n\n    :param block_size: Size of the neighborhood area for threshold calculation.\n    :param contrast_threshold: Threshold for low contrast images.\n    :param C_low_contrast: Constant added to the mean for low contrast images.\n    :param C_high_contrast: Constant added to the mean for high contrast images.\n    :param bg_threshold: Threshold for background color.\n    \"\"\"\n\n    super().__init__(use_greyscale=True)\n    self.block_size = block_size\n    self.c_low_contrast = c_low_contrast\n    self.c_high_contrast = c_high_contrast\n    self.bg_threshold = bg_threshold\n    self.contrast_threshold = contrast_threshold\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.SegmentedAdaptiveThreshold.preprocess_image","title":"<code>preprocess_image(image)</code>","text":"<p>Preprocess the image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Union[Image, ndarray]</code> <p>Loaded PIL image.</p> required <p>Returns:</p> Type Description <code>Tuple[Image, dict]</code> <p>The processed image and metadata (C, background_color, contrast).</p> Source code in <code>presidio_image_redactor/image_processing_engine.py</code> <pre><code>def preprocess_image(\n    self, image: Union[Image.Image, np.ndarray]\n) -&gt; Tuple[Image.Image, dict]:\n    \"\"\"Preprocess the image.\n\n    :param image: Loaded PIL image.\n\n    :return: The processed image and metadata (C, background_color, contrast).\n    \"\"\"\n    if not isinstance(image, np.ndarray):\n        image = self.convert_image_to_array(image)\n\n    # Determine background color\n    background_color = self._get_bg_color(image, True)\n    contrast, _ = self._get_image_contrast(image)\n\n    c = (\n        self.c_low_contrast\n        if contrast &lt;= self.contrast_threshold\n        else self.c_high_contrast\n    )\n\n    if background_color &lt; self.bg_threshold:\n        adaptive_threshold_image = cv2.adaptiveThreshold(\n            image,\n            255,\n            cv2.ADAPTIVE_THRESH_MEAN_C,\n            cv2.THRESH_BINARY_INV,\n            self.block_size,\n            -c,\n        )\n    else:\n        adaptive_threshold_image = cv2.adaptiveThreshold(\n            image,\n            255,\n            cv2.ADAPTIVE_THRESH_MEAN_C,\n            cv2.THRESH_BINARY,\n            self.block_size,\n            c,\n        )\n\n    metadata = {\"C\": c, \"background_color\": background_color, \"contrast\": contrast}\n    return Image.fromarray(adaptive_threshold_image), metadata\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.TesseractOCR","title":"<code>TesseractOCR</code>","text":"<p>               Bases: <code>OCR</code></p> <p>OCR class that performs OCR on a given image.</p> Source code in <code>presidio_image_redactor/tesseract_ocr.py</code> <pre><code>class TesseractOCR(OCR):\n    \"\"\"OCR class that performs OCR on a given image.\"\"\"\n\n    def perform_ocr(self, image: object, **kwargs) -&gt; dict:\n        \"\"\"Perform OCR on a given image.\n\n        :param image: PIL Image/numpy array or file path(str) to be processed\n        :param kwargs: Additional values for OCR image_to_data\n\n        :return: results dictionary containing bboxes and text for each detected word\n        \"\"\"\n        output_type = pytesseract.Output.DICT\n        return pytesseract.image_to_data(image, output_type=output_type, **kwargs)\n</code></pre>"},{"location":"api/image_redactor_python/#presidio_image_redactor.TesseractOCR.perform_ocr","title":"<code>perform_ocr(image, **kwargs)</code>","text":"<p>Perform OCR on a given image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>object</code> <p>PIL Image/numpy array or file path(str) to be processed</p> required <code>kwargs</code> <p>Additional values for OCR image_to_data</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>results dictionary containing bboxes and text for each detected word</p> Source code in <code>presidio_image_redactor/tesseract_ocr.py</code> <pre><code>def perform_ocr(self, image: object, **kwargs) -&gt; dict:\n    \"\"\"Perform OCR on a given image.\n\n    :param image: PIL Image/numpy array or file path(str) to be processed\n    :param kwargs: Additional values for OCR image_to_data\n\n    :return: results dictionary containing bboxes and text for each detected word\n    \"\"\"\n    output_type = pytesseract.Output.DICT\n    return pytesseract.image_to_data(image, output_type=output_type, **kwargs)\n</code></pre>"},{"location":"image-redactor/","title":"Presidio Image Redactor","text":"<p>Please notice, this package is still in beta and not production ready.</p>"},{"location":"image-redactor/#description","title":"Description","text":"<p>The Presidio Image Redactor is a Python based module for detecting and redacting PII text entities in images. </p> <p>This module may also be used on medical DICOM images. The <code>DicomImageRedactorEngine</code> class may be used to redact text PII present as pixels in DICOM images. </p> <p>Note</p> <p>This class only redacts pixel data and does not scrub text PII which may exist in the DICOM metadata.  We highly recommend using the DICOM image redactor engine to redact text from images BEFORE scrubbing metadata PII.*</p>"},{"location":"image-redactor/#installation","title":"Installation","text":"<p>Pre-requisites:</p> <ul> <li>Install Tesseract OCR by following the   instructions on how to install it for your operating system.</li> </ul> <p>Attention</p> <p>For best performance, please use the most up-to-date version of Tesseract OCR. Presidio was tested with v5.2.0.</p> Using pipUsing DockerFrom source <p>Note</p> <p>Consider installing the Presidio python packages on a virtual environment like venv or conda.</p> <p>To get started with Presidio-image-redactor, download the package and the <code>en_core_web_lg</code> spaCy model:</p> <pre><code>pip install presidio-image-redactor\npython -m spacy download en_core_web_lg\n</code></pre> <p>Note</p> <p>This requires Docker to be installed. Download Docker.</p> <pre><code># Download image from Dockerhub\ndocker pull mcr.microsoft.com/presidio-image-redactor\n\n# Run the container with the default port\ndocker run -d -p 5003:3000 mcr.microsoft.com/presidio-image-redactor:latest\n</code></pre> <p>First, clone the Presidio repo. See here for instructions.</p> <p>Then, build the presidio-image-redactor container:</p> <pre><code>cd presidio-image-redactor\ndocker build . -t presidio/presidio-image-redactor\n</code></pre>"},{"location":"image-redactor/#getting-started-standard-image-types","title":"Getting started (standard image types)","text":"PythonAs an HTTP server <p>Once the Presidio-image-redactor package is installed, run this simple script:</p> <pre><code>from PIL import Image\nfrom presidio_image_redactor import ImageRedactorEngine\n\n# Get the image to redact using PIL lib (pillow)\nimage = Image.open(\"./docs/image-redactor/ocr_text.png\")\n\n# Initialize the engine\nengine = ImageRedactorEngine()\n\n# Redact the image with pink color\nredacted_image = engine.redact(image, (255, 192, 203))\n\n# save the redacted image \nredacted_image.save(\"new_image.png\")\n# uncomment to open the image for viewing\n# redacted_image.show()\n</code></pre> <p>You can run presidio image redactor as an http server using either python runtime or using a docker container.</p> <p>Python script example can be found under: /presidio/e2e-tests/tests/test_image_redactor.py</p>"},{"location":"image-redactor/#using-docker-container","title":"Using docker container","text":"<pre><code>cd presidio-image-redactor\ndocker run -p 5003:3000 presidio-image-redactor \n</code></pre>"},{"location":"image-redactor/#using-python-runtime","title":"Using python runtime","text":"<p>Note</p> <p>This requires the Presidio Github repository to be cloned.</p> <pre><code>cd presidio-image-redactor\npython app.py\n# use ocr_test.png as the image to redact, and 255 as the color fill. \n# out.png is the new redacted image received from the server.\ncurl -XPOST \"http://localhost:3000/redact\" -H \"content-type: multipart/form-data\" -F \"image=@ocr_test.png\" -F \"data=\\\"{'color_fill':'255'}\\\"\" &gt; out.png\n</code></pre>"},{"location":"image-redactor/#getting-started-dicom-images","title":"Getting started (DICOM images)","text":"Python <p>Once the Presidio-image-redactor package is installed, run this simple script:</p> <pre><code>import pydicom\nfrom presidio_image_redactor import DicomImageRedactorEngine\n\n# Set input and output paths\ninput_path = \"path/to/your/dicom/file.dcm\"\noutput_dir = \"./output\"\n\n# Initialize the engine\nengine = DicomImageRedactorEngine()\n\n# Option 1: Redact from a loaded DICOM image\ndicom_image = pydicom.dcmread(input_path)\nredacted_dicom_image = engine.redact(dicom_image, fill=\"contrast\")\n\n# Option 2: Redact from a loaded DICOM image and return redacted regions\nredacted_dicom_image, bboxes = engine.redact_and_return_bbox(dicom_image, fill=\"contrast\")\n\n# Option 3: Redact from DICOM file and save redacted regions as json file\nengine.redact_from_file(input_path, output_dir, padding_width=25, fill=\"contrast\", save_bboxes=True)\n\n# Option 4: Redact from directory and save redacted regions as json files\nocr_kwargs = {\"ocr_threshold\": 50}\nengine.redact_from_directory(\"path/to/your/dicom\", output_dir, fill=\"background\", save_bboxes=True, ocr_kwargs=ocr_kwargs)\n</code></pre>"},{"location":"image-redactor/#getting-started-using-the-document-intelligence-ocr-engine","title":"Getting started using the document intelligence OCR engine","text":"<p>Presidio offers two engines for OCR based PII removal. The first is the default engine which uses Tesseract OCR. The second is the Document Intelligence OCR engine which uses Azure's Document Intelligence service, which requires an Azure subscription. The following sections describe how to setup and use the Document Intelligence OCR engine.</p> <p>You will need to register with Azure to get an API key and endpoint.  Perform the steps in the \"Prerequisites\" section of this page.  Once your resource deploys, copy your endpoint and key values and save them for the next step.</p> <p>The most basic usage of the engine can be setup like the following in python <pre><code>diOCR = DocumentIntelligenceOCR(endpoint=\"&lt;your_endpoint&gt;\", key=\"&lt;your_key&gt;\")\n</code></pre></p> <p>The DocumentIntelligenceOCR can also attempt to pull your endpoint and key values from environment variables. <pre><code>$ export DOCUMENT_INTELLIGENCE_ENDPOINT=&lt;your_endpoint&gt;\n$ export DOCUMENT_INTELLIGENCE_KEY=&lt;your_key&gt;\n</code></pre></p>"},{"location":"image-redactor/#document-intelligence-model-support","title":"Document Intelligence Model Support","text":"<p>There are numerous document processing models available, and currently we only support the most basic usage of the model.  For an overview of the functionalities offered by Document Intelligence, see this page. Presidio offers only word-level processing on the result for PII redaction purposes, as all prebuilt document models support this interface. Different models support additional structured support for tables, paragraphs, key-value pairs, fields and other types of metadata in the response. </p> <p>Additional metadata can be sent to the Document Intelligence API call, such as pages, locale, and features, which are documented here. You are encouraged to test each model to see which fits best to your use case.</p>"},{"location":"image-redactor/#creating-an-image-redactor-engine-in-python","title":"Creating an image redactor engine in Python:","text":"<pre><code>diOCR = DocumentIntelligenceOCR()\nia_engine = ImageAnalyzerEngine(ocr=di_ocr)\nmy_engine = ImageRedactorEngine(image_analyzer_engine=ia_engine)\n</code></pre>"},{"location":"image-redactor/#testing-document-inteligence","title":"Testing Document Inteligence","text":"<p>Follow the steps of running the tests</p> <p>The test suite has a series of tests which are only exercised when the appropriate environment variables are populated.  To run the test suite, to test the DocumentIntelligenceOCR engine, call the tests like this:</p> <pre><code>$ export DOCUMENT_INTELLIGENCE_ENDPOINT=&lt;your_endpoint&gt;\n$ export DOCUMENT_INTELLIGENCE_KEY=&lt;your_key&gt;\n$ pytest\n</code></pre>"},{"location":"image-redactor/#evaluating-de-identification-performance","title":"Evaluating de-identification performance","text":"<p>If you are interested in evaluating the performance of the DICOM de-identification against ground truth labels, please see the evaluating DICOM de-identification page.</p>"},{"location":"image-redactor/#side-note-for-windows","title":"Side note for Windows","text":"<p>If you are using a Windows machine, you may run into issues if file paths are too long. Unfortunatley, this is not rare when working with DICOM images that are often nested in directories with descriptive names.</p> <p>To avoid errors where the code may not recognize a path as existing due to the length of the characters in the file path, please enable long paths on your system.</p>"},{"location":"image-redactor/#dicom-data-citation","title":"DICOM Data Citation","text":"<p>The DICOM data used for unit and integration testing for <code>DicomImageRedactorEngine</code> are stored in this repository with permission from the original dataset owners. Please see the dataset information as follows:</p> <p>Rutherford, M., Mun, S.K., Levine, B., Bennett, W.C., Smith, K., Farmer, P., Jarosz, J., Wagner, U., Farahani, K., Prior, F. (2021). A DICOM dataset for evaluation of medical image de-identification (Pseudo-PHI-DICOM-Data) [Data set]. The Cancer Imaging Archive. DOI: https://doi.org/10.7937/s17z-r072</p>"},{"location":"image-redactor/#api-reference","title":"API reference","text":"<p>the API Spec for the Image Redactor REST API reference details and Image Redactor Python API for Python API reference</p>"},{"location":"image-redactor/evaluating_dicom_redaction/","title":"Evaluating DICOM de-identification","text":""},{"location":"image-redactor/evaluating_dicom_redaction/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Introduction</li> <li>Ground truth format</li> <li>Creating ground truth files</li> <li>Evaluating de-identification performance</li> </ul>"},{"location":"image-redactor/evaluating_dicom_redaction/#introduction","title":"Introduction","text":"<p>We can evaluate the performance of the <code>DicomImageRedactorEngine</code> DICOM de-identification by using the <code>DicomImagePiiVerifyEngine</code>. The evaluation results consist of:</p> <ul> <li>Image with bounding boxes identifying detected Personal Health Information (PHI)</li> <li>All positives (True Positives and False Positives)</li> <li>Precision</li> <li>Recall</li> </ul>"},{"location":"image-redactor/evaluating_dicom_redaction/#ground-truth-format","title":"Ground truth format","text":"<p>Ground truth labels are stored as <code>.json</code> files containing filename as the highest level keys. Each filename object consists of an item for each individual entity.</p> <pre><code>{\n    \"your/dicom/dir/file_0.dcm\": [\n        {\n            \"label\": \"DAVIDSON\",\n            \"left\": 25,\n            \"top\": 25,\n            \"width\": 241,\n            \"height\": 37\n        },\n        {\n            \"label\": \"DOUGLAS\",\n            \"left\": 287,\n            \"top\": 25,\n            \"width\": 230,\n            \"height\": 36\n        },\n        {\n            \"label\": \"[M]\",\n            \"left\": 535,\n            \"top\": 25,\n            \"width\": 60,\n            \"height\": 45\n        },\n        {\n            \"label\": \"01.09.2012\",\n            \"left\": 613,\n            \"top\": 26,\n            \"width\": 226,\n            \"height\": 35\n        },\n        {\n            \"label\": \"06.16.1976\",\n            \"left\": 170,\n            \"top\": 72,\n            \"width\": 218,\n            \"height\": 35\n        }\n    ],\n    \"your/dicom/dir/file_1.dcm\": [\n        ...\n    ]\n}\n</code></pre> <p>Return to the Table of Contents</p>"},{"location":"image-redactor/evaluating_dicom_redaction/#creating-ground-truth-files","title":"Creating ground truth files","text":"<p>The <code>DicomImagePiiVerifyEngine</code> class can be used to assist in ground truth label generation. Use the following code snippet to generate the verification image, OCR results, and NER (analyzer) results.</p> <pre><code>import pydicom\nfrom presidio_image_redactor import DicomImagePiiVerifyEngine\n\n# Initialize engine\ndicom_engine = DicomImagePiiVerifyEngine()\n\n# Choose your file to create ground truth for\nfilename = \"path/to/your/file.dcm\"\ninstance = pydicom.dcmread(filename)\npadding_width = 25\n\n# Get OCR and NER results\nverification_image, ocr_results, analyzer_results = dicom_engine.verify_dicom_instance(instance, padding_width)\n\n# Format results for more direct comparison\nocr_results_formatted = dicom_engine.bbox_processor.get_bboxes_from_ocr_results(ocr_results)\nanalyzer_results_formatted = dicom_engine.bbox_processor.get_bboxes_from_analyzer_results(analyzer_results)\n</code></pre> <p>By looking at the output of <code>verify_dicom_instance</code>, we can create a ground truth labels json.</p> <p>Save <code>analyzer_results_formatted</code> as a json file and then perform the following</p> <ol> <li>Group the results into a new item with the file name set as the key.</li> <li>For each item in this group:     a. Remove the \"entity_type\" field and value.     b. Add a new \"label\" field with the value set to the ground truth text PHI with matching coordinate as you can see in the formatted OCR results and verification image.</li> </ol> <p>Then check that your ground truth json contains all the text PHI you can visually confirm in the DICOM image. If something is not detected by the OCR or NER, you will need to manually add the item yourself.</p> <p>Pixel position and size data can be obtained using any labeling software or imaging processing software (e.g., MS Paint) on the verification image.</p> <p>Note: When manually specifying pixel position, make sure to account for any padding introduced in the OCR process (default padding added is 25 pixels).</p>"},{"location":"image-redactor/evaluating_dicom_redaction/#example","title":"Example","text":"<p>Let's say we ran the above code block and see the following for <code>ocr_results_formatted</code> and <code>analyzer_results_formatted</code>.</p> <pre><code>// OCR Results (formatted)\n[\n    {\n        \"left\": 25,\n        \"top\": 25,\n        \"width\": 241,\n        \"height\": 37,\n        \"conf\": 95.833916,\n        \"label\": \"DAVIDSON\"\n    },\n    {\n        \"left\": 287,\n        \"top\": 25,\n        \"width\": 230,\n        \"height\": 36,\n        \"conf\": 93.292221,\n        \"label\": \"DOUGLAS\"\n    }\n]\n\n// Analyzer Results (formatted)\n[\n    {\n        \"entity_type\": \"PERSON\",\n        \"score\": 1.0,\n        \"left\": 25,\n        \"top\": 25,\n        \"width\": 241,\n        \"height\": 37\n    },\n    {\n        \"entity_type\": \"PERSON\",\n        \"score\": 1.0,\n        \"left\": 287,\n        \"top\": 25,\n        \"width\": 230,\n        \"height\": 36\n    }\n]\n</code></pre> <p>Looking at the position and size values of the ground truth and detected text from the analyzer results, we can see that the first item in the analyzer results is likely \"DAVIDSON\" and the second is likely \"DOUGLAS\".</p> <p>With this, we set our ground truth json to the following:</p> <pre><code>// Ground truth json\n{\n    \"path/to/your/file.dcm\": [\n        {\n            \"label\": \"DAVIDSON\",\n            \"left\": 25,\n            \"top\": 25,\n            \"width\": 241,\n            \"height\": 37\n        },\n        {\n            \"label\": \"DOUGLAS\",\n            \"left\": 287,\n            \"top\": 25,\n            \"width\": 230,\n            \"height\": 36\n        }\n    ]\n}\n</code></pre> <p>Return to the Table of Contents</p>"},{"location":"image-redactor/evaluating_dicom_redaction/#evaluating-de-identification-performance","title":"Evaluating de-identification performance","text":"<p>The <code>DicomImagePiiVerifyEngine</code> can be used to evaluate DICOM de-identification performance.</p> <pre><code># Load ground truth for one file\nwith open(gt_path) as json_file:\n    all_ground_truth = json.load(json_file)\nground_truth = all_ground_truth[file_of_interest]\n\n# Select your DICOM instance\ninstance = pydicom.dcmread(file_of_interest)\n\n# Evaluate the DICOM de-identification performance\n_, eval_results = dicom_engine.eval_dicom_instance(instance, ground_truth)\n</code></pre> <p>You can also set optional arguments to see the effect of padding width, ground-truth matching tolerance, and OCR confidence threshold (e.g., <code>ocr_kwargs={\"ocr_threshold\": 50}</code>).</p> <p>For a full demonstration, please see the evaluation notebook.</p> <p>Return to the Table of Contents</p>"},{"location":"samples/","title":"Samples","text":"Topic Data Type Resource Sample Usage Text Python Notebook Presidio Basic Usage Notebook Usage Text Python Notebook Customizing Presidio Analyzer Usage Text Python Notebook Configuring The NLP engine Usage Semi-structured Python Notebook Analyzing structured / semi-structured data in batch Usage Text Python Notebook Encrypting and Decrypting identified entities Usage Text Python Notebook Getting the identified entity value using a custom Operator Usage text Python Notebook Anonymizing known values Usage Images Python Notebook Redacting Text PII from DICOM images Usage Images Python Notebook Using an allow list with image redaction Usage PDF Python Notebook Annotating PII in a PDF Usage Images Python Notebook Plot custom bounding boxes Usage Text Python Notebook Integrating with external services Usage Text Python file Remote Recognizer Usage Structured Python Notebook Presidio Structured Basic Usage Notebook Usage Text Python file Azure AI Language as a Remote Recognizer Usage CSV Python file Analyze and Anonymize CSV file Usage Text Python Using Flair as an external PII model Usage Text Python file Using Span Marker as an external PII model Usage Text Python file Using Transformers as an external PII model Usage Text Python file Pseudonomization (replace PII values using mappings) Usage Text Python file Passing a lambda as a Presidio anonymizer using Faker Usage Text Python file Synthetic data generation with OpenAI Usage Text LiteLLM Proxy PII Masking LLM calls across Anthropic/Gemini/Bedrock/Azure, etc. Usage REST API (postman) Presidio as a REST endpoint Deployment App Service Presidio with App Service Deployment Kubernetes Presidio with Kubernetes Deployment Spark/Azure Databricks Presidio with Spark Deployment Azure Data Factory with App Service ETL for small dataset Deployment Azure Data Factory with Databricks ETL for large datasets ADF Pipeline Azure Data Factory Add Presidio as an HTTP service to your Azure Data Factory ADF Pipeline Azure Data Factory Add Presidio on Databricks to your Azure Data Factory Demo Streamlit app Create a simple demo app using Streamlit"},{"location":"samples/deployments/","title":"Example deployments","text":"<ul> <li>Azure App Service</li> <li>Kubernetes</li> <li>Spark/Azure Databricks</li> <li>Azure Data Factory</li> </ul>"},{"location":"samples/deployments/app-service/","title":"Deploy presidio services to an Azure App Service","text":"<p>Presidio containers can be hosted on an Azure App Service. Azure App Service provides a managed production environment, which supports docker containers and devops optimizations. It is a global scale service with built in security and compliance features that fits multiple cloud workloads. The presidio team uses Azure App Service for both its development environment and the presidio demo website.</p>"},{"location":"samples/deployments/app-service/#deploy-presidio-services-to-azure","title":"Deploy Presidio services to Azure","text":"<p>Use the following button to deploy presidio services to your Azure subscription.</p> <p></p>"},{"location":"samples/deployments/app-service/#deploy-using-command-line-script","title":"Deploy using command-line script","text":"<p>The following script can be used alternatively to the ARM template deployment above. It sets up the same components which are required for each of the presidio services (analyzer and anonymizer) as the template.</p>"},{"location":"samples/deployments/app-service/#basic-setup","title":"Basic setup","text":"<pre><code>RESOURCE_GROUP=&lt;resource group name&gt;\nAPP_SERVICE_NAME=&lt;name of app service&gt;\nLOCATION=&lt;location&gt;\nAPP_SERVICE_SKU=&lt;sku&gt;\n\nIMAGE_NAME=mcr.microsoft.com/presidio-analyzer\n# the following parameters are only required if you build and deploy your own containers from a private registry\nACR_USER_NAME=&lt;user name&gt;\nACR_USER_PASSWORD=&lt;password&gt;\n\n# create the resource group\naz group create --name $RESOURCE_GROUP\n# create the app service plan\naz appservice plan create --name $APP_SERVICE_NAME-plan --resource-group $RESOURCE_GROUP  \\\n--is-linux --location $LOCATION --sku $APP_SERVICE_SKU\n# create the web app using the official presidio images\naz webapp create --name $APP_SERVICE_NAME --plan $APP_SERVICE_NAME-plan \\\n--resource-group $RESOURCE_GROUP -i $IMAGE_NAME\n\n# or alternatively, if building presidio and deploying from a private container registry\naz webapp create --name $APP_SERVICE_NAME --plan $APP_SERVICE_NAME-plan \\\n--resource-group $RESOURCE_GROUP -i $IMAGE_NAME -s $ACR_USER_NAME -w $ACR_USER_PASSWORD\n</code></pre>"},{"location":"samples/deployments/app-service/#blocking-network-access","title":"Blocking network access","text":"<p>Use the following script to restrict network access for a specific ip such as your computer, a front-end website or an API management.</p> <pre><code>FRONT_END_IP_RANGE=[front end ip range]\naz webapp config access-restriction add --resource-group $RESOURCE_GROUP --name $APP_SERVICE_NAME \\\n  --rule-name 'Front-end allow rule' --action Allow --ip-address $FRONT_END_IP_RANGE --priority 100\n</code></pre> <p>Further network isolation, using virtual networks, is possible using an Isolated tier of Azure App Service.</p>"},{"location":"samples/deployments/app-service/#configure-app-service-logging","title":"Configure App Service Logging","text":""},{"location":"samples/deployments/app-service/#logging-to-the-app-service-file-system","title":"Logging to the App Service File System","text":"<pre><code>az webapp log config --name $APP_SERVICE_NAME --resource-group $RESOURCE_GROUP \\\n--application-logging filesystem --detailed-error-messages true \\\n--docker-container-logging filesystem --level information\n</code></pre>"},{"location":"samples/deployments/app-service/#logging-to-log-analytics-workspace","title":"Logging to Log Analytics Workspace","text":"<pre><code>LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP=&lt;resource group of log analytics&gt;\nLOG_ANALYTICS_WORKSPACE_NAME=&lt;log analytics name&gt;\n\n# create a log analytics workspace\naz monitor log-analytics workspace create --resource-group $LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP --workspace-name $LOG_ANALYTICS_WORKSPACE_NAME\n\n# query the log analytics workspace id\nLOG_ANALYTICS_WORKSPACE_ID=$(az monitor log-analytics workspace show --resource-group $LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP --workspace-name $LOG_ANALYTICS_WORKSPACE_NAME --query id -o tsv)\n# query the app service id\nAPP_SERVICE_ID=$(az monitor log-analytics workspace show --resource-group $RESOURCE_GROUP --name $APP_SERVICE_NAME --query id -o tsv)\n\n# create the diagnostics settings\naz monitor diagnostic-settings create --name $APP_SERVICE_NAME-diagnostics --resource /\n$APP_SERVICE_ID --logs   '[{\"category\": \"AppServicePlatformLogs\",\"enabled\": true}, {\"category\": \"AppServiceConsoleLogs\", \"enabled\": true}]' --metrics '[{\"category\": \"AllMetrics\",\"enabled\": true}]' --workspace $LOG_ANALYTICS_WORKSPACE_ID\n</code></pre>"},{"location":"samples/deployments/app-service/#using-an-arm-template","title":"Using an ARM template","text":"<p>Alternatlively, you can use the provided ARM template which can deploy either both or any of the presidio services. Note that while Log Analytics integration with Azure App Service is in preview, the ARM template deployment will not create a Log Analytics resource or configure the diagnostics settings from the App Service to a Log Analytics workspace. To deploy the app services using the provided ARM template, fill in the provided values.json file with the required values and run the following script.</p> <pre><code>az deployment group create --resource-group $RESOURCE_GROUP --template-file presidio-services.json --parameters @values.json\n</code></pre>"},{"location":"samples/deployments/data-factory/","title":"Anonymize PII entities with Azure Data Factory","text":"<p>You can build data anonymization ETL pipelines using Azure Data Factory (ADF) and Presidio. This section provides instructions on how to leverage presidio in Azure Data Factory:</p> <ol> <li>Complete samples - Setup Azure Data Factory and Presidio in a single deployment and run the samples.</li> <li>Using Azure Data Factory Template Gallery to anonymize text files - If you already have an instance of Azure Data Factory and would like to use the built in data-anonymization-with-presidio template to anonymize text files.</li> <li>Using Azure Data Factory Template Gallery to anonymize datasets - If you already have an instance of Azure Data Factory and would like to use the built in data-anonymization-with-presidio template to anonymize csv datasets.</li> </ol>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-databricks/","title":"Anonymize PII entities in datasets using Azure Data Factory template and Presidio on Databricks","text":"<p>This sample uses the built in data anonymization template of Azure Data Factory (which is a part of the Template Gallery) to copy a csv dataset from one location to another, while anonymizing PII data from a text column in the dataset. It leverages the code for using Presidio on Azure Databricks to call Presidio as a Databricks notebook job in the Azure Data Factory (ADF) pipeline to transform the input dataset before mergine the results to an Azure Blob Storage.</p> <p>Note that this solution is capabale of transforming large datasets. For smaller, text based input you may want to work with the Data Anonymization with Presidio as an HTTP service template which offers an easier deployment for Presidio.</p> <p>The sample deploys the following Azure Services:</p> <ul> <li>Azure Storage - The target storage account where data will be persisted.</li> <li>Azure Databricks - Host presidio to anonymize the data.</li> </ul> <p>Additionaly you should already have an instance of Azure Data Factory which hosts and orchestrates the transformation pipeline and a storage account which holds the source files.</p>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-databricks/#about-this-solution-template","title":"About this Solution Template","text":"<p>This template gets the files from your source file-based store. It then anonymizes the content and uploads each of them to the destination store.</p> <p>The template contains three activities:</p> <ul> <li>AnonymizeSource runs the presidio notebook on the input file to create an output folder with csv parts.</li> <li>MergeAnonymizedToTarget merges the csv parts from databricks output folder to a single csv on the target storage container.</li> <li>DeleteAnonymized deletes the temporary output folder.</li> </ul> <p>The template defines four parameters:</p> <ul> <li>SourceStore_Location is the container name of your source store where you want to move files from (STORAGE_CONTAINER_NAME).</li> <li>DestinationStore_Name is the container name in the target storage account which is provisioned by the ARM template.</li> <li>SourceFile_Name is the name of the input file.</li> <li>TextColumn_Name is the name of the column to be anonymized.</li> </ul>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-databricks/#how-to-use-this-solution-template","title":"How to use this Solution Template","text":"<p>To use this template you should first setup the required infrastructure for the sample to run, then setup the template in Azure Data Factory.</p>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-databricks/#setup-presidio","title":"Setup Presidio","text":"<p>Provision and setup the datbricks cluster by following the Deploy and Setup steps in presidio-spark sample. Take a note of the authentication token and do not follow the \"Running the sample\" steps.</p>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-databricks/#setup-azure-data-factory","title":"Setup Azure Data Factory","text":"<ol> <li> <p>Go to the Data anonymization with Presidio on Databricks template. Select the AnonymizedCSV connection (Azure Storage) and select \"New\" from the drop down menu. </p> </li> <li> <p>Name the service \"PresidioStorage\" and select the storage account that was created in the previous steps from your subscription. Note that Target source was also selecte as the sample uses the same storage account for both source and target. </p> </li> <li> <p>Select the Anonymize Source connection (Databricks) and select \"New\" from the drop down menu. </p> </li> <li> <p>Name the service \"PresidioDatabricks\" and select the Azure Databricks workspace that was created in the previous steps from your subscription. Follow through the steps to input the authentication token which was generated in the previous step, or create a new one by following this guide. Select presidio_cluster to run the job. </p> </li> <li> <p>Select Use this template tab</p> </li> <li> <p>You'll see the pipeline, as in the following example: </p> </li> <li> <p>Upload a csv file to the storage container and select Debug, enter the Parameters, and then select Finish. The parameters are the container where you want to move files from, the container name where you want to move the anonymized files to, the csv file name and the name of a text column in the csv file. </p> </li> <li> <p>Review the result. </p> </li> </ol>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-http/","title":"Anonymize PII entities in text using Azure Data Factory template and Presidio as an HTTP service","text":"<p>This sample uses the built in data anonymization template of Azure Data Factory which is a part of the Template Gallery to move a set of text files from one location to another while anonymizing their content. It leverages the code for using Presidio on Azure App Service to call Presidio as an HTTP REST endpoint in the Azure Data Factory (ADF) pipeline while parsing and storing each file as an Azure Blob Storage.</p> <p>Note that given the solution architecture which call presidio services using HTTP, this sample should be used for up to 5000 files, each up to 200KB in size. The restrictions are based on ADF lookup-activity which is used to iterate the files in the storage container (up to 5000 records), and having Presidio as an HTTP endpoint with text being sent over network to be anonymized.  For larger sets please work with the Data Anonymization with Presidio on Databricks template.</p> <p>The sample deploys the following Azure Services:</p> <ul> <li>Azure KeyVault - Holds the access keys for Azure Storage to avoid having keys and secrets in the code.</li> <li>Azure Storage - The target storage account where data will be persisted.</li> <li>Azure App Service - Host presidio to anonymize the data.</li> </ul> <p>Additionaly you should already have an instance of Azure Data Factory which host and orchestrate the transformation pipeline and a storage account which holds the source files.</p>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-http/#about-this-solution-template","title":"About this Solution Template","text":"<p>This template gets the files from your source file-based store. It then anonymizes the content and uploads each of them to the destination store.</p> <p>The template contains eight activities:</p> <ul> <li>GetMetadata gets the list of objects including the files and subfolders from your folder on source store. It will not retrieve the objects recursively.</li> <li>Filter filter the objects list from GetMetadata activity to select the files only.</li> <li>GetSASToken gets the target storage account SAS token from the Azure Key Vault.</li> <li>ForEach gets the file list from the Filter activity and then iterates over the list and passes each file to the Anonymization activities.</li> <li>LoadFileContent loads the content of a text file to an ADF Lookup.</li> <li>PresidioAnalyze sends the text content to Presidio Analyzer.</li> <li>PresidioAnonymize sends the text and the analysis response to Presidio Anonymizer to get the anonymized text.</li> <li>UploadBlob uses Azure Blob Storage REST API to upload the anonymized text to the target container.</li> </ul> <p>The template defines four parameters:</p> <ul> <li>SourceStore_Location is the container name of your source store where you want to move files from.</li> <li>DestinationStore_Name is the name of the target storage account which is provisioned by the ARM template.</li> <li>DestinationStore_Location is the container name of your destination store where you want to move files to. it has a default value of a container which was created during provisioning of the ARM template (presidio).</li> <li>KeyVault_Name is the name of the Azure Key Vault which is provisioned by the ARM template.</li> <li>Analyzer_Url is the URL for the Analyzer App Service which is provisioned by the ARM template.</li> <li>Anonymizer_Url is the URL for the Anonymizer App Service which is provisioned by the ARM template.</li> </ul>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-http/#how-to-use-this-solution-template","title":"How to use this Solution Template","text":"<p>To use this template you should first setup the required infrastructure for the sample to run, then setup the template in Azure Data Factory.</p>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-http/#setup-presidio","title":"Setup Presidio","text":"<p>Create the Azure App Service, the storage accounts and an Azure Key Vault by clicking the Deploy-to-Azure button, or by running the following script to provision the provided ARM template.</p> <p></p> <pre><code>RESOURCE_GROUP=[Name of resource group]\nLOCATION=[location of resources]\n\naz group create --name $RESOURCE_GROUP --location $LOCATION\naz deployment group create -g $RESOURCE_GROUP --template-file ./arm-templates/azure-deploy-adf-template-gallery-http.json\n</code></pre> <p>Note that:</p> <ul> <li>A SAS token keys is created and read from Azure Storage and then imported to Azure Key Vault. Using ARM template built in functions: listAccountSas. This token is time limited.</li> <li>An access policy grants the Azure Data Factory managed identity access to the Azure Key Vault. You should provide your ADF client principal ID by following this guide.</li> </ul>"},{"location":"samples/deployments/data-factory/presidio-data-factory-template-gallery-http/#setup-azure-data-factory","title":"Setup Azure Data Factory","text":"<ol> <li> <p>Go to the Data anonymization with Presidio as an HTTP service template. Select existing connection or create a New connection to your source file store where you want to move files from. Be aware that DataSource_Folder and DataSource_File are reference to the same connection of your source file store. </p> </li> <li> <p>Select Use this template tab</p> </li> <li> <p>You'll see the pipeline, as in the following example: </p> </li> <li> <p>Select Debug, enter the Parameters, and then select Finish. The parameters are the container where you want to move files from and the container path where you want to move the anonymized files to. </p> </li> <li> <p>Review the result. </p> </li> </ol>"},{"location":"samples/deployments/data-factory/presidio-data-factory/","title":"Anonymize PII entities in an Azure Data Factory ETL Pipeline","text":"<p>The following samples showcase two scenarios which use Azure Data Factory (ADF) to move a set of JSON objects from an online location to an Azure Storage while anonymizing their content. The first sample leverages the code for using Presidio on Azure App Service to call Presidio as an HTTP REST endpoint in the ADF pipeline while parsing and storing each file as an Azure Blob Storage. The second sample leverage the code for using Presidio on spark to run over a set of files on an Azure Blob Storage to anonymnize their content, in the case of having a large data set that requires the scale of databricks.</p> <p>The samples deploy and use the following Azure Services:</p> <ul> <li>Azure Data Factory - Host and orchestrate the transformation pipeline.</li> <li>Azure KeyVault - Holds the access keys for Azure Storage to avoid having keys and secrets in the code.</li> <li>Azure Storage - Persistence layer of this sample.</li> <li>Azure Databricks/ Azure App Service - Host presidio to anonymize the data.</li> </ul> <p>The input file used by the samples is hosted on presidio-research repository. It is setup as a variable on the provided ARM template and used by Azure Data Factory as the input source.</p>"},{"location":"samples/deployments/data-factory/presidio-data-factory/#option-1-presidio-as-an-http-rest-endpoint","title":"Option 1: Presidio as an HTTP REST endpoint","text":"<p>By using Presidio as an HTTP endpoint, the user can select which infrastructure best suits their requirements. in this sample, Presidio is deployed to an Azure App Service, but other deployment targets can be used, such as kubernetes.</p> <p></p>"},{"location":"samples/deployments/data-factory/presidio-data-factory/#deploy-the-arm-template","title":"Deploy the ARM template","text":"<p>Create the Azure App Service and the ADF pipeline by clicking the Deploy-to-Azure button, or by running the following script to provision the provided ARM template.</p> <p></p> <pre><code>RESOURCE_GROUP=[Name of resource group]\nLOCATION=[location of resources]\n\naz group create --name $RESOURCE_GROUP --location $LOCATION\naz deployment group create -g $RESOURCE_GROUP --template-file ./arm-templates/azure-deploy-adf-app-service.json\n</code></pre> <p>Note that:</p> <ul> <li>A SAS token keys is created and read from Azure Storage and then imported to Azure Key Vault. Using ARM template built in functions: listAccountSas.</li> <li>An access policy grants the Azure Data Factory managed identity access to the Azure Key Vault by using ARM template reference function to the Data Factory object and acquire its identity.principalId property. This is enabled by setting the data factory ARM resource's identity attribute to managed identity (SystemAssigned).</li> </ul>"},{"location":"samples/deployments/data-factory/presidio-data-factory/#about-this-solution-template","title":"About this Solution Template","text":"<p>This template gets a collection of JSON documents from a file on GitHub. It then extracts one of the text fields of the document, anonymizes the content and uploads it as a text file to the destination store.</p> <p>The template contains seven activities:</p> <ul> <li>GetDataSet-\u200aCopy the dataset from GitHub to the first folder on the Azure Storage blob container (/dataset).</li> <li>LoadSet-\u200aLoads the dataset into the Azure Data Factory memory for processing in a for-each loop.</li> <li>GetSASToken\u200a-\u200aGet the SAS token from Azure Key Vault. This will be used later for writing to the blob container.</li> <li>SaveBlobs\u200a-\u200aIs a For-Each loop activity. It includes a clause which is executed for each document in the array.</li> <li>PresidioAnalyze\u200a-\u200aSends the text to presidio analyzer endpoint.</li> <li>PresidioAnonymize\u200a-\u200aSends the response from presidio analyzer to presidio anonymizer endpoint.</li> <li>UploadBlob\u200a-\u200aSaves the anonymized response from presidio to a randomly named text file on the target Azure Blob Storage.</li> </ul>"},{"location":"samples/deployments/data-factory/presidio-data-factory/#option-2-presidio-on-azure-databricks","title":"Option 2: Presidio on Azure Databricks","text":"<p>By using Presidio as a Notebook step in ADF, we allow Databricks to scale presidio according to the cluster capabilities and the input dataset. Using presidio as a native python package in pyspark can unlock more analysis and de-identifiaction scenarios.</p> <p></p>"},{"location":"samples/deployments/data-factory/presidio-data-factory/#pre-requisite-deploy-azure-databricks","title":"Pre-requisite - Deploy Azure Databricks","text":"<p>Provision and setup the datbricks cluster by following the steps in presidio-spark sample. Note the output key and export it as DATABRICKS_TOKEN environment variable.</p>"},{"location":"samples/deployments/data-factory/presidio-data-factory/#deploy-the-arm-template_1","title":"Deploy the ARM template","text":"<p>Create the rest of the services by running the following script which uses the provided ARM template.</p> <pre><code>RESOURCE_GROUP=[Name of resource group]\nLOCATION=[location of resources]\nDATABRICKS_HOST=https://$DATABRICKS_WORKSPACE_URL\nDATABRICKS_CLUSTER_ID=$(databricks clusters get --cluster-name presidio_cluster | jq -r .cluster_id)\nDATABRICKS_NOTEBOOK_LOCATION=\"/notebooks/01_transform_presidio\"\n\naz deployment group create -g $RESOURCE_GROUP --template-file ./arm-templates/azure-deploy-adf-databricks.json --parameters Databricks_accessToken=$DATABRICKS_TOKEN Databricks_clusterId=$DATABRICKS_CLUSTER_ID Databricks_notebookLocation=$DATABRICKS_NOTEBOOK_LOCATION Databricks_workSpaceUrl=$DATABRICKS_HOST AzureBlobStorage_accountName=$STORAGE_ACCOUNT_NAME AzureBlobStorage_cotainerName=$STORAGE_CONTAINER_NAME\n</code></pre> <p>Note that: Two keys are read from Azure Storage and imported to Azure Key Vault, the account Access Token and a SAS token, using ARM template built in functions: listAccountSas and listKeys.</p>"},{"location":"samples/deployments/data-factory/presidio-data-factory/#about-this-solution-template_1","title":"About this Solution Template","text":"<p>This template gets a collection of JSON documents from a file on GitHub. It then extracts one of the text fields of the document and saves it to a text file on a temporary folder in the storage account (un-anonymized content). It then runs a spark notebook job that anonymizes the content of the files in that folder and saves the result as csv files on the destination store.</p> <p>The template contains seven activities:</p> <ul> <li>GetDataSet\u200a-\u200aCopy the dataset from GitHub to the first folder on the Azure Storage blob container (/dataset).</li> <li>GetSASToken\u200a-\u200aGet the SAS token from Azure Key Vault. This will be used later for writing to the blob container.</li> <li>LoadSet\u200a-\u200a Loads the dataset into the Azure Data Factory memory for processing in a for-each loop.</li> <li>SaveBlobs\u200a-\u200aIs a For-Each loop activity. It includes a clause which is executed for each document in the array.</li> <li>UploadBlob\u200a-\u200aSaves the text file on a temporary container on the target Azure Blob Storage</li> <li>GetSecret\u200a-\u200aGet the storage account secret from Azure Key Vault. This will be used later for accessing the blob container from databricks</li> <li>Presidio-Anonymize\u200a-\u200aIs a databricks spark job which runs presidio on the temporary storage container. the result of this job is a new container (/output) with csv files that contain the anonymized text.</li> </ul>"},{"location":"samples/deployments/k8s/","title":"Deploy presidio to Kubernetes","text":"<p>You can install Presidio locally using KIND, as a service in Kubernetes or AKS.</p> <ul> <li>Deploy locally using KIND</li> <li>Deploy with Kubernetes</li> <li>Prerequisites</li> <li>Step by Step Deployment with customizable parameters</li> </ul>"},{"location":"samples/deployments/k8s/#deploy-locally-with-kind","title":"Deploy locally with KIND","text":"<p>KIND (Kubernetes IN Docker).</p> <ol> <li> <p>Install Docker.</p> </li> <li> <p>Clone Presidio.</p> </li> <li> <p>Run the following script, which will use KIND (Kubernetes emulation in Docker)</p> </li> </ol> <pre><code>cd docs/samples/deployments/k8s/deployment/\n./run-with-kind.sh\n</code></pre> <ol> <li>Wait and verify all pods are running:</li> </ol> <pre><code>kubectl get pod -n presidio\n</code></pre> <ol> <li>Port forwarding of HTTP requests to the API micro-service will be done automatically. In order to run manual:</li> </ol> <pre><code>kubectl port-forward &lt;presidio-analyzer-pod-name&gt; 8080:8080 -n presidio\n</code></pre>"},{"location":"samples/deployments/k8s/#presidio-as-a-service-with-kubernetes","title":"Presidio As a Service with Kubernetes","text":""},{"location":"samples/deployments/k8s/#prerequisites","title":"Prerequisites","text":"<ol> <li>A Kubernetes 1.18+ cluster with RBAC enabled. If you are using AKS RBAC is enabled by default.</li> </ol> <p>!!! note: Note       Note the pod's resource requirements (CPU and memory) and plan the cluster accordingly.</p> <ol> <li> <p>kubectl installed. Verify you can communicate with the cluster by running:</p> <pre><code>kubectl version\n</code></pre> </li> <li> <p>Local helm client.</p> </li> <li>Optional - Container Registry - such as ACR. Only needed if you are using your own presidio images and not the default ones from from Microsoft syndicates container catalog</li> <li>Recent presidio repo is cloned on your local machine.</li> </ol>"},{"location":"samples/deployments/k8s/#step-by-step-deployment-with-customizable-parameters","title":"Step by step deployment with customizable parameters","text":"<ol> <li> <p>Install Helm with RBAC.</p> </li> <li> <p>Optional - Ingress controller for presidio API, e.g., NGINX.</p> </li> </ol> <p>NOTE: Presidio is deployed with an ingress controller by default, and uses <code>nginx</code> as <code>ingress.class</code>.  To change this behavior, deploy the helm chart with <code>ingress.enabled=false</code>.</p> <ol> <li>Deploy from <code>/docs/samples/deployments/k8s/charts/presidio</code></li> </ol> <pre><code># Choose a namespace and ensure it is created\nNAMESPACE=presidio\n\n# Choose the tag, from mcr.microsoft.com, e.g. `latest`\nTAG=latest\n\n# Choose a name for the deployment\nNAME=&lt;name&gt;\n\n# Use Helm to install all required components\nhelm install $NAME . --set tag=$PRESIDIO_LABEL --namespace $NAMESPACE\n\n# If you have your own images in a separate ACR, run\nDOCKER_REGISTRY=&lt;your_registry&gt;\nhelm install $NAME . --set registry=$DOCKER_REGISTRY,tag=$PRESIDIO_LABEL . --namespace $NAMESPACE\n</code></pre>"},{"location":"samples/deployments/spark/","title":"Anonymize PII using Presidio on Spark","text":"<p>You can leverages presidio to perform data anonymization as part of spark notebooks.</p> <p>The following sample uses Azure Databricks and simple text files hosted on Azure Blob Storage. However, it can easily change to fit any other scenario which requires PII analysis or anonymization as part of spark jobs.</p> <p>Note that this code works for Databricks runtime 8.1 (spark 3.1.1) and the libraries described here.</p>"},{"location":"samples/deployments/spark/#the-basics-of-working-with-presidio-in-spark","title":"The basics of working with Presidio in Spark","text":"<p>A typical use case of Presidio in Spark is transforming a text column in a data frame, by anonymizing its content. The following code sample, a part of transform presidio notebook, is the basis of the e2e sample which uses Azure Databricks as the Spark environment.</p> <pre><code>anonymized_column = \"value\" # name of column to anonymize\nanalyzer = AnalyzerEngine()\nanonymizer = AnonymizerEngine()\n\n# broadcast the engines to the cluster nodes\nbroadcasted_analyzer = sc.broadcast(analyzer)\nbroadcasted_anonymizer = sc.broadcast(anonymizer)\n\n# define a pandas UDF function and a series function over it.\ndef anonymize_text(text: str) -&gt; str:\n    analyzer = broadcasted_analyzer.value\n    anonymizer = broadcasted_anonymizer.value\n    analyzer_results = analyzer.analyze(text=text, language=\"en\")\n    anonymized_results = anonymizer.anonymize(\n        text=text,\n        analyzer_results=analyzer_results,\n        operators={\n            \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"&lt;ANONYMIZED&gt;\"})\n        },\n    )\n    return anonymized_results.text\n\n\ndef anonymize_series(s: pd.Series) -&gt; pd.Series:\n    return s.apply(anonymize_text)\n\n\n# define a the function as pandas UDF\nanonymize = pandas_udf(anonymize_series, returnType=StringType())\n\n# apply the udf\nanonymized_df = input_df.withColumn(\n    anonymized_column, anonymize(col(anonymized_column))\n)\n</code></pre>"},{"location":"samples/deployments/spark/#pre-requisites","title":"Pre-requisites","text":"<p>If you do not have an instance of Azure Databricks, follow through with the following steps to provision and setup the required infrastrucutre.</p> <p>If you do have a Databricks workspace and a cluster you wish to configure to run Presidio, jump over to the Configure an existing cluster section.</p>"},{"location":"samples/deployments/spark/#deploy-infrastructure","title":"Deploy Infrastructure","text":"<p>Provision the Azure resources by running the following script.</p> <pre><code>export RESOURCE_GROUP=[resource group name]\nexport STORAGE_ACCOUNT_NAME=[storage account name]\nexport STORAGE_CONTAINER_NAME=[blob container name]\nexport DATABRICKS_WORKSPACE_NAME=[databricks workspace name]\nexport DATABRICKS_SKU=[basic/standard/premium]\nexport LOCATION=[location]\n\n# Create the resource group\naz group create --name $RESOURCE_GROUP --location $LOCATION\n\n# Use ARM template to build the resources and get back the workspace URL\ndeployment_response=$(az deployment group create -g $RESOURCE_GROUP --template-file ./docs/samples/deployments/spark/arm-template/databricks.json  --parameters location=$LOCATION workspaceName=$DATABRICKS_WORKSPACE_NAME storageAccountName=$STORAGE_ACCOUNT_NAME containerName=$STORAGE_CONTAINER_NAME)\n\nexport DATABRICKS_WORKSPACE_URL=$(echo $deployment_response | jq -r \".properties.outputs.workspaceUrl.value\")\nexport DATABRICKS_WORKSPACE_ID=$(echo $deployment_response | jq -r \".properties.outputs.workspaceId.value\")\n</code></pre>"},{"location":"samples/deployments/spark/#setup-databricks","title":"Setup Databricks","text":"<p>The following script will setup a new cluster in the databricks workspace and prepare it to run presidio anonymization jobs. Once finished, the script will output an access key which you can use when working with databricks cli.</p> <pre><code>sh ./scripts/configure_databricks.sh\n</code></pre>"},{"location":"samples/deployments/spark/#configure-an-existing-cluster","title":"Configure an existing cluster","text":"<p>Only follow through with the steps in this section if you have an existing databricks workspace and clsuter you wish to configure to run presidio. If you've followed through with the \"Deploy Infrastructure\" and \"Setup Databricks\" sections you do not have to run the script in this section.</p>"},{"location":"samples/deployments/spark/#set-up-secret-scope-and-secrets-for-storage-account","title":"Set up secret scope and secrets for storage account","text":"<p>Add an Azure Storage account key to secret scope.</p> <pre><code>STORAGE_PRIMARY_KEY=[Primary key of storage account]\n\ndatabricks secrets create-scope --scope storage_scope --initial-manage-principal users\ndatabricks secrets put --scope storage_scope --key storage_account_access_key --string-value \"$STORAGE_PRIMARY_KEY\"\n</code></pre>"},{"location":"samples/deployments/spark/#upload-or-update-cluster-init-scripts","title":"Upload or update cluster init scripts","text":"<p>Presidio libraries are loaded to the cluster on init. Upload the cluster setup script or add its content to the existing cluster's init script.</p> <pre><code>databricks fs cp \"./setup/startup.sh\" \"dbfs:/FileStore/dependencies/startup.sh\"\n</code></pre> <p>Setup the cluster to run the init script.</p>"},{"location":"samples/deployments/spark/#upload-presidio-notebooks","title":"Upload presidio notebooks","text":"<pre><code>databricks workspace import_dir \"./notebooks\" \"/notebooks\" --overwrite\n</code></pre>"},{"location":"samples/deployments/spark/#update-cluster-environment","title":"Update cluster environment","text":"<p>Add the following environment variables to your databricks cluster:</p> <pre><code>\"STORAGE_MOUNT_NAME\": \"/mnt/files\"\n\"STORAGE_CONTAINER_NAME\": [Blob container name]\n\"STORAGE_ACCOUNT_NAME\": [Storage account name]\n</code></pre>"},{"location":"samples/deployments/spark/#mount-the-storage-container","title":"Mount the storage container","text":"<p>Run the notebook 00_setup to mount the storage account to databricks.</p>"},{"location":"samples/deployments/spark/#running-the-sample","title":"Running the sample","text":""},{"location":"samples/deployments/spark/#configure-presidio-transformation-notebook","title":"Configure Presidio transformation notebook","text":"<p>From Databricks workspace, under notebooks folder, open the provided 01_transform_presidio notebook and attach it to the cluster preisidio_cluster. Run the first code-cell and note the following parameters on the top end of the notebook (notebook widgets) and set them accordingly</p> <ul> <li>Input File Format - text (selected).</li> <li>Input path - a folder on the container where input files are found.</li> <li>Output Folder - a folder on the container where output files will be written to.</li> <li>Column to Anonymize - value (selected).</li> </ul>"},{"location":"samples/deployments/spark/#run-the-notebook","title":"Run the notebook","text":"<p>Upload a text file to the blob storage input folder, using any preferd method (Azure Portal, Azure Storage Explorer, Azure CLI).</p> <pre><code>az storage blob upload --account-name $STORAGE_ACCOUNT_NAME  --container $STORAGE_CONTAINER_NAME --file ./[file name] --name input/[file name]\n</code></pre> <p>Run the notebook cells, the output should be csv files which contain two columns, the original file name, and the anonymized content of that file.</p>"},{"location":"samples/deployments/spark/notebooks/00_setup/","title":"00 setup","text":"<p>Databricks notebook source MAGIC %md MAGIC # Mount Azure Storage blob container MAGIC MAGIC Mount an Azure Storage blob container to a databricks cluster. MAGIC MAGIC This sciprt requires the following environment variables to be set. MAGIC MAGIC <ol> MAGIC <li>STORAGE_MOUNT_NAME - Name of mount which will be used by notebooks accessing the mount point.</li> MAGIC <li>STORAGE_ACCOUNT_NAME - Azure Storage account name.</li> MAGIC <li>STORAGE_CONTAINER_NAME - Blob container name</li> MAGIC </ol> MAGIC MAGIC Additionaly, the following secrets are used. MAGIC MAGIC <ol> MAGIC <li>storage_account_access_key under scope storage_scope - storage account key.</li> MAGIC </ol></p> <p>COMMAND ----------</p> In\u00a0[\u00a0]: Copied! <pre>import os\n</pre> import os In\u00a0[\u00a0]: Copied! <pre># Environment Variables\nstorage_mount_name = os.environ[\"STORAGE_MOUNT_NAME\"]\nstorage_account_name = os.environ[\"STORAGE_ACCOUNT_NAME\"]\nstorage_container_name = os.environ[\"STORAGE_CONTAINER_NAME\"]\n</pre> # Environment Variables storage_mount_name = os.environ[\"STORAGE_MOUNT_NAME\"] storage_account_name = os.environ[\"STORAGE_ACCOUNT_NAME\"] storage_container_name = os.environ[\"STORAGE_CONTAINER_NAME\"] <p>COMMAND ----------</p> In\u00a0[\u00a0]: Copied! <pre># Retrieve storage credentials\nstorage_account_access_key = dbutils.secrets.get(\n    scope=\"storage_scope\", key=\"storage_account_access_key\"\n)\n</pre> # Retrieve storage credentials storage_account_access_key = dbutils.secrets.get(     scope=\"storage_scope\", key=\"storage_account_access_key\" ) In\u00a0[\u00a0]: Copied! <pre># unmount container if previously mounted\ndef sub_unmount(str_path):\n    if any(mount.mountPoint == str_path for mount in dbutils.fs.mounts()):\n        dbutils.fs.unmount(str_path)\n</pre> # unmount container if previously mounted def sub_unmount(str_path):     if any(mount.mountPoint == str_path for mount in dbutils.fs.mounts()):         dbutils.fs.unmount(str_path) In\u00a0[\u00a0]: Copied! <pre>sub_unmount(storage_mount_name)\n# Refresh mounts\ndbutils.fs.refreshMounts()\n</pre> sub_unmount(storage_mount_name) # Refresh mounts dbutils.fs.refreshMounts() In\u00a0[\u00a0]: Copied! <pre># mount the container\ndbutils.fs.mount(\n    source=\"wasbs://\"\n    + storage_container_name\n    + \"@\"\n    + storage_account_name\n    + \".blob.core.windows.net\",\n    mount_point=storage_mount_name,\n    extra_configs={\n        \"fs.azure.account.key.\"\n        + storage_account_name\n        + \".blob.core.windows.net\": storage_account_access_key\n    },\n)\n</pre> # mount the container dbutils.fs.mount(     source=\"wasbs://\"     + storage_container_name     + \"@\"     + storage_account_name     + \".blob.core.windows.net\",     mount_point=storage_mount_name,     extra_configs={         \"fs.azure.account.key.\"         + storage_account_name         + \".blob.core.windows.net\": storage_account_access_key     }, )"},{"location":"samples/deployments/spark/notebooks/01_transform_presidio/","title":"01 transform presidio","text":"<p>Databricks notebook source MAGIC %md MAGIC # Anonymize PII Entities with Presidio MAGIC MAGIC Using Presidio, anonymize PII content in text or csv files. MAGIC MAGIC The following code sample: MAGIC <ol> MAGIC <li>Imports the content of a single csv file, or a collection of text files, from a mounted folder</li> MAGIC <li>Anonymizes the content of the text files, or a single column in the csv dataset, using Presidio</li> MAGIC <li>Writes the anonymized content back to the mounted folder, as csv set, under the output folder. MAGIC   The output set from text files anonymization includes a column with the original file path</li> MAGIC </ol> MAGIC MAGIC Input Parameters (widgets): MAGIC <ol> MAGIC <li>Input File Format (file_format) - Input file format, can be either csv or text.</li> MAGIC <li>Input path (storage_input_path) - Folder name in case of text file, a path to a single file in case of csv.</li> MAGIC <li>Output Folder Name (storage_output_folder) - Output folder name</li> MAGIC <li>Column to Anonymize (anonymized_column) - Name of column to anonymize in case of csv. NA for text.</li> MAGIC </ol></p> <p>COMMAND ----------</p> In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.functions import input_file_name, regexp_replace\nfrom pyspark.sql.functions import col, pandas_udf\nimport pandas as pd\nimport os\n</pre> from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig from pyspark.sql.types import StringType from pyspark.sql.functions import input_file_name, regexp_replace from pyspark.sql.functions import col, pandas_udf import pandas as pd import os In\u00a0[\u00a0]: Copied! <pre>dbutils.widgets.dropdown(\n    \"file_format\", \"text\", [\"text\", \"csv\"], \"Input File Format (csv/text)\"\n)\ndbutils.widgets.text(\"storage_input_path\", \"input\", \"Input path (file or folder)\")\ndbutils.widgets.text(\"storage_output_folder\", \"output\", \"Output Folder Name\")\ndbutils.widgets.text(\"anonymized_column\", \"value\", \"Column to Anonymize\")\n</pre> dbutils.widgets.dropdown(     \"file_format\", \"text\", [\"text\", \"csv\"], \"Input File Format (csv/text)\" ) dbutils.widgets.text(\"storage_input_path\", \"input\", \"Input path (file or folder)\") dbutils.widgets.text(\"storage_output_folder\", \"output\", \"Output Folder Name\") dbutils.widgets.text(\"anonymized_column\", \"value\", \"Column to Anonymize\") <p>COMMAND ----------</p> <p>MAGIC %md MAGIC # Import the text files from mounted folder</p> <p>COMMAND ----------</p> In\u00a0[\u00a0]: Copied! <pre>storage_mount_name = os.environ[\"STORAGE_MOUNT_NAME\"]\nstorage_input_path = dbutils.widgets.get(\"storage_input_path\")\nstorage_output_folder = dbutils.widgets.get(\"storage_output_folder\")\nfile_format = dbutils.widgets.get(\"file_format\")\nanonymized_column = dbutils.widgets.get(\"anonymized_column\")\n</pre> storage_mount_name = os.environ[\"STORAGE_MOUNT_NAME\"] storage_input_path = dbutils.widgets.get(\"storage_input_path\") storage_output_folder = dbutils.widgets.get(\"storage_output_folder\") file_format = dbutils.widgets.get(\"file_format\") anonymized_column = dbutils.widgets.get(\"anonymized_column\") In\u00a0[\u00a0]: Copied! <pre>if file_format == \"csv\":\n    input_df = spark.read.option(\"header\", \"true\").csv(\n        storage_mount_name + \"/\" + storage_input_path\n    )\nelif file_format == \"text\":\n    input_df = (\n        spark.read.text(storage_mount_name + \"/\" + storage_input_path + \"/*\")\n        .withColumn(\"filename\", input_file_name())\n        .withColumn(\n            \"filename\",\n            regexp_replace(\"filename\", \"^.*(\" + storage_mount_name + \"/)\", \"\"),\n        )\n    )\n</pre> if file_format == \"csv\":     input_df = spark.read.option(\"header\", \"true\").csv(         storage_mount_name + \"/\" + storage_input_path     ) elif file_format == \"text\":     input_df = (         spark.read.text(storage_mount_name + \"/\" + storage_input_path + \"/*\")         .withColumn(\"filename\", input_file_name())         .withColumn(             \"filename\",             regexp_replace(\"filename\", \"^.*(\" + storage_mount_name + \"/)\", \"\"),         )     ) In\u00a0[\u00a0]: Copied! <pre># load the files\ndisplay(input_df)\n</pre> # load the files display(input_df) <p>COMMAND ----------</p> <p>MAGIC %md MAGIC # Anonymize text using Presidio</p> <p>COMMAND ----------</p> In\u00a0[\u00a0]: Copied! <pre>analyzer = AnalyzerEngine()\nanonymizer = AnonymizerEngine()\nbroadcasted_analyzer = sc.broadcast(analyzer)\nbroadcasted_anonymizer = sc.broadcast(anonymizer)\n</pre> analyzer = AnalyzerEngine() anonymizer = AnonymizerEngine() broadcasted_analyzer = sc.broadcast(analyzer) broadcasted_anonymizer = sc.broadcast(anonymizer) <p>define a pandas UDF function and a series function over it. Note that analyzer and anonymizer are broadcasted.</p> In\u00a0[\u00a0]: Copied! <pre>def anonymize_text(text: str) -&gt; str:\n    analyzer = broadcasted_analyzer.value\n    anonymizer = broadcasted_anonymizer.value\n    analyzer_results = analyzer.analyze(text=text, language=\"en\")\n    anonymized_results = anonymizer.anonymize(\n        text=text,\n        analyzer_results=analyzer_results,\n        operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"&lt;ANONYMIZED&gt;\"})},\n    )\n    return anonymized_results.text\n</pre> def anonymize_text(text: str) -&gt; str:     analyzer = broadcasted_analyzer.value     anonymizer = broadcasted_anonymizer.value     analyzer_results = analyzer.analyze(text=text, language=\"en\")     anonymized_results = anonymizer.anonymize(         text=text,         analyzer_results=analyzer_results,         operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"\"})},     )     return anonymized_results.text In\u00a0[\u00a0]: Copied! <pre>def anonymize_series(s: pd.Series) -&gt; pd.Series:\n    return s.apply(anonymize_text)\n</pre> def anonymize_series(s: pd.Series) -&gt; pd.Series:     return s.apply(anonymize_text) In\u00a0[\u00a0]: Copied! <pre># define a the function as pandas UDF\nanonymize = pandas_udf(anonymize_series, returnType=StringType())\n</pre> # define a the function as pandas UDF anonymize = pandas_udf(anonymize_series, returnType=StringType()) In\u00a0[\u00a0]: Copied! <pre># apply the udf\nanonymized_df = input_df.withColumn(\n    anonymized_column, anonymize(col(anonymized_column))\n)\ndisplay(anonymized_df)\n</pre> # apply the udf anonymized_df = input_df.withColumn(     anonymized_column, anonymize(col(anonymized_column)) ) display(anonymized_df) <p>COMMAND ----------</p> <p>MAGIC %md MAGIC # Write the anonymized content back to mounted folder</p> <p>COMMAND ----------</p> <p>write the dataset to output folder</p> In\u00a0[\u00a0]: Copied! <pre>anonymized_df.write.option(\"header\", \"true\").csv(\n    storage_mount_name + \"/\" + storage_output_folder\n)\n</pre> anonymized_df.write.option(\"header\", \"true\").csv(     storage_mount_name + \"/\" + storage_output_folder ) <p>COMMAND ----------</p>"},{"location":"samples/docker/","title":"Using Presidio in Docker","text":""},{"location":"samples/docker/#description","title":"Description","text":"<p>Presidio can expose REST endpoints for each service using Flask and Docker. Follow the installation guide to learn how to install and run presidio-analyzer and presidio-anonymizer using docker.</p>"},{"location":"samples/docker/#postman-collection","title":"Postman collection","text":"<p>This repository contains a postman collection with sample REST API request for each service. Follow this tutorial to learn how to export the sample requests into postman</p> <ol> <li>Download Presidio Analyzer postman requests</li> <li>Download Presidio Anonymizer postman requests</li> </ol>"},{"location":"samples/docker/#sample-api-calls","title":"Sample API Calls","text":""},{"location":"samples/docker/#simple-text-analysis","title":"Simple Text Analysis","text":"<pre><code>curl -X POST http://localhost:5002/analyze -H \"Content-type: application/json\" --data \"{ \\\"text\\\": \\\"John Smith drivers license is AC432223\\\", \\\"language\\\" : \\\"en\\\"}\"\n</code></pre>"},{"location":"samples/docker/#simple-text-anonymization","title":"Simple Text Anonymization","text":"<pre><code>curl -X POST http://localhost:5001/anonymize -H \"Content-type: application/json\" --data \"{\\\"text\\\": \\\"hello world, my name is Jane Doe. My number is: 034453334\\\", \\\"analyzer_results\\\": [{\\\"start\\\": 24, \\\"end\\\": 32, \\\"score\\\": 0.8, \\\"entity_type\\\": \\\"NAME\\\"}, { \\\"start\\\": 48, \\\"end\\\": 57,  \\\"score\\\": 0.95,\\\"entity_type\\\": \\\"PHONE_NUMBER\\\" }],  \\\"anonymizers\\\": {\\\"DEFAULT\\\": { \\\"type\\\": \\\"replace\\\", \\\"new_value\\\": \\\"ANONYMIZED\\\" },\\\"PHONE_NUMBER\\\": { \\\"type\\\": \\\"mask\\\", \\\"masking_char\\\": \\\"*\\\", \\\"chars_to_mask\\\": 4, \\\"from_end\\\": true }}}\"\n</code></pre>"},{"location":"samples/docker/litellm/","title":"LiteLLM (OpenAI Proxy) with Presidio","text":"<p>Run Presidio PII Masking across Anthropic/Gemini/Bedrock/etc. calls with LiteLLM</p> <p>\ud83d\udc49 Refer to LiteLLM Docs for detailed guide</p> <p>Flow: App &lt;-&gt; <code>LiteLLM Proxy + Presidio PII Masking</code> &lt;-&gt; LLM Provider</p>"},{"location":"samples/docker/litellm/#pre-requiesites","title":"Pre-Requiesites","text":"<ul> <li>Run <code>pip install 'litellm[proxy]'</code> Docs</li> <li>Setup Presidio Docker</li> </ul>"},{"location":"samples/docker/litellm/#quick-start","title":"Quick Start","text":""},{"location":"samples/docker/litellm/#step-1-add-to-env","title":"Step 1. Add to env","text":"<pre><code>export PRESIDIO_ANALYZER_API_BASE=\"http://localhost:5002\"\nexport PRESIDIO_ANONYMIZER_API_BASE=\"http://localhost:5001\"\nexport OPENAI_API_KEY=\"sk-...\"\n</code></pre>"},{"location":"samples/docker/litellm/#step-2-set-presidio-as-a-callback-in-configyaml","title":"Step 2. Set Presidio as a callback in config.yaml","text":"<pre><code>model_list:\n  - model_name: my-openai-model ### RECEIVED MODEL NAME ###\n    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input\n      model: gpt-3.5-turbo ### MODEL NAME sent to `litellm.completion()` ###\n\nlitellm_settings: \n    callbacks = [\"presidio\"]\n</code></pre>"},{"location":"samples/docker/litellm/#step-3-start-proxy","title":"Step 3. Start proxy","text":"<pre><code>litellm --config /path/to/config.yaml\n</code></pre> <p>This will mask the input going to the llm provider</p>"},{"location":"samples/docker/litellm/#output-parsing","title":"Output parsing","text":"<p>LLM responses can sometimes contain the masked tokens. </p> <p>For presidio 'replace' operations, LiteLLM can check the LLM response and replace the masked token with the user-submitted values. </p> <p>Just set <code>litellm.output_parse_pii = True</code>, to enable this. </p> <pre><code>litellm_settings:\n    output_parse_pii: true\n</code></pre> <p>**Expected Flow: **</p> <ol> <li> <p>User Input: \"hello world, my name is Jane Doe. My number is: 034453334\"</p> </li> <li> <p>LLM Input: \"hello world, my name is [PERSON]. My number is: [PHONE_NUMBER]\"</p> </li> <li> <p>LLM Response: \"Hey [PERSON], nice to meet you!\"</p> </li> <li> <p>User Response: \"Hey Jane Doe, nice to meet you!\"</p> </li> </ol>"},{"location":"samples/docker/litellm/#ad-hoc-recognizers","title":"Ad-hoc recognizers","text":"<p>Send ad-hoc recognizers to presidio <code>/analyze</code> by passing a json file to the proxy </p> <p>Example ad-hoc recognizer</p> <pre><code>litellm_settings: \n  callbacks: [\"presidio\"]\n  presidio_ad_hoc_recognizers: \"./hooks/example_presidio_ad_hoc_recognizer.json\"\n</code></pre> <p>You can see this working, when you run the proxy: </p> <pre><code>litellm --config /path/to/config.yaml --debug\n</code></pre> <p>Make a chat completions request, example:</p> <pre><code>{\n  \"model\": \"azure-gpt-3.5\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"John Smith AHV number is 756.3026.0705.92. Zip code: 1334023\"}]\n}\n</code></pre> <p>And search for any log starting with <code>Presidio PII Masking</code>, example: <pre><code>Presidio PII Masking: Redacted pii message: &lt;PERSON&gt; AHV number is &lt;AHV_NUMBER&gt;. Zip code: &lt;US_DRIVER_LICENSE&gt;\n</code></pre></p>"},{"location":"samples/docker/litellm/#turn-onoff-per-key","title":"Turn on/off per key","text":"<p>LiteLLM lets you create virtual keys for calling the proxy. You can use these to control model access, set budgets, track usage, etc. </p> <p>Turn off PII masking for a given key. </p> <p>Do this by setting <code>permissions: {\"pii\": false}</code>, when generating a key. </p> <pre><code>curl --location 'http://0.0.0.0:4000/key/generate' \\\n--header 'Authorization: Bearer sk-1234' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"permissions\": {\"pii\": false}\n}'\n</code></pre>"},{"location":"samples/docker/litellm/#turn-onoff-per-request","title":"Turn on/off per request","text":"<p>The proxy supports 2 request-level PII controls:</p> <ul> <li>no-pii: Optional(bool) - Allow user to turn off pii masking per request.</li> <li>output_parse_pii: Optional(bool) - Allow user to turn off pii output parsing per request. Output Parsing</li> </ul>"},{"location":"samples/docker/litellm/#usage","title":"Usage","text":"<p>Step 1. Create key with pii permissions</p> <p>Set <code>allow_pii_controls</code> to true for a given key. This will allow the user to set request-level PII controls.</p> <pre><code>curl --location 'http://0.0.0.0:4000/key/generate' \\\n--header 'Authorization: Bearer my-master-key' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"permissions\": {\"allow_pii_controls\": true}\n}'\n</code></pre> <p>Step 2. Turn off pii output parsing</p> <pre><code>import os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    # This is the default and can be omitted\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n        base_url=\"http://0.0.0.0:4000\"\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"My name is Jane Doe, my number is 8382043839\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    extra_body={\n        \"content_safety\": {\"output_parse_pii\": False} \n    }\n)\n</code></pre> <p>Step 3: See response</p> <pre><code>{\n  \"id\": \"chatcmpl-8c5qbGTILZa1S4CK3b31yj5N40hFN\",\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n      \"index\": 0,\n      \"message\": {\n        \"content\": \"Hi [PERSON], what can I help you with?\",\n        \"role\": \"assistant\"\n      }\n    }\n  ],\n  \"created\": 1704089632,\n  \"model\": \"gpt-35-turbo\",\n  \"object\": \"chat.completion\",\n  \"system_fingerprint\": null,\n  \"usage\": {\n    \"completion_tokens\": 47,\n    \"prompt_tokens\": 12,\n    \"total_tokens\": 59\n  },\n  \"_response_ms\": 1753.426\n}\n</code></pre>"},{"location":"samples/docker/litellm/#turn-on-for-logging-only","title":"Turn on for logging only","text":"<p>Only apply PII Masking before logging to Langfuse, etc.</p> <p>Not on the actual llm api request / response.</p> <p>This is currently only applied for  - <code>/chat/completion</code> requests - on 'success' logging</p> <ol> <li> <p>Setup config.yaml <pre><code>litellm_settings:\n  presidio_logging_only: true \n\nmodel_list:\n  - model_name: gpt-3.5-turbo\n    litellm_params:\n      model: gpt-3.5-turbo\n      api_key: os.environ/OPENAI_API_KEY\n</code></pre></p> </li> <li> <p>Start proxy</p> </li> </ol> <pre><code>litellm --config /path/to/config.yaml\n</code></pre> <ol> <li>Test it! </li> </ol> <pre><code>curl -X POST 'http://0.0.0.0:4000/chat/completions' \\\n-H 'Content-Type: application/json' \\\n-H 'Authorization: Bearer sk-1234' \\\n-D '{\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Hi, my name is Jane!\"\n    }\n  ]\n  }'\n</code></pre> <p>Expected Logged Response</p> <pre><code>Hi, my name is &lt;PERSON&gt;!\n</code></pre>"},{"location":"samples/python/Anonymizing%20known%20values/","title":"Anonymizing known values","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer  !python -m spacy download en_core_web_lg In\u00a0[2]: Copied! <pre>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry, PatternRecognizer\nfrom presidio_anonymizer import AnonymizerEngine\n</pre> from presidio_analyzer import AnalyzerEngine, RecognizerRegistry, PatternRecognizer from presidio_anonymizer import AnonymizerEngine In\u00a0[3]: Copied! <pre># Get known values as a deny-list\nknown_names_list = [\"George\", \"Abraham\", \"Theodore\", \"Bill\", \"Barack\", \"Donald\", \"Joe\"]\n</pre> # Get known values as a deny-list known_names_list = [\"George\", \"Abraham\", \"Theodore\", \"Bill\", \"Barack\", \"Donald\", \"Joe\"]  In\u00a0[4]: Copied! <pre># Create a PatternRecognizer for the deny list\ndeny_list_recognizer = PatternRecognizer(supported_entity=\"PRESIDENT_FIRST_NAME\", deny_list=known_names_list)\n</pre> # Create a PatternRecognizer for the deny list deny_list_recognizer = PatternRecognizer(supported_entity=\"PRESIDENT_FIRST_NAME\", deny_list=known_names_list) In\u00a0[5]: Copied! <pre>registry = RecognizerRegistry()\nregistry.add_recognizer(deny_list_recognizer)\n\nanalyzer = AnalyzerEngine(registry=registry)\n\nanonymizer = AnonymizerEngine()\n</pre> registry = RecognizerRegistry() registry.add_recognizer(deny_list_recognizer)  analyzer = AnalyzerEngine(registry=registry)  anonymizer = AnonymizerEngine() In\u00a0[6]: Copied! <pre>text=\"George Washington was the first US president\"\n\nresults = analyzer.analyze(text=text, language=\"en\")\n\nprint(\"Identified entities:\")\nprint(results)\nprint(\"\")\nanonymized = anonymizer.anonymize(text=text, analyzer_results=results)\nprint(f\"Anonymized text:\\n{anonymized.text}\")\n</pre> text=\"George Washington was the first US president\"  results = analyzer.analyze(text=text, language=\"en\")  print(\"Identified entities:\") print(results) print(\"\") anonymized = anonymizer.anonymize(text=text, analyzer_results=results) print(f\"Anonymized text:\\n{anonymized.text}\") <pre>Identified entities:\n[type: PRESIDENT_FIRST_NAME, start: 0, end: 6, score: 1.0]\n\nAnonymized text:\n&lt;PRESIDENT_FIRST_NAME&gt; Washington was the first US president\n</pre> In\u00a0[7]: Copied! <pre>person1 = {\"name\": \"Martin Smith\", \n           \"special_value\":\"145A\", \n           \"free_text\": \"Martin Smith, id 145A, likes playing basketball\"}\nperson2 = {\"name\":\"Deb Schmidt\", \n           \"special_value\":\"256B\", \n           \"free_text\": \"Deb Schmidt, id 256B likes playing soccer\"}\nperson3 = {\"name\":\"R2D2\", \n           \"special_value\":\"X1T2\", \n           \"free_text\": \"X1T2 is R2D2's special value\"}\n\ndataset = [person1, person2, person3]\ndataset\n</pre> person1 = {\"name\": \"Martin Smith\",             \"special_value\":\"145A\",             \"free_text\": \"Martin Smith, id 145A, likes playing basketball\"} person2 = {\"name\":\"Deb Schmidt\",             \"special_value\":\"256B\",             \"free_text\": \"Deb Schmidt, id 256B likes playing soccer\"} person3 = {\"name\":\"R2D2\",             \"special_value\":\"X1T2\",             \"free_text\": \"X1T2 is R2D2's special value\"}  dataset = [person1, person2, person3] dataset Out[7]: <pre>[{'name': 'Martin Smith',\n  'special_value': '145A',\n  'free_text': 'Martin Smith, id 145A, likes playing basketball'},\n {'name': 'Deb Schmidt',\n  'special_value': '256B',\n  'free_text': 'Deb Schmidt, id 256B likes playing soccer'},\n {'name': 'R2D2',\n  'special_value': 'X1T2',\n  'free_text': \"X1T2 is R2D2's special value\"}]</pre> <p>We're interested in anonymizing the free text using the values contained in <code>name</code> and <code>special_value</code>. Since these values are only available in the context of one record, we use the ad-hoc recognizer capability in Presidio, instead of a generic deny-list <code>PatternRecognizer</code> added to Presidio's <code>RecognizerRegistry</code>.</p> In\u00a0[8]: Copied! <pre># Go over dataset\nfor person in dataset:\n    \n    # Get the different known values\n    name = person['name']\n    special_val = person['special_value']\n    \n    # Get the free text to anonymize\n    free_text = person['free_text']\n    \n    # Create ad-hoc recognizers\n    ad_hoc_name_recognizer = PatternRecognizer(supported_entity=\"name\", deny_list = [name])\n    ad_hoc_id_recognizer = PatternRecognizer(supported_entity=\"special_value\", deny_list = [special_val])\n    \n    # Run the analyze method with ad_hoc_recognizers:\n    analyzer_results = analyzer.analyze(text=free_text, \n                                        language=\"en\", \n                                        ad_hoc_recognizers=[ad_hoc_name_recognizer, ad_hoc_id_recognizer])\n    \n    # Anonymize results\n    anonymized = anonymizer.anonymize(text=free_text, analyzer_results=analyzer_results)\n    print(anonymized.text)\n    \n    # Store output in original dataset\n    person[\"anonymized_free_text\"] = anonymized.text\n</pre> # Go over dataset for person in dataset:          # Get the different known values     name = person['name']     special_val = person['special_value']          # Get the free text to anonymize     free_text = person['free_text']          # Create ad-hoc recognizers     ad_hoc_name_recognizer = PatternRecognizer(supported_entity=\"name\", deny_list = [name])     ad_hoc_id_recognizer = PatternRecognizer(supported_entity=\"special_value\", deny_list = [special_val])          # Run the analyze method with ad_hoc_recognizers:     analyzer_results = analyzer.analyze(text=free_text,                                          language=\"en\",                                          ad_hoc_recognizers=[ad_hoc_name_recognizer, ad_hoc_id_recognizer])          # Anonymize results     anonymized = anonymizer.anonymize(text=free_text, analyzer_results=analyzer_results)     print(anonymized.text)          # Store output in original dataset     person[\"anonymized_free_text\"] = anonymized.text      <pre>&lt;name&gt;, id &lt;special_value&gt;, likes playing basketball\n&lt;name&gt;, id &lt;special_value&gt; likes playing soccer\n&lt;special_value&gt; is &lt;name&gt;'s special value\n</pre> In\u00a0[9]: Copied! <pre># Dataset now contains the anonymiezd version as well\ndataset\n</pre> # Dataset now contains the anonymiezd version as well dataset Out[9]: <pre>[{'name': 'Martin Smith',\n  'special_value': '145A',\n  'free_text': 'Martin Smith, id 145A, likes playing basketball',\n  'anonymized_free_text': '&lt;name&gt;, id &lt;special_value&gt;, likes playing basketball'},\n {'name': 'Deb Schmidt',\n  'special_value': '256B',\n  'free_text': 'Deb Schmidt, id 256B likes playing soccer',\n  'anonymized_free_text': '&lt;name&gt;, id &lt;special_value&gt; likes playing soccer'},\n {'name': 'R2D2',\n  'special_value': 'X1T2',\n  'free_text': \"X1T2 is R2D2's special value\",\n  'anonymized_free_text': \"&lt;special_value&gt; is &lt;name&gt;'s special value\"}]</pre> <p>Note that in these examples we're only using the custom recognizers we created. We can also add our custom recognizers to the existing recognizers in presidio, by calling <code>registry.load_predefined_recognizers()</code>:</p> In\u00a0[10]: Copied! <pre>registry = RecognizerRegistry()\n\n# Load existing recognizer\nregistry.load_predefined_recognizers()\n\n# Add our custom one\nregistry.add_recognizer(deny_list_recognizer)\n\n# Initialize AnalyzerEngine\nanalyzer = AnalyzerEngine(registry=registry)\n</pre> registry = RecognizerRegistry()  # Load existing recognizer registry.load_predefined_recognizers()  # Add our custom one registry.add_recognizer(deny_list_recognizer)  # Initialize AnalyzerEngine analyzer = AnalyzerEngine(registry=registry) In\u00a0[11]: Copied! <pre>analyzer.analyze(\"George Washington was the first president of the United States\", language=\"en\")\n</pre> analyzer.analyze(\"George Washington was the first president of the United States\", language=\"en\") Out[11]: <pre>[type: PRESIDENT_FIRST_NAME, start: 0, end: 6, score: 1.0,\n type: PERSON, start: 0, end: 17, score: 0.85,\n type: LOCATION, start: 45, end: 62, score: 0.85]</pre> <p>Since George is also a name, it was detected twice, once as a PERSON entity, and once as a custom entity.</p> <p>Read more:</p> <ul> <li>For more info on Presidio Analyzer, see this documentation</li> <li>For more info on Presidio Anonymize, see this documentation</li> <li>To further customize the anonymization type, see this tutorial</li> </ul> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"samples/python/Anonymizing%20known%20values/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonanonymizing20known20valuesipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/Anonymizing%20known%20values.ipynb\u00b6","text":""},{"location":"samples/python/Anonymizing%20known%20values/#anonymizing-known-values","title":"Anonymizing known values\u00b6","text":"<p>In addition to statistical and pattern based approaches, Presidio also supports the identification and anonymization of known values, using the deny-list mechanism. In this example we'll cover two cases:</p> <ol> <li>The known values are known a-priori (e.g., we have a list of names)</li> <li>The known values are only known in the context of a request (e.g., we have the name of a person as the filename)</li> </ol>"},{"location":"samples/python/Anonymizing%20known%20values/#example-1-values-are-known-a-priori","title":"Example 1: values are known a-priori\u00b6","text":"<p>Assume you have a list of potential PII values, you can create a recognizer which would detect them every time they appear in the text. For this case, we can create a deny-list based recognizer, and add it to presidio's <code>RecognizerRegistry</code>:</p>"},{"location":"samples/python/Anonymizing%20known%20values/#example-2-values-are-only-known-in-the-context-of-the-request","title":"Example 2: values are only known in the context of the request\u00b6","text":"<p>In some cases, we know the potential PII values only in the context of a specific text. Examples could be:</p> <ol> <li>Detect PII entities in free text columns in tabular databases, where other columns have entity values we can leverage</li> <li>Detect PII in a file having the filename or other metadata holding potential PII values (e.g. Smith.csv)</li> <li>Anonymize medical images which contain metadata</li> <li>Anonymize financial forms when the actual PII data is known</li> </ol> <p>In this case we can use a functionality called ad-hoc recognizers. Here's a simple example:</p>"},{"location":"samples/python/batch_processing/","title":"Batch processing","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !python -m spacy download en_core_web_lg In\u00a0[3]: Copied! <pre>from typing import List, Optional, Dict, Union, Iterator, Iterable\nimport collections\nfrom dataclasses import dataclass\nimport pprint\n\nimport pandas as pd\n\nfrom presidio_analyzer import AnalyzerEngine, BatchAnalyzerEngine, RecognizerResult, DictAnalyzerResult\nfrom presidio_anonymizer import AnonymizerEngine, BatchAnonymizerEngine\nfrom presidio_anonymizer.entities import EngineResult\n</pre> from typing import List, Optional, Dict, Union, Iterator, Iterable import collections from dataclasses import dataclass import pprint  import pandas as pd  from presidio_analyzer import AnalyzerEngine, BatchAnalyzerEngine, RecognizerResult, DictAnalyzerResult from presidio_anonymizer import AnonymizerEngine, BatchAnonymizerEngine from presidio_anonymizer.entities import EngineResult  In\u00a0[4]: Copied! <pre>columns = [\"name phrase\", \"phone number phrase\", \"integer\", \"boolean\" ]\nsample_data = [\n        ('Charlie likes this', 'Please call 212-555-1234 after 2pm', 1, True),\n        ('You should talk to Mike', 'his number is 978-428-7111', 2, False),\n        ('Mary had a little startup', 'Phone number: 202-342-1234', 3, False)\n]\n</pre> columns = [\"name phrase\", \"phone number phrase\", \"integer\", \"boolean\" ] sample_data = [         ('Charlie likes this', 'Please call 212-555-1234 after 2pm', 1, True),         ('You should talk to Mike', 'his number is 978-428-7111', 2, False),         ('Mary had a little startup', 'Phone number: 202-342-1234', 3, False) ] In\u00a0[5]: Copied! <pre># Create Pandas DataFrame\ndf  = pd.DataFrame(sample_data,columns=columns)\n\ndf\n</pre> # Create Pandas DataFrame df  = pd.DataFrame(sample_data,columns=columns)  df Out[5]: name phrase phone number phrase integer boolean 0 Charlie likes this Please call 212-555-1234 after 2pm 1 True 1 You should talk to Mike his number is 978-428-7111 2 False 2 Mary had a little startup Phone number: 202-342-1234 3 False In\u00a0[6]: Copied! <pre># DataFrame to dict\ndf_dict = df.to_dict(orient=\"list\")\n</pre> # DataFrame to dict df_dict = df.to_dict(orient=\"list\") In\u00a0[7]: Copied! <pre>pprint.pprint(df_dict)\n</pre> pprint.pprint(df_dict) <pre>{'boolean': [True, False, False],\n 'integer': [1, 2, 3],\n 'name phrase': ['Charlie likes this',\n                 'You should talk to Mike',\n                 'Mary had a little startup'],\n 'phone number phrase': ['Please call 212-555-1234 after 2pm',\n                         'his number is 978-428-7111',\n                         'Phone number: 202-342-1234']}\n</pre> In\u00a0[8]: Copied! <pre>analyzer = AnalyzerEngine()\nbatch_analyzer = BatchAnalyzerEngine(analyzer_engine=analyzer)\nbatch_anonymizer = BatchAnonymizerEngine()\n</pre> analyzer = AnalyzerEngine() batch_analyzer = BatchAnalyzerEngine(analyzer_engine=analyzer) batch_anonymizer = BatchAnonymizerEngine() In\u00a0[9]: Copied! <pre>analyzer_results = batch_analyzer.analyze_dict(df_dict, language=\"en\")\nanalyzer_results = list(analyzer_results)\nanalyzer_results\n</pre> analyzer_results = batch_analyzer.analyze_dict(df_dict, language=\"en\") analyzer_results = list(analyzer_results) analyzer_results Out[9]: <pre>[DictAnalyzerResult(key='name phrase', value=['Charlie likes this', 'You should talk to Mike', 'Mary had a little startup'], recognizer_results=[[type: PERSON, start: 0, end: 7, score: 0.85], [type: PERSON, start: 19, end: 23, score: 0.85], [type: PERSON, start: 0, end: 4, score: 0.85]]),\n DictAnalyzerResult(key='phone number phrase', value=['Please call 212-555-1234 after 2pm', 'his number is 978-428-7111', 'Phone number: 202-342-1234'], recognizer_results=[[type: DATE_TIME, start: 31, end: 34, score: 0.85, type: PHONE_NUMBER, start: 12, end: 24, score: 0.75], [type: PHONE_NUMBER, start: 14, end: 26, score: 0.75], [type: PHONE_NUMBER, start: 14, end: 26, score: 0.75]]),\n DictAnalyzerResult(key='integer', value=[1, 2, 3], recognizer_results=[[], [], []]),\n DictAnalyzerResult(key='boolean', value=[True, False, False], recognizer_results=[[], [], []])]</pre> In\u00a0[10]: Copied! <pre>anonymizer_results = batch_anonymizer.anonymize_dict(analyzer_results)\n</pre> anonymizer_results = batch_anonymizer.anonymize_dict(analyzer_results) In\u00a0[11]: Copied! <pre>scrubbed_df = pd.DataFrame(anonymizer_results)\n</pre> scrubbed_df = pd.DataFrame(anonymizer_results) In\u00a0[12]: Copied! <pre>scrubbed_df\n</pre> scrubbed_df Out[12]: name phrase phone number phrase integer boolean 0 &lt;PERSON&gt; likes this Please call &lt;PHONE_NUMBER&gt; after &lt;DATE_TIME&gt; 1 True 1 You should talk to &lt;PERSON&gt; his number is &lt;PHONE_NUMBER&gt; 2 False 2 &lt;PERSON&gt; had a little startup Phone number: &lt;PHONE_NUMBER&gt; 3 False In\u00a0[13]: Copied! <pre>nested_dict = {\n    \"key_a\": {\"key_a1\": \"My phone number is 212-121-1424\"},\n    \"key_b\": {\"www.abc.com\"},\n    \"key_c\": 3,\n    \"names\": [\"James Bond\", \"Clark Kent\", \"Hakeem Olajuwon\", \"No name here!\"]\n}\n\npprint.pprint(nested_dict)\n</pre> nested_dict = {     \"key_a\": {\"key_a1\": \"My phone number is 212-121-1424\"},     \"key_b\": {\"www.abc.com\"},     \"key_c\": 3,     \"names\": [\"James Bond\", \"Clark Kent\", \"Hakeem Olajuwon\", \"No name here!\"] }  pprint.pprint(nested_dict) <pre>{'key_a': {'key_a1': 'My phone number is 212-121-1424'},\n 'key_b': {'www.abc.com'},\n 'key_c': 3,\n 'names': ['James Bond', 'Clark Kent', 'Hakeem Olajuwon', 'No name here!']}\n</pre> In\u00a0[14]: Copied! <pre># Analyze dict\nanalyzer_results = batch_analyzer.analyze_dict(input_dict = nested_dict, language=\"en\")\n\n# Anonymize dict\nanonymizer_results = batch_anonymizer.anonymize_dict(analyzer_results = analyzer_results)\npprint.pprint(anonymizer_results)\n</pre> # Analyze dict analyzer_results = batch_analyzer.analyze_dict(input_dict = nested_dict, language=\"en\")  # Anonymize dict anonymizer_results = batch_anonymizer.anonymize_dict(analyzer_results = analyzer_results) pprint.pprint(anonymizer_results) <pre>{'key_a': {'key_a1': 'My phone number is &lt;PHONE_NUMBER&gt;'},\n 'key_b': ['&lt;URL&gt;'],\n 'key_c': 3,\n 'names': ['&lt;PERSON&gt;', '&lt;PERSON&gt;', '&lt;PERSON&gt;', 'No name here!']}\n</pre> In\u00a0[15]: Copied! <pre>keys_to_skip=[\"key_a1\", \"names\"]\nanalyzer_results = batch_analyzer.analyze_dict(input_dict = nested_dict, language=\"en\", keys_to_skip=keys_to_skip)\n\n# Anonymize dict\nanonymizer_results = batch_anonymizer.anonymize_dict(analyzer_results = analyzer_results)\npprint.pprint(anonymizer_results)\n</pre> keys_to_skip=[\"key_a1\", \"names\"] analyzer_results = batch_analyzer.analyze_dict(input_dict = nested_dict, language=\"en\", keys_to_skip=keys_to_skip)  # Anonymize dict anonymizer_results = batch_anonymizer.anonymize_dict(analyzer_results = analyzer_results) pprint.pprint(anonymizer_results) <pre>{'key_a': {'key_a1': 'My phone number is 212-121-1424'},\n 'key_b': ['&lt;URL&gt;'],\n 'key_c': 3,\n 'names': ['James Bond', 'Clark Kent', 'Hakeem Olajuwon', 'No name here!']}\n</pre> In\u00a0[16]: Copied! <pre>keys_to_skip = [\"key_a.key_a1\"]\n\nanalyzer_results = batch_analyzer.analyze_dict(input_dict = nested_dict, language=\"en\", keys_to_skip=keys_to_skip)\n\n# Anonymize dict\nanonymizer_results = batch_anonymizer.anonymize_dict(analyzer_results = analyzer_results)\npprint.pprint(anonymizer_results)\n</pre> keys_to_skip = [\"key_a.key_a1\"]  analyzer_results = batch_analyzer.analyze_dict(input_dict = nested_dict, language=\"en\", keys_to_skip=keys_to_skip)  # Anonymize dict anonymizer_results = batch_anonymizer.anonymize_dict(analyzer_results = analyzer_results) pprint.pprint(anonymizer_results) <pre>{'key_a': {'key_a1': 'My phone number is 212-121-1424'},\n 'key_b': ['&lt;URL&gt;'],\n 'key_c': 3,\n 'names': ['&lt;PERSON&gt;', '&lt;PERSON&gt;', '&lt;PERSON&gt;', 'No name here!']}\n</pre>"},{"location":"samples/python/batch_processing/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonbatch_processingipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/batch_processing.ipynb\u00b6","text":""},{"location":"samples/python/batch_processing/#run-presidio-on-structured-semi-structured-data","title":"Run Presidio on structured / semi-structured data\u00b6","text":"<p>This sample shows how Presidio could be potentially extended to handle the anonymization of a table or data frame. It introduces methods for the analysis and anonymization of both lists and dicts.</p> <p>Note: this sample input here is a Pandas DataFrame and a JSON file, but it can be used in other scenarios such as querying SQL data or using Spark DataFrames.</p>"},{"location":"samples/python/batch_processing/#set-up-imports","title":"Set up imports\u00b6","text":""},{"location":"samples/python/batch_processing/#example-using-sample-tabular-data","title":"Example using sample tabular data\u00b6","text":""},{"location":"samples/python/batch_processing/#example-using-json","title":"Example using JSON\u00b6","text":""},{"location":"samples/python/batch_processing/#ignoring-specific-keys","title":"Ignoring specific keys\u00b6","text":""},{"location":"samples/python/batch_processing/#ignoring-nested-keys","title":"Ignoring nested keys\u00b6","text":""},{"location":"samples/python/batch_processing/#note","title":"Note!\u00b6","text":"<p>JSON files with objects within lists, e.g.:</p> <pre><code>{\n  \"key\": [\n    {\n      \"key2\": \"Peter Parker\"\n    },\n    {\n      \"key3\": \"555-1234\"\n    }\n  ]\n}\n</code></pre> <p>Are not yet supported. Consider breaking the JSON to parts if needed.</p>"},{"location":"samples/python/custom_presidio/","title":"Custom presidio","text":"In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import AnalyzerEngine, PatternRecognizer, Pattern\n</pre> from presidio_analyzer import AnalyzerEngine, PatternRecognizer, Pattern In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n\n    analyzer = AnalyzerEngine()\n\n    text1 = \"Professor Plum, in the Dining Room, with the candlestick\"\n\n    titles_list = [\n        \"Sir\",\n        \"Ma'am\",\n        \"Madam\",\n        \"Mr.\",\n        \"Mrs.\",\n        \"Ms.\",\n        \"Miss\",\n        \"Dr.\",\n        \"Professor\",\n    ]\n    titles_recognizer = PatternRecognizer(\n        supported_entity=\"TITLE\", deny_list=titles_list\n    )\n    analyzer.registry.add_recognizer(titles_recognizer)\n\n    result = analyzer.analyze(text=text1, language=\"en\")\n    print(f\"\\nDeny List result:\\n {result}\")\n\n    text2 = \"I live in 510 Broad st.\"\n\n    numbers_pattern = Pattern(name=\"numbers_pattern\", regex=r\"\\d+\", score=0.5)\n    number_recognizer = PatternRecognizer(\n        supported_entity=\"NUMBER\", patterns=[numbers_pattern]\n    )\n\n    result = number_recognizer.analyze(text=text2, entities=[\"NUMBER\"])\n    print(f\"\\nRegex result:\\n {result}\")\n</pre> if __name__ == \"__main__\":      analyzer = AnalyzerEngine()      text1 = \"Professor Plum, in the Dining Room, with the candlestick\"      titles_list = [         \"Sir\",         \"Ma'am\",         \"Madam\",         \"Mr.\",         \"Mrs.\",         \"Ms.\",         \"Miss\",         \"Dr.\",         \"Professor\",     ]     titles_recognizer = PatternRecognizer(         supported_entity=\"TITLE\", deny_list=titles_list     )     analyzer.registry.add_recognizer(titles_recognizer)      result = analyzer.analyze(text=text1, language=\"en\")     print(f\"\\nDeny List result:\\n {result}\")      text2 = \"I live in 510 Broad st.\"      numbers_pattern = Pattern(name=\"numbers_pattern\", regex=r\"\\d+\", score=0.5)     number_recognizer = PatternRecognizer(         supported_entity=\"NUMBER\", patterns=[numbers_pattern]     )      result = number_recognizer.analyze(text=text2, entities=[\"NUMBER\"])     print(f\"\\nRegex result:\\n {result}\")"},{"location":"samples/python/customizing_presidio_analyzer/","title":"Customizing Presidio Analyzer","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !python -m spacy download en_core_web_lg In\u00a0[1]: Copied! <pre>from typing import List\nimport pprint\n\nfrom presidio_analyzer import (\n    AnalyzerEngine,\n    PatternRecognizer,\n    EntityRecognizer,\n    Pattern,\n    RecognizerResult,\n)\nfrom presidio_analyzer.recognizer_registry import RecognizerRegistry\nfrom presidio_analyzer.nlp_engine import NlpEngine, SpacyNlpEngine, NlpArtifacts\nfrom presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer\n</pre> from typing import List import pprint  from presidio_analyzer import (     AnalyzerEngine,     PatternRecognizer,     EntityRecognizer,     Pattern,     RecognizerResult, ) from presidio_analyzer.recognizer_registry import RecognizerRegistry from presidio_analyzer.nlp_engine import NlpEngine, SpacyNlpEngine, NlpArtifacts from presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer In\u00a0[68]: Copied! <pre># Helper method to print results nicely\n\n\ndef print_analyzer_results(results: List[RecognizerResult], text: str):\n    \"\"\"Print the results in a human readable way.\"\"\"\n\n    for i, result in enumerate(results):\n        print(f\"Result {i}:\")\n        print(f\" {result}, text: {text[result.start:result.end]}\")\n\n        if result.analysis_explanation is not None:\n            print(f\" {result.analysis_explanation.textual_explanation}\")\n</pre> # Helper method to print results nicely   def print_analyzer_results(results: List[RecognizerResult], text: str):     \"\"\"Print the results in a human readable way.\"\"\"      for i, result in enumerate(results):         print(f\"Result {i}:\")         print(f\" {result}, text: {text[result.start:result.end]}\")          if result.analysis_explanation is not None:             print(f\" {result.analysis_explanation.textual_explanation}\") In\u00a0[69]: Copied! <pre>titles_list = [\n    \"Sir\",\n    \"Ma'am\",\n    \"Madam\",\n    \"Mr.\",\n    \"Mrs.\",\n    \"Ms.\",\n    \"Miss\",\n    \"Dr.\",\n    \"Professor\",\n]\n</pre> titles_list = [     \"Sir\",     \"Ma'am\",     \"Madam\",     \"Mr.\",     \"Mrs.\",     \"Ms.\",     \"Miss\",     \"Dr.\",     \"Professor\", ] <p>Second, let's create a <code>PatternRecognizer</code> which would scan for those titles, by passing a <code>deny_list</code>:</p> In\u00a0[70]: Copied! <pre>titles_recognizer = PatternRecognizer(supported_entity=\"TITLE\", deny_list=titles_list)\n</pre> titles_recognizer = PatternRecognizer(supported_entity=\"TITLE\", deny_list=titles_list) <p>At this point we can call our recognizer directly:</p> In\u00a0[83]: Copied! <pre>text1 = \"I suspect Professor Plum, in the Dining Room, with the candlestick\"\nresult = titles_recognizer.analyze(text1, entities=[\"TITLE\"])\nprint(f\"Result:\\n {result}\")\n</pre> text1 = \"I suspect Professor Plum, in the Dining Room, with the candlestick\" result = titles_recognizer.analyze(text1, entities=[\"TITLE\"]) print(f\"Result:\\n {result}\") <pre>Result:\n [type: TITLE, start: 10, end: 19, score: 1.0]\n</pre> <p>Finally, let's add this new recognizer to the list of recognizers used by the Presidio <code>AnalyzerEngine</code>:</p> In\u00a0[84]: Copied! <pre>analyzer = AnalyzerEngine()\nanalyzer.registry.add_recognizer(titles_recognizer)\n</pre> analyzer = AnalyzerEngine() analyzer.registry.add_recognizer(titles_recognizer) <p>When initializing the <code>AnalyzerEngine</code>, Presidio loads all available recognizers, including the <code>NlpEngine</code> used to detect entities, and extract tokens, lemmas and other linguistic features.</p> <p>Let's run the analyzer with the new recognizer in place:</p> In\u00a0[85]: Copied! <pre>results = analyzer.analyze(text=text1, language=\"en\")\n</pre> results = analyzer.analyze(text=text1, language=\"en\") In\u00a0[86]: Copied! <pre>print_analyzer_results(results, text=text1)\n</pre> print_analyzer_results(results, text=text1) <pre>Result 0:\n type: TITLE, start: 10, end: 19, score: 1.0, text: Professor\nResult 1:\n type: PERSON, start: 20, end: 24, score: 0.85, text: Plum\nResult 2:\n type: LOCATION, start: 29, end: 44, score: 0.85, text: the Dining Room\n</pre> <p>As expected, both the name \"Plum\" and the title were identified as PII:</p> In\u00a0[87]: Copied! <pre>print(\"Identified these PII entities:\")\nfor result in results:\n    print(f\"- {text1[result.start:result.end]} as {result.entity_type}\")\n</pre> print(\"Identified these PII entities:\") for result in results:     print(f\"- {text1[result.start:result.end]} as {result.entity_type}\") <pre>Identified these PII entities:\n- Professor as TITLE\n- Plum as PERSON\n- the Dining Room as LOCATION\n</pre> In\u00a0[88]: Copied! <pre># Define the regex pattern in a Presidio `Pattern` object:\nnumbers_pattern = Pattern(name=\"numbers_pattern\", regex=\"\\d+\", score=0.5)\n\n# Define the recognizer with one or more patterns\nnumber_recognizer = PatternRecognizer(\n    supported_entity=\"NUMBER\", patterns=[numbers_pattern]\n)\n</pre> # Define the regex pattern in a Presidio `Pattern` object: numbers_pattern = Pattern(name=\"numbers_pattern\", regex=\"\\d+\", score=0.5)  # Define the recognizer with one or more patterns number_recognizer = PatternRecognizer(     supported_entity=\"NUMBER\", patterns=[numbers_pattern] ) <p>Testing the recognizer itself:</p> In\u00a0[89]: Copied! <pre>text2 = \"I live in 510 Broad st.\"\n\nnumbers_result = number_recognizer.analyze(text=text2, entities=[\"NUMBER\"])\nprint(\"Result:\")\nprint(numbers_result)\n</pre> text2 = \"I live in 510 Broad st.\"  numbers_result = number_recognizer.analyze(text=text2, entities=[\"NUMBER\"]) print(\"Result:\") print(numbers_result) <pre>Result:\n[type: NUMBER, start: 10, end: 13, score: 0.5]\n</pre> <p>It's important to mention that recognizers is likely to have errors, both false-positive and false-negative, which would impact the entire performance of Presidio. Consider testing each recognizer on a representative dataset prior to integrating it into Presidio. For more info, see the best practices for developing recognizers documentation.</p> In\u00a0[90]: Copied! <pre>class MyRecognizer(EntityRecognizer):\n\n    def load(self) -&gt; None:\n        \"\"\"No loading is required.\"\"\"\n        pass\n\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Logic for detecting a specific PII\n        \"\"\"\n        pass\n</pre> class MyRecognizer(EntityRecognizer):      def load(self) -&gt; None:         \"\"\"No loading is required.\"\"\"         pass      def analyze(         self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts     ) -&gt; List[RecognizerResult]:         \"\"\"         Logic for detecting a specific PII         \"\"\"         pass <p>For example, detecting numbers in either numerical or alphabetic (e.g. Forty five) form:</p> In\u00a0[91]: Copied! <pre>class NumbersRecognizer(EntityRecognizer):\n\n    expected_confidence_level = 0.7  # expected confidence level for this recognizer\n\n    def load(self) -&gt; None:\n        \"\"\"No loading is required.\"\"\"\n        pass\n\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Analyzes test to find tokens which represent numbers (either 123 or One Two Three).\n        \"\"\"\n        results = []\n\n        # iterate over the spaCy tokens, and call `token.like_num`\n        for token in nlp_artifacts.tokens:\n            if token.like_num:\n                result = RecognizerResult(\n                    entity_type=\"NUMBER\",\n                    start=token.idx,\n                    end=token.idx + len(token),\n                    score=self.expected_confidence_level,\n                )\n                results.append(result)\n        return results\n</pre> class NumbersRecognizer(EntityRecognizer):      expected_confidence_level = 0.7  # expected confidence level for this recognizer      def load(self) -&gt; None:         \"\"\"No loading is required.\"\"\"         pass      def analyze(         self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts     ) -&gt; List[RecognizerResult]:         \"\"\"         Analyzes test to find tokens which represent numbers (either 123 or One Two Three).         \"\"\"         results = []          # iterate over the spaCy tokens, and call `token.like_num`         for token in nlp_artifacts.tokens:             if token.like_num:                 result = RecognizerResult(                     entity_type=\"NUMBER\",                     start=token.idx,                     end=token.idx + len(token),                     score=self.expected_confidence_level,                 )                 results.append(result)         return results In\u00a0[92]: Copied! <pre>new_numbers_recognizer = NumbersRecognizer(supported_entities=[\"NUMBER\"])\n</pre> new_numbers_recognizer = NumbersRecognizer(supported_entities=[\"NUMBER\"]) <p>Since this recognizer requires the <code>NlpArtifacts</code>, we would have to call it as part of the <code>AnalyzerEngine</code> flow:</p> In\u00a0[93]: Copied! <pre>text3 = \"Roberto lives in Five 10 Broad st.\"\nanalyzer = AnalyzerEngine()\nanalyzer.registry.add_recognizer(new_numbers_recognizer)\n\nnumbers_results2 = analyzer.analyze(text=text3, language=\"en\")\nprint_analyzer_results(numbers_results2, text=text3)\n</pre> text3 = \"Roberto lives in Five 10 Broad st.\" analyzer = AnalyzerEngine() analyzer.registry.add_recognizer(new_numbers_recognizer)  numbers_results2 = analyzer.analyze(text=text3, language=\"en\") print_analyzer_results(numbers_results2, text=text3) <pre>Result 0:\n type: PERSON, start: 0, end: 7, score: 0.85, text: Roberto\nResult 1:\n type: LOCATION, start: 25, end: 34, score: 0.85, text: Broad st.\nResult 2:\n type: NUMBER, start: 17, end: 21, score: 0.7, text: Five\nResult 3:\n type: NUMBER, start: 22, end: 24, score: 0.7, text: 10\n</pre> <p>The analyzer was able to pick up both numeric and alphabetical numbers, including other types of PII entities from other recognizers (PERSON in this case).</p> In\u00a0[82]: Copied! <pre>from presidio_analyzer.nlp_engine import NlpEngineProvider\n\n# import spacy\n# spacy.cli.download(\"es_core_news_md\")\n\n# Create configuration containing engine name and models\nconfiguration = {\n    \"nlp_engine_name\": \"spacy\",\n    \"models\": [\n        {\"lang_code\": \"es\", \"model_name\": \"es_core_news_md\"},\n        {\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"},\n    ],\n}\n\n# Create NLP engine based on configuration\nprovider = NlpEngineProvider(nlp_configuration=configuration)\nnlp_engine_with_spanish = provider.create_engine()\n\n# Pass the created NLP engine and supported_languages to the AnalyzerEngine\nanalyzer = AnalyzerEngine(\n    nlp_engine=nlp_engine_with_spanish, supported_languages=[\"en\", \"es\"]\n)\n\n# Analyze in different languages\nresults_spanish = analyzer.analyze(text=\"Mi nombre es Morris\", language=\"es\")\nprint(\"Results from Spanish request:\")\nprint(results_spanish)\n\nresults_english = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\nprint(\"Results from English request:\")\nprint(results_english)\n</pre> from presidio_analyzer.nlp_engine import NlpEngineProvider  # import spacy # spacy.cli.download(\"es_core_news_md\")  # Create configuration containing engine name and models configuration = {     \"nlp_engine_name\": \"spacy\",     \"models\": [         {\"lang_code\": \"es\", \"model_name\": \"es_core_news_md\"},         {\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"},     ], }  # Create NLP engine based on configuration provider = NlpEngineProvider(nlp_configuration=configuration) nlp_engine_with_spanish = provider.create_engine()  # Pass the created NLP engine and supported_languages to the AnalyzerEngine analyzer = AnalyzerEngine(     nlp_engine=nlp_engine_with_spanish, supported_languages=[\"en\", \"es\"] )  # Analyze in different languages results_spanish = analyzer.analyze(text=\"Mi nombre es Morris\", language=\"es\") print(\"Results from Spanish request:\") print(results_spanish)  results_english = analyzer.analyze(text=\"My name is Morris\", language=\"en\") print(\"Results from English request:\") print(results_english) <pre>Results from Spanish request:\n[type: PERSON, start: 13, end: 19, score: 0.85]\nResults from English request:\n[type: PERSON, start: 11, end: 17, score: 0.85]\n</pre> <ul> <li>See this documentation for more details on how to configure Presidio support additional NLP models and languages.</li> <li>See this sample for more implemention examples of various NLP engines and NER models.</li> </ul> In\u00a0[94]: Copied! <pre># Define the regex pattern\nregex = r\"(\\b\\d{5}(?:\\-\\d{4})?\\b)\"  # very weak regex pattern\nzipcode_pattern = Pattern(name=\"zip code (weak)\", regex=regex, score=0.01)\n\n# Define the recognizer with the defined pattern\nzipcode_recognizer = PatternRecognizer(\n    supported_entity=\"US_ZIP_CODE\", patterns=[zipcode_pattern]\n)\n\nregistry = RecognizerRegistry()\nregistry.add_recognizer(zipcode_recognizer)\nanalyzer = AnalyzerEngine(registry=registry)\n\n# Test\ntext = \"My zip code is 90210\"\nresults = analyzer.analyze(text=text, language=\"en\")\nprint_analyzer_results(results, text=text)\n</pre> # Define the regex pattern regex = r\"(\\b\\d{5}(?:\\-\\d{4})?\\b)\"  # very weak regex pattern zipcode_pattern = Pattern(name=\"zip code (weak)\", regex=regex, score=0.01)  # Define the recognizer with the defined pattern zipcode_recognizer = PatternRecognizer(     supported_entity=\"US_ZIP_CODE\", patterns=[zipcode_pattern] )  registry = RecognizerRegistry() registry.add_recognizer(zipcode_recognizer) analyzer = AnalyzerEngine(registry=registry)  # Test text = \"My zip code is 90210\" results = analyzer.analyze(text=text, language=\"en\") print_analyzer_results(results, text=text) <pre>Result 0:\n type: US_ZIP_CODE, start: 15, end: 20, score: 0.01, text: 90210\n</pre> <p>So this is working, but would catch any 5 digit string. This is why we set the score to 0.01. Let's use context words to increase score:</p> In\u00a0[96]: Copied! <pre># Define the recognizer with the defined pattern and context words\nzipcode_recognizer = PatternRecognizer(\n    supported_entity=\"US_ZIP_CODE\",\n    patterns=[zipcode_pattern],\n    context=[\"zip\", \"zipcode\"],\n)\n</pre> # Define the recognizer with the defined pattern and context words zipcode_recognizer = PatternRecognizer(     supported_entity=\"US_ZIP_CODE\",     patterns=[zipcode_pattern],     context=[\"zip\", \"zipcode\"], ) <p>When creating an <code>AnalyzerEngine</code> we can provide our own context enhancement logic by passing it to <code>context_aware_enhancer</code> parameter. <code>AnalyzerEngine</code> will create <code>LemmaContextAwareEnhancer</code> by default if not passed, which will enhance score of each matched result if it's recognizer holds context words and those words are found in context of the matched entity.</p> In\u00a0[97]: Copied! <pre>registry = RecognizerRegistry()\nregistry.add_recognizer(zipcode_recognizer)\nanalyzer = AnalyzerEngine(registry=registry)\n</pre> registry = RecognizerRegistry() registry.add_recognizer(zipcode_recognizer) analyzer = AnalyzerEngine(registry=registry) In\u00a0[98]: Copied! <pre># Test\nresults = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\")\nprint(\"Result:\")\nprint_analyzer_results(results, text=text)\n</pre> # Test results = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\") print(\"Result:\") print_analyzer_results(results, text=text) <pre>Result:\nResult 0:\n type: US_ZIP_CODE, start: 15, end: 20, score: 0.4, text: 90210\n</pre> <p>The confidence score is now 0.4, instead of 0.01. because <code>LemmaContextAwareEnhancer</code> default context similarity factor is 0.35 and default minimum score with context similarity is 0.4, we can change that by passing <code>context_similarity_factor</code> and <code>min_score_with_context_similarity</code> parameters of <code>LemmaContextAwareEnhancer</code> to other than values, for example:</p> In\u00a0[99]: Copied! <pre>registry = RecognizerRegistry()\nregistry.add_recognizer(zipcode_recognizer)\nanalyzer = AnalyzerEngine(\n    registry=registry,\n    context_aware_enhancer=LemmaContextAwareEnhancer(\n        context_similarity_factor=0.45, min_score_with_context_similarity=0.4\n    ),\n)\n</pre> registry = RecognizerRegistry() registry.add_recognizer(zipcode_recognizer) analyzer = AnalyzerEngine(     registry=registry,     context_aware_enhancer=LemmaContextAwareEnhancer(         context_similarity_factor=0.45, min_score_with_context_similarity=0.4     ), ) In\u00a0[100]: Copied! <pre># Test\nresults = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\")\nprint(\"Result:\")\nprint_analyzer_results(results, text=text)\n</pre> # Test results = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\") print(\"Result:\") print_analyzer_results(results, text=text) <pre>Result:\nResult 0:\n type: US_ZIP_CODE, start: 15, end: 20, score: 0.46, text: 90210\n</pre> <p>The confidence score is now 0.46 because it got enhanced from 0.01 with 0.45 and is more the minimum of 0.4</p> <p>Presidio supports passing a list of outer context in analyzer level, this is useful if the text is coming from a specific column or a specific user input etc. notice how the \"zip\" context word doesn't appear in the text but still enhance the confidence score from 0.01 to 0.4:</p> In\u00a0[102]: Copied! <pre># Define the recognizer with the defined pattern and context words\nzipcode_recognizer = PatternRecognizer(\n    supported_entity=\"US_ZIP_CODE\",\n    patterns=[zipcode_pattern],\n    context=[\"zip\", \"zipcode\"],\n)\n\nregistry = RecognizerRegistry()\nregistry.add_recognizer(zipcode_recognizer)\nanalyzer = AnalyzerEngine(registry=registry)\n\n# Test\ntext = \"My code is 90210\"\nresult = analyzer.analyze(text=text, language=\"en\", context=[\"zip\"])\nprint(\"Result:\")\nprint_analyzer_results(result, text=text)\n</pre> # Define the recognizer with the defined pattern and context words zipcode_recognizer = PatternRecognizer(     supported_entity=\"US_ZIP_CODE\",     patterns=[zipcode_pattern],     context=[\"zip\", \"zipcode\"], )  registry = RecognizerRegistry() registry.add_recognizer(zipcode_recognizer) analyzer = AnalyzerEngine(registry=registry)  # Test text = \"My code is 90210\" result = analyzer.analyze(text=text, language=\"en\", context=[\"zip\"]) print(\"Result:\") print_analyzer_results(result, text=text) <pre>Result:\nResult 0:\n type: US_ZIP_CODE, start: 11, end: 16, score: 0.4, text: 90210\n</pre> In\u00a0[103]: Copied! <pre>results = analyzer.analyze(\n    text=\"My zip code is 90210\", language=\"en\", return_decision_process=True\n)\ndecision_process = results[0].analysis_explanation\n\npp = pprint.PrettyPrinter()\nprint(\"Decision process output:\\n\")\npp.pprint(decision_process.__dict__)\n</pre> results = analyzer.analyze(     text=\"My zip code is 90210\", language=\"en\", return_decision_process=True ) decision_process = results[0].analysis_explanation  pp = pprint.PrettyPrinter() print(\"Decision process output:\\n\") pp.pprint(decision_process.__dict__) <pre>Decision process output:\n\n{'original_score': 0.01,\n 'pattern': '(\\\\b\\\\d{5}(?:\\\\-\\\\d{4})?\\\\b)',\n 'pattern_name': 'zip code (weak)',\n 'recognizer': 'PatternRecognizer',\n 'regex_flags': regex.I|regex.M|regex.S,\n 'score': 0.4,\n 'score_context_improvement': 0.39,\n 'supportive_context_word': 'zip',\n 'textual_explanation': 'Detected by `PatternRecognizer` using pattern `zip '\n                        'code (weak)`',\n 'validation_result': None}\n</pre> <p>When developing new recognizers, one can add information to this explanation and extend it with additional findings.</p> <p>We will use the built in recognizers that include the <code>URLRecognizer</code> and the NLP model <code>EntityRecognizer</code> and see the default functionality if we don't specify any list of words for the detector to allow to keep in the text.</p> In\u00a0[104]: Copied! <pre>websites_list = [\"bing.com\", \"microsoft.com\"]\ntext1 = \"Bill's favorite website is bing.com, David's is microsoft.com\"\nanalyzer = AnalyzerEngine()\nresults = analyzer.analyze(text=text1, language=\"en\", return_decision_process=True)\nprint_analyzer_results(results, text=text1)\n</pre> websites_list = [\"bing.com\", \"microsoft.com\"] text1 = \"Bill's favorite website is bing.com, David's is microsoft.com\" analyzer = AnalyzerEngine() results = analyzer.analyze(text=text1, language=\"en\", return_decision_process=True) print_analyzer_results(results, text=text1) <pre>Result 0:\n type: PERSON, start: 0, end: 4, score: 0.85, text: Bill\n Identified as PERSON by Spacy's Named Entity Recognition\nResult 1:\n type: URL, start: 27, end: 35, score: 0.85, text: bing.com\n Detected by `UrlRecognizer` using pattern `Non schema URL`\nResult 2:\n type: PERSON, start: 37, end: 42, score: 0.85, text: David\n Identified as PERSON by Spacy's Named Entity Recognition\nResult 3:\n type: URL, start: 48, end: 61, score: 0.85, text: microsoft.com\n Detected by `UrlRecognizer` using pattern `Non schema URL`\n</pre> <p>To specify an allow list we just pass a list of values we want to keep as a parameter to call to <code>analyze</code>. Now we can see that in the results, <code>bing.com</code> is no longer being recognized as a PII item, only <code>microsoft.com</code> as well as the named entities are still recognized since we did include it in the allow list.</p> In\u00a0[105]: Copied! <pre>results = analyzer.analyze(\n    text=text1,\n    language=\"en\",\n    allow_list=[\"bing.com\", \"google.com\"],\n    return_decision_process=True,\n)\nprint_analyzer_results(results, text=text1)\n</pre> results = analyzer.analyze(     text=text1,     language=\"en\",     allow_list=[\"bing.com\", \"google.com\"],     return_decision_process=True, ) print_analyzer_results(results, text=text1) <pre>Result 0:\n type: PERSON, start: 0, end: 4, score: 0.85, text: Bill\n Identified as PERSON by Spacy's Named Entity Recognition\nResult 1:\n type: PERSON, start: 37, end: 42, score: 0.85, text: David\n Identified as PERSON by Spacy's Named Entity Recognition\nResult 2:\n type: URL, start: 48, end: 61, score: 0.85, text: microsoft.com\n Detected by `UrlRecognizer` using pattern `Non schema URL`\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"samples/python/customizing_presidio_analyzer/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythoncustomizing_presidio_analyzeripynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/customizing_presidio_analyzer.ipynb\u00b6","text":""},{"location":"samples/python/customizing_presidio_analyzer/#customizing-the-pii-analysis-process-in-microsoft-presidio","title":"Customizing the PII analysis process in Microsoft Presidio\u00b6","text":"<p>This notebooks covers different customization use cases to:</p> <ol> <li>Adapt Presidio to detect new types of PII entities</li> <li>Adapt Presidio to detect PII entities in a new language</li> <li>Embed new types of detection modules into Presidio, to improve the coverage of the service.</li> </ol>"},{"location":"samples/python/customizing_presidio_analyzer/#installation","title":"Installation\u00b6","text":"<p>First, let's install presidio using <code>pip</code>. For detailed documentation, see the installation docs.</p> <p>Install from PyPI:</p>"},{"location":"samples/python/customizing_presidio_analyzer/#getting-started","title":"Getting started\u00b6","text":"<p>The high level process in Presidio-Analyzer is the following: </p> <p>Load the <code>presidio-analyzer</code> modules. For more information, see the analyzer docs.</p>"},{"location":"samples/python/customizing_presidio_analyzer/#example-1-deny-list-based-pii-recognition","title":"Example 1: Deny-list based PII recognition\u00b6","text":"<p>In this example, we will pass a short list of tokens which should be marked as PII if detected. First, let's define the tokens we want to treat as PII. In this case it would be a list of titles:</p>"},{"location":"samples/python/customizing_presidio_analyzer/#example-2-regex-based-pii-recognition","title":"Example 2: Regex based PII recognition\u00b6","text":"<p>Another simple recognizer we can add is based on regular expressions. Let's assume we want to be extremely conservative and treat any token which contains a number as PII.</p>"},{"location":"samples/python/customizing_presidio_analyzer/#example-3-rule-based-logic-recognizer","title":"Example 3: Rule based logic recognizer\u00b6","text":"<p>Taking the numbers recognizer one step further, let's say we also would like to detect numbers within words, e.g. \"Number One\". We can leverage the underlying spaCy token attributes, or write our own logic to detect such entities.</p> <p>Notes:</p> <ul> <li><p>In this example we would create a new class, which implements <code>EntityRecognizer</code>, the basic recognizer in Presidio. This abstract class requires us to implement the <code>load</code> method and <code>analyze</code> method.</p> </li> <li><p>Each recognizer accepts an object of type <code>NlpArtifacts</code>, which holds pre-computed attributes on the input text.</p> </li> </ul> <p>A new recognizer should have this structure:</p>"},{"location":"samples/python/customizing_presidio_analyzer/#example-4-calling-an-external-service-for-pii-detection","title":"Example 4: Calling an external service for PII detection\u00b6","text":"<p>In a similar way to example 3, we can write logic to call external services for PII detection. For a detailed example, see this part of the documentation.</p> <p>This is a sample implementation of such remote recognizer.</p>"},{"location":"samples/python/customizing_presidio_analyzer/#example-5-supporting-new-languages","title":"Example 5: Supporting new languages\u00b6","text":"<p>Two main parts in Presidio handle the text, and should be adapted if a new language is required:</p> <ol> <li>The <code>NlpEngine</code> containing the NLP model which performs tokenization, lemmatization, Named Entity Recognition and other NLP tasks.</li> <li>The different PII recognizers (<code>EntityRecognizer</code> objects) should be adapted or created.</li> </ol>"},{"location":"samples/python/customizing_presidio_analyzer/#adapting-the-nlp-engine","title":"Adapting the NLP engine\u00b6","text":"<p>As its internal NLP engine, Presidio supports both spaCy and Stanza. Make sure you download the required models from spacy/stanza prior to using them. More details here. For example, to download the Spanish medium spaCy model: <code>python -m spacy download es_core_news_md</code></p> <p>In this example we will configure Presidio to use spaCy as its underlying NLP framework, with NLP models in English and Spanish:</p>"},{"location":"samples/python/customizing_presidio_analyzer/#example-6-using-context-words","title":"Example 6: Using context words\u00b6","text":"<p>Presidio has a internal mechanism for leveraging context words. This mechanism would increse the detection confidence of a PII entity in case a specific word appears before or after it.</p> <p>In this example we would first implement a zip code recognizer without context, and then add context to see how the confidence changes. Zip regex patterns (essentially 5 digits) are very week, so we would want the initial confidence to be low, and increased with the existence of context words.</p>"},{"location":"samples/python/customizing_presidio_analyzer/#example-7-tracing-the-decision-process","title":"Example 7: Tracing the decision process\u00b6","text":"<p>Presidio-analyzer's decision process exposes information on why a specific PII was detected. Such information could contain:</p> <ul> <li>Which recognizer detected the entity</li> <li>Which regex pattern was used</li> <li>Interpretability mechanisms in ML models</li> <li>Which context words improved the score</li> <li>Confidence scores before and after each step And more.</li> </ul> <p>For more information, refer to the decision process documentation.</p> <p>Let's use the decision process output to understand how the zip code value was detected:</p>"},{"location":"samples/python/customizing_presidio_analyzer/#example-8-passing-a-list-of-words-to-keep","title":"Example 8: passing a list of words to keep\u00b6","text":""},{"location":"samples/python/encrypt_decrypt/","title":"Encrypting and Decrypting","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !python -m spacy download en_core_web_lg In\u00a0[2]: Copied! <pre>from presidio_anonymizer import AnonymizerEngine, DeanonymizeEngine\nfrom presidio_anonymizer.entities import RecognizerResult, OperatorResult, OperatorConfig\nfrom presidio_anonymizer.operators import Decrypt\n</pre> from presidio_anonymizer import AnonymizerEngine, DeanonymizeEngine from presidio_anonymizer.entities import RecognizerResult, OperatorResult, OperatorConfig from presidio_anonymizer.operators import Decrypt In\u00a0[3]: Copied! <pre>crypto_key = \"WmZq4t7w!z%C&amp;F)J\"\n</pre> crypto_key = \"WmZq4t7w!z%C&amp;F)J\" In\u00a0[4]: Copied! <pre>engine = AnonymizerEngine()\n\n# Invoke the anonymize function with the text,\n# analyzer results (potentially coming from presidio-analyzer)\n# and an 'encrypt' operator to get an encrypted anonymization output:\nanonymize_result = engine.anonymize(\n    text=\"My name is James Bond\",\n    analyzer_results=[\n        RecognizerResult(entity_type=\"PERSON\", start=11, end=21, score=0.8),\n    ],\n    operators={\"PERSON\": OperatorConfig(\"encrypt\", {\"key\": crypto_key})},\n)\n\nanonymize_result\n</pre> engine = AnonymizerEngine()  # Invoke the anonymize function with the text, # analyzer results (potentially coming from presidio-analyzer) # and an 'encrypt' operator to get an encrypted anonymization output: anonymize_result = engine.anonymize(     text=\"My name is James Bond\",     analyzer_results=[         RecognizerResult(entity_type=\"PERSON\", start=11, end=21, score=0.8),     ],     operators={\"PERSON\": OperatorConfig(\"encrypt\", {\"key\": crypto_key})}, )  anonymize_result Out[4]: <pre>text: My name is M4lla0kBCzu6SwCONL6Y+ZqsPqhBp1Lhdc3t0FKnUwM=.\nitems:\n[\n    {'start': 11, 'end': 55, 'entity_type': 'PERSON', 'text': 'M4lla0kBCzu6SwCONL6Y+ZqsPqhBp1Lhdc3t0FKnUwM=', 'operator': 'encrypt'}\n]</pre> In\u00a0[5]: Copied! <pre># Fetch the anonymized text from the result.\nanonymized_text = anonymize_result.text\n\n# Fetch the anonynized entities from the result.\nanonymized_entities = anonymize_result.items\n</pre> # Fetch the anonymized text from the result. anonymized_text = anonymize_result.text  # Fetch the anonynized entities from the result. anonymized_entities = anonymize_result.items In\u00a0[8]: Copied! <pre># Initialize the engine:\nengine = DeanonymizeEngine()\n\n# Invoke the deanonymize function with the text, anonymizer results\n# and a 'decrypt' operator to get the original text as output.\ndeanonymized_result = engine.deanonymize(\n    text=anonymized_text,\n    entities=anonymized_entities,\n    operators={\"DEFAULT\": OperatorConfig(\"decrypt\", {\"key\": crypto_key})},\n)\n\ndeanonymized_result\n</pre> # Initialize the engine: engine = DeanonymizeEngine()  # Invoke the deanonymize function with the text, anonymizer results # and a 'decrypt' operator to get the original text as output. deanonymized_result = engine.deanonymize(     text=anonymized_text,     entities=anonymized_entities,     operators={\"DEFAULT\": OperatorConfig(\"decrypt\", {\"key\": crypto_key})}, )  deanonymized_result Out[8]: <pre>text: My name is James Bond.\nitems:\n[\n    {'start': 11, 'end': 21, 'entity_type': 'PERSON', 'text': 'James Bond', 'operator': 'decrypt'}\n]</pre> In\u00a0[9]: Copied! <pre># Alternatively, call the Decrypt operator directly:\n\n# Fetch the encrypted entitiy value from the previous stage\nencrypted_entity_value = anonymize_result.items[0].text\n\n# Restore the original entity value\nDecrypt().operate(text=encrypted_entity_value, params={\"key\": crypto_key})\n</pre> # Alternatively, call the Decrypt operator directly:  # Fetch the encrypted entitiy value from the previous stage encrypted_entity_value = anonymize_result.items[0].text  # Restore the original entity value Decrypt().operate(text=encrypted_entity_value, params={\"key\": crypto_key}) Out[9]: <pre>'James Bond'</pre>"},{"location":"samples/python/encrypt_decrypt/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonencrypt_decryptipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/encrypt_decrypt.ipynb\u00b6","text":""},{"location":"samples/python/encrypt_decrypt/#encrypting-and-decrypting-identified-entities","title":"Encrypting and Decrypting identified entities\u00b6","text":"<p>This sample shows how to use Presidio Anonymizer built-in functionality, to encrypt and decrypt identified entities. The encryption is using AES cypher in CBC mode and requires a cryptographic key as an input for both the encryption and the decryption.</p>"},{"location":"samples/python/encrypt_decrypt/#set-up-imports","title":"Set up imports\u00b6","text":""},{"location":"samples/python/encrypt_decrypt/#define-a-cryptographic-key-for-both-encryption-and-decryption","title":"Define a cryptographic key (for both encryption and decryption)\u00b6","text":""},{"location":"samples/python/encrypt_decrypt/#presidio-anonymizer-encrypt","title":"Presidio Anonymizer: Encrypt\u00b6","text":""},{"location":"samples/python/encrypt_decrypt/#presidio-anonymizer-decrypt","title":"Presidio Anonymizer: Decrypt\u00b6","text":""},{"location":"samples/python/example_custom_lambda_anonymizer/","title":"Example custom lambda anonymizer","text":"In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\nfrom faker import Faker\nfrom faker.providers import internet\n</pre> from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig from faker import Faker from faker.providers import internet In\u00a0[\u00a0]: Copied! <pre>def reverse_string(x):\n    \"\"\"Return string in reverse order.\"\"\"\n    return x[::-1]\n</pre> def reverse_string(x):     \"\"\"Return string in reverse order.\"\"\"     return x[::-1] In\u00a0[\u00a0]: Copied! <pre>def anonymize_reverse_lambda(analyzer_results, text_to_anonymize):\n    \"\"\"Anonymize using an example lambda.\"\"\"\n    anonymized_results = anonymizer.anonymize(\n        text=text_to_anonymize,\n        analyzer_results=analyzer_results,\n        operators={\n            \"EMAIL_ADDRESS\": OperatorConfig(\"custom\", {\"lambda\": lambda x: x[::-1]})\n        },\n    )\n\n    return anonymized_results\n</pre> def anonymize_reverse_lambda(analyzer_results, text_to_anonymize):     \"\"\"Anonymize using an example lambda.\"\"\"     anonymized_results = anonymizer.anonymize(         text=text_to_anonymize,         analyzer_results=analyzer_results,         operators={             \"EMAIL_ADDRESS\": OperatorConfig(\"custom\", {\"lambda\": lambda x: x[::-1]})         },     )      return anonymized_results In\u00a0[\u00a0]: Copied! <pre>def anonymize_faker_lambda(analyzer_results, text_to_anonymize):\n    \"\"\"Anonymize using a faker provider.\"\"\"\n\n    anonymized_results = anonymizer.anonymize(\n        text=text_to_anonymize,\n        analyzer_results=analyzer_results,\n        operators={\n            \"EMAIL_ADDRESS\": OperatorConfig(\n                \"custom\", {\"lambda\": lambda x: fake.safe_email()}\n            )\n        },\n    )\n\n    return anonymized_results\n</pre> def anonymize_faker_lambda(analyzer_results, text_to_anonymize):     \"\"\"Anonymize using a faker provider.\"\"\"      anonymized_results = anonymizer.anonymize(         text=text_to_anonymize,         analyzer_results=analyzer_results,         operators={             \"EMAIL_ADDRESS\": OperatorConfig(                 \"custom\", {\"lambda\": lambda x: fake.safe_email()}             )         },     )      return anonymized_results In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    fake = Faker(\"en_US\")\n    fake.add_provider(internet)\n\n    analyzer = AnalyzerEngine()\n    anonymizer = AnonymizerEngine()\n\n    text = \"The user has the following two emails: email1@contoso.com and email2@contoso.com\"  # noqa E501\n    analyzer_results = analyzer.analyze(\n        text=text, entities=[\"EMAIL_ADDRESS\"], language=\"en\"\n    )\n    print(f\"Original Text: {text}\")\n    print(f\"Analyzer result: {analyzer_results}\\n\")\n\n    print(\n        f\"Reverse lambda result: {anonymize_reverse_lambda(analyzer_results, text).text}\"  # noqa E501\n    )\n    print(f\"Faker lambda result: {anonymize_faker_lambda(analyzer_results, text).text}\")\n</pre> if __name__ == \"__main__\":     fake = Faker(\"en_US\")     fake.add_provider(internet)      analyzer = AnalyzerEngine()     anonymizer = AnonymizerEngine()      text = \"The user has the following two emails: email1@contoso.com and email2@contoso.com\"  # noqa E501     analyzer_results = analyzer.analyze(         text=text, entities=[\"EMAIL_ADDRESS\"], language=\"en\"     )     print(f\"Original Text: {text}\")     print(f\"Analyzer result: {analyzer_results}\\n\")      print(         f\"Reverse lambda result: {anonymize_reverse_lambda(analyzer_results, text).text}\"  # noqa E501     )     print(f\"Faker lambda result: {anonymize_faker_lambda(analyzer_results, text).text}\")"},{"location":"samples/python/example_dicom_image_redactor/","title":"Redacting Text PII from DICOM images","text":"In\u00a0[\u00a0]: Copied! <pre>!pip install presidio_analyzer presidio_anonymizer presidio_image_redactor\n!python -m spacy download en_core_web_lg\n</pre> !pip install presidio_analyzer presidio_anonymizer presidio_image_redactor !python -m spacy download en_core_web_lg In\u00a0[1]: Copied! <pre>import glob\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport pydicom\nfrom presidio_image_redactor import DicomImageRedactorEngine\n</pre> import glob from pathlib import Path import matplotlib.pyplot as plt import pydicom from presidio_image_redactor import DicomImageRedactorEngine In\u00a0[2]: Copied! <pre>def compare_dicom_images(\n    instance_original: pydicom.dataset.FileDataset,\n    instance_redacted: pydicom.dataset.FileDataset,\n    figsize: tuple = (11, 11)\n) -&gt; None:\n    \"\"\"Display the DICOM pixel arrays of both original and redacted as images.\n\n    Args:\n        instance_original (pydicom.dataset.FileDataset): A single DICOM instance (with text PHI).\n        instance_redacted (pydicom.dataset.FileDataset): A single DICOM instance (redacted PHI).\n        figsize (tuple): Figure size in inches (width, height).\n    \"\"\"\n    _, ax = plt.subplots(1, 2, figsize=figsize)\n    ax[0].imshow(instance_original.pixel_array, cmap=\"gray\")\n    ax[0].set_title('Original')\n    ax[1].imshow(instance_redacted.pixel_array, cmap=\"gray\")\n    ax[1].set_title('Redacted')\n</pre> def compare_dicom_images(     instance_original: pydicom.dataset.FileDataset,     instance_redacted: pydicom.dataset.FileDataset,     figsize: tuple = (11, 11) ) -&gt; None:     \"\"\"Display the DICOM pixel arrays of both original and redacted as images.      Args:         instance_original (pydicom.dataset.FileDataset): A single DICOM instance (with text PHI).         instance_redacted (pydicom.dataset.FileDataset): A single DICOM instance (redacted PHI).         figsize (tuple): Figure size in inches (width, height).     \"\"\"     _, ax = plt.subplots(1, 2, figsize=figsize)     ax[0].imshow(instance_original.pixel_array, cmap=\"gray\")     ax[0].set_title('Original')     ax[1].imshow(instance_redacted.pixel_array, cmap=\"gray\")     ax[1].set_title('Redacted') <p>Instantiate the DICOM image redactor engine object.</p> <p>Note: The <code>DicomImageRedactorEngine</code> object can initialized with a custom <code>ImageAnalyzerEngine</code>, which may be useful in cases where DICOM metadata is insufficient.</p> In\u00a0[3]: Copied! <pre>engine = DicomImageRedactorEngine()\n</pre> engine = DicomImageRedactorEngine() <p>In cases where you already working with loaded DICOM data, the <code>.redact()</code> function is most appropriate.</p> In\u00a0[4]: Copied! <pre># Load in and process your DICOM file as needed\ndicom_instance = pydicom.dcmread('sample_data/0_ORIGINAL.dcm')\n</pre> # Load in and process your DICOM file as needed dicom_instance = pydicom.dcmread('sample_data/0_ORIGINAL.dcm') In\u00a0[5]: Copied! <pre># Redact\nredacted_dicom_instance = engine.redact(dicom_instance, fill=\"contrast\")\n</pre> # Redact redacted_dicom_instance = engine.redact(dicom_instance, fill=\"contrast\") In\u00a0[6]: Copied! <pre>compare_dicom_images(dicom_instance, redacted_dicom_instance)\n</pre> compare_dicom_images(dicom_instance, redacted_dicom_instance) <p>We can also set the \"fill\" to match the background color to blend in more with the image.</p> In\u00a0[7]: Copied! <pre>redacted_dicom_instance_2 = engine.redact(dicom_instance, fill=\"background\")\ncompare_dicom_images(dicom_instance, redacted_dicom_instance_2)\n</pre> redacted_dicom_instance_2 = engine.redact(dicom_instance, fill=\"background\") compare_dicom_images(dicom_instance, redacted_dicom_instance_2) In\u00a0[8]: Copied! <pre>redacted_dicom_instance = engine.redact(dicom_instance, use_metadata=False) # default is use_metadata=True\ncompare_dicom_images(dicom_instance, redacted_dicom_instance)\n</pre> redacted_dicom_instance = engine.redact(dicom_instance, use_metadata=False) # default is use_metadata=True compare_dicom_images(dicom_instance, redacted_dicom_instance) <p>We can also return the bounding box information for the pixel regions that were redacted.</p> In\u00a0[9]: Copied! <pre>redacted_dicom_instance, bbox = engine.redact_and_return_bbox(dicom_instance)\ncompare_dicom_images(dicom_instance, redacted_dicom_instance)\nprint(f\"Number of redacted regions: {len(bbox)}\")\nprint(bbox)\n</pre> redacted_dicom_instance, bbox = engine.redact_and_return_bbox(dicom_instance) compare_dicom_images(dicom_instance, redacted_dicom_instance) print(f\"Number of redacted regions: {len(bbox)}\") print(bbox) <pre>Number of redacted regions: 4\n[{'top': 0, 'left': 0, 'width': 241, 'height': 37}, {'top': 0, 'left': 262, 'width': 230, 'height': 36}, {'top': 1, 'left': 588, 'width': 226, 'height': 35}, {'top': 47, 'left': 145, 'width': 218, 'height': 35}]\n</pre> In\u00a0[10]: Copied! <pre># Single DICOM (.dcm) file or directory containing DICOM files\ninput_path = 'sample_data/'\n\n# Directory where the output will be written\noutput_parent_dir = 'output/'\n</pre> # Single DICOM (.dcm) file or directory containing DICOM files input_path = 'sample_data/'  # Directory where the output will be written output_parent_dir = 'output/' In\u00a0[11]: Copied! <pre># Redact text PHI from DICOM images\nengine.redact_from_directory(\n    input_dicom_path = input_path,\n    output_dir = output_parent_dir,\n    fill=\"contrast\",\n    save_bboxes=True # if True, saves the redacted region bounding box info to .json files in the output dir\n)\n</pre> # Redact text PHI from DICOM images engine.redact_from_directory(     input_dicom_path = input_path,     output_dir = output_parent_dir,     fill=\"contrast\",     save_bboxes=True # if True, saves the redacted region bounding box info to .json files in the output dir ) <pre>Output written to output\\sample_data\n</pre> <p>Get file paths</p> In\u00a0[12]: Copied! <pre># Original DICOM images\np = Path(input_path).glob(\"**/*.dcm\")\noriginal_files = [x for x in p if x.is_file()]\n\n# Redacted DICOM images\np = Path(output_parent_dir).glob(\"**/*.dcm\")\nredacted_files = [x for x in p if x.is_file()]\n</pre> # Original DICOM images p = Path(input_path).glob(\"**/*.dcm\") original_files = [x for x in p if x.is_file()]  # Redacted DICOM images p = Path(output_parent_dir).glob(\"**/*.dcm\") redacted_files = [x for x in p if x.is_file()] <p>Preview images</p> In\u00a0[13]: Copied! <pre>for i in range(0, len(original_files)):\n    original_file = pydicom.dcmread(original_files[i])\n    redacted_file = pydicom.dcmread(redacted_files[i])\n    \n    compare_dicom_images(original_file, redacted_file)\n</pre> for i in range(0, len(original_files)):     original_file = pydicom.dcmread(original_files[i])     redacted_file = pydicom.dcmread(redacted_files[i])          compare_dicom_images(original_file, redacted_file)"},{"location":"samples/python/example_dicom_image_redactor/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonexample_dicom_image_redactoripynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/example_dicom_image_redactor.ipynb\u00b6","text":""},{"location":"samples/python/example_dicom_image_redactor/#de-identifying-sensitive-burnt-in-text-in-dicom-images","title":"De-identifying sensitive burnt-in text in DICOM images\u00b6","text":"<p>This notebook covers how to:</p> <ol> <li>Redact text Personal Health Information (PHI) present as pixels in DICOM images</li> <li>Visually compare original DICOM images with their redacted versions</li> </ol> <p>This module only redacts pixel data and does not scrub text PHI which may exist in the DICOM metadata. To redact sensitive information from metadata, consider using another package such as the Tools for Health Data Anonymization.</p>"},{"location":"samples/python/example_dicom_image_redactor/#prerequisites","title":"Prerequisites\u00b6","text":"<p>Before getting started, make sure presidio and the latest version of Tesseract OCR are installed. For detailed documentation, see the installation docs.</p>"},{"location":"samples/python/example_dicom_image_redactor/#dataset","title":"Dataset\u00b6","text":"<p>Sample DICOM files are available for use in this notebook in <code>./sample_data</code>. Copies of the original DICOM data were saved into the folder with permission from the dataset owners. Please see the original dataset information below:</p> <p>Rutherford, M., Mun, S.K., Levine, B., Bennett, W.C., Smith, K., Farmer, P., Jarosz, J., Wagner, U., Farahani, K., Prior, F. (2021). A DICOM dataset for evaluation of medical image de-identification (Pseudo-PHI-DICOM-Data) [Data set]. The Cancer Imaging Archive. DOI: https://doi.org/10.7937/s17z-r072</p>"},{"location":"samples/python/example_dicom_image_redactor/#1-setup","title":"1. Setup\u00b6","text":""},{"location":"samples/python/example_dicom_image_redactor/#2-redacting-from-loaded-dicom-image-data","title":"2. Redacting from loaded DICOM image data\u00b6","text":""},{"location":"samples/python/example_dicom_image_redactor/#22-verify-performance","title":"2.2 Verify performance\u00b6","text":"<p>Let's look at the original input and compare against the de-identified output.</p>"},{"location":"samples/python/example_dicom_image_redactor/#23-adjust-parameters","title":"2.3 Adjust parameters\u00b6","text":"<p>With the <code>use_metadata</code> parameter, we can toggle whether the DICOM metadata is used to augment the analyzer which determines which text to redact.</p>"},{"location":"samples/python/example_dicom_image_redactor/#3-redacting-from-dicom-files","title":"3. Redacting from DICOM files\u00b6","text":"<p>Before instantiating your <code>DicomImageRedactorEngine</code> class, determine where you want your input to come from and where you want your output to be written to.</p> <p>Note: The output will mimic the folder structure of the input if the input is a directory. The redact method will operate on all DICOM (.dcm) files in the input directory and all its subdirectories.</p> <p>To protect against overwriting the original DICOM files, the <code>redact_from_file()</code> and <code>redact_from_directory()</code> methods will not run if the <code>output_dir</code> is a directory which already contains any content.</p>"},{"location":"samples/python/example_dicom_image_redactor/#31-run-de-identification","title":"3.1. Run de-identification\u00b6","text":"<p>Use the <code>DicomImageRedactorEngine</code> class to process your DICOM images. If you have only one image to process and want to specify that directly instead of a directory, use <code>.redact_from_file()</code> instead of <code>.redact_from_directory()</code>.</p>"},{"location":"samples/python/example_dicom_image_redactor/#32-verify-performance","title":"3.2. Verify performance\u00b6","text":"<p>Let's look at the original input and compare against the de-identified output.</p>"},{"location":"samples/python/example_dicom_image_redactor/#conclusion","title":"Conclusion\u00b6","text":"<p>As seen in the DICOM image previews above, we see that our <code>DicomImageRedactorEngine</code> is able to successfully mask out text PHI present in the DICOM images without compromising image quality.</p> <p>Note: Performance is best when the burnt-in text is also present within the DICOM metadata. We recommend not scrubbing metadata until after performing image de-identification.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/","title":"Example dicom redactor evaluation","text":"In\u00a0[\u00a0]: Copied! <pre>!pip install presidio_analyzer presidio_anonymizer presidio_image_redactor\n!python -m spacy download en_core_web_lg\n</pre> !pip install presidio_analyzer presidio_anonymizer presidio_image_redactor !python -m spacy download en_core_web_lg In\u00a0[1]: Copied! <pre>import os\nimport json\nimport pandas as pd\nimport pydicom\n\nfrom presidio_image_redactor import DicomImagePiiVerifyEngine\n</pre> import os import json import pandas as pd import pydicom  from presidio_image_redactor import DicomImagePiiVerifyEngine In\u00a0[2]: Copied! <pre># Set paths\ndata_dir = \"sample_data\"\ngt_path = \"sample_data/ground_truth.json\"\n</pre> # Set paths data_dir = \"sample_data\" gt_path = \"sample_data/ground_truth.json\" In\u00a0[3]: Copied! <pre># Load ground truth JSON\nwith open(gt_path) as json_file:\n    gt = json.load(json_file)\n\n# Get list of files\ngt_dicom_files = list(gt.keys())\ngt_dicom_files\n</pre> # Load ground truth JSON with open(gt_path) as json_file:     gt = json.load(json_file)  # Get list of files gt_dicom_files = list(gt.keys()) gt_dicom_files Out[3]: <pre>['sample_data/0_ORIGINAL.dcm',\n 'sample_data/1_ORIGINAL.dcm',\n 'sample_data/2_ORIGINAL.dcm',\n 'sample_data/3_ORIGINAL.dcm']</pre> In\u00a0[4]: Copied! <pre>dicom_engine = DicomImagePiiVerifyEngine()\n</pre> dicom_engine = DicomImagePiiVerifyEngine() In\u00a0[5]: Copied! <pre># Select one file to work with\nfile_of_interest = gt_dicom_files[0]\ngt_file_of_interest = gt[file_of_interest]\n</pre> # Select one file to work with file_of_interest = gt_dicom_files[0] gt_file_of_interest = gt[file_of_interest] In\u00a0[6]: Copied! <pre># Return image to visually inspect\ninstance = pydicom.dcmread(file_of_interest)\nverify_image, ocr_results, analyzer_results = dicom_engine.verify_dicom_instance(instance)\n</pre> # Return image to visually inspect instance = pydicom.dcmread(file_of_interest) verify_image, ocr_results, analyzer_results = dicom_engine.verify_dicom_instance(instance) In\u00a0[7]: Copied! <pre>def get_PHI_list(PHI: list) -&gt; list:\n    \"\"\"Get list of PHI from ground truth for a single file.\n    \n    Args:\n        PHI_dict (list): List of ground truth or detected text PHI.\n    \n    Return:\n        PHI_list (list): List of PHI (just text).\n    \"\"\"\n    PHI_list = []\n    for item in PHI:\n        PHI_list.append(item['label'])\n    \n    return PHI_list\n</pre> def get_PHI_list(PHI: list) -&gt; list:     \"\"\"Get list of PHI from ground truth for a single file.          Args:         PHI_dict (list): List of ground truth or detected text PHI.          Return:         PHI_list (list): List of PHI (just text).     \"\"\"     PHI_list = []     for item in PHI:         PHI_list.append(item['label'])          return PHI_list In\u00a0[\u00a0]: Copied! <pre>_, eval_results = dicom_engine.eval_dicom_instance(instance, gt_file_of_interest)\n</pre> _, eval_results = dicom_engine.eval_dicom_instance(instance, gt_file_of_interest) <p>Results</p> In\u00a0[9]: Copied! <pre>print(f\"Precision: {eval_results['precision']}\")\nprint(f\"Recall: {eval_results['recall']}\")\nprint(f\"All Positives: {get_PHI_list(eval_results['all_positives'])}\")\nprint(f\"Ground Truth: {get_PHI_list(eval_results['ground_truth'])}\")\n</pre> print(f\"Precision: {eval_results['precision']}\") print(f\"Recall: {eval_results['recall']}\") print(f\"All Positives: {get_PHI_list(eval_results['all_positives'])}\") print(f\"Ground Truth: {get_PHI_list(eval_results['ground_truth'])}\") <pre>Precision: 1.0\nRecall: 1.0\nAll Positives: ['DAVIDSON', 'DOUGLAS', '[M]', '01.09.2012', '06.16.1976']\nGround Truth: ['DAVIDSON', 'DOUGLAS', '[M]', '01.09.2012', '06.16.1976']\n</pre> In\u00a0[10]: Copied! <pre># Initialize lists to turn into results table\nlist_of_files = gt_dicom_files\nlist_of_gt = []\nlist_of_pos = []\nlist_of_recall = []\nlist_of_precision = []\n</pre> # Initialize lists to turn into results table list_of_files = gt_dicom_files list_of_gt = [] list_of_pos = [] list_of_recall = [] list_of_precision = [] <p>Loop through all the files</p> In\u00a0[\u00a0]: Copied! <pre>for file in gt_dicom_files:\n    # Setup\n    ground_truth = gt[file]\n    instance = pydicom.dcmread(file)\n    \n    # Evaluate\n    _, eval_results = dicom_engine.eval_dicom_instance(instance, ground_truth)\n    \n    # Save results\n    list_of_gt.append(get_PHI_list(eval_results[\"ground_truth\"]))\n    list_of_pos.append(get_PHI_list(eval_results[\"all_positives\"]))\n    list_of_recall.append(eval_results[\"recall\"])\n    list_of_precision.append(eval_results[\"precision\"])\n</pre> for file in gt_dicom_files:     # Setup     ground_truth = gt[file]     instance = pydicom.dcmread(file)          # Evaluate     _, eval_results = dicom_engine.eval_dicom_instance(instance, ground_truth)          # Save results     list_of_gt.append(get_PHI_list(eval_results[\"ground_truth\"]))     list_of_pos.append(get_PHI_list(eval_results[\"all_positives\"]))     list_of_recall.append(eval_results[\"recall\"])     list_of_precision.append(eval_results[\"precision\"]) <p>Create a summary results table</p> In\u00a0[12]: Copied! <pre># Organize results into a table\nall_results_dict = {\n    \"file\": list_of_files,\n    \"ground_truth\": list_of_gt,\n    \"all_positives\": list_of_pos,\n    \"recall\": list_of_recall,\n    \"precision\": list_of_precision\n}\n\ndf_results = pd.DataFrame(all_results_dict)\ndf_results\n</pre> # Organize results into a table all_results_dict = {     \"file\": list_of_files,     \"ground_truth\": list_of_gt,     \"all_positives\": list_of_pos,     \"recall\": list_of_recall,     \"precision\": list_of_precision }  df_results = pd.DataFrame(all_results_dict) df_results Out[12]: file ground_truth all_positives recall precision 0 sample_data/0_ORIGINAL.dcm [DAVIDSON, DOUGLAS, [M], 01.09.2012, 06.16.1976] [DAVIDSON, DOUGLAS, [M], 01.09.2012, 06.16.1976] 1.0 1.0 1 sample_data/1_ORIGINAL.dcm [MARTIN, CHAD, [U], 01.01.2000] [MARTIN, CHAD, [U], 01.01.2000] 1.0 1.0 2 sample_data/2_ORIGINAL.dcm [KAUFMAN, SCOTT, [M], 03.09.2012, 07.22.1943] [KAUFMAN, 07.22.1943, SCOTT, [M], 03.09.2012] 1.0 1.0 3 sample_data/3_ORIGINAL.dcm [MEYER, STEPHANIE, [F], 02.25.2012, 07.16.1953] [MEYER, STEPHANIE, [F], 02.25.2012, 07.16.1953] 1.0 1.0 <p>For example, if we set <code>padding_width=1</code>, this can negatively impact the OCR step which identifies all text regardless of PHI status in an image if text is bordering the edges of the image. When the OCR fails to return all text, we cannot reliably detect PHI.</p> In\u00a0[\u00a0]: Copied! <pre># Select file\nfile_of_interest = gt_dicom_files[3]\ngt_file_of_interest = gt[file_of_interest]\ninstance = pydicom.dcmread(file_of_interest)\n\n# Run evaluation with minimal padding (0 padding not allowed)\n_, eval_results = dicom_engine.eval_dicom_instance(instance, gt_file_of_interest, padding_width=1)\n</pre> # Select file file_of_interest = gt_dicom_files[3] gt_file_of_interest = gt[file_of_interest] instance = pydicom.dcmread(file_of_interest)  # Run evaluation with minimal padding (0 padding not allowed) _, eval_results = dicom_engine.eval_dicom_instance(instance, gt_file_of_interest, padding_width=1) <p>Notice how low the recall is and how different the detected PHI list is here than in the summary table above which ran de-identification and evaluation with the default  <code>padding_width=25</code>.</p> In\u00a0[14]: Copied! <pre>print(f\"Precision: {eval_results['precision']}\")\nprint(f\"Recall: {eval_results['recall']}\")\nprint(f\"All Positives: {get_PHI_list(eval_results['all_positives'])}\")\nprint(f\"Ground Truth: {get_PHI_list(eval_results['ground_truth'])}\")\n</pre> print(f\"Precision: {eval_results['precision']}\") print(f\"Recall: {eval_results['recall']}\") print(f\"All Positives: {get_PHI_list(eval_results['all_positives'])}\") print(f\"Ground Truth: {get_PHI_list(eval_results['ground_truth'])}\") <pre>Precision: 1.0\nRecall: 0.2\nAll Positives: ['07.16.1953']\nGround Truth: ['MEYER', 'STEPHANIE', '[F]', '02.25.2012', '07.16.1953']\n</pre>"},{"location":"samples/python/example_dicom_redactor_evaluation/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonexample_dicom_redactor_evaluationipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/example_dicom_redactor_evaluation.ipynb\u00b6","text":""},{"location":"samples/python/example_dicom_redactor_evaluation/#evaluate-dicom-de-identification-performance","title":"Evaluate DICOM de-identification performance\u00b6","text":"<p>This notebook demonstrates how to use the <code>DicomImagePiiVerifyEngine</code> to evaluate how well the <code>DicomImageRedactorEngine</code> de-identifies text Personal Health Information (PHI) from DICOM images when ground truth labels are available.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#prerequisites","title":"Prerequisites\u00b6","text":"<p>Before getting started, make sure presidio and the latest version of Tesseract OCR are installed. For detailed documentation, see the installation docs.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#dataset","title":"Dataset\u00b6","text":"<p>Sample DICOM files are available for use in this notebook in <code>./sample_data</code>. Copies of the original DICOM data were saved into the folder with permission from the dataset owners. Please see the original dataset information below:</p> <p>Rutherford, M., Mun, S.K., Levine, B., Bennett, W.C., Smith, K., Farmer, P., Jarosz, J., Wagner, U., Farahani, K., Prior, F. (2021). A DICOM dataset for evaluation of medical image de-identification (Pseudo-PHI-DICOM-Data) [Data set]. The Cancer Imaging Archive. DOI: https://doi.org/10.7937/s17z-r072</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#load-ground-truth","title":"Load ground truth\u00b6","text":"<p>Load the ground truth labels. For more information on the ground truth format, please see the evaluating DICOM de-identification page.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#initialize-the-verification-engine","title":"Initialize the verification engine\u00b6","text":"<p>This engine will be used for both verification and evaluation.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#verify-detected-phi-for-one-dicom-image","title":"Verify detected PHI for one DICOM image\u00b6","text":"<p>To visually identify what text is being detected as PHI on a DICOM image, use the <code>.verify_dicom_instance()</code> method.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#evaluate-de-identification-performance","title":"Evaluate de-identification performance\u00b6","text":"<p>To evaluate how well the actual sensitive text (specified in the ground truth) are identified and redacted, use the <code>.evaluate_dicom_instance()</code> method.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#for-one-image","title":"For one image\u00b6","text":"<p>Display the DICOM image with bounding boxes identifying the detected PHI.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#for-multiple-images","title":"For multiple images\u00b6","text":""},{"location":"samples/python/example_dicom_redactor_evaluation/#experiment-with-settings","title":"Experiment with settings\u00b6","text":"<p>You can experiment with different settings such as <code>padding_width</code>, <code>tolerance</code>, and any additional arguments to feed into the image analyzer in your DICOM verification engine and see the effect on performance.</p> <p>Changing tolerance does not affect the de-identification logic nor image redaction. Tolerance is only used for matching analyzer results to ground truth labels.</p>"},{"location":"samples/python/example_dicom_redactor_evaluation/#conclusion","title":"Conclusion\u00b6","text":"<p>The <code>DicomImagePiiVerifyEngine</code> allows us to easily do a visual inspection on the identified PHI and also evaluate how well the de-identification worked compared to a provided ground truth.</p> <p>In the case of these sample images, the precision and recall of the Presidio <code>DicomImageRedactorEngine</code> redact function is 1.0 when we use the default values <code>padding_width=25</code> and <code>tolerance=50</code>.</p>"},{"location":"samples/python/example_pdf_annotation/","title":"Annotating PII in a PDF","text":"In\u00a0[\u00a0]: Copied! <pre>!pip install presidio_analyzer\n!pip install presidio_anonymizer\n!python -m spacy download en_core_web_lg\n!pip install pdfminer.six\n!pip install pikepdf\n</pre> !pip install presidio_analyzer !pip install presidio_anonymizer !python -m spacy download en_core_web_lg !pip install pdfminer.six !pip install pikepdf In\u00a0[4]: Copied! <pre># For Presidio\nfrom presidio_analyzer import AnalyzerEngine, PatternRecognizer\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\n\n# For console output\nfrom pprint import pprint\n\n# For extracting text\nfrom pdfminer.high_level import extract_text, extract_pages\nfrom pdfminer.layout import LTTextContainer, LTChar, LTTextLine\n\n# For updating the PDF\nfrom pikepdf import Pdf, AttachedFileSpec, Name, Dictionary, Array\n</pre> # For Presidio from presidio_analyzer import AnalyzerEngine, PatternRecognizer from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig  # For console output from pprint import pprint  # For extracting text from pdfminer.high_level import extract_text, extract_pages from pdfminer.layout import LTTextContainer, LTChar, LTTextLine  # For updating the PDF from pikepdf import Pdf, AttachedFileSpec, Name, Dictionary, Array In\u00a0[5]: Copied! <pre>analyzer = AnalyzerEngine()\n\nanalyzed_character_sets = []\n\nfor page_layout in extract_pages(\"./sample_data/sample.pdf\"):\n    for text_container in page_layout:\n        if isinstance(text_container, LTTextContainer):\n\n            # The element is a LTTextContainer, containing a paragraph of text.\n            text_to_anonymize = text_container.get_text()\n\n            # Analyze the text using the analyzer engine\n            analyzer_results = analyzer.analyze(text=text_to_anonymize, language='en')\n \n            if text_to_anonymize.isspace() == False:\n                print(text_to_anonymize)\n                print(analyzer_results)\n\n            characters = list([])\n\n            # Grab the characters from the PDF\n            for text_line in filter(lambda t: isinstance(t, LTTextLine), text_container):\n                    for character in filter(lambda t: isinstance(t, LTChar), text_line):\n                            characters.append(character)\n\n\n            # Slice out the characters that match the analyzer results.\n            for result in analyzer_results:\n                start = result.start\n                end = result.end\n                analyzed_character_sets.append({\"characters\": characters[start:end], \"result\": result})\n</pre> analyzer = AnalyzerEngine()  analyzed_character_sets = []  for page_layout in extract_pages(\"./sample_data/sample.pdf\"):     for text_container in page_layout:         if isinstance(text_container, LTTextContainer):              # The element is a LTTextContainer, containing a paragraph of text.             text_to_anonymize = text_container.get_text()              # Analyze the text using the analyzer engine             analyzer_results = analyzer.analyze(text=text_to_anonymize, language='en')               if text_to_anonymize.isspace() == False:                 print(text_to_anonymize)                 print(analyzer_results)              characters = list([])              # Grab the characters from the PDF             for text_line in filter(lambda t: isinstance(t, LTTextLine), text_container):                     for character in filter(lambda t: isinstance(t, LTChar), text_line):                             characters.append(character)               # Slice out the characters that match the analyzer results.             for result in analyzer_results:                 start = result.start                 end = result.end                 analyzed_character_sets.append({\"characters\": characters[start:end], \"result\": result}) <pre>This is a test PDF, created by Microsoft Word. \n\n[]\nHi my name is Charles Darwin and my email is cdarwin@hmsbeagle.org \n\n[type: EMAIL_ADDRESS, start: 45, end: 66, score: 1.0, type: PERSON, start: 14, end: 28, score: 0.85, type: URL, start: 53, end: 66, score: 0.5]\nYou can contact me on 01234 567890. \n\n[type: PHONE_NUMBER, start: 22, end: 34, score: 0.4, type: US_DRIVER_LICENSE, start: 28, end: 34, score: 0.01]\n</pre> In\u00a0[6]: Copied! <pre># Combine the bounding boxes into a single bounding box.\ndef combine_rect(rectA, rectB):\n    a, b = rectA, rectB\n    startX = min( a[0], b[0] )\n    startY = min( a[1], b[1] )\n    endX = max( a[2], b[2] )\n    endY = max( a[3], b[3] )\n    return (startX, startY, endX, endY)\n\nanalyzed_bounding_boxes = []\n\n# For each character set, combine the bounding boxes into a single bounding box.\nfor analyzed_character_set in analyzed_character_sets:\n    completeBoundingBox = analyzed_character_set[\"characters\"][0].bbox\n    \n    for character in analyzed_character_set[\"characters\"]:\n        completeBoundingBox = combine_rect(completeBoundingBox, character.bbox)\n    \n    analyzed_bounding_boxes.append({\"boundingBox\": completeBoundingBox, \"result\": analyzed_character_set[\"result\"]})\n</pre> # Combine the bounding boxes into a single bounding box. def combine_rect(rectA, rectB):     a, b = rectA, rectB     startX = min( a[0], b[0] )     startY = min( a[1], b[1] )     endX = max( a[2], b[2] )     endY = max( a[3], b[3] )     return (startX, startY, endX, endY)  analyzed_bounding_boxes = []  # For each character set, combine the bounding boxes into a single bounding box. for analyzed_character_set in analyzed_character_sets:     completeBoundingBox = analyzed_character_set[\"characters\"][0].bbox          for character in analyzed_character_set[\"characters\"]:         completeBoundingBox = combine_rect(completeBoundingBox, character.bbox)          analyzed_bounding_boxes.append({\"boundingBox\": completeBoundingBox, \"result\": analyzed_character_set[\"result\"]}) In\u00a0[7]: Copied! <pre>pdf = Pdf.open(\"./sample_data/sample.pdf\")\n\nannotations = []\n\n# Create a highlight annotation for each bounding box.\nfor analyzed_bounding_box in analyzed_bounding_boxes:\n\n    boundingBox = analyzed_bounding_box[\"boundingBox\"]\n\n    # Create the annotation. \n    # We could also create a redaction annotation if the ongoing workflows supports them.\n    highlight = Dictionary(\n        Type=Name.Annot,\n        Subtype=Name.Highlight,\n        QuadPoints=[boundingBox[0], boundingBox[3],\n                    boundingBox[2], boundingBox[3],\n                    boundingBox[0], boundingBox[1],\n                    boundingBox[2], boundingBox[1]],\n        Rect=[boundingBox[0], boundingBox[1], boundingBox[2], boundingBox[3]],\n        C=[1, 0, 0],\n        CA=0.5,\n        T=analyzed_bounding_box[\"result\"].entity_type,\n    )\n    \n    annotations.append(highlight)\n\n# Add the annotations to the PDF.\npdf.pages[0].Annots = pdf.make_indirect(annotations)\n\n# And save.\npdf.save(\"./sample_data/sample_annotated.pdf\")\n</pre> pdf = Pdf.open(\"./sample_data/sample.pdf\")  annotations = []  # Create a highlight annotation for each bounding box. for analyzed_bounding_box in analyzed_bounding_boxes:      boundingBox = analyzed_bounding_box[\"boundingBox\"]      # Create the annotation.      # We could also create a redaction annotation if the ongoing workflows supports them.     highlight = Dictionary(         Type=Name.Annot,         Subtype=Name.Highlight,         QuadPoints=[boundingBox[0], boundingBox[3],                     boundingBox[2], boundingBox[3],                     boundingBox[0], boundingBox[1],                     boundingBox[2], boundingBox[1]],         Rect=[boundingBox[0], boundingBox[1], boundingBox[2], boundingBox[3]],         C=[1, 0, 0],         CA=0.5,         T=analyzed_bounding_box[\"result\"].entity_type,     )          annotations.append(highlight)  # Add the annotations to the PDF. pdf.pages[0].Annots = pdf.make_indirect(annotations)  # And save. pdf.save(\"./sample_data/sample_annotated.pdf\") In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"samples/python/example_pdf_annotation/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonexample_pdf_annotationipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/example_pdf_annotation.ipynb\u00b6","text":""},{"location":"samples/python/example_pdf_annotation/#annotating-pii-in-a-pdf","title":"Annotating PII in a PDF\u00b6","text":"<p>This sample takes a PDF as an input, extracts the text, identifies PII using Presidio and annotates the PII using highlight annotations.</p>"},{"location":"samples/python/example_pdf_annotation/#prerequisites","title":"Prerequisites\u00b6","text":"<p>Before getting started, make sure the following packages are installed. For detailed documentation, see the installation docs.</p> <p>Install from PyPI:</p>"},{"location":"samples/python/example_pdf_annotation/#analyze-the-text-in-the-pdf","title":"Analyze the text in the PDF\u00b6","text":"<p>To extract the text from the PDF, we use the pdf miner library. We extract the text from the PDF at the text container level. This is roughly equivalent to a paragraph.</p> <p>We then use Presidio Analyzer to identify the PII and it's location in the text.</p> <p>The Presidio analyzer is using pre-defined entity recognizers, and offers the option to create custom recognizers.</p>"},{"location":"samples/python/example_pdf_annotation/#create-phrase-bounding-boxes","title":"Create phrase bounding boxes\u00b6","text":"<p>The next task is to take the character data, and inflate it into full phrase bounding boxes.</p> <p>For example, for an email address, we'll turn the bounding boxes for each character in the email address into one single bounding box.</p>"},{"location":"samples/python/example_pdf_annotation/#add-highlight-annotations","title":"Add highlight annotations\u00b6","text":"<p>We finally iterate through all the analyzed bounding boxes and create highlight annotations for all of them.</p>"},{"location":"samples/python/example_pdf_annotation/#result","title":"Result\u00b6","text":"<p>The output from the samples above creates a new PDF. This contains the original content, with text highlight annotations where the PII has been found.</p> <p>Each text annotation contains the name of the entity found.</p>"},{"location":"samples/python/example_pdf_annotation/#note","title":"Note\u00b6","text":"<p>Before relying on this methodology to detect or markup PII from a PDF, please be aware of the following:</p>"},{"location":"samples/python/example_pdf_annotation/#text-extraction","title":"Text extraction\u00b6","text":"<p>We purposely use a different library specifically for extracting text from the PDF. This is because text extraction is hard to get right, and it's worth using a library specifically developed with the purpose in mind.</p> <p>For more details, see:</p> <p>https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html</p> <p>That said, even with a purpose built library, there may be occasions where PII is present and visible in a PDF, but it is not detected by the sample code.</p> <p>This includes, but is not limited to:</p> <ul> <li>Text that cannot be reliable extracted to be analyzed. (e.g. incorrect spacing, wrong reading order)</li> <li>Text present in previous iterations of the PDF which is hidden from text extraction. (See incremental editing)</li> <li>Text present in images. (requires OCRing)</li> <li>Text present in annotations.</li> </ul>"},{"location":"samples/python/example_remote_recognizer/","title":"Example remote recognizer","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nExample implementation of a RemoteRecognizer.\n\nRemote recognizers call external APIs\nto get additional PII identification capabilities.\nThese results are added to all the other results\ngathered by the different recognizers.\n\nThe actual call logic (e.g., HTTP or gRPC)\nshould be implemented within this class.\nIn this example, we use the `requests` package to perform a POST request.\nFlow:\n1. During `load`, call `supported_entities`\nto get a list of what this service can detect\n2. Translate the response coming from the `supported_entities` endpoint\n3. During `analyze`, perform a POST request to the PII detector endpoint\n4. Translate the response coming from the\nPII detector endpoint into a List[RecognizerResult]\n5. Return results\n\nNote: In this example we mimic an external PII detector\nby using Presidio Analyzer itself.\n\n\"\"\"\n</pre> \"\"\" Example implementation of a RemoteRecognizer.  Remote recognizers call external APIs to get additional PII identification capabilities. These results are added to all the other results gathered by the different recognizers.  The actual call logic (e.g., HTTP or gRPC) should be implemented within this class. In this example, we use the `requests` package to perform a POST request. Flow: 1. During `load`, call `supported_entities` to get a list of what this service can detect 2. Translate the response coming from the `supported_entities` endpoint 3. During `analyze`, perform a POST request to the PII detector endpoint 4. Translate the response coming from the PII detector endpoint into a List[RecognizerResult] 5. Return results  Note: In this example we mimic an external PII detector by using Presidio Analyzer itself.  \"\"\" In\u00a0[\u00a0]: Copied! <pre>import json\nimport logging\nfrom typing import List\n</pre> import json import logging from typing import List In\u00a0[\u00a0]: Copied! <pre>import requests\n</pre> import requests In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import RemoteRecognizer, RecognizerResult\nfrom presidio_analyzer.nlp_engine import NlpArtifacts\n</pre> from presidio_analyzer import RemoteRecognizer, RecognizerResult from presidio_analyzer.nlp_engine import NlpArtifacts In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-analyzer\")\n</pre> logger = logging.getLogger(\"presidio-analyzer\") In\u00a0[\u00a0]: Copied! <pre>class ExampleRemoteRecognizer(RemoteRecognizer):\n    \"\"\"\n    A reference implementation of a remote recognizer.\n\n    Calls Presidio analyzer as if it was an external remote PII detector\n    :param pii_identification_url: Service URL for detecting PII\n    :param supported_entities_url: Service URL for getting the supported entities\n    by this service\n    \"\"\"\n\n    def __init__(\n        self,\n        pii_identification_url: str = \"https://MYPIISERVICE_URL/detect\",\n        supported_entities_url: str = \"https://MYPIISERVICE_URL/supported_entities\",\n    ):\n        self.pii_identification_url = pii_identification_url\n        self.supported_entities_url = supported_entities_url\n\n        super().__init__(\n            supported_entities=[], name=None, supported_language=\"en\", version=\"1.0\"\n        )\n\n    def load(self) -&gt; None:\n        \"\"\"Call the get_supported_entities API of the external service.\"\"\"\n        try:\n            response = requests.get(\n                self.supported_entities_url,\n                params={\"language\": self.supported_language},\n            )\n            self.supported_entities = self._supported_entities_from_response(response)\n\n        except requests.exceptions.RequestException as e:\n            logger.error(f\"Failed to get supported entities from external service. {e}\")\n            self.supported_language = []\n\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"Call an external service for PII detection.\"\"\"\n\n        payload = {\"text\": text, \"language\": self.supported_language}\n\n        response = requests.post(\n            self.pii_identification_url,\n            json=payload,\n            timeout=200,\n        )\n\n        results = self._recognizer_results_from_response(response)\n\n        return results\n\n    def get_supported_entities(self) -&gt; List[str]:\n        \"\"\"Return the list of supported entities.\"\"\"\n        return self.supported_entities\n\n    @staticmethod\n    def _recognizer_results_from_response(\n        response: requests.Response,\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"Translate the service's response to a list of RecognizerResult.\"\"\"\n        results = json.loads(response.text)\n        recognizer_results = [RecognizerResult(**result) for result in results]\n\n        return recognizer_results\n\n    @staticmethod\n    def _supported_entities_from_response(response: requests.Response) -&gt; List[str]:\n        \"\"\"Translate the service's supported entities list to Presidio's.\"\"\"\n        return json.loads(response.text)\n</pre> class ExampleRemoteRecognizer(RemoteRecognizer):     \"\"\"     A reference implementation of a remote recognizer.      Calls Presidio analyzer as if it was an external remote PII detector     :param pii_identification_url: Service URL for detecting PII     :param supported_entities_url: Service URL for getting the supported entities     by this service     \"\"\"      def __init__(         self,         pii_identification_url: str = \"https://MYPIISERVICE_URL/detect\",         supported_entities_url: str = \"https://MYPIISERVICE_URL/supported_entities\",     ):         self.pii_identification_url = pii_identification_url         self.supported_entities_url = supported_entities_url          super().__init__(             supported_entities=[], name=None, supported_language=\"en\", version=\"1.0\"         )      def load(self) -&gt; None:         \"\"\"Call the get_supported_entities API of the external service.\"\"\"         try:             response = requests.get(                 self.supported_entities_url,                 params={\"language\": self.supported_language},             )             self.supported_entities = self._supported_entities_from_response(response)          except requests.exceptions.RequestException as e:             logger.error(f\"Failed to get supported entities from external service. {e}\")             self.supported_language = []      def analyze(         self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts     ) -&gt; List[RecognizerResult]:         \"\"\"Call an external service for PII detection.\"\"\"          payload = {\"text\": text, \"language\": self.supported_language}          response = requests.post(             self.pii_identification_url,             json=payload,             timeout=200,         )          results = self._recognizer_results_from_response(response)          return results      def get_supported_entities(self) -&gt; List[str]:         \"\"\"Return the list of supported entities.\"\"\"         return self.supported_entities      @staticmethod     def _recognizer_results_from_response(         response: requests.Response,     ) -&gt; List[RecognizerResult]:         \"\"\"Translate the service's response to a list of RecognizerResult.\"\"\"         results = json.loads(response.text)         recognizer_results = [RecognizerResult(**result) for result in results]          return recognizer_results      @staticmethod     def _supported_entities_from_response(response: requests.Response) -&gt; List[str]:         \"\"\"Translate the service's supported entities list to Presidio's.\"\"\"         return json.loads(response.text) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n\n    # Illustrative example only: Run Presidio analyzer\n    # as if it was an external PII detection mechanism.\n    rec = ExampleRemoteRecognizer(\n        pii_identification_url=\"http://localhost:5002/analyze\",\n        supported_entities_url=\"http://localhost:5002/supportedentities\",\n    )\n\n    remote_results = rec.analyze(\n        text=\"My name is Morris\", entities=[\"PERSON\"], nlp_artifacts=None\n    )\n    print(remote_results)\n</pre> if __name__ == \"__main__\":      # Illustrative example only: Run Presidio analyzer     # as if it was an external PII detection mechanism.     rec = ExampleRemoteRecognizer(         pii_identification_url=\"http://localhost:5002/analyze\",         supported_entities_url=\"http://localhost:5002/supportedentities\",     )      remote_results = rec.analyze(         text=\"My name is Morris\", entities=[\"PERSON\"], nlp_artifacts=None     )     print(remote_results)"},{"location":"samples/python/example_structured/","title":"Presidio Structured Basic Usage","text":"In\u00a0[\u00a0]: Copied! <pre>from presidio_structured import StructuredEngine, JsonAnalysisBuilder, PandasAnalysisBuilder, StructuredAnalysis, CsvReader, JsonReader, JsonDataProcessor, PandasDataProcessor\n</pre> from presidio_structured import StructuredEngine, JsonAnalysisBuilder, PandasAnalysisBuilder, StructuredAnalysis, CsvReader, JsonReader, JsonDataProcessor, PandasDataProcessor <p>This sample showcases presidio-structured on structured and semi-structured data containing sensitive data like names, emails, and addresses. It differs from the sample for the batch analyzer/anonymizer engines example, which includes narrative phrases that might contain sensitive data. The presence of personal data embedded in these phrases requires to analyze and to anonymize the text inside the cells, which is not the case for our structured sample, where the sensitive data is already separated into columns.</p> In\u00a0[13]: Copied! <pre>sample_df = CsvReader().read(\"./csv_sample_data/test_structured.csv\")\nsample_df\n</pre> sample_df = CsvReader().read(\"./csv_sample_data/test_structured.csv\") sample_df Out[13]: id name email street city state non_pii 0 1 John Doe john.doe@example.com 123 Main St Anytown CA reallynotpii 1 2 Jane Smith jane.smith@example.com 456 Elm St Somewhere TX reallynotapii 2 3 Alice Johnson alice.johnson@example.com 789 Pine St Elsewhere NY reallynotapiiatall In\u00a0[14]: Copied! <pre>sample_json = JsonReader().read(\"./sample_data/test_structured.json\")\nsample_json\n</pre> sample_json = JsonReader().read(\"./sample_data/test_structured.json\") sample_json Out[14]: <pre>{'id': 1,\n 'name': 'John Doe',\n 'email': 'john.doe@example.com',\n 'address': {'street': '123 Main St',\n  'city': 'Anytown',\n  'state': 'CA',\n  'non_pii': 'reallynotapiiatall'}}</pre> In\u00a0[15]: Copied! <pre># contains nested objects in lists\nsample_complex_json = JsonReader().read(\"./sample_data/test_structured_complex.json\")\nsample_complex_json\n</pre> # contains nested objects in lists sample_complex_json = JsonReader().read(\"./sample_data/test_structured_complex.json\") sample_complex_json Out[15]: <pre>{'users': [{'id': 1,\n   'name': 'John Doe',\n   'email': 'john.doe@example.com',\n   'address': {'street': '123 Main St',\n    'city': 'Anytown',\n    'state': 'CA',\n    'non_pii': 'reallynotpii'}},\n  {'id': 2,\n   'name': 'Jane Smith',\n   'email': 'jane.smith@example.com',\n   'address': {'street': '456 Elm St',\n    'city': 'Somewhere',\n    'state': 'TX',\n    'non_pii': 'reallynotapii'}},\n  {'id': 3,\n   'name': 'Alice Johnson',\n   'email': 'alice.johnson@example.com',\n   'address': {'street': '789 Pine St',\n    'city': 'Elsewhere',\n    'state': 'NY',\n    'non_pii': 'reallynotapiiatall'}}]}</pre> In\u00a0[16]: Copied! <pre># Automatically detect the entity for the columns\ntabular_analysis = PandasAnalysisBuilder().generate_analysis(sample_df)\ntabular_analysis\n</pre> # Automatically detect the entity for the columns tabular_analysis = PandasAnalysisBuilder().generate_analysis(sample_df) tabular_analysis Out[16]: <pre>StructuredAnalysis(entity_mapping={'name': 'PERSON', 'email': 'URL', 'city': 'LOCATION', 'state': 'LOCATION'})</pre> In\u00a0[17]: Copied! <pre># anonymized data defaults to be replaced with None, unless operators is specified\n\npandas_engine = StructuredEngine(data_processor=PandasDataProcessor())\ndf_to_be_anonymized = sample_df.copy() # in-place anonymization\nanonymized_df = pandas_engine.anonymize(df_to_be_anonymized, tabular_analysis, operators=None) # explicit None for clarity\nanonymized_df\n</pre> # anonymized data defaults to be replaced with None, unless operators is specified  pandas_engine = StructuredEngine(data_processor=PandasDataProcessor()) df_to_be_anonymized = sample_df.copy() # in-place anonymization anonymized_df = pandas_engine.anonymize(df_to_be_anonymized, tabular_analysis, operators=None) # explicit None for clarity anonymized_df Out[17]: id name email street city state non_pii 0 1 &lt;None&gt; &lt;None&gt; 123 Main St &lt;None&gt; &lt;None&gt; reallynotpii 1 2 &lt;None&gt; &lt;None&gt; 456 Elm St &lt;None&gt; &lt;None&gt; reallynotapii 2 3 &lt;None&gt; &lt;None&gt; 789 Pine St &lt;None&gt; &lt;None&gt; reallynotapiiatall In\u00a0[18]: Copied! <pre>from presidio_anonymizer.entities.engine import OperatorConfig\nfrom faker import Faker\nfake = Faker()\n\noperators = {\n    \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"person...\"}),\n    \"EMAIL_ADDRESS\": OperatorConfig(\"custom\", {\"lambda\": lambda x: fake.safe_email()})\n    # etc...\n    }\nanonymized_df = pandas_engine.anonymize(sample_df, tabular_analysis, operators=operators)\nanonymized_df\n</pre> from presidio_anonymizer.entities.engine import OperatorConfig from faker import Faker fake = Faker()  operators = {     \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"person...\"}),     \"EMAIL_ADDRESS\": OperatorConfig(\"custom\", {\"lambda\": lambda x: fake.safe_email()})     # etc...     } anonymized_df = pandas_engine.anonymize(sample_df, tabular_analysis, operators=operators) anonymized_df Out[18]: id name email street city state non_pii 0 1 person... &lt;None&gt; 123 Main St &lt;None&gt; &lt;None&gt; reallynotpii 1 2 person... &lt;None&gt; 456 Elm St &lt;None&gt; &lt;None&gt; reallynotapii 2 3 person... &lt;None&gt; 789 Pine St &lt;None&gt; &lt;None&gt; reallynotapiiatall In\u00a0[19]: Copied! <pre>json_analysis = JsonAnalysisBuilder().generate_analysis(sample_json)\njson_analysis\n</pre> json_analysis = JsonAnalysisBuilder().generate_analysis(sample_json) json_analysis Out[19]: <pre>StructuredAnalysis(entity_mapping={'name': 'PERSON', 'email': 'EMAIL_ADDRESS', 'address.city': 'LOCATION'})</pre> In\u00a0[20]: Copied! <pre># Currently does not support nested objects in lists\ntry:\n    json_complex_analysis = JsonAnalysisBuilder().generate_analysis(sample_complex_json)\nexcept ValueError as e:\n    print(e)\n\n# however, we can define it manually:\njson_complex_analysis = StructuredAnalysis(entity_mapping={\n    \"users.name\":\"PERSON\",\n    \"users.address.street\":\"LOCATION\",\n    \"users.address.city\":\"LOCATION\",\n    \"users.address.state\":\"LOCATION\",\n    \"users.email\": \"EMAIL_ADDRESS\",\n})\n</pre> # Currently does not support nested objects in lists try:     json_complex_analysis = JsonAnalysisBuilder().generate_analysis(sample_complex_json) except ValueError as e:     print(e)  # however, we can define it manually: json_complex_analysis = StructuredAnalysis(entity_mapping={     \"users.name\":\"PERSON\",     \"users.address.street\":\"LOCATION\",     \"users.address.city\":\"LOCATION\",     \"users.address.state\":\"LOCATION\",     \"users.email\": \"EMAIL_ADDRESS\", }) <pre>Analyzer.analyze_iterator only works on primitive types (int, float, bool, str). Lists of objects are not yet supported.\n</pre> In\u00a0[21]: Copied! <pre># anonymizing simple data\njson_engine = StructuredEngine(data_processor=JsonDataProcessor())\nanonymized_json = json_engine.anonymize(sample_json, json_analysis, operators=operators)\nanonymized_json\n</pre> # anonymizing simple data json_engine = StructuredEngine(data_processor=JsonDataProcessor()) anonymized_json = json_engine.anonymize(sample_json, json_analysis, operators=operators) anonymized_json Out[21]: <pre>{'id': 1,\n 'name': 'person...',\n 'email': 'duarteangela@example.org',\n 'address': {'street': '123 Main St',\n  'city': '&lt;None&gt;',\n  'state': 'CA',\n  'non_pii': 'reallynotapiiatall'}}</pre> In\u00a0[22]: Copied! <pre>anonymized_complex_json = json_engine.anonymize(sample_complex_json, json_complex_analysis, operators=operators)\nanonymized_complex_json\n</pre> anonymized_complex_json = json_engine.anonymize(sample_complex_json, json_complex_analysis, operators=operators) anonymized_complex_json Out[22]: <pre>{'users': [{'id': 1,\n   'name': 'person...',\n   'email': 'bmcfarland@example.org',\n   'address': {'street': '&lt;None&gt;',\n    'city': '&lt;None&gt;',\n    'state': '&lt;None&gt;',\n    'non_pii': 'reallynotpii'}},\n  {'id': 2,\n   'name': 'person...',\n   'email': 'bmcfarland@example.org',\n   'address': {'street': '&lt;None&gt;',\n    'city': '&lt;None&gt;',\n    'state': '&lt;None&gt;',\n    'non_pii': 'reallynotapii'}},\n  {'id': 3,\n   'name': 'person...',\n   'email': 'bmcfarland@example.org',\n   'address': {'street': '&lt;None&gt;',\n    'city': '&lt;None&gt;',\n    'state': '&lt;None&gt;',\n    'non_pii': 'reallynotapiiatall'}}]}</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"samples/python/example_structured/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonexample_structuredipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/example_structured.ipynb\u00b6","text":""},{"location":"samples/python/example_structured/#loading-in-data","title":"Loading in data\u00b6","text":""},{"location":"samples/python/example_structured/#tabular-csv-data-defining-generating-tabular-analysis-anonymization","title":"Tabular (csv) data: defining &amp; generating tabular analysis, anonymization.\u00b6","text":""},{"location":"samples/python/example_structured/#we-can-also-define-operators-using-operatorconfig-similar-as-to-the-anonymizerengine","title":"We can also define operators using OperatorConfig similar as to the AnonymizerEngine:\u00b6","text":""},{"location":"samples/python/example_structured/#semi-structured-json-data-simple-and-complex-analysis-anonymization","title":"Semi-structured (JSON) data: simple and complex analysis, anonymization\u00b6","text":""},{"location":"samples/python/flair_recognizer/","title":"Flair recognizer","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nfrom typing import Optional, List, Tuple, Set\n</pre> import logging from typing import Optional, List, Tuple, Set In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import (\n    RecognizerResult,\n    EntityRecognizer,\n    AnalysisExplanation,\n)\nfrom presidio_analyzer.nlp_engine import NlpArtifacts\n</pre> from presidio_analyzer import (     RecognizerResult,     EntityRecognizer,     AnalysisExplanation, ) from presidio_analyzer.nlp_engine import NlpArtifacts In\u00a0[\u00a0]: Copied! <pre>try:\n    from flair.data import Sentence\n    from flair.models import SequenceTagger\nexcept ImportError:\n    print(\"Flair is not installed\")\n</pre> try:     from flair.data import Sentence     from flair.models import SequenceTagger except ImportError:     print(\"Flair is not installed\") In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-analyzer\")\n</pre> logger = logging.getLogger(\"presidio-analyzer\") In\u00a0[\u00a0]: Copied! <pre>class FlairRecognizer(EntityRecognizer):\n    \"\"\"\n    Wrapper for a flair model, if needed to be used within Presidio Analyzer.\n\n    :example:\n    &gt;from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\n    &gt;flair_recognizer = FlairRecognizer()\n\n    &gt;registry = RecognizerRegistry()\n    &gt;registry.add_recognizer(flair_recognizer)\n\n    &gt;analyzer = AnalyzerEngine(registry=registry)\n\n    &gt;results = analyzer.analyze(\n    &gt;    \"My name is Christopher and I live in Irbid.\",\n    &gt;    language=\"en\",\n    &gt;    return_decision_process=True,\n    &gt;)\n    &gt;for result in results:\n    &gt;    print(result)\n    &gt;    print(result.analysis_explanation)\n\n\n    \"\"\"\n\n    ENTITIES = [\n        \"LOCATION\",\n        \"PERSON\",\n        \"ORGANIZATION\",\n        # \"MISCELLANEOUS\"   # - There are no direct correlation with Presidio entities.\n    ]\n\n    DEFAULT_EXPLANATION = \"Identified as {} by Flair's Named Entity Recognition\"\n\n    CHECK_LABEL_GROUPS = [\n        ({\"LOCATION\"}, {\"LOC\", \"LOCATION\"}),\n        ({\"PERSON\"}, {\"PER\", \"PERSON\"}),\n        ({\"ORGANIZATION\"}, {\"ORG\"}),\n        # ({\"MISCELLANEOUS\"}, {\"MISC\"}), # Probably not PII\n    ]\n\n    MODEL_LANGUAGES = {\n        \"en\": \"flair/ner-english-large\",\n        \"es\": \"flair/ner-spanish-large\",\n        \"de\": \"flair/ner-german-large\",\n        \"nl\": \"flair/ner-dutch-large\",\n    }\n\n    PRESIDIO_EQUIVALENCES = {\n        \"PER\": \"PERSON\",\n        \"LOC\": \"LOCATION\",\n        \"ORG\": \"ORGANIZATION\",\n        # 'MISC': 'MISCELLANEOUS'   # - Probably not PII\n    }\n\n    def __init__(\n        self,\n        supported_language: str = \"en\",\n        supported_entities: Optional[List[str]] = None,\n        check_label_groups: Optional[Tuple[Set, Set]] = None,\n        model: SequenceTagger = None,\n    ):\n        self.check_label_groups = (\n            check_label_groups if check_label_groups else self.CHECK_LABEL_GROUPS\n        )\n\n        supported_entities = supported_entities if supported_entities else self.ENTITIES\n        self.model = (\n            model\n            if model\n            else SequenceTagger.load(self.MODEL_LANGUAGES.get(supported_language))\n        )\n\n        super().__init__(\n            supported_entities=supported_entities,\n            supported_language=supported_language,\n            name=\"Flair Analytics\",\n        )\n\n    def load(self) -&gt; None:\n        \"\"\"Load the model, not used. Model is loaded during initialization.\"\"\"\n        pass\n\n    def get_supported_entities(self) -&gt; List[str]:\n        \"\"\"\n        Return supported entities by this model.\n\n        :return: List of the supported entities.\n        \"\"\"\n        return self.supported_entities\n\n    # Class to use Flair with Presidio as an external recognizer.\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Analyze text using Text Analytics.\n\n        :param text: The text for analysis.\n        :param entities: Not working properly for this recognizer.\n        :param nlp_artifacts: Not used by this recognizer.\n        :param language: Text language. Supported languages in MODEL_LANGUAGES\n        :return: The list of Presidio RecognizerResult constructed from the recognized\n            Flair detections.\n        \"\"\"\n\n        results = []\n\n        sentences = Sentence(text)\n        self.model.predict(sentences)\n\n        # If there are no specific list of entities, we will look for all of it.\n        if not entities:\n            entities = self.supported_entities\n\n        for entity in entities:\n            if entity not in self.supported_entities:\n                continue\n\n            for ent in sentences.get_spans(\"ner\"):\n                if not self.__check_label(\n                    entity, ent.labels[0].value, self.check_label_groups\n                ):\n                    continue\n                textual_explanation = self.DEFAULT_EXPLANATION.format(\n                    ent.labels[0].value\n                )\n                explanation = self.build_flair_explanation(\n                    round(ent.score, 2), textual_explanation\n                )\n                flair_result = self._convert_to_recognizer_result(ent, explanation)\n\n                results.append(flair_result)\n\n        return results\n\n    def _convert_to_recognizer_result(self, entity, explanation) -&gt; RecognizerResult:\n\n        entity_type = self.PRESIDIO_EQUIVALENCES.get(entity.tag, entity.tag)\n        flair_score = round(entity.score, 2)\n\n        flair_results = RecognizerResult(\n            entity_type=entity_type,\n            start=entity.start_position,\n            end=entity.end_position,\n            score=flair_score,\n            analysis_explanation=explanation,\n        )\n\n        return flair_results\n\n    def build_flair_explanation(\n        self, original_score: float, explanation: str\n    ) -&gt; AnalysisExplanation:\n        \"\"\"\n        Create explanation for why this result was detected.\n\n        :param original_score: Score given by this recognizer\n        :param explanation: Explanation string\n        :return:\n        \"\"\"\n        explanation = AnalysisExplanation(\n            recognizer=self.__class__.__name__,\n            original_score=original_score,\n            textual_explanation=explanation,\n        )\n        return explanation\n\n    @staticmethod\n    def __check_label(\n        entity: str, label: str, check_label_groups: Tuple[Set, Set]\n    ) -&gt; bool:\n        return any(\n            [entity in egrp and label in lgrp for egrp, lgrp in check_label_groups]\n        )\n</pre> class FlairRecognizer(EntityRecognizer):     \"\"\"     Wrapper for a flair model, if needed to be used within Presidio Analyzer.      :example:     &gt;from presidio_analyzer import AnalyzerEngine, RecognizerRegistry      &gt;flair_recognizer = FlairRecognizer()      &gt;registry = RecognizerRegistry()     &gt;registry.add_recognizer(flair_recognizer)      &gt;analyzer = AnalyzerEngine(registry=registry)      &gt;results = analyzer.analyze(     &gt;    \"My name is Christopher and I live in Irbid.\",     &gt;    language=\"en\",     &gt;    return_decision_process=True,     &gt;)     &gt;for result in results:     &gt;    print(result)     &gt;    print(result.analysis_explanation)       \"\"\"      ENTITIES = [         \"LOCATION\",         \"PERSON\",         \"ORGANIZATION\",         # \"MISCELLANEOUS\"   # - There are no direct correlation with Presidio entities.     ]      DEFAULT_EXPLANATION = \"Identified as {} by Flair's Named Entity Recognition\"      CHECK_LABEL_GROUPS = [         ({\"LOCATION\"}, {\"LOC\", \"LOCATION\"}),         ({\"PERSON\"}, {\"PER\", \"PERSON\"}),         ({\"ORGANIZATION\"}, {\"ORG\"}),         # ({\"MISCELLANEOUS\"}, {\"MISC\"}), # Probably not PII     ]      MODEL_LANGUAGES = {         \"en\": \"flair/ner-english-large\",         \"es\": \"flair/ner-spanish-large\",         \"de\": \"flair/ner-german-large\",         \"nl\": \"flair/ner-dutch-large\",     }      PRESIDIO_EQUIVALENCES = {         \"PER\": \"PERSON\",         \"LOC\": \"LOCATION\",         \"ORG\": \"ORGANIZATION\",         # 'MISC': 'MISCELLANEOUS'   # - Probably not PII     }      def __init__(         self,         supported_language: str = \"en\",         supported_entities: Optional[List[str]] = None,         check_label_groups: Optional[Tuple[Set, Set]] = None,         model: SequenceTagger = None,     ):         self.check_label_groups = (             check_label_groups if check_label_groups else self.CHECK_LABEL_GROUPS         )          supported_entities = supported_entities if supported_entities else self.ENTITIES         self.model = (             model             if model             else SequenceTagger.load(self.MODEL_LANGUAGES.get(supported_language))         )          super().__init__(             supported_entities=supported_entities,             supported_language=supported_language,             name=\"Flair Analytics\",         )      def load(self) -&gt; None:         \"\"\"Load the model, not used. Model is loaded during initialization.\"\"\"         pass      def get_supported_entities(self) -&gt; List[str]:         \"\"\"         Return supported entities by this model.          :return: List of the supported entities.         \"\"\"         return self.supported_entities      # Class to use Flair with Presidio as an external recognizer.     def analyze(         self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None     ) -&gt; List[RecognizerResult]:         \"\"\"         Analyze text using Text Analytics.          :param text: The text for analysis.         :param entities: Not working properly for this recognizer.         :param nlp_artifacts: Not used by this recognizer.         :param language: Text language. Supported languages in MODEL_LANGUAGES         :return: The list of Presidio RecognizerResult constructed from the recognized             Flair detections.         \"\"\"          results = []          sentences = Sentence(text)         self.model.predict(sentences)          # If there are no specific list of entities, we will look for all of it.         if not entities:             entities = self.supported_entities          for entity in entities:             if entity not in self.supported_entities:                 continue              for ent in sentences.get_spans(\"ner\"):                 if not self.__check_label(                     entity, ent.labels[0].value, self.check_label_groups                 ):                     continue                 textual_explanation = self.DEFAULT_EXPLANATION.format(                     ent.labels[0].value                 )                 explanation = self.build_flair_explanation(                     round(ent.score, 2), textual_explanation                 )                 flair_result = self._convert_to_recognizer_result(ent, explanation)                  results.append(flair_result)          return results      def _convert_to_recognizer_result(self, entity, explanation) -&gt; RecognizerResult:          entity_type = self.PRESIDIO_EQUIVALENCES.get(entity.tag, entity.tag)         flair_score = round(entity.score, 2)          flair_results = RecognizerResult(             entity_type=entity_type,             start=entity.start_position,             end=entity.end_position,             score=flair_score,             analysis_explanation=explanation,         )          return flair_results      def build_flair_explanation(         self, original_score: float, explanation: str     ) -&gt; AnalysisExplanation:         \"\"\"         Create explanation for why this result was detected.          :param original_score: Score given by this recognizer         :param explanation: Explanation string         :return:         \"\"\"         explanation = AnalysisExplanation(             recognizer=self.__class__.__name__,             original_score=original_score,             textual_explanation=explanation,         )         return explanation      @staticmethod     def __check_label(         entity: str, label: str, check_label_groups: Tuple[Set, Set]     ) -&gt; bool:         return any(             [entity in egrp and label in lgrp for egrp, lgrp in check_label_groups]         ) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n\n    from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\n    flair_recognizer = (\n        FlairRecognizer()\n    )  # This would download a very large (+2GB) model on the first run\n\n    registry = RecognizerRegistry()\n    registry.add_recognizer(flair_recognizer)\n\n    analyzer = AnalyzerEngine(registry=registry)\n\n    results = analyzer.analyze(\n        \"My name is Christopher and I live in Irbid.\",\n        language=\"en\",\n        return_decision_process=True,\n    )\n    for result in results:\n        print(result)\n        print(result.analysis_explanation)\n</pre> if __name__ == \"__main__\":      from presidio_analyzer import AnalyzerEngine, RecognizerRegistry      flair_recognizer = (         FlairRecognizer()     )  # This would download a very large (+2GB) model on the first run      registry = RecognizerRegistry()     registry.add_recognizer(flair_recognizer)      analyzer = AnalyzerEngine(registry=registry)      results = analyzer.analyze(         \"My name is Christopher and I live in Irbid.\",         language=\"en\",         return_decision_process=True,     )     for result in results:         print(result)         print(result.analysis_explanation)"},{"location":"samples/python/getting_entity_values/","title":"Getting entity values","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !python -m spacy download en_core_web_lg In\u00a0[1]: Copied! <pre>from presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\n</pre> from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig In\u00a0[2]: Copied! <pre>analyzer = AnalyzerEngine()\nanonymizer = AnonymizerEngine()\n</pre> analyzer = AnalyzerEngine() anonymizer = AnonymizerEngine() In\u00a0[3]: Copied! <pre>text_to_analyze = \"Hi my name is Charles Darwin and my email is cdarwin@hmsbeagle.org\"\nanalyzer_results = analyzer.analyze(text_to_analyze, language=\"en\")\n</pre> text_to_analyze = \"Hi my name is Charles Darwin and my email is cdarwin@hmsbeagle.org\" analyzer_results = analyzer.analyze(text_to_analyze, language=\"en\")  <p>A naive approach for getting the text values:</p> In\u00a0[4]: Copied! <pre>[(text_to_analyze[res.start:res.end], res.start, res.end) for res in analyzer_results]\n</pre> [(text_to_analyze[res.start:res.end], res.start, res.end) for res in analyzer_results] Out[4]: <pre>[('cdarwin@hmsbeagle.org', 45, 66),\n ('Charles Darwin', 14, 28),\n ('hmsbeagle.org', 53, 66)]</pre> <p>Another option is to set up a custom operator* which runs an identity function (<code>lambda x: x</code>). This operator doesn't really anonymize, but replaces the identified value with itself. This is useful as the Anonymizer handles the overlaps automatically.</p> <p>In this example, the URL (hmsbeagle.org) is contained in the email address, so it's ommitted from the final result.</p> <p>* an <code>Operator</code> is usually either an <code>Anonymizer</code> or <code>Deanonymizer</code> on the presidio-anonymizer library/</p> In\u00a0[7]: Copied! <pre>anonymized_results = anonymizer.anonymize(\n        text=text_to_analyze,\n        analyzer_results=analyzer_results,            \n        operators={\"DEFAULT\": OperatorConfig(\"custom\", {\"lambda\": lambda x: x})}        \n    )\n</pre> anonymized_results = anonymizer.anonymize(         text=text_to_analyze,         analyzer_results=analyzer_results,                     operators={\"DEFAULT\": OperatorConfig(\"custom\", {\"lambda\": lambda x: x})}             ) <p>The operator defined here is <code>DEFAULT</code>, meaning it will be used for all entities. The <code>OperatorConfig</code> is a custom one and the labmda is the identity function.</p> <p>Output text, start and end locations for each detected entity</p> In\u00a0[8]: Copied! <pre>[(item.text, item.start, item.end) for item in anonymized_results.items]\n</pre> [(item.text, item.start, item.end) for item in anonymized_results.items] Out[8]: <pre>[('cdarwin@hmsbeagle.org', 45, 66), ('Charles Darwin', 14, 28)]</pre> <p>A third option would be to use the <code>keep</code> operator:</p> In\u00a0[9]: Copied! <pre>anonymized_results_with_keep = anonymizer.anonymize(\n        text=text_to_analyze,\n        analyzer_results=analyzer_results,            \n        operators={\"DEFAULT\": OperatorConfig(\"keep\")}        \n    )\n[(item.text, item.start, item.end) for item in anonymized_results_with_keep.items]\n</pre> anonymized_results_with_keep = anonymizer.anonymize(         text=text_to_analyze,         analyzer_results=analyzer_results,                     operators={\"DEFAULT\": OperatorConfig(\"keep\")}             ) [(item.text, item.start, item.end) for item in anonymized_results_with_keep.items] Out[9]: <pre>[('cdarwin@hmsbeagle.org', 45, 66), ('Charles Darwin', 14, 28)]</pre>"},{"location":"samples/python/getting_entity_values/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythongetting_entity_valuesipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/getting_entity_values.ipynb\u00b6","text":""},{"location":"samples/python/getting_entity_values/#getting-a-list-of-all-identified-texts","title":"Getting a list of all identified texts\u00b6","text":"<p>This sample illustrates how to get a list of all the identified PII entities using Presidio Analyzer for detection and a custom Presidio Anonymizer operator.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/","title":"Using an allow list with image redaction","text":"In\u00a0[\u00a0]: Copied! <pre>!pip install presidio_analyzer presidio_anonymizer presidio_image_redactor\n!python -m spacy download en_core_web_lg\n</pre> !pip install presidio_analyzer presidio_anonymizer presidio_image_redactor !python -m spacy download en_core_web_lg In\u00a0[1]: Copied! <pre>from PIL import Image\nimport pydicom\nfrom presidio_analyzer import Pattern, PatternRecognizer\nfrom presidio_image_redactor import ImageRedactorEngine, DicomImageRedactorEngine\nimport matplotlib.pyplot as plt\n</pre> from PIL import Image import pydicom from presidio_analyzer import Pattern, PatternRecognizer from presidio_image_redactor import ImageRedactorEngine, DicomImageRedactorEngine import matplotlib.pyplot as plt <p>Initialize engines used for image redaction</p> In\u00a0[2]: Copied! <pre># Standard images\nengine = ImageRedactorEngine()\n\n# DICOM images\ndicom_engine = DicomImageRedactorEngine()\npadding_width = 3\nfill = \"background\"\n</pre> # Standard images engine = ImageRedactorEngine()  # DICOM images dicom_engine = DicomImageRedactorEngine() padding_width = 3 fill = \"background\" In\u00a0[3]: Copied! <pre>image = Image.open(\"../../image-redactor/ocr_text.png\")\ndisplay(image)\n</pre> image = Image.open(\"../../image-redactor/ocr_text.png\") display(image) <p>And this is what the image looks like with the standard, default behavior redaction.</p> In\u00a0[4]: Copied! <pre>redacted_image = engine.redact(image, (255, 192, 203))\ndisplay(redacted_image)\n</pre> redacted_image = engine.redact(image, (255, 192, 203)) display(redacted_image) In\u00a0[5]: Copied! <pre>instance = pydicom.dcmread(\"./sample_data/0_ORIGINAL.dcm\")\nplt.imshow(instance.pixel_array, cmap=\"gray\")\n</pre> instance = pydicom.dcmread(\"./sample_data/0_ORIGINAL.dcm\") plt.imshow(instance.pixel_array, cmap=\"gray\") Out[5]: <pre>&lt;matplotlib.image.AxesImage at 0x1edb761bd00&gt;</pre> <p>And this is what the image looks like with the standard, default behavior redaction.</p> In\u00a0[6]: Copied! <pre>results = dicom_engine.redact(instance, padding_width=padding_width, fill=fill)\nplt.imshow(results.pixel_array, cmap=\"gray\")\n</pre> results = dicom_engine.redact(instance, padding_width=padding_width, fill=fill) plt.imshow(results.pixel_array, cmap=\"gray\") Out[6]: <pre>&lt;matplotlib.image.AxesImage at 0x1edb7da4610&gt;</pre> <p>Redacted image when using the allow list approach</p> In\u00a0[7]: Copied! <pre>redacted_image = engine.redact(image, (255, 192, 203), allow_list=[\"David\", \"(212) 555-1234\"])\ndisplay(redacted_image)\n</pre> redacted_image = engine.redact(image, (255, 192, 203), allow_list=[\"David\", \"(212) 555-1234\"]) display(redacted_image) <p>Redacted DICOM image when using the allow list approach</p> In\u00a0[8]: Copied! <pre>results = dicom_engine.redact(instance, padding_width=padding_width, fill=fill, allow_list=[\"DAVIDSON\"])\nplt.imshow(results.pixel_array, cmap=\"gray\")\n</pre> results = dicom_engine.redact(instance, padding_width=padding_width, fill=fill, allow_list=[\"DAVIDSON\"]) plt.imshow(results.pixel_array, cmap=\"gray\") Out[8]: <pre>&lt;matplotlib.image.AxesImage at 0x1edaedf6340&gt;</pre> <p>Create a custom recognizer to mark all text as sensitive</p> In\u00a0[9]: Copied! <pre>pattern_all_text = Pattern(name=\"any_text\", regex=r\"(?s).*\", score=0.5)\ncustom_recognizer = PatternRecognizer(\n    supported_entity=\"TEXT\",\n    patterns=[pattern_all_text],\n)\n</pre> pattern_all_text = Pattern(name=\"any_text\", regex=r\"(?s).*\", score=0.5) custom_recognizer = PatternRecognizer(     supported_entity=\"TEXT\",     patterns=[pattern_all_text], ) <p>Then pass that custom recognizer into your redactor engine as an ad-hoc recognizer</p> In\u00a0[10]: Copied! <pre># Standard image\nredacted_image = engine.redact(\n    image,\n    (255, 192, 203),\n    ad_hoc_recognizers = [custom_recognizer], # you can pass in multiple ad-hoc recognizers\n    allow_list=[\"This\", \"project\",]\n)\ndisplay(redacted_image)\n</pre> # Standard image redacted_image = engine.redact(     image,     (255, 192, 203),     ad_hoc_recognizers = [custom_recognizer], # you can pass in multiple ad-hoc recognizers     allow_list=[\"This\", \"project\",] ) display(redacted_image) In\u00a0[11]: Copied! <pre># DICOM image\nresults = dicom_engine.redact(\n    instance,\n    padding_width = padding_width,\n    fill = fill,\n    ad_hoc_recognizers = [custom_recognizer], # you can pass in multiple ad-hoc recognizers\n    allow_list = [\"DAVIDSON\", \"L\"]\n)\nplt.imshow(results.pixel_array, cmap=\"gray\")\n</pre> # DICOM image results = dicom_engine.redact(     instance,     padding_width = padding_width,     fill = fill,     ad_hoc_recognizers = [custom_recognizer], # you can pass in multiple ad-hoc recognizers     allow_list = [\"DAVIDSON\", \"L\"] ) plt.imshow(results.pixel_array, cmap=\"gray\") Out[11]: <pre>&lt;matplotlib.image.AxesImage at 0x1edaee5f160&gt;</pre> <p>Create a custom recognizer that marks all text as sensitive</p> In\u00a0[12]: Copied! <pre>pattern_all_text = Pattern(name=\"any_text\", regex=r\"(?s).*\", score=0.5)\ncustom_recognizer = PatternRecognizer(\n    supported_entity=\"TEXT\",\n    patterns=[pattern_all_text],\n)\n</pre> pattern_all_text = Pattern(name=\"any_text\", regex=r\"(?s).*\", score=0.5) custom_recognizer = PatternRecognizer(     supported_entity=\"TEXT\",     patterns=[pattern_all_text], ) <p>Specify an empty allow list such that no text is allowed</p> In\u00a0[13]: Copied! <pre># Standard image\nredacted_image = engine.redact(\n    image,\n    (255, 192, 203),\n    ad_hoc_recognizers = [custom_recognizer],\n    allow_list=[]\n)\ndisplay(redacted_image)\n</pre> # Standard image redacted_image = engine.redact(     image,     (255, 192, 203),     ad_hoc_recognizers = [custom_recognizer],     allow_list=[] ) display(redacted_image) In\u00a0[14]: Copied! <pre># DICOM image\nresults = dicom_engine.redact(\n    instance,\n    padding_width = padding_width,\n    fill = fill,\n    ad_hoc_recognizers = [custom_recognizer],\n    allow_list = []\n)\nplt.imshow(results.pixel_array, cmap=\"gray\")\n</pre> # DICOM image results = dicom_engine.redact(     instance,     padding_width = padding_width,     fill = fill,     ad_hoc_recognizers = [custom_recognizer],     allow_list = [] ) plt.imshow(results.pixel_array, cmap=\"gray\") Out[14]: <pre>&lt;matplotlib.image.AxesImage at 0x1edaeee7580&gt;</pre> <p>In this case, we see that all text picked up by the OCR is redacted. The \"L\" on the right side of the DICOM image and the single \"a\" in the standard image are still visible because they were not detected by the OCR.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonimage_redaction_allow_list_approachipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/image_redaction_allow_list_approach.ipynb\u00b6","text":""},{"location":"samples/python/image_redaction_allow_list_approach/#allow-list-approach-with-image-redaction","title":"Allow list approach with image redaction\u00b6","text":"<p>This notebook covers how to use the <code>allow_list</code> argument to prevent certain words from being redacted from images and explains how you can use this to implement a strict redact all text approach.</p> <p>Note: Always place the <code>allow_list</code> argument last in your redact call as this is considered a text analyzer kwarg.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#prerequisites","title":"Prerequisites\u00b6","text":"<p>Before getting started, make sure presidio and the latest version of Tesseract OCR are installed. For detailed documentation, see the installation docs.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#0-imports-and-initializations","title":"0. Imports and initializations\u00b6","text":""},{"location":"samples/python/image_redaction_allow_list_approach/#1-example-images","title":"1. Example images\u00b6","text":"<p>In this notebook, we will use the following examples images.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#11-standard-example-image","title":"1.1 Standard example image\u00b6","text":""},{"location":"samples/python/image_redaction_allow_list_approach/#12-dicom-medical-image","title":"1.2 DICOM medical image\u00b6","text":"<p>For more information on DICOM image redaction, please see example_dicom_image_redactor.ipynb and the Image redactor module documentation.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#2-scenario-prevent-some-words-from-being-redacted","title":"2. Scenario: Prevent some words from being redacted\u00b6","text":"<p>Whether using the default recognizer, registering your own custom recognizer, or using ad-hoc recognizers to identify sensitive entities, there may be times where you do not want certain words redacted.</p> <p>In these cases, we can use the <code>allow_list</code> argument passed into the <code>ImageAnalyzerEngine</code> via our redact engine to preserve specified strings.</p> <p>Note: The <code>allow_list</code> argument should be positioned as the last argument in the redact call as it is considered a text analyzer kwarg.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#3-scenario-only-allow-specific-words-while-redacting-all-other-text","title":"3. Scenario : Only allow specific words while redacting all other text\u00b6","text":"<p>In some cases, we want to preserve certain words and redact all other text in the image. We can create an ad-hoc recognizer that considers all text as sensitive and couple that with the allow list.</p> <p>Note: The <code>allow_list</code> argument should be positioned as the last argument in the redact call as it is considered a text analyzer kwarg.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#4-scenario-redact-all-text-on-the-image","title":"4. Scenario: Redact all text on the image\u00b6","text":"<p>When it is critical to minimize False Negatives during the redaction process, we recommend using a \"redact all\" approach to redact all detected text.</p> <p>As with the other scenarios, good OCR performance is critical in ensuring the analyzer can pick up on all text in the image. False Negatives may still occur with images if the OCR fails to pick up on all the text.</p> <p>Note: The <code>allow_list</code> argument should be positioned as the last argument in the redact call as it is considered a text analyzer kwarg.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#conclusion","title":"Conclusion\u00b6","text":"<p>The <code>allow_list</code> argument can be used in both standard and DICOM iamge redaction to allow specified words to avoid redaction. This can also be used to redact all detected text.</p> <p>While this approach allows for the greatest recall in terms of redacting sensitive text, it is dependent on the performance of the text detection which comes before analysis.</p>"},{"location":"samples/python/image_redaction_allow_list_approach/#tips-for-improved-performance","title":"Tips for improved performance\u00b6","text":"<ol> <li>To avoid False Negative redaction, we recommend applying preprocessing techniques or experimenting with parameters to improve OCR performance or use an alternative approach to improve text detection. We are actively working on adding a preprocessing module to allow for easy application of image preprocessing methods.</li> <li>We recommend augmenting your allowlist to consider various casing and punctuation.</li> </ol>"},{"location":"samples/python/integrating_with_external_services/","title":"Integrating with external services","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !python -m spacy download en_core_web_lg <p>####### Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/integrating_with_external_services.ipynb</p> In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import AnalyzerEngine\nfrom text_analytics.example_text_analytics_recognizer import TextAnalyticsEntityCategory, TextAnalyticsRecognizer\n</pre> from presidio_analyzer import AnalyzerEngine from text_analytics.example_text_analytics_recognizer import TextAnalyticsEntityCategory, TextAnalyticsRecognizer <ol> <li>Define which entities to get from Text Analytics</li> </ol> In\u00a0[\u00a0]: Copied! <pre>ta_entities = [\n    TextAnalyticsEntityCategory(name=\"Person\",\n                                entity_type=\"NAME\",\n                                supported_languages=[\"en\"]),\n    TextAnalyticsEntityCategory(name=\"Age\",\n                                entity_type=\"AGE\",\n                                subcategory = \"Age\", \n                                supported_languages=[\"en\"]),\n    TextAnalyticsEntityCategory(name=\"InternationlBankingAccountNumber\",\n                                entity_type=\"IBAN\",\n                                supported_languages=[\"en\"])]\n</pre> ta_entities = [     TextAnalyticsEntityCategory(name=\"Person\",                                 entity_type=\"NAME\",                                 supported_languages=[\"en\"]),     TextAnalyticsEntityCategory(name=\"Age\",                                 entity_type=\"AGE\",                                 subcategory = \"Age\",                                  supported_languages=[\"en\"]),     TextAnalyticsEntityCategory(name=\"InternationlBankingAccountNumber\",                                 entity_type=\"IBAN\",                                 supported_languages=[\"en\"])] <p>For a full list of entities: https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/named-entity-types?tabs=personal</p> <ol> <li>Instantiate the remote recognizer object (In this case <code>TextAnalyticsRecognizer</code>)</li> </ol> In\u00a0[\u00a0]: Copied! <pre>text_analytics_recognizer = TextAnalyticsRecognizer(\n        text_analytics_key=\"&lt;YOUR_TEXT_ANALYTICS_KEY&gt;\",\n        text_analytics_endpoint=\"&lt;YOUR_TEXT_ANALYTICS_ENDPOINT&gt;\",\n        text_analytics_categories = ta_entities)\n</pre> text_analytics_recognizer = TextAnalyticsRecognizer(         text_analytics_key=\"\",         text_analytics_endpoint=\"\",         text_analytics_categories = ta_entities) <ol> <li>Add the new recognizer to the list of recognizers and run the <code>PresidioAnalyzer</code></li> </ol> In\u00a0[\u00a0]: Copied! <pre>analyzer = AnalyzerEngine()\nanalyzer.registry.add_recognizer(text_analytics_recognizer)\n\nresults = analyzer.analyze(\n    text=\"David is 30 years old. His IBAN: IL150120690000003111111\", language=\"en\"\n)\nprint(results)\n</pre> analyzer = AnalyzerEngine() analyzer.registry.add_recognizer(text_analytics_recognizer)  results = analyzer.analyze(     text=\"David is 30 years old. His IBAN: IL150120690000003111111\", language=\"en\" ) print(results)"},{"location":"samples/python/integrating_with_external_services/#integrating-external-modelsservices-with-presidio","title":"Integrating external models/services with Presidio\u00b6","text":"<p>Presidio analyzer is comprised of a set of PII recognizers which can run local or remotely. In this notebook we'll give an example of integrating an external service into Presidio-Analyzer.</p>"},{"location":"samples/python/integrating_with_external_services/#azure-text-analytics","title":"Azure Text Analytics\u00b6","text":"<p>Azure Text Analytics is a cloud-based service that provides advanced natural language processing over raw text. One of its main functions includes Named Entity Recognition (NER), which has the ability to identify different entities in text and categorize them into pre-defined classes or types.</p>"},{"location":"samples/python/integrating_with_external_services/#supported-entity-categories-in-the-text-analytics-api","title":"Supported entity categories in the Text Analytics API\u00b6","text":"<p>Text Analytics supports multiple PII entity categories. The Text Analytics service runs a predictive model to identify and categorize named entities from an input document. The service's latest version includes the ability to detect personal (PII) and health (PHI) information. A list of all supported entities can be found in the official documentation.</p>"},{"location":"samples/python/integrating_with_external_services/#prerequisites","title":"Prerequisites\u00b6","text":"<p>To use Text Analytics with Preisido, an Azure Text Analytics resource should first be created under an Azure subscription. Follow the official documentation for instructions. The key and endpoint, generated once the resource is created, should replace the placeholders <code>&lt;YOUR_TEXT_ANALYTICS_KEY&gt;</code> and <code>&lt;YOUR_TEXT_ANALYTICS_ENDPOINT&gt;</code> in this notebook, respectively.</p>"},{"location":"samples/python/integrating_with_external_services/#text-analytics-recognizer","title":"Text Analytics Recognizer\u00b6","text":"<p>In this example we will use the <code>TextAnalyticsRecognizer</code> sample implementation. This class extends Presidio's Remote Recognizer for calling the Text Analytics service REST API. For additional information of a remote recognizer, see the ExampleRemoteRecognizer sample.</p>"},{"location":"samples/python/keep_entities/","title":"Keep entities","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !python -m spacy download en_core_web_lg In\u00a0[1]: Copied! <pre>from presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import RecognizerResult, OperatorConfig\n</pre> from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import RecognizerResult, OperatorConfig In\u00a0[2]: Copied! <pre>engine = AnonymizerEngine()\n\n# Invoke the anonymize function with the text,\n# analyzer results (potentially coming from presidio-analyzer)\n# and 'keep' operator on &lt;PERSON&gt; PIIs\nanonymize_result = engine.anonymize(\n    text=\"My name is James Bond, I live in London\",\n    analyzer_results=[\n        RecognizerResult(entity_type=\"PERSON\", start=11, end=21, score=0.8),\n        RecognizerResult(entity_type=\"LOCATION\", start=33, end=39, score=0.8),\n    ],\n    operators={\n        \"PERSON\": OperatorConfig(\"keep\"),\n        \"DEFAULT\": OperatorConfig(\"replace\"),\n    },\n)\n</pre> engine = AnonymizerEngine()  # Invoke the anonymize function with the text, # analyzer results (potentially coming from presidio-analyzer) # and 'keep' operator on  PIIs anonymize_result = engine.anonymize(     text=\"My name is James Bond, I live in London\",     analyzer_results=[         RecognizerResult(entity_type=\"PERSON\", start=11, end=21, score=0.8),         RecognizerResult(entity_type=\"LOCATION\", start=33, end=39, score=0.8),     ],     operators={         \"PERSON\": OperatorConfig(\"keep\"),         \"DEFAULT\": OperatorConfig(\"replace\"),     }, ) In\u00a0[3]: Copied! <pre>anonymize_result\n</pre> anonymize_result Out[3]: <pre>text: My name is James Bond, I live in &lt;LOCATION&gt;\nitems:\n[\n    {'start': 33, 'end': 43, 'entity_type': 'LOCATION', 'text': '&lt;LOCATION&gt;', 'operator': 'replace'},\n    {'start': 11, 'end': 21, 'entity_type': 'PERSON', 'text': 'James Bond', 'operator': 'keep'}\n]</pre>"},{"location":"samples/python/keep_entities/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonkeep_entitiesipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/keep_entities.ipynb\u00b6","text":""},{"location":"samples/python/keep_entities/#keeping-some-piis-from-being-anonymized","title":"Keeping some PIIs from being anonymized\u00b6","text":"<p>This sample shows how to use Presidio's <code>keep</code> anonymizer to keep some of the identified PIIs in the output string</p>"},{"location":"samples/python/keep_entities/#set-up-imports","title":"Set up imports\u00b6","text":""},{"location":"samples/python/keep_entities/#presidio-anonymizer-keep-person-names","title":"Presidio Anonymizer: Keep person names\u00b6","text":"<p>This example input has 2 PIIs, an person name and a location. We configure the anonymizer to replace the location name with a placeholder, but keep the person name unmodified.</p>"},{"location":"samples/python/keep_entities/#result-name-unmodified-but-tracked","title":"Result: Name unmodified, but tracked\u00b6","text":"<p>The person name is preserved in the result text, but remains tracked in the items list.</p>"},{"location":"samples/python/plot_custom_bboxes/","title":"Plot custom bboxes","text":"In\u00a0[\u00a0]: Copied! <pre>!pip install presidio_analyzer presidio_anonymizer presidio_image_redactor\n!python -m spacy download en_core_web_lg\n</pre> !pip install presidio_analyzer presidio_anonymizer presidio_image_redactor !python -m spacy download en_core_web_lg In\u00a0[1]: Copied! <pre>from PIL import Image\nimport pydicom\nfrom presidio_image_redactor import ImageAnalyzerEngine, ImagePiiVerifyEngine, DicomImagePiiVerifyEngine\nimport matplotlib.pyplot as plt\n</pre> from PIL import Image import pydicom from presidio_image_redactor import ImageAnalyzerEngine, ImagePiiVerifyEngine, DicomImagePiiVerifyEngine import matplotlib.pyplot as plt <p>Initialize engines used for image redaction</p> In\u00a0[2]: Copied! <pre># Image analyzer engine\nimage_analyzer_engine = ImageAnalyzerEngine()\n\n# Verification engines\nverify_engine = ImagePiiVerifyEngine() # standard images\ndicom_verify_engine = DicomImagePiiVerifyEngine() # DICOM images\npadding_width = 3\n</pre> # Image analyzer engine image_analyzer_engine = ImageAnalyzerEngine()  # Verification engines verify_engine = ImagePiiVerifyEngine() # standard images dicom_verify_engine = DicomImagePiiVerifyEngine() # DICOM images padding_width = 3 In\u00a0[3]: Copied! <pre>image = Image.open(\"../../image-redactor/ocr_text.png\")\ndisplay(image)\n</pre> image = Image.open(\"../../image-redactor/ocr_text.png\") display(image) <p>And this is what the image looks like with the standard, default behavior of the verification engine.</p> In\u00a0[4]: Copied! <pre>verify_image = verify_engine.verify(image, display_image=True)\n</pre> verify_image = verify_engine.verify(image, display_image=True) In\u00a0[5]: Copied! <pre>instance = pydicom.dcmread(\"./sample_data/0_ORIGINAL.dcm\")\nplt.imshow(instance.pixel_array, cmap=\"gray\")\n</pre> instance = pydicom.dcmread(\"./sample_data/0_ORIGINAL.dcm\") plt.imshow(instance.pixel_array, cmap=\"gray\") Out[5]: <pre>&lt;matplotlib.image.AxesImage at 0x1f2a91512b0&gt;</pre> <p>And this is what the image looks like with the standard, default behavior verification.</p> In\u00a0[6]: Copied! <pre>dicom_image, dicom_ocr_bboxes, dicom_analyzer_bboxes = dicom_verify_engine.verify_dicom_instance(\n    instance,\n    padding_width=padding_width,\n    display_image=True\n)\n</pre> dicom_image, dicom_ocr_bboxes, dicom_analyzer_bboxes = dicom_verify_engine.verify_dicom_instance(     instance,     padding_width=padding_width,     display_image=True ) In\u00a0[7]: Copied! <pre>len(dicom_ocr_bboxes)\n</pre> len(dicom_ocr_bboxes) Out[7]: <pre>9</pre> In\u00a0[8]: Copied! <pre>len(dicom_analyzer_bboxes)\n</pre> len(dicom_analyzer_bboxes) Out[8]: <pre>4</pre> <p>Let's look at the format of the analyzer results bounding boxes returned by the DICOM verification engine. This the general format expected of custom bounding boxes passed into <code>add_custom_bbox()</code>.</p> In\u00a0[9]: Copied! <pre>type(dicom_analyzer_bboxes)\n</pre> type(dicom_analyzer_bboxes) Out[9]: <pre>list</pre> In\u00a0[10]: Copied! <pre>type(dicom_analyzer_bboxes[0])\n</pre> type(dicom_analyzer_bboxes[0]) Out[10]: <pre>dict</pre> In\u00a0[11]: Copied! <pre>dicom_analyzer_bboxes[0]\n</pre> dicom_analyzer_bboxes[0] Out[11]: <pre>{'entity_type': 'PERSON',\n 'score': 0.85,\n 'left': 3,\n 'top': 3,\n 'width': 241,\n 'height': 37,\n 'is_PII': True}</pre> <p>For our custom bounding boxes, the \"entity_type\" and \"is_PII\" fields are optional and \"score\" is not used. However, the \"is_PII\" field is helpful in visually identifying which bounding boxes from your given bounding box list are considered PII.</p> In\u00a0[12]: Copied! <pre># Example provided bounding box list\ngiven_bboxes = [\n    {\n        'entity_type': 'PERSON',\n         'left': 3,\n         'top': 3,\n         'width': 241,\n         'height': 37,\n         'is_PII': True\n    },\n    {\n        'entity_type': 'PERSON',\n         'left': 179,\n         'top': 150,\n         'width': 300,\n         'height': 74,\n         'is_PII': False\n    }\n]\n</pre> # Example provided bounding box list given_bboxes = [     {         'entity_type': 'PERSON',          'left': 3,          'top': 3,          'width': 241,          'height': 37,          'is_PII': True     },     {         'entity_type': 'PERSON',          'left': 179,          'top': 150,          'width': 300,          'height': 74,          'is_PII': False     } ] <p>Let's plot the given bounding boxes.</p> In\u00a0[13]: Copied! <pre># Let's plot with the given bounding boxes\ntest_image = image_analyzer_engine.add_custom_bboxes(image, given_bboxes, show_text_annotation=True)\n</pre> # Let's plot with the given bounding boxes test_image = image_analyzer_engine.add_custom_bboxes(image, given_bboxes, show_text_annotation=True) <p>While the placement of our example bounding boxes here is not ideal, this shows how you can easily visualize if a provided set of bounding boxes match your expectations.</p>"},{"location":"samples/python/plot_custom_bboxes/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonplot_custom_bboxesipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/plot_custom_bboxes.ipynb\u00b6","text":""},{"location":"samples/python/plot_custom_bboxes/#plot-custom-bounding-boxes","title":"Plot custom bounding boxes\u00b6","text":"<p>This notebook covers how to use the image verification engines to plot custom bounding boxes. This can be helpful when you want to verify a provided set of bounding boxes against an image.</p>"},{"location":"samples/python/plot_custom_bboxes/#prerequisites","title":"Prerequisites\u00b6","text":"<p>Before getting started, make sure presidio and the latest version of Tesseract OCR are installed. For detailed documentation, see the installation docs.</p>"},{"location":"samples/python/plot_custom_bboxes/#0-imports-and-initializations","title":"0. Imports and initializations\u00b6","text":""},{"location":"samples/python/plot_custom_bboxes/#1-example-images","title":"1. Example images\u00b6","text":"<p>In this notebook, we will use the following examples images.</p>"},{"location":"samples/python/plot_custom_bboxes/#11-standard-example-image","title":"1.1 Standard example image\u00b6","text":""},{"location":"samples/python/plot_custom_bboxes/#12-dicom-medical-image","title":"1.2 DICOM medical image\u00b6","text":"<p>For more information on DICOM image redaction, please see example_dicom_image_redactor.ipynb and the Image redactor module documentation.</p>"},{"location":"samples/python/plot_custom_bboxes/#2-plot-custom-bounding-boxes","title":"2. Plot custom bounding boxes\u00b6","text":"<p>There may be situations where you want to visually validate whether a set of given bounding boxes match your expectations on an image. In these cases, we can call <code>ImageAnalyzerEngine.add_custom_bbox()</code> instead of using the verify methods which include OCR and text analysis.</p>"},{"location":"samples/python/presidio_notebook/","title":"Presidio notebook","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !python -m spacy download en_core_web_lg In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import AnalyzerEngine, PatternRecognizer\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\nimport json\nfrom pprint import pprint\n</pre> from presidio_analyzer import AnalyzerEngine, PatternRecognizer from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig import json from pprint import pprint In\u00a0[\u00a0]: Copied! <pre>text_to_anonymize = \"His name is Mr. Jones and his phone number is 212-555-5555\"\n</pre> text_to_anonymize = \"His name is Mr. Jones and his phone number is 212-555-5555\" In\u00a0[\u00a0]: Copied! <pre>analyzer = AnalyzerEngine()\nanalyzer_results = analyzer.analyze(text=text_to_anonymize, entities=[\"PHONE_NUMBER\"], language='en')\n\nprint(analyzer_results)\n</pre> analyzer = AnalyzerEngine() analyzer_results = analyzer.analyze(text=text_to_anonymize, entities=[\"PHONE_NUMBER\"], language='en')  print(analyzer_results) In\u00a0[\u00a0]: Copied! <pre>titles_recognizer = PatternRecognizer(supported_entity=\"TITLE\",\n                                      deny_list=[\"Mr.\",\"Mrs.\",\"Miss\"])\n\npronoun_recognizer = PatternRecognizer(supported_entity=\"PRONOUN\",\n                                       deny_list=[\"he\", \"He\", \"his\", \"His\", \"she\", \"She\", \"hers\", \"Hers\"])\n\nanalyzer.registry.add_recognizer(titles_recognizer)\nanalyzer.registry.add_recognizer(pronoun_recognizer)\n\nanalyzer_results = analyzer.analyze(text=text_to_anonymize,\n                            entities=[\"TITLE\", \"PRONOUN\"],\n                            language=\"en\")\nprint(analyzer_results)\n</pre> titles_recognizer = PatternRecognizer(supported_entity=\"TITLE\",                                       deny_list=[\"Mr.\",\"Mrs.\",\"Miss\"])  pronoun_recognizer = PatternRecognizer(supported_entity=\"PRONOUN\",                                        deny_list=[\"he\", \"He\", \"his\", \"His\", \"she\", \"She\", \"hers\", \"Hers\"])  analyzer.registry.add_recognizer(titles_recognizer) analyzer.registry.add_recognizer(pronoun_recognizer)  analyzer_results = analyzer.analyze(text=text_to_anonymize,                             entities=[\"TITLE\", \"PRONOUN\"],                             language=\"en\") print(analyzer_results)  <p>Call Presidio Analyzer and get analyzed results with all the configured recognizers - default and new custom recognizers</p> In\u00a0[\u00a0]: Copied! <pre>analyzer_results = analyzer.analyze(text=text_to_anonymize, language='en')\n\nanalyzer_results\n</pre> analyzer_results = analyzer.analyze(text=text_to_anonymize, language='en')  analyzer_results In\u00a0[\u00a0]: Copied! <pre>anonymizer = AnonymizerEngine()\n\nanonymized_results = anonymizer.anonymize(\n    text=text_to_anonymize,\n    analyzer_results=analyzer_results,    \n    operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"&lt;ANONYMIZED&gt;\"}), \n                        \"PHONE_NUMBER\": OperatorConfig(\"mask\", {\"type\": \"mask\", \"masking_char\" : \"*\", \"chars_to_mask\" : 12, \"from_end\" : True}),\n                        \"TITLE\": OperatorConfig(\"redact\", {})}\n)\n\nprint(f\"text: {anonymized_results.text}\")\nprint(\"detailed response:\")\n\npprint(json.loads(anonymized_results.to_json()))\n</pre> anonymizer = AnonymizerEngine()  anonymized_results = anonymizer.anonymize(     text=text_to_anonymize,     analyzer_results=analyzer_results,         operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"\"}),                          \"PHONE_NUMBER\": OperatorConfig(\"mask\", {\"type\": \"mask\", \"masking_char\" : \"*\", \"chars_to_mask\" : 12, \"from_end\" : True}),                         \"TITLE\": OperatorConfig(\"redact\", {})} )  print(f\"text: {anonymized_results.text}\") print(\"detailed response:\")  pprint(json.loads(anonymized_results.to_json())) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"samples/python/presidio_notebook/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonpresidio_notebookipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/presidio_notebook.ipynb\u00b6","text":""},{"location":"samples/python/presidio_notebook/#analyze-text-for-pii-entities","title":"Analyze Text for PII Entities\u00b6","text":"<p>Using Presidio Analyzer, analyze a text to identify PII entities. The Presidio analyzer is using pre-defined entity recognizers, and offers the option to create custom recognizers.</p> <p>The following code sample will:</p> <ul> <li>Set up the Analyzer engine: load the NLP module (spaCy model by default) and other PII recognizers</li> <li>Call analyzer to get analyzed results for \"PHONE_NUMBER\" entity type</li> </ul>"},{"location":"samples/python/presidio_notebook/#create-custom-pii-entity-recognizers","title":"Create Custom PII Entity Recognizers\u00b6","text":"<p>Presidio Analyzer comes with a pre-defined set of entity recognizers. It also allows adding new recognizers without changing the analyzer base code, by creating custom recognizers. In the following example, we will create two new recognizers of type <code>PatternRecognizer</code> to identify titles and pronouns in the analyzed text. A <code>PatternRecognizer</code> is a PII entity recognizer which uses regular expressions or deny-lists.</p> <p>The following code sample will:</p> <ul> <li>Create custom recognizers</li> <li>Add the new custom recognizers to the analyzer</li> <li>Call analyzer to get results from the new recognizers</li> </ul>"},{"location":"samples/python/presidio_notebook/#anonymize-text-with-identified-pii-entities","title":"Anonymize Text with Identified PII Entities\u00b6","text":"<p>Presidio Anonymizer iterates over the Presidio Analyzer result, and provides anonymization capabilities for the identified text. The anonymizer provides 5 types of anonymizers - replace, redact, mask, hash and encrypt. The default is replace</p> <p>The following code sample will:</p> <ol> <li>Setup the anonymizer engine </li> <li>Create an anonymizer request - text to anonymize, list of anonymizers to apply and the results from the analyzer request</li> <li>Anonymize the text</li> </ol>"},{"location":"samples/python/process_csv_file/","title":"Process csv file","text":"In\u00a0[\u00a0]: Copied! <pre>import csv\nimport pprint\nfrom typing import List, Iterable, Optional\n</pre> import csv import pprint from typing import List, Iterable, Optional In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import BatchAnalyzerEngine, DictAnalyzerResult\nfrom presidio_anonymizer import BatchAnonymizerEngine\n</pre> from presidio_analyzer import BatchAnalyzerEngine, DictAnalyzerResult from presidio_anonymizer import BatchAnonymizerEngine In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nExample implementing a CSV analyzer\n\nThis example shows how to use the Presidio Analyzer and Anonymizer\nto detect and anonymize PII in a CSV file.\nIt uses the BatchAnalyzerEngine to analyze the CSV file, and \nBatchAnonymizerEngine to anonymize the requested columns.\n\nContent of csv file:\nid,name,city,comments\n1,John,New York,called him yesterday to confirm he requested to call back in 2 days\n2,Jill,Los Angeles,accepted the offer license number AC432223\n3,Jack,Chicago,need to call him at phone number 212-555-5555\n\n\"\"\"\n</pre> \"\"\" Example implementing a CSV analyzer  This example shows how to use the Presidio Analyzer and Anonymizer to detect and anonymize PII in a CSV file. It uses the BatchAnalyzerEngine to analyze the CSV file, and  BatchAnonymizerEngine to anonymize the requested columns.  Content of csv file: id,name,city,comments 1,John,New York,called him yesterday to confirm he requested to call back in 2 days 2,Jill,Los Angeles,accepted the offer license number AC432223 3,Jack,Chicago,need to call him at phone number 212-555-5555  \"\"\" In\u00a0[\u00a0]: Copied! <pre>class CSVAnalyzer(BatchAnalyzerEngine):\n\n    def analyze_csv(\n        self,\n        csv_full_path: str,\n        language: str,\n        keys_to_skip: Optional[List[str]] = None,\n        **kwargs,\n    ) -&gt; Iterable[DictAnalyzerResult]:\n\n        with open(csv_full_path, 'r') as csv_file:\n            csv_list = list(csv.reader(csv_file))\n            csv_dict = {header: list(map(str, values)) for header, *values in zip(*csv_list)}\n            analyzer_results = self.analyze_dict(csv_dict, language, keys_to_skip)\n            return list(analyzer_results)\n</pre> class CSVAnalyzer(BatchAnalyzerEngine):      def analyze_csv(         self,         csv_full_path: str,         language: str,         keys_to_skip: Optional[List[str]] = None,         **kwargs,     ) -&gt; Iterable[DictAnalyzerResult]:          with open(csv_full_path, 'r') as csv_file:             csv_list = list(csv.reader(csv_file))             csv_dict = {header: list(map(str, values)) for header, *values in zip(*csv_list)}             analyzer_results = self.analyze_dict(csv_dict, language, keys_to_skip)             return list(analyzer_results) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n\n    analyzer = CSVAnalyzer()\n    analyzer_results = analyzer.analyze_csv('./csv_sample_data/sample_data.csv',\n                                            language=\"en\")\n    pprint.pprint(analyzer_results)\n\n    anonymizer = BatchAnonymizerEngine()\n    anonymized_results = anonymizer.anonymize_dict(analyzer_results)\n    pprint.pprint(anonymized_results)\n</pre> if __name__ == \"__main__\":      analyzer = CSVAnalyzer()     analyzer_results = analyzer.analyze_csv('./csv_sample_data/sample_data.csv',                                             language=\"en\")     pprint.pprint(analyzer_results)      anonymizer = BatchAnonymizerEngine()     anonymized_results = anonymizer.anonymize_dict(analyzer_results)     pprint.pprint(anonymized_results)"},{"location":"samples/python/pseudonomyzation/","title":"Pseudonomization","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !python -m spacy download en_core_web_lg In\u00a0[2]: Copied! <pre>from presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine, DeanonymizeEngine, OperatorConfig\nfrom presidio_anonymizer.operators import Operator, OperatorType\n\nfrom typing import Dict\nfrom pprint import pprint\n</pre> from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine, DeanonymizeEngine, OperatorConfig from presidio_anonymizer.operators import Operator, OperatorType  from typing import Dict from pprint import pprint In\u00a0[3]: Copied! <pre>text = \"Peter gave his book to Heidi which later gave it to Nicole. Peter lives in London and Nicole lives in Tashkent.\"\nprint(\"original text:\")\npprint(text)\nanalyzer = AnalyzerEngine()\nanalyzer_results = analyzer.analyze(text=text, language=\"en\")\nprint(\"analyzer results:\")\npprint(analyzer_results)\n</pre> text = \"Peter gave his book to Heidi which later gave it to Nicole. Peter lives in London and Nicole lives in Tashkent.\" print(\"original text:\") pprint(text) analyzer = AnalyzerEngine() analyzer_results = analyzer.analyze(text=text, language=\"en\") print(\"analyzer results:\") pprint(analyzer_results)  <pre>original text:\n('Peter gave his book to Heidi which later gave it to Nicole. Peter lives in '\n 'London and Nicole lives in Tashkent.')\nanalyzer results:\n[type: PERSON, start: 0, end: 5, score: 0.85,\n type: PERSON, start: 23, end: 28, score: 0.85,\n type: PERSON, start: 52, end: 58, score: 0.85,\n type: PERSON, start: 60, end: 65, score: 0.85,\n type: LOCATION, start: 75, end: 81, score: 0.85,\n type: PERSON, start: 86, end: 92, score: 0.85,\n type: LOCATION, start: 102, end: 110, score: 0.85]\n</pre> In\u00a0[4]: Copied! <pre>class InstanceCounterAnonymizer(Operator):\n    \"\"\"\n    Anonymizer which replaces the entity value\n    with an instance counter per entity.\n    \"\"\"\n\n    REPLACING_FORMAT = \"&lt;{entity_type}_{index}&gt;\"\n\n    def operate(self, text: str, params: Dict = None) -&gt; str:\n        \"\"\"Anonymize the input text.\"\"\"\n\n        entity_type: str = params[\"entity_type\"]\n\n        # entity_mapping is a dict of dicts containing mappings per entity type\n        entity_mapping: Dict[Dict:str] = params[\"entity_mapping\"]\n\n        entity_mapping_for_type = entity_mapping.get(entity_type)\n        if not entity_mapping_for_type:\n            new_text = self.REPLACING_FORMAT.format(\n                entity_type=entity_type, index=0\n            )\n            entity_mapping[entity_type] = {}\n\n        else:\n            if text in entity_mapping_for_type:\n                return entity_mapping_for_type[text]\n\n            previous_index = self._get_last_index(entity_mapping_for_type)\n            new_text = self.REPLACING_FORMAT.format(\n                entity_type=entity_type, index=previous_index + 1\n            )\n\n        entity_mapping[entity_type][text] = new_text\n        return new_text\n\n    @staticmethod\n    def _get_last_index(entity_mapping_for_type: Dict) -&gt; int:\n        \"\"\"Get the last index for a given entity type.\"\"\"\n\n        def get_index(value: str) -&gt; int:\n            return int(value.split(\"_\")[-1][:-1])\n\n        indices = [get_index(v) for v in entity_mapping_for_type.values()]\n        return max(indices)\n\n    def validate(self, params: Dict = None) -&gt; None:\n        \"\"\"Validate operator parameters.\"\"\"\n\n        if \"entity_mapping\" not in params:\n            raise ValueError(\"An input Dict called `entity_mapping` is required.\")\n        if \"entity_type\" not in params:\n            raise ValueError(\"An entity_type param is required.\")\n\n    def operator_name(self) -&gt; str:\n        return \"entity_counter\"\n\n    def operator_type(self) -&gt; OperatorType:\n        return OperatorType.Anonymize\n</pre> class InstanceCounterAnonymizer(Operator):     \"\"\"     Anonymizer which replaces the entity value     with an instance counter per entity.     \"\"\"      REPLACING_FORMAT = \"&lt;{entity_type}_{index}&gt;\"      def operate(self, text: str, params: Dict = None) -&gt; str:         \"\"\"Anonymize the input text.\"\"\"          entity_type: str = params[\"entity_type\"]          # entity_mapping is a dict of dicts containing mappings per entity type         entity_mapping: Dict[Dict:str] = params[\"entity_mapping\"]          entity_mapping_for_type = entity_mapping.get(entity_type)         if not entity_mapping_for_type:             new_text = self.REPLACING_FORMAT.format(                 entity_type=entity_type, index=0             )             entity_mapping[entity_type] = {}          else:             if text in entity_mapping_for_type:                 return entity_mapping_for_type[text]              previous_index = self._get_last_index(entity_mapping_for_type)             new_text = self.REPLACING_FORMAT.format(                 entity_type=entity_type, index=previous_index + 1             )          entity_mapping[entity_type][text] = new_text         return new_text      @staticmethod     def _get_last_index(entity_mapping_for_type: Dict) -&gt; int:         \"\"\"Get the last index for a given entity type.\"\"\"          def get_index(value: str) -&gt; int:             return int(value.split(\"_\")[-1][:-1])          indices = [get_index(v) for v in entity_mapping_for_type.values()]         return max(indices)      def validate(self, params: Dict = None) -&gt; None:         \"\"\"Validate operator parameters.\"\"\"          if \"entity_mapping\" not in params:             raise ValueError(\"An input Dict called `entity_mapping` is required.\")         if \"entity_type\" not in params:             raise ValueError(\"An entity_type param is required.\")      def operator_name(self) -&gt; str:         return \"entity_counter\"      def operator_type(self) -&gt; OperatorType:         return OperatorType.Anonymize In\u00a0[5]: Copied! <pre># Create Anonymizer engine and add the custom anonymizer\nanonymizer_engine = AnonymizerEngine()\nanonymizer_engine.add_anonymizer(InstanceCounterAnonymizer)\n\n# Create a mapping between entity types and counters\nentity_mapping = dict()\n\n# Anonymize the text\n\nanonymized_result = anonymizer_engine.anonymize(\n    text,\n    analyzer_results,\n    {\n        \"DEFAULT\": OperatorConfig(\n            \"entity_counter\", {\"entity_mapping\": entity_mapping}\n        )\n    },\n)\n\nprint(anonymized_result.text)\n</pre> # Create Anonymizer engine and add the custom anonymizer anonymizer_engine = AnonymizerEngine() anonymizer_engine.add_anonymizer(InstanceCounterAnonymizer)  # Create a mapping between entity types and counters entity_mapping = dict()  # Anonymize the text  anonymized_result = anonymizer_engine.anonymize(     text,     analyzer_results,     {         \"DEFAULT\": OperatorConfig(             \"entity_counter\", {\"entity_mapping\": entity_mapping}         )     }, )  print(anonymized_result.text)  <pre>&lt;PERSON_1&gt; gave his book to &lt;PERSON_2&gt; which later gave it to &lt;PERSON_0&gt;. &lt;PERSON_1&gt; lives in &lt;LOCATION_1&gt; and &lt;PERSON_0&gt; lives in &lt;LOCATION_0&gt;.\n</pre> <p>Note that the order is reversed due to the way entities are replaced in Presidio.</p> <p>Since the user/client is holding the entity_mapping, it is possible to use it for de-anonymization as well. First, let's look at its contents.</p> In\u00a0[6]: Copied! <pre>pprint(entity_mapping, indent=2)\n</pre> pprint(entity_mapping, indent=2) <pre>{ 'LOCATION': {'London': '&lt;LOCATION_1&gt;', 'Tashkent': '&lt;LOCATION_0&gt;'},\n  'PERSON': { 'Heidi': '&lt;PERSON_2&gt;',\n              'Nicole': '&lt;PERSON_0&gt;',\n              'Peter': '&lt;PERSON_1&gt;'}}\n</pre> In\u00a0[7]: Copied! <pre>class InstanceCounterDeanonymizer(Operator):\n    \"\"\"\n    Deanonymizer which replaces the unique identifier \n    with the original text.\n    \"\"\"\n\n    def operate(self, text: str, params: Dict = None) -&gt; str:\n        \"\"\"Anonymize the input text.\"\"\"\n\n        entity_type: str = params[\"entity_type\"]\n\n        # entity_mapping is a dict of dicts containing mappings per entity type\n        entity_mapping: Dict[Dict:str] = params[\"entity_mapping\"]\n\n        if entity_type not in entity_mapping:\n            raise ValueError(f\"Entity type {entity_type} not found in entity mapping!\")\n        if text not in entity_mapping[entity_type].values():\n            raise ValueError(f\"Text {text} not found in entity mapping for entity type {entity_type}!\")\n\n        return self._find_key_by_value(entity_mapping[entity_type], text)\n\n    @staticmethod\n    def _find_key_by_value(entity_mapping, value):\n        for key, val in entity_mapping.items():\n            if val == value:\n                return key\n        return None\n    \n    def validate(self, params: Dict = None) -&gt; None:\n        \"\"\"Validate operator parameters.\"\"\"\n\n        if \"entity_mapping\" not in params:\n            raise ValueError(\"An input Dict called `entity_mapping` is required.\")\n        if \"entity_type\" not in params:\n            raise ValueError(\"An entity_type param is required.\")\n\n    def operator_name(self) -&gt; str:\n        return \"entity_counter_deanonymizer\"\n\n    def operator_type(self) -&gt; OperatorType:\n        return OperatorType.Deanonymize\n</pre> class InstanceCounterDeanonymizer(Operator):     \"\"\"     Deanonymizer which replaces the unique identifier      with the original text.     \"\"\"      def operate(self, text: str, params: Dict = None) -&gt; str:         \"\"\"Anonymize the input text.\"\"\"          entity_type: str = params[\"entity_type\"]          # entity_mapping is a dict of dicts containing mappings per entity type         entity_mapping: Dict[Dict:str] = params[\"entity_mapping\"]          if entity_type not in entity_mapping:             raise ValueError(f\"Entity type {entity_type} not found in entity mapping!\")         if text not in entity_mapping[entity_type].values():             raise ValueError(f\"Text {text} not found in entity mapping for entity type {entity_type}!\")          return self._find_key_by_value(entity_mapping[entity_type], text)      @staticmethod     def _find_key_by_value(entity_mapping, value):         for key, val in entity_mapping.items():             if val == value:                 return key         return None          def validate(self, params: Dict = None) -&gt; None:         \"\"\"Validate operator parameters.\"\"\"          if \"entity_mapping\" not in params:             raise ValueError(\"An input Dict called `entity_mapping` is required.\")         if \"entity_type\" not in params:             raise ValueError(\"An entity_type param is required.\")      def operator_name(self) -&gt; str:         return \"entity_counter_deanonymizer\"      def operator_type(self) -&gt; OperatorType:         return OperatorType.Deanonymize  In\u00a0[8]: Copied! <pre>deanonymizer_engine = DeanonymizeEngine()\ndeanonymizer_engine.add_deanonymizer(InstanceCounterDeanonymizer)\n\ndeanonymized = deanonymizer_engine.deanonymize(\n    anonymized_result.text, \n    anonymized_result.items, \n    {\"DEFAULT\": OperatorConfig(\"entity_counter_deanonymizer\", \n                               params={\"entity_mapping\": entity_mapping})}\n)\nprint(\"anonymized text:\")\npprint(anonymized_result.text)\nprint(\"de-anonymized text:\")\npprint(deanonymized.text)\n</pre> deanonymizer_engine = DeanonymizeEngine() deanonymizer_engine.add_deanonymizer(InstanceCounterDeanonymizer)  deanonymized = deanonymizer_engine.deanonymize(     anonymized_result.text,      anonymized_result.items,      {\"DEFAULT\": OperatorConfig(\"entity_counter_deanonymizer\",                                 params={\"entity_mapping\": entity_mapping})} ) print(\"anonymized text:\") pprint(anonymized_result.text) print(\"de-anonymized text:\") pprint(deanonymized.text) <pre>anonymized text:\n('&lt;PERSON_1&gt; gave his book to &lt;PERSON_2&gt; which later gave it to &lt;PERSON_0&gt;. '\n '&lt;PERSON_1&gt; lives in &lt;LOCATION_1&gt; and &lt;PERSON_0&gt; lives in &lt;LOCATION_0&gt;.')\nde-anonymized text:\n('Peter gave his book to Heidi which later gave it to Nicole. Peter lives in '\n 'London and Nicole lives in Tashkent.')\n</pre>"},{"location":"samples/python/pseudonomyzation/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonpseudonomyzationipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/pseudonomyzation.ipynb\u00b6","text":""},{"location":"samples/python/pseudonomyzation/#use-presidio-anonymizer-for-pseudonymization-of-pii-data","title":"Use Presidio Anonymizer for Pseudonymization of PII data\u00b6","text":"<p>Pseudonymization is a data management and de-identification procedure by which personally identifiable information fields within a data record are replaced by one or more artificial identifiers, or pseudonyms. (https://en.wikipedia.org/wiki/Pseudonymization)</p> <p>In this notebook, we'll show an example of how to use the Presidio Anonymizer library to pseudonymize PII data. In this example, we will replace each value with a unique identifier (e.g. &lt;PERSON_14&gt;). Then, we'll de-anonymize the data by replacing the unique identifiers back with their mapped PII values.</p>"},{"location":"samples/python/pseudonomyzation/#important-the-following-logic-is-not-thread-safe-and-may-produce-incorrect-results-if-run-concurrently-in-a-multi-threaded-environment-since-the-mapping-has-to-be-shared-between-threadsworkersprocesses","title":"Important: The following logic is not thread-safe and may produce incorrect results if run concurrently in a multi-threaded environment, since the mapping has to be shared between threads/workers/processes.\u00b6","text":""},{"location":"samples/python/pseudonomyzation/#1-using-the-analyzerengine-to-identify-pii-in-a-text","title":"1. Using the <code>AnalyzerEngine</code> to identify PII in a text\u00b6","text":""},{"location":"samples/python/pseudonomyzation/#2-creating-a-custom-anonymizer-called-operator-which-replaces-each-text-with-a-unique-identifier","title":"2. Creating a custom Anonymizer (called Operator) which replaces each text with a unique identifier.\u00b6","text":"<p>To create a custom anonymizer, we need to create a class that inherits from <code>Operator</code> and implement the <code>operate</code> method. This method receives the original text and a dictionary called <code>params</code> with the configuration defined by the user. The method should return the anonymized text.</p> <p>In this example we also implement the <code>validate</code> method to check that the input parameters are available, i.e. that the <code>entity_type</code> and <code>entity_mapping</code> parameters are defined, as they are required for this specific anonymizer. <code>entity_mapping</code> is a dictionary that maps each entity value to a unique identifier, for each entity type.</p>"},{"location":"samples/python/pseudonomyzation/#3-passing-the-new-operator-to-the-anonymizerengine-and-use-it-to-anonymize-the-text","title":"3. Passing the new operator to the <code>AnonymizerEngine</code> and use it to anonymize the text.\u00b6","text":""},{"location":"samples/python/pseudonomyzation/#4-de-anonymizing-the-text-using-the-entity_mapping","title":"4. De-anonymizing the text using the entity_mapping\u00b6","text":"<p>Similar to the anonymization operator, we need to create a custom de-anonymization operator. This operator will replace the unique identifiers with the original values.</p>"},{"location":"samples/python/simple_anonymization_example/","title":"Simple anonymization example","text":"In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\nfrom pprint import pprint\nimport json\n</pre> from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig from pprint import pprint import json In\u00a0[\u00a0]: Copied! <pre>text_to_anonymize = \"His name is Tom and his phone number is 212-555-5555\"\n</pre> text_to_anonymize = \"His name is Tom and his phone number is 212-555-5555\" In\u00a0[\u00a0]: Copied! <pre>analyzer = AnalyzerEngine()\nanonymizer = AnonymizerEngine()\n</pre> analyzer = AnalyzerEngine() anonymizer = AnonymizerEngine() In\u00a0[\u00a0]: Copied! <pre>analyzer_results = analyzer.analyze(text=text_to_anonymize, language=\"en\")\nprint(\"PII Detection:\")\nprint(analyzer_results)\n</pre> analyzer_results = analyzer.analyze(text=text_to_anonymize, language=\"en\") print(\"PII Detection:\") print(analyzer_results) In\u00a0[\u00a0]: Copied! <pre>anonymized_results = anonymizer.anonymize(\n    text=text_to_anonymize,\n    analyzer_results=analyzer_results,\n    operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"&lt;ANONYMIZED&gt;\"})},\n)\nprint(\"\\nPII Anonymization:\")\npprint(json.loads(anonymized_results.to_json()))\n</pre> anonymized_results = anonymizer.anonymize(     text=text_to_anonymize,     analyzer_results=analyzer_results,     operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"\"})}, ) print(\"\\nPII Anonymization:\") pprint(json.loads(anonymized_results.to_json()))"},{"location":"samples/python/span_marker_recognizer/","title":"Span marker recognizer","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nfrom typing import Optional, List, Dict\n</pre> import logging from typing import Optional, List, Dict In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import (\n    RecognizerResult,\n    EntityRecognizer,\n    AnalysisExplanation,\n)\nfrom presidio_analyzer.nlp_engine import NlpArtifacts\n</pre> from presidio_analyzer import (     RecognizerResult,     EntityRecognizer,     AnalysisExplanation, ) from presidio_analyzer.nlp_engine import NlpArtifacts In\u00a0[\u00a0]: Copied! <pre>try:\n    from span_marker import SpanMarkerModel\nexcept ImportError:\n    print(\"Span Marker is not installed\")\n</pre> try:     from span_marker import SpanMarkerModel except ImportError:     print(\"Span Marker is not installed\") In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-analyzer\")\n</pre> logger = logging.getLogger(\"presidio-analyzer\") In\u00a0[\u00a0]: Copied! <pre>class SpanMarkerRecognizer(EntityRecognizer):\n    \"\"\"\n    Wrapper for a span marker models, if needed to be used within Presidio Analyzer.\n    :param supported_language: The language supported by the model,\n    default is set to English (en).\n    :param model: A string referencing a Span Marker model name or path.\n    :param supported_entities: A list of entities supported by Presidio.\n    :param presidio_equivalences: Mapping of model-defined entities with\n    Presidio-supported entities.\n    :param ignore_labels: A list of entities specified by the model that\n    should not be extracted.\n\n    :example:\n    &gt;from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\n    &gt;span_marker_recognizer = SpanMarkerRecognizer()\n\n    &gt;registry = RecognizerRegistry()\n    &gt;registry.add_recognizer(span_marker_recognizer)\n\n    &gt;analyzer = AnalyzerEngine(registry=registry)\n\n    &gt;results = analyzer.analyze(\n    &gt;    \"My name is Vijay and I live in Pune.\",\n    &gt;    language=\"en\",\n    &gt;    return_decision_process=True,\n    &gt;)\n    &gt;for result in results:\n    &gt;    print(result)\n    &gt;    print(result.analysis_explanation)\n\n\n    \"\"\"\n\n    ENTITIES = [\n        \"PERSON\",\n        \"LOCATION\",\n        \"ORGANIZATION\",\n        # \"MISCELLANEOUS\"   # - There are no direct correlation with Presidio entities.\n    ]\n\n    DEFAULT_MODEL = \"tomaarsen/span-marker-bert-base-fewnerd-fine-super\"\n\n    DEFAULT_EXPLANATION = \"Identified as {} by Span Marker's Named Entity Recognition\"\n\n    PRESIDIO_EQUIVALENCES = {\n        \"person-other\": \"PERSON\",\n        \"location-GPE\": \"LOCATION\",\n        \"organization-company\": \"ORGANIZATION\",\n        # 'MISC': 'MISCELLANEOUS'   # - Probably not PII\n    }\n\n    IGNORE_LABELS = [\"O\"]\n\n    def __init__(\n        self,\n        supported_language: str = \"en\",\n        model: str = None,\n        supported_entities: Optional[List[str]] = None,\n        presidio_equivalences: Optional[Dict[str, str]] = None,\n        ignore_labels: Optional[List[str]] = None,\n    ):\n        self.model = (\n            model\n            if model\n            else self.DEFAULT_MODEL\n        )\n\n        self.presidio_equivalences = (\n            presidio_equivalences\n            if presidio_equivalences\n            else self.PRESIDIO_EQUIVALENCES\n        )\n\n        supported_entities = (\n            supported_entities if supported_entities else self.ENTITIES\n        )\n\n        self.ignore_labels = (\n            ignore_labels if ignore_labels else self.IGNORE_LABELS\n        )\n\n        labels = list(self.presidio_equivalences.keys())\n        self.span_marker_model = SpanMarkerModel.from_pretrained(\n            self.model,\n            labels=labels\n        )\n\n        super().__init__(\n            supported_entities=supported_entities,\n            supported_language=supported_language,\n            name=\"Span Marker Analytics\",\n        )\n\n    def load(self) -&gt; None:\n        \"\"\"Load the model, not used. Model is loaded during initialization.\"\"\"\n        pass\n\n    def get_supported_entities(self) -&gt; List[str]:\n        \"\"\"\n        Return supported entities by this model.\n\n        :return: List of the supported entities.\n        \"\"\"\n        return self.supported_entities\n\n    # Class to use Span Marker with Presidio as an external recognizer.\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Analyze text using Text Analytics.\n\n        :param text: The text for analysis.\n        :param entities: Not working properly for this recognizer.\n        :param nlp_artifacts: Not used by this recognizer.\n        :return: The list of Presidio RecognizerResult constructed from the recognized\n            Span Marker detections.\n        \"\"\"\n\n        results = []\n        ner_res = self.span_marker_model.predict(text)\n\n        for res in ner_res:\n            if not self.__check_label(\n                res['label']\n            ):\n                continue\n            textual_explanation = self.DEFAULT_EXPLANATION.format(\n                res['label']\n            )\n            explanation = self.build_span_marker_explanation(\n                round(res['score'], 2), textual_explanation\n            )\n            span_marker_result = self._convert_to_recognizer_result(res, explanation)\n            results.append(span_marker_result)\n\n        return results\n\n    def _convert_to_recognizer_result(self, entity, explanation) -&gt; RecognizerResult:\n\n        entity_type = self.presidio_equivalences.get(entity['label'], entity['label'])\n        span_marker_score = round(entity['score'], 2)\n\n        span_marker_results = RecognizerResult(\n            entity_type=entity_type,\n            start=entity['char_start_index'],\n            end=entity['char_end_index'],\n            score=span_marker_score,\n            analysis_explanation=explanation,\n        )\n\n        return span_marker_results\n\n    def build_span_marker_explanation(\n        self, original_score: float, explanation: str\n    ) -&gt; AnalysisExplanation:\n        \"\"\"\n        Create explanation for why this result was detected.\n\n        :param original_score: Score given by this recognizer\n        :param explanation: Explanation string\n        :return:\n        \"\"\"\n        explanation = AnalysisExplanation(\n            recognizer=self.__class__.__name__,\n            original_score=original_score,\n            textual_explanation=explanation,\n        )\n        return explanation\n\n    def __check_label(\n        self, label: str\n    ) -&gt; bool:\n        entity = self.presidio_equivalences.get(label, None)\n\n        if entity in self.ignore_labels:\n            return None\n\n        if entity is None:\n            logger.warning(f\"Found unrecognized label {label}, returning entity as is\")\n            return label\n\n        if entity not in self.supported_entities:\n            logger.warning(f\"Found entity {entity} which is not supported by Presidio\")\n            return entity\n        return entity\n</pre> class SpanMarkerRecognizer(EntityRecognizer):     \"\"\"     Wrapper for a span marker models, if needed to be used within Presidio Analyzer.     :param supported_language: The language supported by the model,     default is set to English (en).     :param model: A string referencing a Span Marker model name or path.     :param supported_entities: A list of entities supported by Presidio.     :param presidio_equivalences: Mapping of model-defined entities with     Presidio-supported entities.     :param ignore_labels: A list of entities specified by the model that     should not be extracted.      :example:     &gt;from presidio_analyzer import AnalyzerEngine, RecognizerRegistry      &gt;span_marker_recognizer = SpanMarkerRecognizer()      &gt;registry = RecognizerRegistry()     &gt;registry.add_recognizer(span_marker_recognizer)      &gt;analyzer = AnalyzerEngine(registry=registry)      &gt;results = analyzer.analyze(     &gt;    \"My name is Vijay and I live in Pune.\",     &gt;    language=\"en\",     &gt;    return_decision_process=True,     &gt;)     &gt;for result in results:     &gt;    print(result)     &gt;    print(result.analysis_explanation)       \"\"\"      ENTITIES = [         \"PERSON\",         \"LOCATION\",         \"ORGANIZATION\",         # \"MISCELLANEOUS\"   # - There are no direct correlation with Presidio entities.     ]      DEFAULT_MODEL = \"tomaarsen/span-marker-bert-base-fewnerd-fine-super\"      DEFAULT_EXPLANATION = \"Identified as {} by Span Marker's Named Entity Recognition\"      PRESIDIO_EQUIVALENCES = {         \"person-other\": \"PERSON\",         \"location-GPE\": \"LOCATION\",         \"organization-company\": \"ORGANIZATION\",         # 'MISC': 'MISCELLANEOUS'   # - Probably not PII     }      IGNORE_LABELS = [\"O\"]      def __init__(         self,         supported_language: str = \"en\",         model: str = None,         supported_entities: Optional[List[str]] = None,         presidio_equivalences: Optional[Dict[str, str]] = None,         ignore_labels: Optional[List[str]] = None,     ):         self.model = (             model             if model             else self.DEFAULT_MODEL         )          self.presidio_equivalences = (             presidio_equivalences             if presidio_equivalences             else self.PRESIDIO_EQUIVALENCES         )          supported_entities = (             supported_entities if supported_entities else self.ENTITIES         )          self.ignore_labels = (             ignore_labels if ignore_labels else self.IGNORE_LABELS         )          labels = list(self.presidio_equivalences.keys())         self.span_marker_model = SpanMarkerModel.from_pretrained(             self.model,             labels=labels         )          super().__init__(             supported_entities=supported_entities,             supported_language=supported_language,             name=\"Span Marker Analytics\",         )      def load(self) -&gt; None:         \"\"\"Load the model, not used. Model is loaded during initialization.\"\"\"         pass      def get_supported_entities(self) -&gt; List[str]:         \"\"\"         Return supported entities by this model.          :return: List of the supported entities.         \"\"\"         return self.supported_entities      # Class to use Span Marker with Presidio as an external recognizer.     def analyze(         self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None     ) -&gt; List[RecognizerResult]:         \"\"\"         Analyze text using Text Analytics.          :param text: The text for analysis.         :param entities: Not working properly for this recognizer.         :param nlp_artifacts: Not used by this recognizer.         :return: The list of Presidio RecognizerResult constructed from the recognized             Span Marker detections.         \"\"\"          results = []         ner_res = self.span_marker_model.predict(text)          for res in ner_res:             if not self.__check_label(                 res['label']             ):                 continue             textual_explanation = self.DEFAULT_EXPLANATION.format(                 res['label']             )             explanation = self.build_span_marker_explanation(                 round(res['score'], 2), textual_explanation             )             span_marker_result = self._convert_to_recognizer_result(res, explanation)             results.append(span_marker_result)          return results      def _convert_to_recognizer_result(self, entity, explanation) -&gt; RecognizerResult:          entity_type = self.presidio_equivalences.get(entity['label'], entity['label'])         span_marker_score = round(entity['score'], 2)          span_marker_results = RecognizerResult(             entity_type=entity_type,             start=entity['char_start_index'],             end=entity['char_end_index'],             score=span_marker_score,             analysis_explanation=explanation,         )          return span_marker_results      def build_span_marker_explanation(         self, original_score: float, explanation: str     ) -&gt; AnalysisExplanation:         \"\"\"         Create explanation for why this result was detected.          :param original_score: Score given by this recognizer         :param explanation: Explanation string         :return:         \"\"\"         explanation = AnalysisExplanation(             recognizer=self.__class__.__name__,             original_score=original_score,             textual_explanation=explanation,         )         return explanation      def __check_label(         self, label: str     ) -&gt; bool:         entity = self.presidio_equivalences.get(label, None)          if entity in self.ignore_labels:             return None          if entity is None:             logger.warning(f\"Found unrecognized label {label}, returning entity as is\")             return label          if entity not in self.supported_entities:             logger.warning(f\"Found entity {entity} which is not supported by Presidio\")             return entity         return entity In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n\n    from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\n    span_marker_recognizer = (\n        SpanMarkerRecognizer()\n    )\n\n    registry = RecognizerRegistry()\n    registry.add_recognizer(span_marker_recognizer)\n\n    analyzer = AnalyzerEngine(registry=registry)\n\n    results = analyzer.analyze(\n        \"My name is Vijay and I live in Pune.\",\n        language=\"en\",\n        return_decision_process=True,\n    )\n    for result in results:\n        print(result)\n        print(result.analysis_explanation)\n</pre> if __name__ == \"__main__\":      from presidio_analyzer import AnalyzerEngine, RecognizerRegistry      span_marker_recognizer = (         SpanMarkerRecognizer()     )      registry = RecognizerRegistry()     registry.add_recognizer(span_marker_recognizer)      analyzer = AnalyzerEngine(registry=registry)      results = analyzer.analyze(         \"My name is Vijay and I live in Pune.\",         language=\"en\",         return_decision_process=True,     )     for result in results:         print(result)         print(result.analysis_explanation)"},{"location":"samples/python/synth_data_with_openai/","title":"Synth data with openai","text":"In\u00a0[\u00a0]: Copied! <pre># download presidio\n!pip install presidio_analyzer presidio_anonymizer\n!pip install openai pandas\n!python -m spacy download en_core_web_lg\n</pre> # download presidio !pip install presidio_analyzer presidio_anonymizer !pip install openai pandas !python -m spacy download en_core_web_lg In\u00a0[3]: Copied! <pre>import pprint\nfrom dotenv import load_dotenv\nimport os\nimport pandas as pd\nfrom openai import OpenAI\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n)\n#Or put explicitly in notebook. Find out more here: https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key\n</pre> import pprint from dotenv import load_dotenv import os import pandas as pd from openai import OpenAI  load_dotenv()  client = OpenAI(     api_key=os.environ.get(\"OPENAI_API_KEY\"), ) #Or put explicitly in notebook. Find out more here: https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key In\u00a0[4]: Copied! <pre>def call_completion_model(prompt:str, model:str=\"gpt-3.5-turbo\", max_tokens:int=512) -&gt;str:\n    \"\"\"Creates a request for the OpenAI Completion service and returns the response.\n    \n    :param prompt: The prompt for the completion model\n    :param model: OpenAI model name\n    :param max_tokens: Model's max tokens parameter\n    \"\"\"\n\n    completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": prompt,\n        }\n    ],\n    model=model,\n)\n\n    return completion.choices[0].message.content\n</pre> def call_completion_model(prompt:str, model:str=\"gpt-3.5-turbo\", max_tokens:int=512) -&gt;str:     \"\"\"Creates a request for the OpenAI Completion service and returns the response.          :param prompt: The prompt for the completion model     :param model: OpenAI model name     :param max_tokens: Model's max tokens parameter     \"\"\"      completion = client.chat.completions.create(     messages=[         {             \"role\": \"user\",             \"content\": prompt,         }     ],     model=model, )      return completion.choices[0].message.content In\u00a0[5]: Copied! <pre>from presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine\n\nanalyzer = AnalyzerEngine()\nanonymizer = AnonymizerEngine()\n\nsample = \"\"\"\nHello, my name is David Johnson and I live in Maine.\nMy credit card number is 4095-2609-9393-4932 and my crypto wallet id is 16Yeky6GMjeNkAiNcBY7ZhrLoMSgg1BoyZ.\n\nOn September 18 I visited microsoft.com and sent an email to test@presidio.site,  from the IP 192.168.0.1.\n\nMy passport: 191280342 and my phone number: (212) 555-1234.\n\nThis is a valid International Bank Account Number: IL150120690000003111111 . Can you please check the status on bank account 954567876544?\n\nKate's social security number is 078-05-1126.  Her driver license? it is 1234567A.\n\"\"\"\n\nresults = analyzer.analyze(sample, language=\"en\")\nanonymized = anonymizer.anonymize(text=sample, analyzer_results=results)\nanonymized_text = anonymized.text\nprint(anonymized_text)\n</pre> from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine  analyzer = AnalyzerEngine() anonymizer = AnonymizerEngine()  sample = \"\"\" Hello, my name is David Johnson and I live in Maine. My credit card number is 4095-2609-9393-4932 and my crypto wallet id is 16Yeky6GMjeNkAiNcBY7ZhrLoMSgg1BoyZ.  On September 18 I visited microsoft.com and sent an email to test@presidio.site,  from the IP 192.168.0.1.  My passport: 191280342 and my phone number: (212) 555-1234.  This is a valid International Bank Account Number: IL150120690000003111111 . Can you please check the status on bank account 954567876544?  Kate's social security number is 078-05-1126.  Her driver license? it is 1234567A. \"\"\"  results = analyzer.analyze(sample, language=\"en\") anonymized = anonymizer.anonymize(text=sample, analyzer_results=results) anonymized_text = anonymized.text print(anonymized_text)  <pre>\nHello, my name is &lt;PERSON&gt; and I live in &lt;LOCATION&gt;.\nMy credit card number is &lt;CREDIT_CARD&gt; and my crypto wallet id is &lt;CRYPTO&gt;.\n\nOn &lt;DATE_TIME&gt; I visited &lt;URL&gt; and sent an email to &lt;EMAIL_ADDRESS&gt;,  from the IP &lt;IP_ADDRESS&gt;.\n\nMy passport: &lt;US_PASSPORT&gt; and my phone number: &lt;PHONE_NUMBER&gt;.\n\nThis is a valid International Bank Account Number: &lt;IBAN_CODE&gt; . Can you please check the status on bank account &lt;US_BANK_NUMBER&gt;?\n\n&lt;PERSON&gt;'s social security number is &lt;US_SSN&gt;.  Her driver license? it is &lt;US_DRIVER_LICENSE&gt;.\n\n</pre> In\u00a0[6]: Copied! <pre>def create_prompt(anonymized_text: str) -&gt; str:\n    \"\"\"\n    Create the prompt with instructions to GPT-3.\n    \n    :param anonymized_text: Text with placeholders instead of PII values, e.g. My name is &lt;PERSON&gt;.\n    \"\"\"\n\n    prompt = f\"\"\"\n    Your role is to create synthetic text based on de-identified text with placeholders instead of Personally Identifiable Information (PII).\n    Replace the placeholders (e.g. ,&lt;PERSON&gt;, {{DATE}}, {{ip_address}}) with fake values.\n    Instructions:\n    a. Use completely random numbers, so every digit is drawn between 0 and 9.\n    b. Use realistic names that come from diverse genders, ethnicities and countries.\n    c. If there are no placeholders, return the text as is.\n    d. Keep the formatting as close to the original as possible.\n    e. If PII exists in the input, replace it with fake values in the output.\n    f. Remove whitespace before and after the generated text\n    \n    input: [[TEXT STARTS]] How do I change the limit on my credit card {{credit_card_number}}?[[TEXT ENDS]]\n    output: How do I change the limit on my credit card 2539 3519 2345 1555?\n    input: [[TEXT STARTS]]&lt;PERSON&gt; was the chief science officer at &lt;ORGANIZATION&gt;.[[TEXT ENDS]]\n    output: Katherine Buckjov was the chief science officer at NASA.\n    input: [[TEXT STARTS]]Cameroon lives in &lt;LOCATION&gt;.[[TEXT ENDS]]\n    output: Vladimir lives in Moscow.\n    \n    input: [[TEXT STARTS]]{anonymized_text}[[TEXT ENDS]]\n    output:\"\"\"\n    return prompt\n</pre> def create_prompt(anonymized_text: str) -&gt; str:     \"\"\"     Create the prompt with instructions to GPT-3.          :param anonymized_text: Text with placeholders instead of PII values, e.g. My name is .     \"\"\"      prompt = f\"\"\"     Your role is to create synthetic text based on de-identified text with placeholders instead of Personally Identifiable Information (PII).     Replace the placeholders (e.g. ,, {{DATE}}, {{ip_address}}) with fake values.     Instructions:     a. Use completely random numbers, so every digit is drawn between 0 and 9.     b. Use realistic names that come from diverse genders, ethnicities and countries.     c. If there are no placeholders, return the text as is.     d. Keep the formatting as close to the original as possible.     e. If PII exists in the input, replace it with fake values in the output.     f. Remove whitespace before and after the generated text          input: [[TEXT STARTS]] How do I change the limit on my credit card {{credit_card_number}}?[[TEXT ENDS]]     output: How do I change the limit on my credit card 2539 3519 2345 1555?     input: [[TEXT STARTS]] was the chief science officer at .[[TEXT ENDS]]     output: Katherine Buckjov was the chief science officer at NASA.     input: [[TEXT STARTS]]Cameroon lives in .[[TEXT ENDS]]     output: Vladimir lives in Moscow.          input: [[TEXT STARTS]]{anonymized_text}[[TEXT ENDS]]     output:\"\"\"     return prompt In\u00a0[7]: Copied! <pre>print(\"This is the prompt with de-identified values:\")\nprint(create_prompt(anonymized_text))\n</pre> print(\"This is the prompt with de-identified values:\") print(create_prompt(anonymized_text)) <pre>This is the prompt with de-identified values:\n\n    Your role is to create synthetic text based on de-identified text with placeholders instead of Personally Identifiable Information (PII).\n    Replace the placeholders (e.g. ,&lt;PERSON&gt;, {DATE}, {ip_address}) with fake values.\n    Instructions:\n    a. Use completely random numbers, so every digit is drawn between 0 and 9.\n    b. Use realistic names that come from diverse genders, ethnicities and countries.\n    c. If there are no placeholders, return the text as is.\n    d. Keep the formatting as close to the original as possible.\n    e. If PII exists in the input, replace it with fake values in the output.\n    f. Remove whitespace before and after the generated text\n    \n    input: [[TEXT STARTS]] How do I change the limit on my credit card {credit_card_number}?[[TEXT ENDS]]\n    output: How do I change the limit on my credit card 2539 3519 2345 1555?\n    input: [[TEXT STARTS]]&lt;PERSON&gt; was the chief science officer at &lt;ORGANIZATION&gt;.[[TEXT ENDS]]\n    output: Katherine Buckjov was the chief science officer at NASA.\n    input: [[TEXT STARTS]]Cameroon lives in &lt;LOCATION&gt;.[[TEXT ENDS]]\n    output: Vladimir lives in Moscow.\n    \n    input: [[TEXT STARTS]]\nHello, my name is &lt;PERSON&gt; and I live in &lt;LOCATION&gt;.\nMy credit card number is &lt;CREDIT_CARD&gt; and my crypto wallet id is &lt;CRYPTO&gt;.\n\nOn &lt;DATE_TIME&gt; I visited &lt;URL&gt; and sent an email to &lt;EMAIL_ADDRESS&gt;,  from the IP &lt;IP_ADDRESS&gt;.\n\nMy passport: &lt;US_PASSPORT&gt; and my phone number: &lt;PHONE_NUMBER&gt;.\n\nThis is a valid International Bank Account Number: &lt;IBAN_CODE&gt; . Can you please check the status on bank account &lt;US_BANK_NUMBER&gt;?\n\n&lt;PERSON&gt;'s social security number is &lt;US_SSN&gt;.  Her driver license? it is &lt;US_DRIVER_LICENSE&gt;.\n[[TEXT ENDS]]\n    output:\n</pre> In\u00a0[8]: Copied! <pre>gpt_res = call_completion_model(create_prompt(anonymized_text))\n</pre> gpt_res = call_completion_model(create_prompt(anonymized_text)) In\u00a0[9]: Copied! <pre>print(gpt_res)\n</pre> print(gpt_res) <pre>Hello, my name is Aaliyah and I live in Tokyo.\nMy credit card number is 4928 7562 1034 8907 and my crypto wallet id is 0x3B 7a 5f 1C.\n\nOn 02/07/2023 15:45 I visited www.example.com and sent an email to example@email.com,  from the IP 127.0.0.1.\n\nMy passport: L921483B and my phone number: +1 (555) 123-4567.\n\nThis is a valid International Bank Account Number: FR76 1234 5789 1256 3321 7564 901. Can you please check the status on bank account 987654321?\n\nEliana's social security number is 123-45-6789.  Her driver license? it is DL12345678.\n</pre> In\u00a0[10]: Copied! <pre>import urllib\n\ntemplates = []\n\nurl = \"https://raw.githubusercontent.com/microsoft/presidio-research/master/presidio_evaluator/data_generator/raw_data/templates.txt\"\nfor line in urllib.request.urlopen(url):\n    templates.append(line.decode('utf-8'))\n</pre> import urllib  templates = []  url = \"https://raw.githubusercontent.com/microsoft/presidio-research/master/presidio_evaluator/data_generator/raw_data/templates.txt\" for line in urllib.request.urlopen(url):     templates.append(line.decode('utf-8'))  In\u00a0[11]: Copied! <pre>print(\"Example templates:\")\ntemplates[:5]\n</pre> print(\"Example templates:\") templates[:5] <pre>Example templates:\n</pre> Out[11]: <pre>['I want to increase limit on my card # {{credit_card_number}} for certain duration of time. is it possible?\\n',\n 'My credit card {{credit_card_number}} has been lost, Can I request you to block it.\\n',\n 'Need to change billing date of my card {{credit_card_number}}\\n',\n 'I want to update my primary and secondary address to the same: {{address}}\\n',\n \"In case of my child's account, we need to add {{person}} as guardian\\n\"]</pre> In\u00a0[12]: Copied! <pre>templates_to_use = templates[:5]\n\n\nimport time\npp = pprint.PrettyPrinter(indent=2, width=110)\nsentences = []\nfor template in templates_to_use:\n    synth_sentence = call_completion_model(create_prompt(template))\n    sentence_dict = {\"original\": template, \"synthetic\":synth_sentence.strip()}\n    sentences.append(sentence_dict)\n    pp.pprint(sentence_dict)\n    time.sleep(3) # wait to not get blocked by service (only applicable for the free tier)\n    print(\"--------------\")\n</pre> templates_to_use = templates[:5]   import time pp = pprint.PrettyPrinter(indent=2, width=110) sentences = [] for template in templates_to_use:     synth_sentence = call_completion_model(create_prompt(template))     sentence_dict = {\"original\": template, \"synthetic\":synth_sentence.strip()}     sentences.append(sentence_dict)     pp.pprint(sentence_dict)     time.sleep(3) # wait to not get blocked by service (only applicable for the free tier)     print(\"--------------\")  <pre>{ 'original': 'I want to increase limit on my card # {{credit_card_number}} for certain duration of time. is '\n              'it possible?\\n',\n  'synthetic': 'I want to increase limit on my card # 4701 2895 7462 8306 for certain duration of time. is '\n               'it possible?'}\n--------------\n{ 'original': 'My credit card {{credit_card_number}} has been lost, Can I request you to block it.\\n',\n  'synthetic': 'My credit card 4892 7634 1023 8756 has been lost, Can I request you to block it.'}\n--------------\n{ 'original': 'Need to change billing date of my card {{credit_card_number}}\\n',\n  'synthetic': 'Need to change billing date of my card 4876 2035 6981 7423'}\n--------------\n{ 'original': 'I want to update my primary and secondary address to the same: {{address}}\\n',\n  'synthetic': 'I want to update my primary and secondary address to the same: 123 Main Street, Apt 4.'}\n--------------\n{ 'original': \"In case of my child's account, we need to add {{person}} as guardian\\n\",\n  'synthetic': \"In case of my child's account, we need to add Abdul as guardian\"}\n--------------\n</pre> <pre>--------------\n{ 'original': '{{name}} lives at {{building_number}} {{street_name}}, {{city}}\\n',\n  'synthetic': 'John Smith lives at 635 Poplar Street, Houston'}\n--------------\n{ 'original': '{{first_name_male}} had given {{first_name}} his address: {{building_number}} '\n              '{{street_name}}\\n',\n  'synthetic': 'Adam had given Sarah his address: 44 Apple Street'}\n--------------\n{ 'original': '{{first_name_male}} had given {{first_name}} his address: {{building_number}} '\n              '{{street_name}}, {{city}}\\n',\n  'synthetic': 'David had given Emma his address: 515 Elm Street, Camden.'}\n--------------\n{ 'original': 'What is your address? it is {{address}}\\n',\n  'synthetic': 'What is your address? it is 3498 Allensby Street, Los Angeles, CA 90011.'}\n--------------\n{'original': 'We moved here from {{city}}\\n', 'synthetic': 'We moved here from Paris.'}\n--------------\n{'original': 'We moved here from {{country}}\\n', 'synthetic': 'We moved here from Venezuela.'}\n--------------\n{ 'original': '{{person}}\\\\n\\\\n{{building_number}} {{street_name}}\\\\n {{secondary_address}}\\\\n {{city}}\\\\n '\n              '{{country}} {{postcode}}\\\\n{{phone_number}}-Office\\\\,{{phone_number}}-Fax\\n',\n  'synthetic': 'Jessica Thompson\\n'\n               '    8745 West Drive\\n'\n               '    Suite 1402\\n'\n               '    Brooklyn, NY USA 12009\\n'\n               '    789-534-9921-Office, 567-945-0023-Fax'}\n--------------\n{ 'original': '{{person}}\\\\n{{job}}\\\\n{{organization}}\\\\n{{address}}\\n',\n  'synthetic': 'John Smith\\\\nAccountant\\\\nGlobalTech Solutions\\\\n25 Speedwell Street, Richmond, VA 23223'}\n--------------\n{ 'original': 'Our offices are located at {{address}}\\n',\n  'synthetic': 'Our offices are located at 1234 Main St, Los Angeles, CA 91234.'}\n--------------\n{ 'original': 'Please return to {{address}} in case of an issue.\\n',\n  'synthetic': 'Please return to 123 Cherry Street, El Monte, CA 91731 in case of an issue.'}\n--------------\n{ 'original': '{{organization}}\\\\n\\\\n{{address}}\\n',\n  'synthetic': 'ABC Inc.\\n     1234 Main Street, Anytown, ST 12345'}\n--------------\n{ 'original': 'The {{organization}} office is at {{address}}\\n',\n  'synthetic': 'The ABC Corporation office is at 123 Redwood Street, Anytown, USA.'}\n--------------\n{ 'original': '{{name}}\\\\n{{organization}}\\\\n{{address}}\\\\n{{phone_number}} office\\\\n{{phone_number}} '\n              'fax\\\\n{{phone_number}} mobile\\\\n\\n',\n  'synthetic': 'Larry Fernandez\\\\nStar Enterprises\\\\n421 5th Avenue, Los Angeles, CA 90012\\\\n123-456-7890 '\n               'office\\\\n456-789-0123 fax\\\\n256-454-2397 mobile\\\\n'}\n--------------\n{ 'original': '{{name}}\\\\n{{organization}}\\\\n{{address}}\\\\nMobile: {{phone_number}}\\\\nDesk: '\n              '{{phone_number}}\\\\nFax: {{phone_number}}\\\\n\\n',\n  'synthetic': 'John Brown\\n'\n               '    ABC Consulting\\n'\n               '    5th St., Suite 116, LA CA 90004\\n'\n               '    Mobile: 213-294-4497\\n'\n               '    Desk: 424-348-1275\\n'\n               '    Fax: 323-456-2545'}\n--------------\n{ 'original': 'Billing address: {{name}}\\\\n    {{building_number}} {{street_name}} '\n              '{{secondary_address}}\\\\n   {{city}}\\\\n    {{state_abbr}}\\\\n    {{zipcode}}\\\\n\\n',\n  'synthetic': 'Billing address: Mariam Rajput\\n'\n               '    576 Broadway Street Apartment A8\\n'\n               '   Sacramento\\n'\n               '    CA\\n'\n               '    95349'}\n--------------\n{ 'original': \"As promised, here's {{first_name}}'s address:\\\\n\\\\n{{address}}\\n\",\n  'synthetic': \"As promised, here's Aamir's address:\\\\n\\\\n2166 Sesame Street, Fortaleza, Cear\u00e1, Brazil.\"}\n--------------\n{ 'original': '&gt;{{name}}\\\\n&gt;{{organization}}\\\\n&gt;{{person}}\\\\n&gt;{{building_number}} '\n              '{{street_name}}\\\\n&gt;{{secondary_address}}\\\\n&gt;{{city}}\\\\n&gt;{{country}} {{postcode}}\\n',\n  'synthetic': '&gt;Freda Chen\\n'\n               '&gt;Example Inc.\\n'\n               '&gt;John Doe\\n'\n               '&gt;50 Main Street\\n'\n               '&gt;Apt. 2\\n'\n               '&gt;New York\\n'\n               '&gt;United States 10005'}\n--------------\n{ 'original': '??? {{name}}\\\\n??? {{organization}}\\\\n??? {{building_number}} {{street_name}}\\\\n??? '\n              '{{secondary_address}}\\\\n??? {{city}}\\\\n??? {{country}} {{postcode}}\\n',\n  'synthetic': 'John Smith\\n'\n               '     ABC Corporation\\n'\n               '     192 Main Street\\n'\n               '     Suite 100\\n'\n               '     Austin\\n'\n               '     United States 78701'}\n--------------\n{ 'original': '&gt; \\\\n&gt; {{name}}\\\\n&gt; {{organization}}\\\\n&gt; {{person}}\\\\n&gt; {{building_number}} '\n              '{{street_name}}\\\\n&gt; {{secondary_address}}\\\\n&gt; {{city}}\\\\n&gt; {{country}} {{postcode}}\\n',\n  'synthetic': '&gt; John Doe\\n'\n               '    &gt; ABC Corp\\n'\n               '    &gt; Jane Smith\\n'\n               '    &gt; 123 Main Street\\n'\n               '    &gt; APT 8\\n'\n               '    &gt; San Francisco\\n'\n               '    &gt; United States 12345'}\n--------------\n{ 'original': 'Pedestrians must enter on {{street_name}} St. the first three months\\n',\n  'synthetic': 'Pedestrians must enter on Jericho Avenue St. the first three months'}\n--------------\n{ 'original': 'When: {{date_time}}\\\\nWhere: {{city}} Country Club.\\n',\n  'synthetic': 'When: 05/01/2020 10:00am\\\\nWhere: Richmond Country Club.'}\n--------------\n{ 'original': \"We'll meet {{day_of_week}} at {{organization}}, {{building_number}} {{street_name}}, \"\n              '{{city}}\\n',\n  'synthetic': \"We'll meet Monday at Smartdel Solutions, 145 King Street, San Diego.\"}\n--------------\n{ 'original': 'They had 6: {{first_name}}, {{first_name}}, {{first_name}}, {{first_name}}, {{first_name}} '\n              'and {{first_name}}.\\n',\n  'synthetic': 'They had 6: Sarah, Micheal, Kanak, Hana, Mei and Dan.'}\n--------------\n{'original': 'She moved here from {{country}}\\n', 'synthetic': 'She moved here from Mexico.'}\n--------------\n{'original': 'My zip code is {{zipcode}}\\n', 'synthetic': 'My zip code is 47713.'}\n--------------\n{'original': 'ZIP: {{zipcode}}\\n', 'synthetic': 'ZIP: 08547'}\n--------------\n{'original': 'The bus station is on {{street_name}}\\n', 'synthetic': 'The bus station is on Wilson Avenue.'}\n--------------\n{ 'original': \"They're not answering at {{phone_number}}\\n\",\n  'synthetic': \"They're not answering at 654-339-1013.\"}\n--------------\n{ 'original': 'God gave rock and roll to you, gave rock and roll to you, put it in the soul of everyone.\\n',\n  'synthetic': 'God gave rock and roll to you, gave rock and roll to you, put it in the soul of everyone.'}\n--------------\n{'original': '3... 2... 1... liftoff!\\n', 'synthetic': '3... 2... 1... liftoff!'}\n--------------\n{ 'original': 'My great great grandfather was called {{name_male}}, and my great great grandmother was '\n              'called {{name_female}}\\n',\n  'synthetic': 'My great great grandfather was called Michael, and my great great grandmother was called '\n               'Emma.'}\n--------------\n{'original': 'She named him {{first_name_male}}\\n', 'synthetic': 'She named him Juan.'}\n--------------\n{ 'original': 'Name:    {{name}}\\\\nAddress:     {{address}}\\n',\n  'synthetic': 'Name:    Amari Walters\\\\nAddress:     32 Webster Street, Salem, MA 01819'}\n--------------\n{ 'original': 'Follow up with {{name}} in a couple of months.\\n',\n  'synthetic': 'Follow up with Beatriz Lawrence in a couple of months.'}\n--------------\n{ 'original': '{{prefix_male}} {{last_name_male}} is a {{age}} year old man who grew up in {{city}}.\\n',\n  'synthetic': 'Mr.Williams is a 28 year old man who grew up in Dallas.'}\n--------------\n{ 'original': 'Date: {{date_time}}\\\\nName: {{name}}\\\\nPhone: {{phone_number}}\\n',\n  'synthetic': 'Date: 01/03/2021 13:45 \\\\nName: Pratima Joshi \\\\nPhone: 467-562-8954'}\n--------------\n{ 'original': '{{first_name}}: \"Who are you?\"\\\\n{{first_name_female}}:\"I\\'m {{first_name}}\\'s daughter\".\\n',\n  'synthetic': 'Bob: \"Who are you?\"\\\\nMaria:\"I\\'m Bob\\'s daughter\".'}\n--------------\n{ 'original': 'At my suggestion, one morning over breakfast, she agreed, and on the last Sunday before Labor '\n              'Day we returned to {{city}} by helicopter.\\n',\n  'synthetic': 'At my suggestion, one morning over breakfast, she agreed, and on the last Sunday before '\n               'Labor Day we returned to Paris by helicopter.'}\n</pre> <pre>--------------\n{ 'original': \"It was a done thing between him and {{first_name}}'s kid; and everybody thought so.\\n\",\n  'synthetic': \"It was a done thing between him and Jeffery's kid; and everybody thought so.\"}\n--------------\n{ 'original': 'Capitalized words like Wisdom and Discipline are often mistaken with names.\\n',\n  'synthetic': 'Capitalized words like Wisdom and Discipline are often mistaken with names.'}\n--------------\n{ 'original': 'The letter arrived at {{address}} last night.\\n',\n  'synthetic': 'The letter arrived at 1143 Orange Street last night.'}\n--------------\n{ 'original': 'The Princess Royal arrived at {{city}} this morning from {{country}}.\\n',\n  'synthetic': 'The Princess Royal arrived at London this morning from France.'}\n--------------\n{'original': \"I'm in {{city}}, at the conference\\n\", 'synthetic': \"I'm in Toronto, at the conference.\"}\n--------------\n{ 'original': '{{name}}, the {{job}}, said: \"I\\'m glad to hear that this has been withdrawn \u2013 quite why they '\n              'thought this would go down well is beyond me.\"\\n',\n  'synthetic': 'Gloria Green, the Nurse Practitioner, said: \"I\\'m glad to hear that this has been withdrawn '\n               '\u2013 quite why they thought this would go down well is beyond me.\"'}\n--------------\n{ 'original': '\"I\\'m glad to hear that {{country}} is moving in that direction,\" says {{last_name}}.\\n',\n  'synthetic': '\"I\\'m glad to hear that Canada is moving in that direction,\" says Smith.'}\n--------------\n{ 'original': 'I am {{nation_woman}} but I live in {{country}}.\\n',\n  'synthetic': 'I am Marianna Montenegro but I live in Ukraine.'}\n--------------\n{'original': 'We are proud {{nation_plural}}\\n', 'synthetic': 'We are proud Americans.'}\n--------------\n{ 'original': \"{{person}}'s killers sentenced to life in prison\\n\",\n  'synthetic': \"John Smith's killers sentenced to life in prison\"}\n--------------\n{ 'original': \"{{country}} leader gives 'kill without warning' order\\n\",\n  'synthetic': \"Brazilian leader gives 'kill without warning' order\"}\n--------------\n{ 'original': 'The {{nationality}} Border Force have detained top-flight tennis player {{name_female}} over '\n              'visa disputes.\\n',\n  'synthetic': 'The British Border Force have detained top-flight tennis player Maria Rodriguez over visa '\n               'disputes.'}\n--------------\n{ 'original': 'You will be responsible for the husbandry and care of a large variety of species including '\n              'lemurs, antelope, camels, and more\\n',\n  'synthetic': 'You will be responsible for the husbandry and care of a large variety of species including '\n               'lemurs, antelope, camels, and more.'}\n--------------\n{ 'original': '{{name}}\\\\n\\\\n{{job}}\\\\n\\\\nPersonal '\n              'Info:\\\\nPhone:\\\\n{{phone_number}}\\\\n\\\\nE-mail:\\\\n{{email}}\\\\n\\\\nWebsite:\\\\n{{url}}\\\\n\\\\nAddress:\\\\n{{address}}.\\n',\n  'synthetic': 'Robert James\\\\n\\\\nSoftware Engineer\\\\n\\\\nPersonal '\n               'Info:\\\\nPhone:\\\\n555-847-8915\\\\n\\\\nE-mail:\\\\nrobertjames@example.com\\\\n\\\\nWebsite:\\\\nwww.example.com\\\\n\\\\nAddress:\\\\n277 '\n               'Park Ave North, Denver, CO 80100.'}\n--------------\n{ 'original': '{{name}}\\\\n\\\\n{{city}}\\\\n{{country}}\\n',\n  'synthetic': 'John Smith\\n     Los Angeles\\n     United States'}\n--------------\n{ 'original': 'Title VII of the Civil Rights Act of {{year}} protects individuals against employment '\n              'discrimination on the basis of race and color as well as national origin, sex, or religion.\\n',\n  'synthetic': 'Title VII of the Civil Rights Act of 1964 protects individuals against employment '\n               'discrimination on the basis of race and color as well as national origin, sex, or religion.'}\n--------------\n{ 'original': 'Energetic and driven salesperson with 8+ years of professional experience in inbound and '\n              'outbound sales. Awarded Salesperson of the Month three times. Helped increase inbound sales '\n              'by 16% within the first year of employment. Looking to support {{organization}} in {{city}} '\n              '{{zipcode}} in its mission to become a market-leading solution.\\n',\n  'synthetic': 'Energetic and driven salesperson with 8+ years of professional experience in inbound and '\n               'outbound sales. Awarded Salesperson of the Month three times. Helped increase inbound sales '\n               'by 16% within the first year of employment. Looking to support Acme Corporation in Los '\n               'Angeles 90018 in its mission to become a market-leading solution.'}\n--------------\n{ 'original': 'The bus drops you off at {{building_number}} {{street_name}} St.\\n',\n  'synthetic': 'The bus drops you off at 2774 Chestnut St.'}\n--------------\n{ 'original': 'Ask the driver to stop at the corner of {{street_name}} St. and {{street_name}} St.\\n',\n  'synthetic': 'Ask the driver to stop at the corner of Maple St. and Sycamore St.'}\n--------------\n{ 'original': 'He lives on the north side of {{street_name}}.\\n',\n  'synthetic': 'He lives on the north side of Abbey Road.'}\n--------------\n{ 'original': \"I used to work for {{organization}} as {{job}}, but quit a few months ago. Now I'm \"\n              'unemployed.\\n',\n  'synthetic': \"I used to work for ABC Corporation as Software Engineer, but quit a few months ago. Now I'm \"\n               'unemployed.'}\n--------------\n{'original': '{{city}} bridge is falling down.\\n', 'synthetic': 'Berlin bridge is falling down.'}\n--------------\n{ 'original': '{{name}} of {{organization}} is the CEO of the year. ABC Business considered several other '\n              \"influential CEOs for this year's honor, including {{name}} of {{organization}}, \"\n              \"{{organization}}'s {{name}}, {{name}} of {{organization}}'s, {{name}} of {{organization}}, \"\n              \"and {{organization}}'s {{name}}.\\n\",\n  'synthetic': 'Franklin Smith of Technology Solutions International is the CEO of the year. ABC Business '\n               \"considered several other influential CEOs for this year's honor, including Madison Chang of \"\n               \"Radiance Digital, Radiance Digital's Ashleigh Jones, Cash Huang of Clark &amp; Partner's, Sierra \"\n               \"Urbina of Intelicity, and Clark &amp; Partners's Asher Kenney.\"}\n--------------\n{ 'original': '{{organization}} is a design agency based in {{city}}.\\n',\n  'synthetic': 'Maestro Design Inc. is a design agency based in Amsterdam.'}\n--------------\n{ 'original': 'Action &amp; Adventure, Animation, Comedy, Kids &amp; Family, Mystery &amp; Suspense\\\\nDirected By:    '\n              '{{name}}\\n',\n  'synthetic': 'Action &amp; Adventure, Animation, Comedy, Kids &amp; Family, Mystery &amp; Suspense\\n'\n               'Directed By: Esther Jones'}\n--------------\n{ 'original': '{{first_name}}: What a wife.\\\\n{{first_name}}: Remember me, {{first_name}}? When I killed '\n              'your brother, I talked just like this!\\\\n{{first_name}}: You saved my life! How can I ever '\n              'repay you?\\n',\n  'synthetic': 'Emma: What a wife.\\n'\n               '    Emma: Remember me, Emma? When I killed your brother, I talked just like this!\\n'\n               '    Emma: You saved my life! How can I ever repay you?'}\n--------------\n{'original': 'He just turned {{age}} years old\\n', 'synthetic': 'He just turned 7 years old'}\n--------------\n{ 'original': \"I'm {{name}}, originally from {{city}}, and i'm {{age}} y/o.\\n\",\n  'synthetic': \"I'm Emily Evanston, originally from London, and I'm 24 y/o.\"}\n--------------\n{ 'original': 'Patient is a {{age}}-year-old male with a history of headaches\\n',\n  'synthetic': 'Patient is a 35-year-old male with a history of headaches'}\n--------------\n{'original': 'I just turned {{age}}\\n', 'synthetic': 'I just turned 24.'}\n--------------\n{'original': 'My father retired at the age of {{age}}\\n', 'synthetic': 'My father retired at the age of 60.'}\n--------------\n{ 'original': 'This {{age}} year old female complaining of stomach pain.\\n',\n  'synthetic': 'This 28 year old female complaining of stomach pain.'}\n--------------\n{ 'original': \"My birthday is on the weekend. I'll turn {{age}}.\\n\",\n  'synthetic': \"My birthday is on the weekend. I'll turn 20.\"}\n--------------\n{'original': 'My brother just turned {{age}}\\n', 'synthetic': 'My brother just turned 18.'}\n</pre> <pre>--------------\n{ 'original': '{{prefix}} {{last_name}} flew to {{city}} on {{day_of_week}} morning.',\n  'synthetic': 'Dr. Nguyen flew to Los Angeles on Tuesday morning.'}\n--------------\n</pre> <p>This notebook demonstrates how to leverage OpenAI models for fake/surrogate data generation. It uses Presidio to first de-identify data (as de-identification might be required prior to passing the model to OpenAI), and then uses OpenAI completion models to create synthetic/fake/surrogate data based on real data. OpenAI models would also potentially remove additional PII entities, if those are not detected by Presidio.</p> <p>Some impressions:</p> <ol> <li>LLMs sometimes gives additonal output, especially if the text is a question or concerning a human/bot interaction. Engineering the prompt can mitigate some of these issues. Potential post-processing might be required.</li> <li>LLMs sometimes creates fake values even in the absence of placeholders.</li> <li>LLMs re-uses context from other sentences, which could cause phone numbers are sometimes generated using a credit card pattern or other similar mistakes.</li> <li>Co-references are sometimes missed (i.e. two name placeholders that should be filled with the same name, or referencing he/she to a male/female name)</li> </ol> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"samples/python/synth_data_with_openai/#path-to-notebook-httpswwwgithubcommicrosoftpresidioblobmaindocssamplespythonsynth_data_with_openaiipynb","title":"Path to notebook: https://www.github.com/microsoft/presidio/blob/main/docs/samples/python/synth_data_with_openai.ipynb\u00b6","text":""},{"location":"samples/python/synth_data_with_openai/#use-presidio-openai-to-turn-real-text-into-fake-text","title":"Use Presidio + OpenAI to turn real text into fake text\u00b6","text":"<p>This notebook uses Presidio to turn text with PII into text where PII entities are replaced with placeholders, e.g. \"<code>My name is David</code>\" turns into \"<code>My name is {{PERSON}}</code>\". Then, it calls the OpenAI API to create a fake record which is based on the original one.</p> <p>Flow:</p> <ol> <li><code>My friend David lives in Paris. He likes it.</code></li> <li><code>My friend {{PERSON}} lives in {{CITY}}. He likes it.</code></li> <li><code>My friend Lucy lives in Beirut. She likes it.</code></li> </ol> <p>Note that OpenAI completion models could possibly detect PII values and replace them in one call, but it is suggested to validate that all PII entities are indeed detected.</p>"},{"location":"samples/python/synth_data_with_openai/#imports-and-set-up-openai-key","title":"Imports and set up OpenAI Key\u00b6","text":""},{"location":"samples/python/synth_data_with_openai/#define-request-for-the-openai-service","title":"Define request for the OpenAI service\u00b6","text":""},{"location":"samples/python/synth_data_with_openai/#de-identify-data-using-presidio-analyzer-and-anonymizer","title":"De-identify data using Presidio Analyzer and Anonymizer\u00b6","text":""},{"location":"samples/python/synth_data_with_openai/#create-prompt-instructions-text-to-manipulate","title":"Create prompt (instructions + text to manipulate)\u00b6","text":""},{"location":"samples/python/synth_data_with_openai/#call-the-llm","title":"Call the LLM\u00b6","text":""},{"location":"samples/python/synth_data_with_openai/#alternatively-run-on-a-list-of-template-sentences","title":"Alternatively, run on a list of template sentences:\u00b6","text":""},{"location":"samples/python/streamlit/","title":"Simple demo website for Presidio","text":"<p>Here's a simple app, written in pure Python, to create a demo website for Presidio. The app is based on the streamlit package.</p> <p>A live version can be found here: https://huggingface.co/spaces/presidio/presidio_demo</p>"},{"location":"samples/python/streamlit/#requirements","title":"Requirements","text":"<ol> <li>Clone the repo and move to the <code>docs/samples/python/streamlit</code> folder</li> <li>Install dependencies (preferably in a virtual environment)</li> </ol> <pre><code>pip install -r requirements\n</code></pre> <p>Note: This would install additional packages such as <code>transformers</code> and <code>flair</code> which are not mandatory for using Presidio.</p> <ol> <li>Optional: Update the <code>analyzer_engine</code> and <code>anonymizer_engine</code> functions for your specific implementation (in <code>presidio_helpers.py</code>).</li> <li>Start the app:</li> </ol> <pre><code>streamlit run presidio_streamlit.py\n</code></pre> <ol> <li>Consider adding an <code>.env</code> file with the following environment variables, for further customizability: <pre><code>TA_KEY=YOUR_TEXT_ANALYTICS_KEY\nTA_ENDPOINT=YOUR_TEXT_ANALYTICS_ENDPOINT\nOPENAI_TYPE=\"Azure\" #or \"openai\"\nOPENAI_KEY=YOUR_OPENAI_KEY\nOPENAI_API_VERSION = \"2023-05-15\"\nAZURE_OPENAI_ENDPOINT=YOUR_AZURE_OPENAI_AZURE_OPENAI_ENDPOINT\nAZURE_OPENAI_DEPLOYMENT=text-davinci-003\nALLOW_OTHER_MODELS=true #true if the user could download new models\n</code></pre></li> </ol>"},{"location":"samples/python/streamlit/#output","title":"Output","text":"<p>Output should be similar to this screenshot: </p>"},{"location":"samples/python/streamlit/azure_ai_language_wrapper/","title":"Azure ai language wrapper","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nfrom typing import List, Optional\nimport logging\nimport dotenv\nfrom azure.ai.textanalytics import TextAnalyticsClient\nfrom azure.core.credentials import AzureKeyCredential\n</pre> import os from typing import List, Optional import logging import dotenv from azure.ai.textanalytics import TextAnalyticsClient from azure.core.credentials import AzureKeyCredential In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import EntityRecognizer, RecognizerResult, AnalysisExplanation\nfrom presidio_analyzer.nlp_engine import NlpArtifacts\n</pre> from presidio_analyzer import EntityRecognizer, RecognizerResult, AnalysisExplanation from presidio_analyzer.nlp_engine import NlpArtifacts In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-streamlit\")\n</pre> logger = logging.getLogger(\"presidio-streamlit\") In\u00a0[\u00a0]: Copied! <pre>class AzureAIServiceWrapper(EntityRecognizer):\n    from azure.ai.textanalytics._models import PiiEntityCategory\n\n    TA_SUPPORTED_ENTITIES = [r.value for r in PiiEntityCategory]\n\n    def __init__(\n        self,\n        supported_entities: Optional[List[str]] = None,\n        supported_language: str = \"en\",\n        ta_client: Optional[TextAnalyticsClient] = None,\n        ta_key: Optional[str] = None,\n        ta_endpoint: Optional[str] = None,\n    ):\n        \"\"\"\n        Wrapper for the Azure Text Analytics client\n        :param ta_client: object of type TextAnalyticsClient\n        :param ta_key: Azure cognitive Services for Language key\n        :param ta_endpoint: Azure cognitive Services for Language endpoint\n        \"\"\"\n\n        if not supported_entities:\n            supported_entities = self.TA_SUPPORTED_ENTITIES\n\n        super().__init__(\n            supported_entities=supported_entities,\n            supported_language=supported_language,\n            name=\"Azure AI Language PII\",\n        )\n\n        self.ta_key = ta_key\n        self.ta_endpoint = ta_endpoint\n\n        if not ta_client:\n            ta_client = self.__authenticate_client(ta_key, ta_endpoint)\n        self.ta_client = ta_client\n\n    @staticmethod\n    def __authenticate_client(key: str, endpoint: str):\n        ta_credential = AzureKeyCredential(key)\n        text_analytics_client = TextAnalyticsClient(\n            endpoint=endpoint, credential=ta_credential\n        )\n        return text_analytics_client\n\n    def analyze(\n        self, text: str, entities: List[str] = None, nlp_artifacts: NlpArtifacts = None\n    ) -&gt; List[RecognizerResult]:\n        if not entities:\n            entities = []\n        response = self.ta_client.recognize_pii_entities(\n            [text], language=self.supported_language\n        )\n        results = [doc for doc in response if not doc.is_error]\n        recognizer_results = []\n        for res in results:\n            for entity in res.entities:\n                if entity.category not in self.supported_entities:\n                    continue\n                analysis_explanation = AzureAIServiceWrapper._build_explanation(\n                    original_score=entity.confidence_score,\n                    entity_type=entity.category,\n                )\n                recognizer_results.append(\n                    RecognizerResult(\n                        entity_type=entity.category,\n                        start=entity.offset,\n                        end=entity.offset + len(entity.text),\n                        score=entity.confidence_score,\n                        analysis_explanation=analysis_explanation,\n                    )\n                )\n\n        return recognizer_results\n\n    @staticmethod\n    def _build_explanation(\n        original_score: float, entity_type: str\n    ) -&gt; AnalysisExplanation:\n        explanation = AnalysisExplanation(\n            recognizer=AzureAIServiceWrapper.__class__.__name__,\n            original_score=original_score,\n            textual_explanation=f\"Identified as {entity_type} by Text Analytics\",\n        )\n        return explanation\n\n    def load(self) -&gt; None:\n        pass\n</pre> class AzureAIServiceWrapper(EntityRecognizer):     from azure.ai.textanalytics._models import PiiEntityCategory      TA_SUPPORTED_ENTITIES = [r.value for r in PiiEntityCategory]      def __init__(         self,         supported_entities: Optional[List[str]] = None,         supported_language: str = \"en\",         ta_client: Optional[TextAnalyticsClient] = None,         ta_key: Optional[str] = None,         ta_endpoint: Optional[str] = None,     ):         \"\"\"         Wrapper for the Azure Text Analytics client         :param ta_client: object of type TextAnalyticsClient         :param ta_key: Azure cognitive Services for Language key         :param ta_endpoint: Azure cognitive Services for Language endpoint         \"\"\"          if not supported_entities:             supported_entities = self.TA_SUPPORTED_ENTITIES          super().__init__(             supported_entities=supported_entities,             supported_language=supported_language,             name=\"Azure AI Language PII\",         )          self.ta_key = ta_key         self.ta_endpoint = ta_endpoint          if not ta_client:             ta_client = self.__authenticate_client(ta_key, ta_endpoint)         self.ta_client = ta_client      @staticmethod     def __authenticate_client(key: str, endpoint: str):         ta_credential = AzureKeyCredential(key)         text_analytics_client = TextAnalyticsClient(             endpoint=endpoint, credential=ta_credential         )         return text_analytics_client      def analyze(         self, text: str, entities: List[str] = None, nlp_artifacts: NlpArtifacts = None     ) -&gt; List[RecognizerResult]:         if not entities:             entities = []         response = self.ta_client.recognize_pii_entities(             [text], language=self.supported_language         )         results = [doc for doc in response if not doc.is_error]         recognizer_results = []         for res in results:             for entity in res.entities:                 if entity.category not in self.supported_entities:                     continue                 analysis_explanation = AzureAIServiceWrapper._build_explanation(                     original_score=entity.confidence_score,                     entity_type=entity.category,                 )                 recognizer_results.append(                     RecognizerResult(                         entity_type=entity.category,                         start=entity.offset,                         end=entity.offset + len(entity.text),                         score=entity.confidence_score,                         analysis_explanation=analysis_explanation,                     )                 )          return recognizer_results      @staticmethod     def _build_explanation(         original_score: float, entity_type: str     ) -&gt; AnalysisExplanation:         explanation = AnalysisExplanation(             recognizer=AzureAIServiceWrapper.__class__.__name__,             original_score=original_score,             textual_explanation=f\"Identified as {entity_type} by Text Analytics\",         )         return explanation      def load(self) -&gt; None:         pass In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    import presidio_helpers\n\n    dotenv.load_dotenv()\n    text = \"\"\"\n    Here are a few example sentences we currently support:\n\n    Hello, my name is David Johnson and I live in Maine.\n    My credit card number is 4095-2609-9393-4932 and my crypto wallet id is 16Yeky6GMjeNkAiNcBY7ZhrLoMSgg1BoyZ.\n    \n    On September 18 I visited microsoft.com and sent an email to test@presidio.site,  from the IP 192.168.0.1.\n    \n    My passport: 191280342 and my phone number: (212) 555-1234.\n    \n    This is a valid International Bank Account Number: IL150120690000003111111 . Can you please check the status on bank account 954567876544?\n    \n    Kate's social security number is 078-05-1126.  Her driver license? it is 1234567A.\n    \"\"\"\n    analyzer = presidio_helpers.analyzer_engine(\n        model_path=\"Azure Text Analytics PII\",\n        ta_key=os.environ[\"TA_KEY\"],\n        ta_endpoint=os.environ[\"TA_ENDPOINT\"],\n    )\n    analyzer.analyze(text=text, language=\"en\")\n</pre> if __name__ == \"__main__\":     import presidio_helpers      dotenv.load_dotenv()     text = \"\"\"     Here are a few example sentences we currently support:      Hello, my name is David Johnson and I live in Maine.     My credit card number is 4095-2609-9393-4932 and my crypto wallet id is 16Yeky6GMjeNkAiNcBY7ZhrLoMSgg1BoyZ.          On September 18 I visited microsoft.com and sent an email to test@presidio.site,  from the IP 192.168.0.1.          My passport: 191280342 and my phone number: (212) 555-1234.          This is a valid International Bank Account Number: IL150120690000003111111 . Can you please check the status on bank account 954567876544?          Kate's social security number is 078-05-1126.  Her driver license? it is 1234567A.     \"\"\"     analyzer = presidio_helpers.analyzer_engine(         model_path=\"Azure Text Analytics PII\",         ta_key=os.environ[\"TA_KEY\"],         ta_endpoint=os.environ[\"TA_ENDPOINT\"],     )     analyzer.analyze(text=text, language=\"en\")"},{"location":"samples/python/streamlit/flair_recognizer/","title":"Flair recognizer","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nfrom typing import Optional, List, Tuple, Set\n</pre> import logging from typing import Optional, List, Tuple, Set In\u00a0[\u00a0]: Copied! <pre>from presidio_analyzer import (\n    RecognizerResult,\n    EntityRecognizer,\n    AnalysisExplanation,\n)\nfrom presidio_analyzer.nlp_engine import NlpArtifacts\n</pre> from presidio_analyzer import (     RecognizerResult,     EntityRecognizer,     AnalysisExplanation, ) from presidio_analyzer.nlp_engine import NlpArtifacts In\u00a0[\u00a0]: Copied! <pre>from flair.data import Sentence\nfrom flair.models import SequenceTagger\n</pre> from flair.data import Sentence from flair.models import SequenceTagger In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-analyzer\")\n</pre> logger = logging.getLogger(\"presidio-analyzer\") In\u00a0[\u00a0]: Copied! <pre>class FlairRecognizer(EntityRecognizer):\n    \"\"\"\n    Wrapper for a flair model, if needed to be used within Presidio Analyzer.\n\n    :example:\n    &gt;from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\n    &gt;flair_recognizer = FlairRecognizer()\n\n    &gt;registry = RecognizerRegistry()\n    &gt;registry.add_recognizer(flair_recognizer)\n\n    &gt;analyzer = AnalyzerEngine(registry=registry)\n\n    &gt;results = analyzer.analyze(\n    &gt;    \"My name is Christopher and I live in Irbid.\",\n    &gt;    language=\"en\",\n    &gt;    return_decision_process=True,\n    &gt;)\n    &gt;for result in results:\n    &gt;    print(result)\n    &gt;    print(result.analysis_explanation)\n\n\n    \"\"\"\n\n    ENTITIES = [\n        \"LOCATION\",\n        \"PERSON\",\n        \"ORGANIZATION\",\n        # \"MISCELLANEOUS\"   # - There are no direct correlation with Presidio entities.\n    ]\n\n    DEFAULT_EXPLANATION = \"Identified as {} by Flair's Named Entity Recognition\"\n\n    CHECK_LABEL_GROUPS = [\n        ({\"LOCATION\"}, {\"LOC\", \"LOCATION\"}),\n        ({\"PERSON\"}, {\"PER\", \"PERSON\"}),\n        ({\"ORGANIZATION\"}, {\"ORG\"}),\n        # ({\"MISCELLANEOUS\"}, {\"MISC\"}), # Probably not PII\n    ]\n\n    MODEL_LANGUAGES = {\"en\": \"flair/ner-english-large\"}\n\n    PRESIDIO_EQUIVALENCES = {\n        \"PER\": \"PERSON\",\n        \"LOC\": \"LOCATION\",\n        \"ORG\": \"ORGANIZATION\",\n        # 'MISC': 'MISCELLANEOUS'   # - Probably not PII\n    }\n\n    def __init__(\n        self,\n        supported_language: str = \"en\",\n        supported_entities: Optional[List[str]] = None,\n        check_label_groups: Optional[Tuple[Set, Set]] = None,\n        model: SequenceTagger = None,\n        model_path: Optional[str] = None,\n    ):\n        self.check_label_groups = (\n            check_label_groups if check_label_groups else self.CHECK_LABEL_GROUPS\n        )\n\n        supported_entities = supported_entities if supported_entities else self.ENTITIES\n\n        if model and model_path:\n            raise ValueError(\"Only one of model or model_path should be provided.\")\n        elif model and not model_path:\n            self.model = model\n        elif not model and model_path:\n            print(f\"Loading model from {model_path}\")\n            self.model = SequenceTagger.load(model_path)\n        else:\n            print(f\"Loading model for language {supported_language}\")\n            self.model = SequenceTagger.load(\n                self.MODEL_LANGUAGES.get(supported_language)\n            )\n\n        super().__init__(\n            supported_entities=supported_entities,\n            supported_language=supported_language,\n            name=\"Flair Analytics\",\n        )\n\n    def load(self) -&gt; None:\n        \"\"\"Load the model, not used. Model is loaded during initialization.\"\"\"\n        pass\n\n    def get_supported_entities(self) -&gt; List[str]:\n        \"\"\"\n        Return supported entities by this model.\n\n        :return: List of the supported entities.\n        \"\"\"\n        return self.supported_entities\n\n    # Class to use Flair with Presidio as an external recognizer.\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Analyze text using Text Analytics.\n\n        :param text: The text for analysis.\n        :param entities: Not working properly for this recognizer.\n        :param nlp_artifacts: Not used by this recognizer.\n        :param language: Text language. Supported languages in MODEL_LANGUAGES\n        :return: The list of Presidio RecognizerResult constructed from the recognized\n            Flair detections.\n        \"\"\"\n\n        results = []\n\n        sentences = Sentence(text)\n        self.model.predict(sentences)\n\n        # If there are no specific list of entities, we will look for all of it.\n        if not entities:\n            entities = self.supported_entities\n\n        for entity in entities:\n            if entity not in self.supported_entities:\n                continue\n\n            for ent in sentences.get_spans(\"ner\"):\n                if not self.__check_label(\n                    entity, ent.labels[0].value, self.check_label_groups\n                ):\n                    continue\n                textual_explanation = self.DEFAULT_EXPLANATION.format(\n                    ent.labels[0].value\n                )\n                explanation = self.build_flair_explanation(\n                    round(ent.score, 2), textual_explanation\n                )\n                flair_result = self._convert_to_recognizer_result(ent, explanation)\n\n                results.append(flair_result)\n\n        return results\n\n    def _convert_to_recognizer_result(self, entity, explanation) -&gt; RecognizerResult:\n        entity_type = self.PRESIDIO_EQUIVALENCES.get(entity.tag, entity.tag)\n        flair_score = round(entity.score, 2)\n\n        flair_results = RecognizerResult(\n            entity_type=entity_type,\n            start=entity.start_position,\n            end=entity.end_position,\n            score=flair_score,\n            analysis_explanation=explanation,\n        )\n\n        return flair_results\n\n    def build_flair_explanation(\n        self, original_score: float, explanation: str\n    ) -&gt; AnalysisExplanation:\n        \"\"\"\n        Create explanation for why this result was detected.\n\n        :param original_score: Score given by this recognizer\n        :param explanation: Explanation string\n        :return:\n        \"\"\"\n        explanation = AnalysisExplanation(\n            recognizer=self.__class__.__name__,\n            original_score=original_score,\n            textual_explanation=explanation,\n        )\n        return explanation\n\n    @staticmethod\n    def __check_label(\n        entity: str, label: str, check_label_groups: Tuple[Set, Set]\n    ) -&gt; bool:\n        return any(\n            [entity in egrp and label in lgrp for egrp, lgrp in check_label_groups]\n        )\n</pre> class FlairRecognizer(EntityRecognizer):     \"\"\"     Wrapper for a flair model, if needed to be used within Presidio Analyzer.      :example:     &gt;from presidio_analyzer import AnalyzerEngine, RecognizerRegistry      &gt;flair_recognizer = FlairRecognizer()      &gt;registry = RecognizerRegistry()     &gt;registry.add_recognizer(flair_recognizer)      &gt;analyzer = AnalyzerEngine(registry=registry)      &gt;results = analyzer.analyze(     &gt;    \"My name is Christopher and I live in Irbid.\",     &gt;    language=\"en\",     &gt;    return_decision_process=True,     &gt;)     &gt;for result in results:     &gt;    print(result)     &gt;    print(result.analysis_explanation)       \"\"\"      ENTITIES = [         \"LOCATION\",         \"PERSON\",         \"ORGANIZATION\",         # \"MISCELLANEOUS\"   # - There are no direct correlation with Presidio entities.     ]      DEFAULT_EXPLANATION = \"Identified as {} by Flair's Named Entity Recognition\"      CHECK_LABEL_GROUPS = [         ({\"LOCATION\"}, {\"LOC\", \"LOCATION\"}),         ({\"PERSON\"}, {\"PER\", \"PERSON\"}),         ({\"ORGANIZATION\"}, {\"ORG\"}),         # ({\"MISCELLANEOUS\"}, {\"MISC\"}), # Probably not PII     ]      MODEL_LANGUAGES = {\"en\": \"flair/ner-english-large\"}      PRESIDIO_EQUIVALENCES = {         \"PER\": \"PERSON\",         \"LOC\": \"LOCATION\",         \"ORG\": \"ORGANIZATION\",         # 'MISC': 'MISCELLANEOUS'   # - Probably not PII     }      def __init__(         self,         supported_language: str = \"en\",         supported_entities: Optional[List[str]] = None,         check_label_groups: Optional[Tuple[Set, Set]] = None,         model: SequenceTagger = None,         model_path: Optional[str] = None,     ):         self.check_label_groups = (             check_label_groups if check_label_groups else self.CHECK_LABEL_GROUPS         )          supported_entities = supported_entities if supported_entities else self.ENTITIES          if model and model_path:             raise ValueError(\"Only one of model or model_path should be provided.\")         elif model and not model_path:             self.model = model         elif not model and model_path:             print(f\"Loading model from {model_path}\")             self.model = SequenceTagger.load(model_path)         else:             print(f\"Loading model for language {supported_language}\")             self.model = SequenceTagger.load(                 self.MODEL_LANGUAGES.get(supported_language)             )          super().__init__(             supported_entities=supported_entities,             supported_language=supported_language,             name=\"Flair Analytics\",         )      def load(self) -&gt; None:         \"\"\"Load the model, not used. Model is loaded during initialization.\"\"\"         pass      def get_supported_entities(self) -&gt; List[str]:         \"\"\"         Return supported entities by this model.          :return: List of the supported entities.         \"\"\"         return self.supported_entities      # Class to use Flair with Presidio as an external recognizer.     def analyze(         self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None     ) -&gt; List[RecognizerResult]:         \"\"\"         Analyze text using Text Analytics.          :param text: The text for analysis.         :param entities: Not working properly for this recognizer.         :param nlp_artifacts: Not used by this recognizer.         :param language: Text language. Supported languages in MODEL_LANGUAGES         :return: The list of Presidio RecognizerResult constructed from the recognized             Flair detections.         \"\"\"          results = []          sentences = Sentence(text)         self.model.predict(sentences)          # If there are no specific list of entities, we will look for all of it.         if not entities:             entities = self.supported_entities          for entity in entities:             if entity not in self.supported_entities:                 continue              for ent in sentences.get_spans(\"ner\"):                 if not self.__check_label(                     entity, ent.labels[0].value, self.check_label_groups                 ):                     continue                 textual_explanation = self.DEFAULT_EXPLANATION.format(                     ent.labels[0].value                 )                 explanation = self.build_flair_explanation(                     round(ent.score, 2), textual_explanation                 )                 flair_result = self._convert_to_recognizer_result(ent, explanation)                  results.append(flair_result)          return results      def _convert_to_recognizer_result(self, entity, explanation) -&gt; RecognizerResult:         entity_type = self.PRESIDIO_EQUIVALENCES.get(entity.tag, entity.tag)         flair_score = round(entity.score, 2)          flair_results = RecognizerResult(             entity_type=entity_type,             start=entity.start_position,             end=entity.end_position,             score=flair_score,             analysis_explanation=explanation,         )          return flair_results      def build_flair_explanation(         self, original_score: float, explanation: str     ) -&gt; AnalysisExplanation:         \"\"\"         Create explanation for why this result was detected.          :param original_score: Score given by this recognizer         :param explanation: Explanation string         :return:         \"\"\"         explanation = AnalysisExplanation(             recognizer=self.__class__.__name__,             original_score=original_score,             textual_explanation=explanation,         )         return explanation      @staticmethod     def __check_label(         entity: str, label: str, check_label_groups: Tuple[Set, Set]     ) -&gt; bool:         return any(             [entity in egrp and label in lgrp for egrp, lgrp in check_label_groups]         )"},{"location":"samples/python/streamlit/flair_recognizer/#taken-from-httpsgithubcommicrosoftpresidioblobmaindocssamplespythonflair_recognizerpy","title":"Taken from https://github.com/microsoft/presidio/blob/main/docs/samples/python/flair_recognizer.py\u00b6","text":""},{"location":"samples/python/streamlit/openai_fake_data_generator/","title":"Openai fake data generator","text":"In\u00a0[\u00a0]: Copied! <pre>from collections import namedtuple\nfrom typing import Optional\n</pre> from collections import namedtuple from typing import Optional In\u00a0[\u00a0]: Copied! <pre>import openai\nfrom openai import OpenAI, AzureOpenAI\nimport logging\n</pre> import openai from openai import OpenAI, AzureOpenAI import logging In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-streamlit\")\n</pre> logger = logging.getLogger(\"presidio-streamlit\") In\u00a0[\u00a0]: Copied! <pre>OpenAIParams = namedtuple(\n    \"open_ai_params\",\n    [\"openai_key\", \"model\", \"api_base\", \"deployment_id\", \"api_version\", \"api_type\"],\n)\n</pre> OpenAIParams = namedtuple(     \"open_ai_params\",     [\"openai_key\", \"model\", \"api_base\", \"deployment_id\", \"api_version\", \"api_type\"], ) In\u00a0[\u00a0]: Copied! <pre>def call_completion_model(\n    prompt: str,\n    openai_params: OpenAIParams,\n    max_tokens: Optional[int] = 256,\n) -&gt; str:\n    \"\"\"Creates a request for the OpenAI Completion service and returns the response.\n\n    :param prompt: The prompt for the completion model\n    :param openai_params: OpenAI parameters for the completion model\n    :param max_tokens: The maximum number of tokens to generate.\n    \"\"\"\n    if openai_params.api_type.lower() == \"azure\":\n        client = AzureOpenAI(\n            api_version=openai_params.api_version,\n            api_key=openai_params.openai_key,\n            azure_endpoint=openai_params.api_base,\n            azure_deployment=openai_params.deployment_id,\n        )\n    else:\n        client = OpenAI(api_key=openai_params.openai_key)\n\n    response = client.completions.create(\n        model=openai_params.model,\n        prompt=prompt,\n        max_tokens=max_tokens,\n    )\n\n    return response.choices[0].text.strip()\n</pre> def call_completion_model(     prompt: str,     openai_params: OpenAIParams,     max_tokens: Optional[int] = 256, ) -&gt; str:     \"\"\"Creates a request for the OpenAI Completion service and returns the response.      :param prompt: The prompt for the completion model     :param openai_params: OpenAI parameters for the completion model     :param max_tokens: The maximum number of tokens to generate.     \"\"\"     if openai_params.api_type.lower() == \"azure\":         client = AzureOpenAI(             api_version=openai_params.api_version,             api_key=openai_params.openai_key,             azure_endpoint=openai_params.api_base,             azure_deployment=openai_params.deployment_id,         )     else:         client = OpenAI(api_key=openai_params.openai_key)      response = client.completions.create(         model=openai_params.model,         prompt=prompt,         max_tokens=max_tokens,     )      return response.choices[0].text.strip() In\u00a0[\u00a0]: Copied! <pre>def create_prompt(anonymized_text: str) -&gt; str:\n    \"\"\"\n    Create the prompt with instructions to GPT-3.\n\n    :param anonymized_text: Text with placeholders instead of PII values, e.g. My name is &lt;PERSON&gt;.\n    \"\"\"\n\n    prompt = f\"\"\"\n    Your role is to create synthetic text based on de-identified text with placeholders instead of Personally Identifiable Information (PII).\n    Replace the placeholders (e.g. ,&lt;PERSON&gt;, {{DATE}}, {{ip_address}}) with fake values.\n\n    Instructions:\n\n    a. Use completely random numbers, so every digit is drawn between 0 and 9.\n    b. Use realistic names that come from diverse genders, ethnicities and countries.\n    c. If there are no placeholders, return the text as is.\n    d. Keep the formatting as close to the original as possible.\n    e. If PII exists in the input, replace it with fake values in the output.\n    f. Remove whitespace before and after the generated text\n    \n    input: [[TEXT STARTS]] How do I change the limit on my credit card {{credit_card_number}}?[[TEXT ENDS]]\n    output: How do I change the limit on my credit card 2539 3519 2345 1555?\n    input: [[TEXT STARTS]]&lt;PERSON&gt; was the chief science officer at &lt;ORGANIZATION&gt;.[[TEXT ENDS]]\n    output: Katherine Buckjov was the chief science officer at NASA.\n    input: [[TEXT STARTS]]Cameroon lives in &lt;LOCATION&gt;.[[TEXT ENDS]]\n    output: Vladimir lives in Moscow.\n    \n    input: [[TEXT STARTS]]{anonymized_text}[[TEXT ENDS]]\n    output:\"\"\"\n    return prompt\n</pre> def create_prompt(anonymized_text: str) -&gt; str:     \"\"\"     Create the prompt with instructions to GPT-3.      :param anonymized_text: Text with placeholders instead of PII values, e.g. My name is .     \"\"\"      prompt = f\"\"\"     Your role is to create synthetic text based on de-identified text with placeholders instead of Personally Identifiable Information (PII).     Replace the placeholders (e.g. ,, {{DATE}}, {{ip_address}}) with fake values.      Instructions:      a. Use completely random numbers, so every digit is drawn between 0 and 9.     b. Use realistic names that come from diverse genders, ethnicities and countries.     c. If there are no placeholders, return the text as is.     d. Keep the formatting as close to the original as possible.     e. If PII exists in the input, replace it with fake values in the output.     f. Remove whitespace before and after the generated text          input: [[TEXT STARTS]] How do I change the limit on my credit card {{credit_card_number}}?[[TEXT ENDS]]     output: How do I change the limit on my credit card 2539 3519 2345 1555?     input: [[TEXT STARTS]] was the chief science officer at .[[TEXT ENDS]]     output: Katherine Buckjov was the chief science officer at NASA.     input: [[TEXT STARTS]]Cameroon lives in .[[TEXT ENDS]]     output: Vladimir lives in Moscow.          input: [[TEXT STARTS]]{anonymized_text}[[TEXT ENDS]]     output:\"\"\"     return prompt"},{"location":"samples/python/streamlit/presidio_helpers/","title":"Presidio helpers","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nHelper methods for the Presidio Streamlit app\n\"\"\"\nfrom typing import List, Optional, Tuple\nimport logging\nimport streamlit as st\nfrom presidio_analyzer import (\n    AnalyzerEngine,\n    RecognizerResult,\n    RecognizerRegistry,\n    PatternRecognizer,\n    Pattern,\n)\nfrom presidio_analyzer.nlp_engine import NlpEngine\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\n</pre> \"\"\" Helper methods for the Presidio Streamlit app \"\"\" from typing import List, Optional, Tuple import logging import streamlit as st from presidio_analyzer import (     AnalyzerEngine,     RecognizerResult,     RecognizerRegistry,     PatternRecognizer,     Pattern, ) from presidio_analyzer.nlp_engine import NlpEngine from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import OperatorConfig In\u00a0[\u00a0]: Copied! <pre>from openai_fake_data_generator import (\n    call_completion_model,\n    OpenAIParams,\n    create_prompt,\n)\nfrom presidio_nlp_engine_config import (\n    create_nlp_engine_with_spacy,\n    create_nlp_engine_with_flair,\n    create_nlp_engine_with_transformers,\n    create_nlp_engine_with_azure_ai_language,\n    create_nlp_engine_with_stanza,\n)\n</pre> from openai_fake_data_generator import (     call_completion_model,     OpenAIParams,     create_prompt, ) from presidio_nlp_engine_config import (     create_nlp_engine_with_spacy,     create_nlp_engine_with_flair,     create_nlp_engine_with_transformers,     create_nlp_engine_with_azure_ai_language,     create_nlp_engine_with_stanza, ) In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-streamlit\")\n</pre> logger = logging.getLogger(\"presidio-streamlit\") In\u00a0[\u00a0]: Copied! <pre>@st.cache_resource\ndef nlp_engine_and_registry(\n    model_family: str,\n    model_path: str,\n    ta_key: Optional[str] = None,\n    ta_endpoint: Optional[str] = None,\n) -&gt; Tuple[NlpEngine, RecognizerRegistry]:\n    \"\"\"Create the NLP Engine instance based on the requested model.\n    :param model_family: Which model package to use for NER.\n    :param model_path: Which model to use for NER. E.g.,\n        \"StanfordAIMI/stanford-deidentifier-base\",\n        \"obi/deid_roberta_i2b2\",\n        \"en_core_web_lg\"\n    :param ta_key: Key to the Text Analytics endpoint (only if model_path = \"Azure Text Analytics\")\n    :param ta_endpoint: Endpoint of the Text Analytics instance (only if model_path = \"Azure Text Analytics\")\n    \"\"\"\n\n    # Set up NLP Engine according to the model of choice\n    if \"spacy\" in model_family.lower():\n        return create_nlp_engine_with_spacy(model_path)\n    if \"stanza\" in model_family.lower():\n        return create_nlp_engine_with_stanza(model_path)\n    elif \"flair\" in model_family.lower():\n        return create_nlp_engine_with_flair(model_path)\n    elif \"huggingface\" in model_family.lower():\n        return create_nlp_engine_with_transformers(model_path)\n    elif \"azure ai language\" in model_family.lower():\n        return create_nlp_engine_with_azure_ai_language(ta_key, ta_endpoint)\n    else:\n        raise ValueError(f\"Model family {model_family} not supported\")\n</pre> @st.cache_resource def nlp_engine_and_registry(     model_family: str,     model_path: str,     ta_key: Optional[str] = None,     ta_endpoint: Optional[str] = None, ) -&gt; Tuple[NlpEngine, RecognizerRegistry]:     \"\"\"Create the NLP Engine instance based on the requested model.     :param model_family: Which model package to use for NER.     :param model_path: Which model to use for NER. E.g.,         \"StanfordAIMI/stanford-deidentifier-base\",         \"obi/deid_roberta_i2b2\",         \"en_core_web_lg\"     :param ta_key: Key to the Text Analytics endpoint (only if model_path = \"Azure Text Analytics\")     :param ta_endpoint: Endpoint of the Text Analytics instance (only if model_path = \"Azure Text Analytics\")     \"\"\"      # Set up NLP Engine according to the model of choice     if \"spacy\" in model_family.lower():         return create_nlp_engine_with_spacy(model_path)     if \"stanza\" in model_family.lower():         return create_nlp_engine_with_stanza(model_path)     elif \"flair\" in model_family.lower():         return create_nlp_engine_with_flair(model_path)     elif \"huggingface\" in model_family.lower():         return create_nlp_engine_with_transformers(model_path)     elif \"azure ai language\" in model_family.lower():         return create_nlp_engine_with_azure_ai_language(ta_key, ta_endpoint)     else:         raise ValueError(f\"Model family {model_family} not supported\") In\u00a0[\u00a0]: Copied! <pre>@st.cache_resource\ndef analyzer_engine(\n    model_family: str,\n    model_path: str,\n    ta_key: Optional[str] = None,\n    ta_endpoint: Optional[str] = None,\n) -&gt; AnalyzerEngine:\n    \"\"\"Create the NLP Engine instance based on the requested model.\n    :param model_family: Which model package to use for NER.\n    :param model_path: Which model to use for NER:\n        \"StanfordAIMI/stanford-deidentifier-base\",\n        \"obi/deid_roberta_i2b2\",\n        \"en_core_web_lg\"\n    :param ta_key: Key to the Text Analytics endpoint (only if model_path = \"Azure Text Analytics\")\n    :param ta_endpoint: Endpoint of the Text Analytics instance (only if model_path = \"Azure Text Analytics\")\n    \"\"\"\n    nlp_engine, registry = nlp_engine_and_registry(\n        model_family, model_path, ta_key, ta_endpoint\n    )\n    analyzer = AnalyzerEngine(nlp_engine=nlp_engine, registry=registry)\n    return analyzer\n</pre> @st.cache_resource def analyzer_engine(     model_family: str,     model_path: str,     ta_key: Optional[str] = None,     ta_endpoint: Optional[str] = None, ) -&gt; AnalyzerEngine:     \"\"\"Create the NLP Engine instance based on the requested model.     :param model_family: Which model package to use for NER.     :param model_path: Which model to use for NER:         \"StanfordAIMI/stanford-deidentifier-base\",         \"obi/deid_roberta_i2b2\",         \"en_core_web_lg\"     :param ta_key: Key to the Text Analytics endpoint (only if model_path = \"Azure Text Analytics\")     :param ta_endpoint: Endpoint of the Text Analytics instance (only if model_path = \"Azure Text Analytics\")     \"\"\"     nlp_engine, registry = nlp_engine_and_registry(         model_family, model_path, ta_key, ta_endpoint     )     analyzer = AnalyzerEngine(nlp_engine=nlp_engine, registry=registry)     return analyzer In\u00a0[\u00a0]: Copied! <pre>@st.cache_resource\ndef anonymizer_engine():\n    \"\"\"Return AnonymizerEngine.\"\"\"\n    return AnonymizerEngine()\n</pre> @st.cache_resource def anonymizer_engine():     \"\"\"Return AnonymizerEngine.\"\"\"     return AnonymizerEngine() In\u00a0[\u00a0]: Copied! <pre>@st.cache_data\ndef get_supported_entities(\n    model_family: str, model_path: str, ta_key: str, ta_endpoint: str\n):\n    \"\"\"Return supported entities from the Analyzer Engine.\"\"\"\n    return analyzer_engine(\n        model_family, model_path, ta_key, ta_endpoint\n    ).get_supported_entities() + [\"GENERIC_PII\"]\n</pre> @st.cache_data def get_supported_entities(     model_family: str, model_path: str, ta_key: str, ta_endpoint: str ):     \"\"\"Return supported entities from the Analyzer Engine.\"\"\"     return analyzer_engine(         model_family, model_path, ta_key, ta_endpoint     ).get_supported_entities() + [\"GENERIC_PII\"] In\u00a0[\u00a0]: Copied! <pre>@st.cache_data\ndef analyze(\n    model_family: str, model_path: str, ta_key: str, ta_endpoint: str, **kwargs\n):\n    \"\"\"Analyze input using Analyzer engine and input arguments (kwargs).\"\"\"\n    if \"entities\" not in kwargs or \"All\" in kwargs[\"entities\"]:\n        kwargs[\"entities\"] = None\n\n    if \"deny_list\" in kwargs and kwargs[\"deny_list\"] is not None:\n        ad_hoc_recognizer = create_ad_hoc_deny_list_recognizer(kwargs[\"deny_list\"])\n        kwargs[\"ad_hoc_recognizers\"] = [ad_hoc_recognizer] if ad_hoc_recognizer else []\n        del kwargs[\"deny_list\"]\n\n    if \"regex_params\" in kwargs and len(kwargs[\"regex_params\"]) &gt; 0:\n        ad_hoc_recognizer = create_ad_hoc_regex_recognizer(*kwargs[\"regex_params\"])\n        kwargs[\"ad_hoc_recognizers\"] = [ad_hoc_recognizer] if ad_hoc_recognizer else []\n        del kwargs[\"regex_params\"]\n\n    return analyzer_engine(model_family, model_path, ta_key, ta_endpoint).analyze(\n        **kwargs\n    )\n</pre> @st.cache_data def analyze(     model_family: str, model_path: str, ta_key: str, ta_endpoint: str, **kwargs ):     \"\"\"Analyze input using Analyzer engine and input arguments (kwargs).\"\"\"     if \"entities\" not in kwargs or \"All\" in kwargs[\"entities\"]:         kwargs[\"entities\"] = None      if \"deny_list\" in kwargs and kwargs[\"deny_list\"] is not None:         ad_hoc_recognizer = create_ad_hoc_deny_list_recognizer(kwargs[\"deny_list\"])         kwargs[\"ad_hoc_recognizers\"] = [ad_hoc_recognizer] if ad_hoc_recognizer else []         del kwargs[\"deny_list\"]      if \"regex_params\" in kwargs and len(kwargs[\"regex_params\"]) &gt; 0:         ad_hoc_recognizer = create_ad_hoc_regex_recognizer(*kwargs[\"regex_params\"])         kwargs[\"ad_hoc_recognizers\"] = [ad_hoc_recognizer] if ad_hoc_recognizer else []         del kwargs[\"regex_params\"]      return analyzer_engine(model_family, model_path, ta_key, ta_endpoint).analyze(         **kwargs     ) In\u00a0[\u00a0]: Copied! <pre>def anonymize(\n    text: str,\n    operator: str,\n    analyze_results: List[RecognizerResult],\n    mask_char: Optional[str] = None,\n    number_of_chars: Optional[str] = None,\n    encrypt_key: Optional[str] = None,\n):\n    \"\"\"Anonymize identified input using Presidio Anonymizer.\n\n    :param text: Full text\n    :param operator: Operator name\n    :param mask_char: Mask char (for mask operator)\n    :param number_of_chars: Number of characters to mask (for mask operator)\n    :param encrypt_key: Encryption key (for encrypt operator)\n    :param analyze_results: list of results from presidio analyzer engine\n    \"\"\"\n\n    if operator == \"mask\":\n        operator_config = {\n            \"type\": \"mask\",\n            \"masking_char\": mask_char,\n            \"chars_to_mask\": number_of_chars,\n            \"from_end\": False,\n        }\n\n    # Define operator config\n    elif operator == \"encrypt\":\n        operator_config = {\"key\": encrypt_key}\n    elif operator == \"highlight\":\n        operator_config = {\"lambda\": lambda x: x}\n    else:\n        operator_config = None\n\n    # Change operator if needed as intermediate step\n    if operator == \"highlight\":\n        operator = \"custom\"\n    elif operator == \"synthesize\":\n        operator = \"replace\"\n    else:\n        operator = operator\n\n    res = anonymizer_engine().anonymize(\n        text,\n        analyze_results,\n        operators={\"DEFAULT\": OperatorConfig(operator, operator_config)},\n    )\n    return res\n</pre> def anonymize(     text: str,     operator: str,     analyze_results: List[RecognizerResult],     mask_char: Optional[str] = None,     number_of_chars: Optional[str] = None,     encrypt_key: Optional[str] = None, ):     \"\"\"Anonymize identified input using Presidio Anonymizer.      :param text: Full text     :param operator: Operator name     :param mask_char: Mask char (for mask operator)     :param number_of_chars: Number of characters to mask (for mask operator)     :param encrypt_key: Encryption key (for encrypt operator)     :param analyze_results: list of results from presidio analyzer engine     \"\"\"      if operator == \"mask\":         operator_config = {             \"type\": \"mask\",             \"masking_char\": mask_char,             \"chars_to_mask\": number_of_chars,             \"from_end\": False,         }      # Define operator config     elif operator == \"encrypt\":         operator_config = {\"key\": encrypt_key}     elif operator == \"highlight\":         operator_config = {\"lambda\": lambda x: x}     else:         operator_config = None      # Change operator if needed as intermediate step     if operator == \"highlight\":         operator = \"custom\"     elif operator == \"synthesize\":         operator = \"replace\"     else:         operator = operator      res = anonymizer_engine().anonymize(         text,         analyze_results,         operators={\"DEFAULT\": OperatorConfig(operator, operator_config)},     )     return res In\u00a0[\u00a0]: Copied! <pre>def annotate(text: str, analyze_results: List[RecognizerResult]):\n    \"\"\"Highlight the identified PII entities on the original text\n\n    :param text: Full text\n    :param analyze_results: list of results from presidio analyzer engine\n    \"\"\"\n    tokens = []\n\n    # Use the anonymizer to resolve overlaps\n    results = anonymize(\n        text=text,\n        operator=\"highlight\",\n        analyze_results=analyze_results,\n    )\n\n    # sort by start index\n    results = sorted(results.items, key=lambda x: x.start)\n    for i, res in enumerate(results):\n        if i == 0:\n            tokens.append(text[: res.start])\n\n        # append entity text and entity type\n        tokens.append((text[res.start : res.end], res.entity_type))\n\n        # if another entity coming i.e. we're not at the last results element, add text up to next entity\n        if i != len(results) - 1:\n            tokens.append(text[res.end : results[i + 1].start])\n        # if no more entities coming, add all remaining text\n        else:\n            tokens.append(text[res.end :])\n    return tokens\n</pre> def annotate(text: str, analyze_results: List[RecognizerResult]):     \"\"\"Highlight the identified PII entities on the original text      :param text: Full text     :param analyze_results: list of results from presidio analyzer engine     \"\"\"     tokens = []      # Use the anonymizer to resolve overlaps     results = anonymize(         text=text,         operator=\"highlight\",         analyze_results=analyze_results,     )      # sort by start index     results = sorted(results.items, key=lambda x: x.start)     for i, res in enumerate(results):         if i == 0:             tokens.append(text[: res.start])          # append entity text and entity type         tokens.append((text[res.start : res.end], res.entity_type))          # if another entity coming i.e. we're not at the last results element, add text up to next entity         if i != len(results) - 1:             tokens.append(text[res.end : results[i + 1].start])         # if no more entities coming, add all remaining text         else:             tokens.append(text[res.end :])     return tokens In\u00a0[\u00a0]: Copied! <pre>def create_fake_data(\n    text: str,\n    analyze_results: List[RecognizerResult],\n    openai_params: OpenAIParams,\n):\n    \"\"\"Creates a synthetic version of the text using OpenAI APIs\"\"\"\n    if not openai_params.openai_key:\n        return \"Please provide your OpenAI key\"\n    results = anonymize(text=text, operator=\"replace\", analyze_results=analyze_results)\n    prompt = create_prompt(results.text)\n    print(f\"Prompt: {prompt}\")\n    fake = call_completion_model(prompt=prompt, openai_params=openai_params)\n    return fake\n</pre> def create_fake_data(     text: str,     analyze_results: List[RecognizerResult],     openai_params: OpenAIParams, ):     \"\"\"Creates a synthetic version of the text using OpenAI APIs\"\"\"     if not openai_params.openai_key:         return \"Please provide your OpenAI key\"     results = anonymize(text=text, operator=\"replace\", analyze_results=analyze_results)     prompt = create_prompt(results.text)     print(f\"Prompt: {prompt}\")     fake = call_completion_model(prompt=prompt, openai_params=openai_params)     return fake In\u00a0[\u00a0]: Copied! <pre>@st.cache_data\ndef call_openai_api(\n    prompt: str, openai_model_name: str, openai_deployment_name: Optional[str] = None\n) -&gt; str:\n    fake_data = call_completion_model(\n        prompt, model=openai_model_name, deployment_id=openai_deployment_name\n    )\n    return fake_data\n</pre> @st.cache_data def call_openai_api(     prompt: str, openai_model_name: str, openai_deployment_name: Optional[str] = None ) -&gt; str:     fake_data = call_completion_model(         prompt, model=openai_model_name, deployment_id=openai_deployment_name     )     return fake_data In\u00a0[\u00a0]: Copied! <pre>def create_ad_hoc_deny_list_recognizer(\n    deny_list=Optional[List[str]],\n) -&gt; Optional[PatternRecognizer]:\n    if not deny_list:\n        return None\n\n    deny_list_recognizer = PatternRecognizer(\n        supported_entity=\"GENERIC_PII\", deny_list=deny_list\n    )\n    return deny_list_recognizer\n</pre> def create_ad_hoc_deny_list_recognizer(     deny_list=Optional[List[str]], ) -&gt; Optional[PatternRecognizer]:     if not deny_list:         return None      deny_list_recognizer = PatternRecognizer(         supported_entity=\"GENERIC_PII\", deny_list=deny_list     )     return deny_list_recognizer In\u00a0[\u00a0]: Copied! <pre>def create_ad_hoc_regex_recognizer(\n    regex: str, entity_type: str, score: float, context: Optional[List[str]] = None\n) -&gt; Optional[PatternRecognizer]:\n    if not regex:\n        return None\n    pattern = Pattern(name=\"Regex pattern\", regex=regex, score=score)\n    regex_recognizer = PatternRecognizer(\n        supported_entity=entity_type, patterns=[pattern], context=context\n    )\n    return regex_recognizer\n</pre> def create_ad_hoc_regex_recognizer(     regex: str, entity_type: str, score: float, context: Optional[List[str]] = None ) -&gt; Optional[PatternRecognizer]:     if not regex:         return None     pattern = Pattern(name=\"Regex pattern\", regex=regex, score=score)     regex_recognizer = PatternRecognizer(         supported_entity=entity_type, patterns=[pattern], context=context     )     return regex_recognizer"},{"location":"samples/python/streamlit/presidio_nlp_engine_config/","title":"Presidio nlp engine config","text":"In\u00a0[\u00a0]: Copied! <pre>import logging\nfrom typing import Tuple\n</pre> import logging from typing import Tuple In\u00a0[\u00a0]: Copied! <pre>import spacy\nfrom presidio_analyzer import RecognizerRegistry\nfrom presidio_analyzer.nlp_engine import (\n    NlpEngine,\n    NlpEngineProvider,\n)\n</pre> import spacy from presidio_analyzer import RecognizerRegistry from presidio_analyzer.nlp_engine import (     NlpEngine,     NlpEngineProvider, ) In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-streamlit\")\n</pre> logger = logging.getLogger(\"presidio-streamlit\") In\u00a0[\u00a0]: Copied! <pre>def create_nlp_engine_with_spacy(\n    model_path: str,\n) -&gt; Tuple[NlpEngine, RecognizerRegistry]:\n    \"\"\"\n    Instantiate an NlpEngine with a spaCy model\n    :param model_path: path to model / model name.\n    \"\"\"\n    nlp_configuration = {\n        \"nlp_engine_name\": \"spacy\",\n        \"models\": [{\"lang_code\": \"en\", \"model_name\": model_path}],\n        \"ner_model_configuration\": {\n            \"model_to_presidio_entity_mapping\": {\n                \"PER\": \"PERSON\",\n                \"PERSON\": \"PERSON\",\n                \"NORP\": \"NRP\",\n                \"FAC\": \"FACILITY\",\n                \"LOC\": \"LOCATION\",\n                \"GPE\": \"LOCATION\",\n                \"LOCATION\": \"LOCATION\",\n                \"ORG\": \"ORGANIZATION\",\n                \"ORGANIZATION\": \"ORGANIZATION\",\n                \"DATE\": \"DATE_TIME\",\n                \"TIME\": \"DATE_TIME\",\n            },\n            \"low_confidence_score_multiplier\": 0.4,\n            \"low_score_entity_names\": [\"ORG\", \"ORGANIZATION\"],\n        },\n    }\n\n    nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n\n    registry = RecognizerRegistry()\n    registry.load_predefined_recognizers(nlp_engine=nlp_engine)\n\n    return nlp_engine, registry\n</pre> def create_nlp_engine_with_spacy(     model_path: str, ) -&gt; Tuple[NlpEngine, RecognizerRegistry]:     \"\"\"     Instantiate an NlpEngine with a spaCy model     :param model_path: path to model / model name.     \"\"\"     nlp_configuration = {         \"nlp_engine_name\": \"spacy\",         \"models\": [{\"lang_code\": \"en\", \"model_name\": model_path}],         \"ner_model_configuration\": {             \"model_to_presidio_entity_mapping\": {                 \"PER\": \"PERSON\",                 \"PERSON\": \"PERSON\",                 \"NORP\": \"NRP\",                 \"FAC\": \"FACILITY\",                 \"LOC\": \"LOCATION\",                 \"GPE\": \"LOCATION\",                 \"LOCATION\": \"LOCATION\",                 \"ORG\": \"ORGANIZATION\",                 \"ORGANIZATION\": \"ORGANIZATION\",                 \"DATE\": \"DATE_TIME\",                 \"TIME\": \"DATE_TIME\",             },             \"low_confidence_score_multiplier\": 0.4,             \"low_score_entity_names\": [\"ORG\", \"ORGANIZATION\"],         },     }      nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()      registry = RecognizerRegistry()     registry.load_predefined_recognizers(nlp_engine=nlp_engine)      return nlp_engine, registry In\u00a0[\u00a0]: Copied! <pre>def create_nlp_engine_with_stanza(\n    model_path: str,\n) -&gt; Tuple[NlpEngine, RecognizerRegistry]:\n    \"\"\"\n    Instantiate an NlpEngine with a stanza model\n    :param model_path: path to model / model name.\n    \"\"\"\n    nlp_configuration = {\n        \"nlp_engine_name\": \"stanza\",\n        \"models\": [{\"lang_code\": \"en\", \"model_name\": model_path}],\n        \"ner_model_configuration\": {\n            \"model_to_presidio_entity_mapping\": {\n                \"PER\": \"PERSON\",\n                \"PERSON\": \"PERSON\",\n                \"NORP\": \"NRP\",\n                \"FAC\": \"FACILITY\",\n                \"LOC\": \"LOCATION\",\n                \"GPE\": \"LOCATION\",\n                \"LOCATION\": \"LOCATION\",\n                \"ORG\": \"ORGANIZATION\",\n                \"ORGANIZATION\": \"ORGANIZATION\",\n                \"DATE\": \"DATE_TIME\",\n                \"TIME\": \"DATE_TIME\",\n            }\n        },\n    }\n\n    nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n\n    registry = RecognizerRegistry()\n    registry.load_predefined_recognizers(nlp_engine=nlp_engine)\n\n    return nlp_engine, registry\n</pre> def create_nlp_engine_with_stanza(     model_path: str, ) -&gt; Tuple[NlpEngine, RecognizerRegistry]:     \"\"\"     Instantiate an NlpEngine with a stanza model     :param model_path: path to model / model name.     \"\"\"     nlp_configuration = {         \"nlp_engine_name\": \"stanza\",         \"models\": [{\"lang_code\": \"en\", \"model_name\": model_path}],         \"ner_model_configuration\": {             \"model_to_presidio_entity_mapping\": {                 \"PER\": \"PERSON\",                 \"PERSON\": \"PERSON\",                 \"NORP\": \"NRP\",                 \"FAC\": \"FACILITY\",                 \"LOC\": \"LOCATION\",                 \"GPE\": \"LOCATION\",                 \"LOCATION\": \"LOCATION\",                 \"ORG\": \"ORGANIZATION\",                 \"ORGANIZATION\": \"ORGANIZATION\",                 \"DATE\": \"DATE_TIME\",                 \"TIME\": \"DATE_TIME\",             }         },     }      nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()      registry = RecognizerRegistry()     registry.load_predefined_recognizers(nlp_engine=nlp_engine)      return nlp_engine, registry In\u00a0[\u00a0]: Copied! <pre>def create_nlp_engine_with_transformers(\n    model_path: str,\n) -&gt; Tuple[NlpEngine, RecognizerRegistry]:\n    \"\"\"\n    Instantiate an NlpEngine with a TransformersRecognizer and a small spaCy model.\n    The TransformersRecognizer would return results from Transformers models, the spaCy model\n    would return NlpArtifacts such as POS and lemmas.\n    :param model_path: HuggingFace model path.\n    \"\"\"\n    print(f\"Loading Transformers model: {model_path} of type {type(model_path)}\")\n\n    nlp_configuration = {\n        \"nlp_engine_name\": \"transformers\",\n        \"models\": [\n            {\n                \"lang_code\": \"en\",\n                \"model_name\": {\"spacy\": \"en_core_web_sm\", \"transformers\": model_path},\n            }\n        ],\n        \"ner_model_configuration\": {\n            \"model_to_presidio_entity_mapping\": {\n                \"PER\": \"PERSON\",\n                \"PERSON\": \"PERSON\",\n                \"LOC\": \"LOCATION\",\n                \"LOCATION\": \"LOCATION\",\n                \"GPE\": \"LOCATION\",\n                \"ORG\": \"ORGANIZATION\",\n                \"ORGANIZATION\": \"ORGANIZATION\",\n                \"NORP\": \"NRP\",\n                \"AGE\": \"AGE\",\n                \"ID\": \"ID\",\n                \"EMAIL\": \"EMAIL\",\n                \"PATIENT\": \"PERSON\",\n                \"STAFF\": \"PERSON\",\n                \"HOSP\": \"ORGANIZATION\",\n                \"PATORG\": \"ORGANIZATION\",\n                \"DATE\": \"DATE_TIME\",\n                \"TIME\": \"DATE_TIME\",\n                \"PHONE\": \"PHONE_NUMBER\",\n                \"HCW\": \"PERSON\",\n                \"HOSPITAL\": \"ORGANIZATION\",\n                \"FACILITY\": \"LOCATION\",\n            },\n            \"low_confidence_score_multiplier\": 0.4,\n            \"low_score_entity_names\": [\"ID\"],\n            \"labels_to_ignore\": [\n                \"CARDINAL\",\n                \"EVENT\",\n                \"LANGUAGE\",\n                \"LAW\",\n                \"MONEY\",\n                \"ORDINAL\",\n                \"PERCENT\",\n                \"PRODUCT\",\n                \"QUANTITY\",\n                \"WORK_OF_ART\",\n            ],\n        },\n    }\n\n    nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n\n    registry = RecognizerRegistry()\n    registry.load_predefined_recognizers(nlp_engine=nlp_engine)\n\n    return nlp_engine, registry\n</pre> def create_nlp_engine_with_transformers(     model_path: str, ) -&gt; Tuple[NlpEngine, RecognizerRegistry]:     \"\"\"     Instantiate an NlpEngine with a TransformersRecognizer and a small spaCy model.     The TransformersRecognizer would return results from Transformers models, the spaCy model     would return NlpArtifacts such as POS and lemmas.     :param model_path: HuggingFace model path.     \"\"\"     print(f\"Loading Transformers model: {model_path} of type {type(model_path)}\")      nlp_configuration = {         \"nlp_engine_name\": \"transformers\",         \"models\": [             {                 \"lang_code\": \"en\",                 \"model_name\": {\"spacy\": \"en_core_web_sm\", \"transformers\": model_path},             }         ],         \"ner_model_configuration\": {             \"model_to_presidio_entity_mapping\": {                 \"PER\": \"PERSON\",                 \"PERSON\": \"PERSON\",                 \"LOC\": \"LOCATION\",                 \"LOCATION\": \"LOCATION\",                 \"GPE\": \"LOCATION\",                 \"ORG\": \"ORGANIZATION\",                 \"ORGANIZATION\": \"ORGANIZATION\",                 \"NORP\": \"NRP\",                 \"AGE\": \"AGE\",                 \"ID\": \"ID\",                 \"EMAIL\": \"EMAIL\",                 \"PATIENT\": \"PERSON\",                 \"STAFF\": \"PERSON\",                 \"HOSP\": \"ORGANIZATION\",                 \"PATORG\": \"ORGANIZATION\",                 \"DATE\": \"DATE_TIME\",                 \"TIME\": \"DATE_TIME\",                 \"PHONE\": \"PHONE_NUMBER\",                 \"HCW\": \"PERSON\",                 \"HOSPITAL\": \"ORGANIZATION\",                 \"FACILITY\": \"LOCATION\",             },             \"low_confidence_score_multiplier\": 0.4,             \"low_score_entity_names\": [\"ID\"],             \"labels_to_ignore\": [                 \"CARDINAL\",                 \"EVENT\",                 \"LANGUAGE\",                 \"LAW\",                 \"MONEY\",                 \"ORDINAL\",                 \"PERCENT\",                 \"PRODUCT\",                 \"QUANTITY\",                 \"WORK_OF_ART\",             ],         },     }      nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()      registry = RecognizerRegistry()     registry.load_predefined_recognizers(nlp_engine=nlp_engine)      return nlp_engine, registry In\u00a0[\u00a0]: Copied! <pre>def create_nlp_engine_with_flair(\n    model_path: str,\n) -&gt; Tuple[NlpEngine, RecognizerRegistry]:\n    \"\"\"\n    Instantiate an NlpEngine with a FlairRecognizer and a small spaCy model.\n    The FlairRecognizer would return results from Flair models, the spaCy model\n    would return NlpArtifacts such as POS and lemmas.\n    :param model_path: Flair model path.\n    \"\"\"\n    from flair_recognizer import FlairRecognizer\n\n    registry = RecognizerRegistry()\n    registry.load_predefined_recognizers()\n\n    # there is no official Flair NlpEngine, hence we load it as an additional recognizer\n\n    if not spacy.util.is_package(\"en_core_web_sm\"):\n        spacy.cli.download(\"en_core_web_sm\")\n    # Using a small spaCy model + a Flair NER model\n    flair_recognizer = FlairRecognizer(model_path=model_path)\n    nlp_configuration = {\n        \"nlp_engine_name\": \"spacy\",\n        \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}],\n    }\n    registry.add_recognizer(flair_recognizer)\n    registry.remove_recognizer(\"SpacyRecognizer\")\n\n    nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n\n    return nlp_engine, registry\n</pre> def create_nlp_engine_with_flair(     model_path: str, ) -&gt; Tuple[NlpEngine, RecognizerRegistry]:     \"\"\"     Instantiate an NlpEngine with a FlairRecognizer and a small spaCy model.     The FlairRecognizer would return results from Flair models, the spaCy model     would return NlpArtifacts such as POS and lemmas.     :param model_path: Flair model path.     \"\"\"     from flair_recognizer import FlairRecognizer      registry = RecognizerRegistry()     registry.load_predefined_recognizers()      # there is no official Flair NlpEngine, hence we load it as an additional recognizer      if not spacy.util.is_package(\"en_core_web_sm\"):         spacy.cli.download(\"en_core_web_sm\")     # Using a small spaCy model + a Flair NER model     flair_recognizer = FlairRecognizer(model_path=model_path)     nlp_configuration = {         \"nlp_engine_name\": \"spacy\",         \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}],     }     registry.add_recognizer(flair_recognizer)     registry.remove_recognizer(\"SpacyRecognizer\")      nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()      return nlp_engine, registry In\u00a0[\u00a0]: Copied! <pre>def create_nlp_engine_with_azure_ai_language(ta_key: str, ta_endpoint: str):\n    \"\"\"\n    Instantiate an NlpEngine with a TextAnalyticsWrapper and a small spaCy model.\n    The TextAnalyticsWrapper would return results from calling Azure Text Analytics PII, the spaCy model\n    would return NlpArtifacts such as POS and lemmas.\n    :param ta_key: Azure Text Analytics key.\n    :param ta_endpoint: Azure Text Analytics endpoint.\n    \"\"\"\n    from azure_ai_language_wrapper import AzureAIServiceWrapper\n\n    if not ta_key or not ta_endpoint:\n        raise RuntimeError(\"Please fill in the Text Analytics endpoint details\")\n\n    registry = RecognizerRegistry()\n    registry.load_predefined_recognizers()\n\n    azure_ai_language_recognizer = AzureAIServiceWrapper(\n        ta_endpoint=ta_endpoint, ta_key=ta_key\n    )\n    nlp_configuration = {\n        \"nlp_engine_name\": \"spacy\",\n        \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}],\n    }\n\n    nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n\n    registry.add_recognizer(azure_ai_language_recognizer)\n    registry.remove_recognizer(\"SpacyRecognizer\")\n\n    return nlp_engine, registry\n</pre> def create_nlp_engine_with_azure_ai_language(ta_key: str, ta_endpoint: str):     \"\"\"     Instantiate an NlpEngine with a TextAnalyticsWrapper and a small spaCy model.     The TextAnalyticsWrapper would return results from calling Azure Text Analytics PII, the spaCy model     would return NlpArtifacts such as POS and lemmas.     :param ta_key: Azure Text Analytics key.     :param ta_endpoint: Azure Text Analytics endpoint.     \"\"\"     from azure_ai_language_wrapper import AzureAIServiceWrapper      if not ta_key or not ta_endpoint:         raise RuntimeError(\"Please fill in the Text Analytics endpoint details\")      registry = RecognizerRegistry()     registry.load_predefined_recognizers()      azure_ai_language_recognizer = AzureAIServiceWrapper(         ta_endpoint=ta_endpoint, ta_key=ta_key     )     nlp_configuration = {         \"nlp_engine_name\": \"spacy\",         \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}],     }      nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()      registry.add_recognizer(azure_ai_language_recognizer)     registry.remove_recognizer(\"SpacyRecognizer\")      return nlp_engine, registry"},{"location":"samples/python/streamlit/presidio_streamlit/","title":"Presidio streamlit","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Streamlit app for Presidio.\"\"\"\nimport logging\nimport os\nimport traceback\n</pre> \"\"\"Streamlit app for Presidio.\"\"\" import logging import os import traceback In\u00a0[\u00a0]: Copied! <pre>import dotenv\nimport pandas as pd\nimport streamlit as st\nimport streamlit.components.v1 as components\nfrom annotated_text import annotated_text\nfrom streamlit_tags import st_tags\n</pre> import dotenv import pandas as pd import streamlit as st import streamlit.components.v1 as components from annotated_text import annotated_text from streamlit_tags import st_tags In\u00a0[\u00a0]: Copied! <pre>from openai_fake_data_generator import OpenAIParams\nfrom presidio_helpers import (\n    get_supported_entities,\n    analyze,\n    anonymize,\n    annotate,\n    create_fake_data,\n    analyzer_engine,\n)\n</pre> from openai_fake_data_generator import OpenAIParams from presidio_helpers import (     get_supported_entities,     analyze,     anonymize,     annotate,     create_fake_data,     analyzer_engine, ) In\u00a0[\u00a0]: Copied! <pre>st.set_page_config(\n    page_title=\"Presidio demo\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\",\n    menu_items={\n        \"About\": \"https://microsoft.github.io/presidio/\",\n    },\n)\n</pre> st.set_page_config(     page_title=\"Presidio demo\",     layout=\"wide\",     initial_sidebar_state=\"expanded\",     menu_items={         \"About\": \"https://microsoft.github.io/presidio/\",     }, ) In\u00a0[\u00a0]: Copied! <pre>dotenv.load_dotenv()\nlogger = logging.getLogger(\"presidio-streamlit\")\n</pre> dotenv.load_dotenv() logger = logging.getLogger(\"presidio-streamlit\") In\u00a0[\u00a0]: Copied! <pre>allow_other_models = os.getenv(\"ALLOW_OTHER_MODELS\", False)\n</pre> allow_other_models = os.getenv(\"ALLOW_OTHER_MODELS\", False) In\u00a0[\u00a0]: Copied! <pre># Sidebar\nst.sidebar.header(\n    \"\"\"\nPII De-Identification with [Microsoft Presidio](https://microsoft.github.io/presidio/)\n\"\"\"\n)\n</pre> # Sidebar st.sidebar.header(     \"\"\" PII De-Identification with [Microsoft Presidio](https://microsoft.github.io/presidio/) \"\"\" ) In\u00a0[\u00a0]: Copied! <pre>model_help_text = \"\"\"\n    Select which Named Entity Recognition (NER) model to use for PII detection, in parallel to rule-based recognizers.\n    Presidio supports multiple NER packages off-the-shelf, such as spaCy, Huggingface, Stanza and Flair,\n    as well as service such as Azure Text Analytics PII.\n    \"\"\"\nst_ta_key = st_ta_endpoint = \"\"\n</pre> model_help_text = \"\"\"     Select which Named Entity Recognition (NER) model to use for PII detection, in parallel to rule-based recognizers.     Presidio supports multiple NER packages off-the-shelf, such as spaCy, Huggingface, Stanza and Flair,     as well as service such as Azure Text Analytics PII.     \"\"\" st_ta_key = st_ta_endpoint = \"\" In\u00a0[\u00a0]: Copied! <pre>model_list = [\n    \"spaCy/en_core_web_lg\",\n    \"flair/ner-english-large\",\n    \"HuggingFace/obi/deid_roberta_i2b2\",\n    \"HuggingFace/StanfordAIMI/stanford-deidentifier-base\",\n    \"stanza/en\",\n    \"Azure AI Language\",\n    \"Other\",\n]\nif not allow_other_models:\n    model_list.pop()\n# Select model\nst_model = st.sidebar.selectbox(\n    \"NER model package\",\n    model_list,\n    index=2,\n    help=model_help_text,\n)\n</pre> model_list = [     \"spaCy/en_core_web_lg\",     \"flair/ner-english-large\",     \"HuggingFace/obi/deid_roberta_i2b2\",     \"HuggingFace/StanfordAIMI/stanford-deidentifier-base\",     \"stanza/en\",     \"Azure AI Language\",     \"Other\", ] if not allow_other_models:     model_list.pop() # Select model st_model = st.sidebar.selectbox(     \"NER model package\",     model_list,     index=2,     help=model_help_text, ) In\u00a0[\u00a0]: Copied! <pre># Extract model package.\nst_model_package = st_model.split(\"/\")[0]\n</pre> # Extract model package. st_model_package = st_model.split(\"/\")[0] In\u00a0[\u00a0]: Copied! <pre># Remove package prefix (if needed)\nst_model = (\n    st_model\n    if st_model_package.lower() not in (\"spacy\", \"stanza\", \"huggingface\")\n    else \"/\".join(st_model.split(\"/\")[1:])\n)\n</pre> # Remove package prefix (if needed) st_model = (     st_model     if st_model_package.lower() not in (\"spacy\", \"stanza\", \"huggingface\")     else \"/\".join(st_model.split(\"/\")[1:]) ) In\u00a0[\u00a0]: Copied! <pre>if st_model == \"Other\":\n    st_model_package = st.sidebar.selectbox(\n        \"NER model OSS package\", options=[\"spaCy\", \"stanza\", \"Flair\", \"HuggingFace\"]\n    )\n    st_model = st.sidebar.text_input(f\"NER model name\", value=\"\")\n</pre> if st_model == \"Other\":     st_model_package = st.sidebar.selectbox(         \"NER model OSS package\", options=[\"spaCy\", \"stanza\", \"Flair\", \"HuggingFace\"]     )     st_model = st.sidebar.text_input(f\"NER model name\", value=\"\") In\u00a0[\u00a0]: Copied! <pre>if st_model == \"Azure AI Language\":\n    st_ta_key = st.sidebar.text_input(\n        f\"Azure AI Language key\", value=os.getenv(\"TA_KEY\", \"\"), type=\"password\"\n    )\n    st_ta_endpoint = st.sidebar.text_input(\n        f\"Azure AI Language endpoint\",\n        value=os.getenv(\"TA_ENDPOINT\", default=\"\"),\n        help=\"For more info: https://learn.microsoft.com/en-us/azure/cognitive-services/language-service/personally-identifiable-information/overview\",  # noqa: E501\n    )\n</pre> if st_model == \"Azure AI Language\":     st_ta_key = st.sidebar.text_input(         f\"Azure AI Language key\", value=os.getenv(\"TA_KEY\", \"\"), type=\"password\"     )     st_ta_endpoint = st.sidebar.text_input(         f\"Azure AI Language endpoint\",         value=os.getenv(\"TA_ENDPOINT\", default=\"\"),         help=\"For more info: https://learn.microsoft.com/en-us/azure/cognitive-services/language-service/personally-identifiable-information/overview\",  # noqa: E501     ) In\u00a0[\u00a0]: Copied! <pre>st.sidebar.warning(\"Note: Models might take some time to download. \")\n</pre> st.sidebar.warning(\"Note: Models might take some time to download. \") In\u00a0[\u00a0]: Copied! <pre>analyzer_params = (st_model_package, st_model, st_ta_key, st_ta_endpoint)\nlogger.debug(f\"analyzer_params: {analyzer_params}\")\n</pre> analyzer_params = (st_model_package, st_model, st_ta_key, st_ta_endpoint) logger.debug(f\"analyzer_params: {analyzer_params}\") In\u00a0[\u00a0]: Copied! <pre>st_operator = st.sidebar.selectbox(\n    \"De-identification approach\",\n    [\"redact\", \"replace\", \"synthesize\", \"highlight\", \"mask\", \"hash\", \"encrypt\"],\n    index=1,\n    help=\"\"\"\n    Select which manipulation to the text is requested after PII has been identified.\\n\n    - Redact: Completely remove the PII text\\n\n    - Replace: Replace the PII text with a constant, e.g. &lt;PERSON&gt;\\n\n    - Synthesize: Replace with fake values (requires an OpenAI key)\\n\n    - Highlight: Shows the original text with PII highlighted in colors\\n\n    - Mask: Replaces a requested number of characters with an asterisk (or other mask character)\\n\n    - Hash: Replaces with the hash of the PII string\\n\n    - Encrypt: Replaces with an AES encryption of the PII string, allowing the process to be reversed\n         \"\"\",\n)\nst_mask_char = \"*\"\nst_number_of_chars = 15\nst_encrypt_key = \"WmZq4t7w!z%C&amp;F)J\"\n</pre> st_operator = st.sidebar.selectbox(     \"De-identification approach\",     [\"redact\", \"replace\", \"synthesize\", \"highlight\", \"mask\", \"hash\", \"encrypt\"],     index=1,     help=\"\"\"     Select which manipulation to the text is requested after PII has been identified.\\n     - Redact: Completely remove the PII text\\n     - Replace: Replace the PII text with a constant, e.g. \\n     - Synthesize: Replace with fake values (requires an OpenAI key)\\n     - Highlight: Shows the original text with PII highlighted in colors\\n     - Mask: Replaces a requested number of characters with an asterisk (or other mask character)\\n     - Hash: Replaces with the hash of the PII string\\n     - Encrypt: Replaces with an AES encryption of the PII string, allowing the process to be reversed          \"\"\", ) st_mask_char = \"*\" st_number_of_chars = 15 st_encrypt_key = \"WmZq4t7w!z%C&amp;F)J\" In\u00a0[\u00a0]: Copied! <pre>open_ai_params = None\n</pre> open_ai_params = None In\u00a0[\u00a0]: Copied! <pre>logger.debug(f\"st_operator: {st_operator}\")\n</pre> logger.debug(f\"st_operator: {st_operator}\") In\u00a0[\u00a0]: Copied! <pre>def set_up_openai_synthesis():\n    \"\"\"Set up the OpenAI API key and model for text synthesis.\"\"\"\n\n    if os.getenv(\"OPENAI_TYPE\", default=\"openai\") == \"Azure\":\n        openai_api_type = \"azure\"\n        st_openai_api_base = st.sidebar.text_input(\n            \"Azure OpenAI base URL\",\n            value=os.getenv(\"AZURE_OPENAI_ENDPOINT\", default=\"\"),\n        )\n        openai_key = os.getenv(\"AZURE_OPENAI_KEY\", default=\"\")\n        st_deployment_id = st.sidebar.text_input(\n            \"Deployment name\", value=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", default=\"\")\n        )\n        st_openai_version = st.sidebar.text_input(\n            \"OpenAI version\",\n            value=os.getenv(\"OPENAI_API_VERSION\", default=\"2023-05-15\"),\n        )\n    else:\n        openai_api_type = \"openai\"\n        st_openai_version = st_openai_api_base = None\n        st_deployment_id = \"\"\n        openai_key = os.getenv(\"OPENAI_KEY\", default=\"\")\n    st_openai_key = st.sidebar.text_input(\n        \"OPENAI_KEY\",\n        value=openai_key,\n        help=\"See https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key for more info.\",\n        type=\"password\",\n    )\n    st_openai_model = st.sidebar.text_input(\n        \"OpenAI model for text synthesis\",\n        value=os.getenv(\"OPENAI_MODEL\", default=\"text-davinci-003\"),\n        help=\"See more here: https://platform.openai.com/docs/models/\",\n    )\n    return (\n        openai_api_type,\n        st_openai_api_base,\n        st_deployment_id,\n        st_openai_version,\n        st_openai_key,\n        st_openai_model,\n    )\n</pre> def set_up_openai_synthesis():     \"\"\"Set up the OpenAI API key and model for text synthesis.\"\"\"      if os.getenv(\"OPENAI_TYPE\", default=\"openai\") == \"Azure\":         openai_api_type = \"azure\"         st_openai_api_base = st.sidebar.text_input(             \"Azure OpenAI base URL\",             value=os.getenv(\"AZURE_OPENAI_ENDPOINT\", default=\"\"),         )         openai_key = os.getenv(\"AZURE_OPENAI_KEY\", default=\"\")         st_deployment_id = st.sidebar.text_input(             \"Deployment name\", value=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", default=\"\")         )         st_openai_version = st.sidebar.text_input(             \"OpenAI version\",             value=os.getenv(\"OPENAI_API_VERSION\", default=\"2023-05-15\"),         )     else:         openai_api_type = \"openai\"         st_openai_version = st_openai_api_base = None         st_deployment_id = \"\"         openai_key = os.getenv(\"OPENAI_KEY\", default=\"\")     st_openai_key = st.sidebar.text_input(         \"OPENAI_KEY\",         value=openai_key,         help=\"See https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key for more info.\",         type=\"password\",     )     st_openai_model = st.sidebar.text_input(         \"OpenAI model for text synthesis\",         value=os.getenv(\"OPENAI_MODEL\", default=\"text-davinci-003\"),         help=\"See more here: https://platform.openai.com/docs/models/\",     )     return (         openai_api_type,         st_openai_api_base,         st_deployment_id,         st_openai_version,         st_openai_key,         st_openai_model,     ) In\u00a0[\u00a0]: Copied! <pre>if st_operator == \"mask\":\n    st_number_of_chars = st.sidebar.number_input(\n        \"number of chars\", value=st_number_of_chars, min_value=0, max_value=100\n    )\n    st_mask_char = st.sidebar.text_input(\n        \"Mask character\", value=st_mask_char, max_chars=1\n    )\nelif st_operator == \"encrypt\":\n    st_encrypt_key = st.sidebar.text_input(\"AES key\", value=st_encrypt_key)\nelif st_operator == \"synthesize\":\n    (\n        openai_api_type,\n        st_openai_api_base,\n        st_deployment_id,\n        st_openai_version,\n        st_openai_key,\n        st_openai_model,\n    ) = set_up_openai_synthesis()\n\n    open_ai_params = OpenAIParams(\n        openai_key=st_openai_key,\n        model=st_openai_model,\n        api_base=st_openai_api_base,\n        deployment_id=st_deployment_id,\n        api_version=st_openai_version,\n        api_type=openai_api_type,\n    )\n</pre> if st_operator == \"mask\":     st_number_of_chars = st.sidebar.number_input(         \"number of chars\", value=st_number_of_chars, min_value=0, max_value=100     )     st_mask_char = st.sidebar.text_input(         \"Mask character\", value=st_mask_char, max_chars=1     ) elif st_operator == \"encrypt\":     st_encrypt_key = st.sidebar.text_input(\"AES key\", value=st_encrypt_key) elif st_operator == \"synthesize\":     (         openai_api_type,         st_openai_api_base,         st_deployment_id,         st_openai_version,         st_openai_key,         st_openai_model,     ) = set_up_openai_synthesis()      open_ai_params = OpenAIParams(         openai_key=st_openai_key,         model=st_openai_model,         api_base=st_openai_api_base,         deployment_id=st_deployment_id,         api_version=st_openai_version,         api_type=openai_api_type,     ) In\u00a0[\u00a0]: Copied! <pre>st_threshold = st.sidebar.slider(\n    label=\"Acceptance threshold\",\n    min_value=0.0,\n    max_value=1.0,\n    value=0.35,\n    help=\"Define the threshold for accepting a detection as PII. See more here: \",\n)\n</pre> st_threshold = st.sidebar.slider(     label=\"Acceptance threshold\",     min_value=0.0,     max_value=1.0,     value=0.35,     help=\"Define the threshold for accepting a detection as PII. See more here: \", ) In\u00a0[\u00a0]: Copied! <pre>st_return_decision_process = st.sidebar.checkbox(\n    \"Add analysis explanations to findings\",\n    value=False,\n    help=\"Add the decision process to the output table. \"\n    \"More information can be found here: https://microsoft.github.io/presidio/analyzer/decision_process/\",\n)\n</pre> st_return_decision_process = st.sidebar.checkbox(     \"Add analysis explanations to findings\",     value=False,     help=\"Add the decision process to the output table. \"     \"More information can be found here: https://microsoft.github.io/presidio/analyzer/decision_process/\", ) In\u00a0[\u00a0]: Copied! <pre># Allow and deny lists\nst_deny_allow_expander = st.sidebar.expander(\n    \"Allowlists and denylists\",\n    expanded=False,\n)\n</pre> # Allow and deny lists st_deny_allow_expander = st.sidebar.expander(     \"Allowlists and denylists\",     expanded=False, ) In\u00a0[\u00a0]: Copied! <pre>with st_deny_allow_expander:\n    st_allow_list = st_tags(\n        label=\"Add words to the allowlist\", text=\"Enter word and press enter.\"\n    )\n    st.caption(\n        \"Allowlists contain words that are not considered PII, but are detected as such.\"\n    )\n\n    st_deny_list = st_tags(\n        label=\"Add words to the denylist\", text=\"Enter word and press enter.\"\n    )\n    st.caption(\n        \"Denylists contain words that are considered PII, but are not detected as such.\"\n    )\n# Main panel\n</pre> with st_deny_allow_expander:     st_allow_list = st_tags(         label=\"Add words to the allowlist\", text=\"Enter word and press enter.\"     )     st.caption(         \"Allowlists contain words that are not considered PII, but are detected as such.\"     )      st_deny_list = st_tags(         label=\"Add words to the denylist\", text=\"Enter word and press enter.\"     )     st.caption(         \"Denylists contain words that are considered PII, but are not detected as such.\"     ) # Main panel In\u00a0[\u00a0]: Copied! <pre>with st.expander(\"About this demo\", expanded=False):\n    st.info(\n        \"\"\"Presidio is an open source customizable framework for PII detection and de-identification.\n        \\n\\n[Code](https://aka.ms/presidio) | \n        [Tutorial](https://microsoft.github.io/presidio/tutorial/) | \n        [Installation](https://microsoft.github.io/presidio/installation/) | \n        [FAQ](https://microsoft.github.io/presidio/faq/) |\n        [Feedback](https://forms.office.com/r/9ufyYjfDaY) |\"\"\"\n    )\n\n    st.info(\n        \"\"\"\n    Use this demo to:\n    - Experiment with different off-the-shelf models and NLP packages.\n    - Explore the different de-identification options, including redaction, masking, encryption and more.\n    - Generate synthetic text with Microsoft Presidio and OpenAI.\n    - Configure allow and deny lists.\n    \n    This demo website shows some of Presidio's capabilities.\n    [Visit our website](https://microsoft.github.io/presidio) for more info,\n    samples and deployment options.    \n    \"\"\"\n    )\n\n    st.markdown(\n        \"[![Pypi Downloads](https://img.shields.io/pypi/dm/presidio-analyzer.svg)](https://img.shields.io/pypi/dm/presidio-analyzer.svg)\"  # noqa\n        \"[![MIT license](https://img.shields.io/badge/license-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)\"\n        \"![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/presidio?style=social)\"\n    )\n</pre> with st.expander(\"About this demo\", expanded=False):     st.info(         \"\"\"Presidio is an open source customizable framework for PII detection and de-identification.         \\n\\n[Code](https://aka.ms/presidio) |          [Tutorial](https://microsoft.github.io/presidio/tutorial/) |          [Installation](https://microsoft.github.io/presidio/installation/) |          [FAQ](https://microsoft.github.io/presidio/faq/) |         [Feedback](https://forms.office.com/r/9ufyYjfDaY) |\"\"\"     )      st.info(         \"\"\"     Use this demo to:     - Experiment with different off-the-shelf models and NLP packages.     - Explore the different de-identification options, including redaction, masking, encryption and more.     - Generate synthetic text with Microsoft Presidio and OpenAI.     - Configure allow and deny lists.          This demo website shows some of Presidio's capabilities.     [Visit our website](https://microsoft.github.io/presidio) for more info,     samples and deployment options.         \"\"\"     )      st.markdown(         \"[![Pypi Downloads](https://img.shields.io/pypi/dm/presidio-analyzer.svg)](https://img.shields.io/pypi/dm/presidio-analyzer.svg)\"  # noqa         \"[![MIT license](https://img.shields.io/badge/license-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)\"         \"![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/presidio?style=social)\"     ) In\u00a0[\u00a0]: Copied! <pre>analyzer_load_state = st.info(\"Starting Presidio analyzer...\")\n</pre> analyzer_load_state = st.info(\"Starting Presidio analyzer...\") In\u00a0[\u00a0]: Copied! <pre>analyzer_load_state.empty()\n</pre> analyzer_load_state.empty() In\u00a0[\u00a0]: Copied! <pre># Read default text\nwith open(\"demo_text.txt\") as f:\n    demo_text = f.readlines()\n</pre> # Read default text with open(\"demo_text.txt\") as f:     demo_text = f.readlines() In\u00a0[\u00a0]: Copied! <pre># Create two columns for before and after\ncol1, col2 = st.columns(2)\n</pre> # Create two columns for before and after col1, col2 = st.columns(2) In\u00a0[\u00a0]: Copied! <pre># Before:\ncol1.subheader(\"Input\")\nst_text = col1.text_area(\n    label=\"Enter text\", value=\"\".join(demo_text), height=400, key=\"text_input\"\n)\n</pre> # Before: col1.subheader(\"Input\") st_text = col1.text_area(     label=\"Enter text\", value=\"\".join(demo_text), height=400, key=\"text_input\" ) In\u00a0[\u00a0]: Copied! <pre>try:\n    # Choose entities\n    st_entities_expander = st.sidebar.expander(\"Choose entities to look for\")\n    st_entities = st_entities_expander.multiselect(\n        label=\"Which entities to look for?\",\n        options=get_supported_entities(*analyzer_params),\n        default=list(get_supported_entities(*analyzer_params)),\n        help=\"Limit the list of PII entities detected. \"\n        \"This list is dynamic and based on the NER model and registered recognizers. \"\n        \"More information can be found here: https://microsoft.github.io/presidio/analyzer/adding_recognizers/\",\n    )\n\n    # Before\n    analyzer_load_state = st.info(\"Starting Presidio analyzer...\")\n    analyzer = analyzer_engine(*analyzer_params)\n    analyzer_load_state.empty()\n\n    st_analyze_results = analyze(\n        *analyzer_params,\n        text=st_text,\n        entities=st_entities,\n        language=\"en\",\n        score_threshold=st_threshold,\n        return_decision_process=st_return_decision_process,\n        allow_list=st_allow_list,\n        deny_list=st_deny_list,\n    )\n\n    # After\n    if st_operator not in (\"highlight\", \"synthesize\"):\n        with col2:\n            st.subheader(f\"Output\")\n            st_anonymize_results = anonymize(\n                text=st_text,\n                operator=st_operator,\n                mask_char=st_mask_char,\n                number_of_chars=st_number_of_chars,\n                encrypt_key=st_encrypt_key,\n                analyze_results=st_analyze_results,\n            )\n            st.text_area(\n                label=\"De-identified\", value=st_anonymize_results.text, height=400\n            )\n    elif st_operator == \"synthesize\":\n        with col2:\n            st.subheader(f\"OpenAI Generated output\")\n            fake_data = create_fake_data(\n                st_text,\n                st_analyze_results,\n                open_ai_params,\n            )\n            st.text_area(label=\"Synthetic data\", value=fake_data, height=400)\n    else:\n        st.subheader(\"Highlighted\")\n        annotated_tokens = annotate(text=st_text, analyze_results=st_analyze_results)\n        # annotated_tokens\n        annotated_text(*annotated_tokens)\n\n    # table result\n    st.subheader(\n        \"Findings\"\n        if not st_return_decision_process\n        else \"Findings with decision factors\"\n    )\n    if st_analyze_results:\n        df = pd.DataFrame.from_records([r.to_dict() for r in st_analyze_results])\n        df[\"text\"] = [st_text[res.start : res.end] for res in st_analyze_results]\n\n        df_subset = df[[\"entity_type\", \"text\", \"start\", \"end\", \"score\"]].rename(\n            {\n                \"entity_type\": \"Entity type\",\n                \"text\": \"Text\",\n                \"start\": \"Start\",\n                \"end\": \"End\",\n                \"score\": \"Confidence\",\n            },\n            axis=1,\n        )\n        df_subset[\"Text\"] = [st_text[res.start : res.end] for res in st_analyze_results]\n        if st_return_decision_process:\n            analysis_explanation_df = pd.DataFrame.from_records(\n                [r.analysis_explanation.to_dict() for r in st_analyze_results]\n            )\n            df_subset = pd.concat([df_subset, analysis_explanation_df], axis=1)\n        st.dataframe(df_subset.reset_index(drop=True), use_container_width=True)\n    else:\n        st.text(\"No findings\")\n</pre> try:     # Choose entities     st_entities_expander = st.sidebar.expander(\"Choose entities to look for\")     st_entities = st_entities_expander.multiselect(         label=\"Which entities to look for?\",         options=get_supported_entities(*analyzer_params),         default=list(get_supported_entities(*analyzer_params)),         help=\"Limit the list of PII entities detected. \"         \"This list is dynamic and based on the NER model and registered recognizers. \"         \"More information can be found here: https://microsoft.github.io/presidio/analyzer/adding_recognizers/\",     )      # Before     analyzer_load_state = st.info(\"Starting Presidio analyzer...\")     analyzer = analyzer_engine(*analyzer_params)     analyzer_load_state.empty()      st_analyze_results = analyze(         *analyzer_params,         text=st_text,         entities=st_entities,         language=\"en\",         score_threshold=st_threshold,         return_decision_process=st_return_decision_process,         allow_list=st_allow_list,         deny_list=st_deny_list,     )      # After     if st_operator not in (\"highlight\", \"synthesize\"):         with col2:             st.subheader(f\"Output\")             st_anonymize_results = anonymize(                 text=st_text,                 operator=st_operator,                 mask_char=st_mask_char,                 number_of_chars=st_number_of_chars,                 encrypt_key=st_encrypt_key,                 analyze_results=st_analyze_results,             )             st.text_area(                 label=\"De-identified\", value=st_anonymize_results.text, height=400             )     elif st_operator == \"synthesize\":         with col2:             st.subheader(f\"OpenAI Generated output\")             fake_data = create_fake_data(                 st_text,                 st_analyze_results,                 open_ai_params,             )             st.text_area(label=\"Synthetic data\", value=fake_data, height=400)     else:         st.subheader(\"Highlighted\")         annotated_tokens = annotate(text=st_text, analyze_results=st_analyze_results)         # annotated_tokens         annotated_text(*annotated_tokens)      # table result     st.subheader(         \"Findings\"         if not st_return_decision_process         else \"Findings with decision factors\"     )     if st_analyze_results:         df = pd.DataFrame.from_records([r.to_dict() for r in st_analyze_results])         df[\"text\"] = [st_text[res.start : res.end] for res in st_analyze_results]          df_subset = df[[\"entity_type\", \"text\", \"start\", \"end\", \"score\"]].rename(             {                 \"entity_type\": \"Entity type\",                 \"text\": \"Text\",                 \"start\": \"Start\",                 \"end\": \"End\",                 \"score\": \"Confidence\",             },             axis=1,         )         df_subset[\"Text\"] = [st_text[res.start : res.end] for res in st_analyze_results]         if st_return_decision_process:             analysis_explanation_df = pd.DataFrame.from_records(                 [r.analysis_explanation.to_dict() for r in st_analyze_results]             )             df_subset = pd.concat([df_subset, analysis_explanation_df], axis=1)         st.dataframe(df_subset.reset_index(drop=True), use_container_width=True)     else:         st.text(\"No findings\") In\u00a0[\u00a0]: Copied! <pre>except Exception as e:\n    print(e)\n    traceback.print_exc()\n    st.error(e)\n</pre> except Exception as e:     print(e)     traceback.print_exc()     st.error(e) In\u00a0[\u00a0]: Copied! <pre>components.html(\n    \"\"\"\n    &lt;script type=\"text/javascript\"&gt;\n    (function(c,l,a,r,i,t,y){\n        c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};\n        t=l.createElement(r);t.async=1;t.src=\"https://www.clarity.ms/tag/\"+i;\n        y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);\n    })(window, document, \"clarity\", \"script\", \"h7f8bp42n8\");\n    &lt;/script&gt;\n    \"\"\"\n)\n</pre> components.html(     \"\"\"          \"\"\" )"},{"location":"samples/python/streamlit/test_streamlit/","title":"Test streamlit","text":"In\u00a0[\u00a0]: Copied! <pre>from presidio_helpers import analyzer_engine, analyze, anonymize\n</pre> from presidio_helpers import analyzer_engine, analyze, anonymize In\u00a0[\u00a0]: Copied! <pre>def test_streamlit_logic():\n    st_model = \"en\"  # st_model = \"StanfordAIMI/stanford-deidentifier-base\"\n    st_model_package = \"stanza\"  ##st_model_package = \"HuggingFace\"\n    st_ta_key = None\n    st_ta_endpoint = None\n\n    analyzer_params = (st_model_package, st_model, st_ta_key, st_ta_endpoint)\n\n    # Read default text\n    with open(\"demo_text.txt\") as f:\n        demo_text = f.readlines()\n\n    st_text = \"\".join(demo_text)\n\n    # instantiate and cache AnalyzerEngine\n    analyzer_engine(*analyzer_params)\n\n    # Analyze\n    st_analyze_results = analyze(\n        *analyzer_params,\n        text=st_text,\n        entities=\"All\",\n        language=\"en\",\n        score_threshold=0.35,\n        return_decision_process=True,\n        allow_list=[],\n        deny_list=[],\n    )\n\n    # Anonymize\n    st_anonymize_results = anonymize(\n        text=st_text,\n        operator=\"replace\",\n        mask_char=None,\n        number_of_chars=None,\n        encrypt_key=None,\n        analyze_results=st_analyze_results,\n    )\n\n    assert st_anonymize_results.text != \"\"\n</pre> def test_streamlit_logic():     st_model = \"en\"  # st_model = \"StanfordAIMI/stanford-deidentifier-base\"     st_model_package = \"stanza\"  ##st_model_package = \"HuggingFace\"     st_ta_key = None     st_ta_endpoint = None      analyzer_params = (st_model_package, st_model, st_ta_key, st_ta_endpoint)      # Read default text     with open(\"demo_text.txt\") as f:         demo_text = f.readlines()      st_text = \"\".join(demo_text)      # instantiate and cache AnalyzerEngine     analyzer_engine(*analyzer_params)      # Analyze     st_analyze_results = analyze(         *analyzer_params,         text=st_text,         entities=\"All\",         language=\"en\",         score_threshold=0.35,         return_decision_process=True,         allow_list=[],         deny_list=[],     )      # Anonymize     st_anonymize_results = anonymize(         text=st_text,         operator=\"replace\",         mask_char=None,         number_of_chars=None,         encrypt_key=None,         analyze_results=st_analyze_results,     )      assert st_anonymize_results.text != \"\""},{"location":"samples/python/text_analytics/","title":"Azure AI Language Integration","text":""},{"location":"samples/python/text_analytics/#introduction","title":"Introduction","text":"<p>Azure Text Analytics is a cloud-based service that provides advanced natural language processing over raw text. One of its main functions includes  Named Entity Recognition (NER), which has the ability to identify different entities in text and categorize them into pre-defined classes or types. This document will demonstrate Presidio integration with Azure Text Analytics.</p>"},{"location":"samples/python/text_analytics/#supported-entity-categories-in-the-text-analytics-api","title":"Supported entity categories in the Text Analytics API","text":"<p>Azure AI Language supports multiple PII entity categories. The Azure AI Laguage service runs a predictive model to identify and categorize named entities from an input document. The service's latest version includes the ability to detect personal (PII) and health (PHI) information. A list of all supported entities can be found in the official documentation.</p>"},{"location":"samples/python/text_analytics/#prerequisites","title":"Prerequisites","text":"<p>To use Azure AI Language with Preisido, an Azure AI Language resource should first be created under an Azure subscription. Follow the official documentation for instructions. The key and endpoint, generated once the resource is created,  will be used when integrating with Text Analytics, using a Presidio Text Analytics recognizer.</p>"},{"location":"samples/python/text_analytics/#azure-ai-language-recognizer","title":"Azure AI Language Recognizer","text":"<p>The implementation of a <code>AzureAILanguage</code> recognizer can be found here.</p>"},{"location":"samples/python/text_analytics/#how-to-integrate-azure-ai-language-into-presidio","title":"How to integrate Azure AI Language into Presidio","text":"<ol> <li> <p>Install the package with the azure-ai-language extra:   <pre><code>pip install \"presidio-analyzer[azure-ai-language]\"\n</code></pre></p> </li> <li> <p>Define environment varibles <code>AZURE_AI_KEY</code> and <code>AZURE_AI_ENDPOINT</code></p> </li> <li> <p>Add the <code>AzureAILanguageRecognizer</code> to the recognizer registry:</p> </li> </ol> <pre><code>from presidio_analyzer import AnalyzerEngine\nfrom presidio_analyzer.predefined_recognizers import AzureAILanguageRecognizer\n\nazure_ai_language = AzureAILanguageRecognizer()\n\nanalyzer = AnalyzerEngine()\nanalyzer.registry.add_recognizer(azure_ai_language)\n\nanalyzer.analyze(text=\"My email is email@email.com\", language=\"en\")\n</code></pre>"},{"location":"samples/python/text_analytics/__init__/","title":"init","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Presidio + Text Analytics example.\"\"\"\n</pre> \"\"\"Presidio + Text Analytics example.\"\"\""},{"location":"samples/python/transformers_recognizer/","title":"Add a Transformers model based EntityRecognizer","text":"<p>Note</p> <p>This example demonstrates how to create a Presidio Recognizer. To integrate a transformers model as a Presidio NLP Engine, see this documentation.</p> <p>We allow these two options, as a user might want to have multiple NER models running in parallel. In this case, one can create multiple <code>EntityRecognizer</code> instances, each serving a different model. If you only plan to use one NER model, consider creating a <code>TransformersNlpEngine</code> instead of the <code>TransformersRecognizer</code> described in this document.</p> <p>When initializing the <code>TransformersRecognizer</code>, choose from the following options:</p> <ol> <li> <p>A string referencing an uploaded model to HuggingFace. See the different available options for models here.</p> </li> <li> <p>Initialize your own <code>TokenClassificationPipeline</code> instance using your custom transformers model and use it for inference.</p> </li> <li> <p>Provide the path to your own local custom trained model.</p> </li> </ol> <p>Note</p> <p>For each combination of model &amp; dataset, it is recommended to create a configuration object which includes setting necessary parameters for getting the correct results. Please reference this configuraion.py file for examples.</p>"},{"location":"samples/python/transformers_recognizer/#example-code","title":"Example Code","text":"<p>This example code uses a <code>TransformersRecognizer</code> for NER, and removes the default <code>SpacyRecognizer</code>. In order to be able to use spaCy features such as lemmas, we introduce the small (and faster) <code>en_core_web_sm</code> model.</p> <p>link to full TransformersRecognizer code</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\nfrom presidio_analyzer.nlp_engine import NlpEngineProvider\nimport spacy\n\nmodel_path = \"obi/deid_roberta_i2b2\"\nsupported_entities = BERT_DEID_CONFIGURATION.get(\n    \"PRESIDIO_SUPPORTED_ENTITIES\")\ntransformers_recognizer = TransformersRecognizer(model_path=model_path,\n                                                 supported_entities=supported_entities)\n\n# This would download a large (~500Mb) model on the first run\ntransformers_recognizer.load_transformer(**BERT_DEID_CONFIGURATION)\n\n# Add transformers model to the registry\nregistry = RecognizerRegistry()\nregistry.add_recognizer(transformers_recognizer)\nregistry.remove_recognizer(\"SpacyRecognizer\")\n\n# Use small spacy model, for faster inference.\nif not spacy.util.is_package(\"en_core_web_sm\"):\n    spacy.cli.download(\"en_core_web_sm\")\n\nnlp_configuration = {\n    \"nlp_engine_name\": \"spacy\",\n    \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}],\n}\n\nnlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n\nanalyzer = AnalyzerEngine(registry=registry, nlp_engine=nlp_engine)\n\nsample = \"My name is John and I live in NY\"\nresults = analyzer.analyze(sample, language=\"en\",\n                           return_decision_process=True,\n                           )\nprint(\"Found the following entities:\")\nfor result in results:\n    print(result, '----', sample[result.start:result.end])\n</code></pre>"},{"location":"samples/python/transformers_recognizer/__init__/","title":"init","text":""},{"location":"samples/python/transformers_recognizer/configuration/","title":"Configuration","text":"In\u00a0[\u00a0]: Copied! <pre>STANFORD_COFIGURATION = {\n    \"DEFAULT_MODEL_PATH\": \"StanfordAIMI/stanford-deidentifier-base\",\n    \"PRESIDIO_SUPPORTED_ENTITIES\": [\n        \"LOCATION\",\n        \"PERSON\",\n        \"ORGANIZATION\",\n        \"AGE\",\n        \"PHONE_NUMBER\",\n        \"EMAIL\",\n        \"DATE_TIME\",\n        \"DEVICE\",\n        \"ZIP\",\n        \"PROFESSION\",\n        \"USERNAME\",\n        \"ID\"\n\n    ],\n    \"LABELS_TO_IGNORE\": [\"O\"],\n    \"DEFAULT_EXPLANATION\": \"Identified as {} by the StanfordAIMI/stanford-deidentifier-base NER model\",\n    \"SUB_WORD_AGGREGATION\": \"simple\",\n    \"DATASET_TO_PRESIDIO_MAPPING\": {\n        \"DATE\": \"DATE_TIME\",\n        \"DOCTOR\": \"PERSON\",\n        \"PATIENT\": \"PERSON\",\n        \"HOSPITAL\": \"LOCATION\",\n        \"MEDICALRECORD\": \"ID\",\n        \"IDNUM\": \"ID\",\n        \"ORGANIZATION\": \"ORGANIZATION\",\n        \"ZIP\": \"ZIP\",\n        \"PHONE\": \"PHONE_NUMBER\",\n        \"USERNAME\": \"USERNAME\",\n        \"STREET\": \"LOCATION\",\n        \"PROFESSION\": \"PROFESSION\",\n        \"COUNTRY\": \"LOCATION\",\n        \"LOCATION-OTHER\": \"LOCATION\",\n        \"FAX\": \"PHONE_NUMBER\",\n        \"EMAIL\": \"EMAIL\",\n        \"STATE\": \"LOCATION\",\n        \"DEVICE\": \"DEVICE\",\n        \"ORG\": \"ORGANIZATION\",\n        \"AGE\": \"AGE\",\n    },\n    \"MODEL_TO_PRESIDIO_MAPPING\": {\n        \"PER\": \"PERSON\",\n        \"PERSON\": \"PERSON\",\n        \"LOC\": \"LOCATION\",\n        \"ORG\": \"ORGANIZATION\",\n        \"AGE\": \"AGE\",\n        \"PATIENT\": \"PERSON\",\n        \"HCW\": \"PERSON\",\n        \"HOSPITAL\": \"LOCATION\",\n        \"PATORG\": \"ORGANIZATION\",\n        \"DATE\": \"DATE_TIME\",\n        \"PHONE\": \"PHONE_NUMBER\",\n        \"VENDOR\": \"ORGANIZATION\",\n    },\n    \"CHUNK_OVERLAP_SIZE\": 40,\n    \"CHUNK_SIZE\": 600,\n    \"ID_SCORE_MULTIPLIER\": 0.4,\n    \"ID_ENTITY_NAME\": \"ID\"\n}\n</pre> STANFORD_COFIGURATION = {     \"DEFAULT_MODEL_PATH\": \"StanfordAIMI/stanford-deidentifier-base\",     \"PRESIDIO_SUPPORTED_ENTITIES\": [         \"LOCATION\",         \"PERSON\",         \"ORGANIZATION\",         \"AGE\",         \"PHONE_NUMBER\",         \"EMAIL\",         \"DATE_TIME\",         \"DEVICE\",         \"ZIP\",         \"PROFESSION\",         \"USERNAME\",         \"ID\"      ],     \"LABELS_TO_IGNORE\": [\"O\"],     \"DEFAULT_EXPLANATION\": \"Identified as {} by the StanfordAIMI/stanford-deidentifier-base NER model\",     \"SUB_WORD_AGGREGATION\": \"simple\",     \"DATASET_TO_PRESIDIO_MAPPING\": {         \"DATE\": \"DATE_TIME\",         \"DOCTOR\": \"PERSON\",         \"PATIENT\": \"PERSON\",         \"HOSPITAL\": \"LOCATION\",         \"MEDICALRECORD\": \"ID\",         \"IDNUM\": \"ID\",         \"ORGANIZATION\": \"ORGANIZATION\",         \"ZIP\": \"ZIP\",         \"PHONE\": \"PHONE_NUMBER\",         \"USERNAME\": \"USERNAME\",         \"STREET\": \"LOCATION\",         \"PROFESSION\": \"PROFESSION\",         \"COUNTRY\": \"LOCATION\",         \"LOCATION-OTHER\": \"LOCATION\",         \"FAX\": \"PHONE_NUMBER\",         \"EMAIL\": \"EMAIL\",         \"STATE\": \"LOCATION\",         \"DEVICE\": \"DEVICE\",         \"ORG\": \"ORGANIZATION\",         \"AGE\": \"AGE\",     },     \"MODEL_TO_PRESIDIO_MAPPING\": {         \"PER\": \"PERSON\",         \"PERSON\": \"PERSON\",         \"LOC\": \"LOCATION\",         \"ORG\": \"ORGANIZATION\",         \"AGE\": \"AGE\",         \"PATIENT\": \"PERSON\",         \"HCW\": \"PERSON\",         \"HOSPITAL\": \"LOCATION\",         \"PATORG\": \"ORGANIZATION\",         \"DATE\": \"DATE_TIME\",         \"PHONE\": \"PHONE_NUMBER\",         \"VENDOR\": \"ORGANIZATION\",     },     \"CHUNK_OVERLAP_SIZE\": 40,     \"CHUNK_SIZE\": 600,     \"ID_SCORE_MULTIPLIER\": 0.4,     \"ID_ENTITY_NAME\": \"ID\" } In\u00a0[\u00a0]: Copied! <pre>BERT_DEID_CONFIGURATION = {\n    \"PRESIDIO_SUPPORTED_ENTITIES\": [\n        \"LOCATION\",\n        \"PERSON\",\n        \"ORGANIZATION\",\n        \"AGE\",\n        \"PHONE_NUMBER\",\n        \"EMAIL\",\n        \"DATE_TIME\",\n        \"ZIP\",\n        \"PROFESSION\",\n        \"USERNAME\",\n        \"ID\"\n    ],\n    \"DEFAULT_MODEL_PATH\": \"obi/deid_roberta_i2b2\",\n    \"LABELS_TO_IGNORE\": [\"O\"],\n    \"DEFAULT_EXPLANATION\": \"Identified as {} by the obi/deid_roberta_i2b2 NER model\",\n    \"SUB_WORD_AGGREGATION\": \"simple\",\n    \"DATASET_TO_PRESIDIO_MAPPING\": {\n        \"DATE\": \"DATE_TIME\",\n        \"DOCTOR\": \"PERSON\",\n        \"PATIENT\": \"PERSON\",\n        \"HOSPITAL\": \"ORGANIZATION\",\n        \"MEDICALRECORD\": \"O\",\n        \"IDNUM\": \"O\",\n        \"ORGANIZATION\": \"ORGANIZATION\",\n        \"ZIP\": \"O\",\n        \"PHONE\": \"PHONE_NUMBER\",\n        \"USERNAME\": \"\",\n        \"STREET\": \"LOCATION\",\n        \"PROFESSION\": \"PROFESSION\",\n        \"COUNTRY\": \"LOCATION\",\n        \"LOCATION-OTHER\": \"LOCATION\",\n        \"FAX\": \"PHONE_NUMBER\",\n        \"EMAIL\": \"EMAIL\",\n        \"STATE\": \"LOCATION\",\n        \"DEVICE\": \"O\",\n        \"ORG\": \"ORGANIZATION\",\n        \"AGE\": \"AGE\",\n    },\n    \"MODEL_TO_PRESIDIO_MAPPING\": {\n        \"PER\": \"PERSON\",\n        \"LOC\": \"LOCATION\",\n        \"ORG\": \"ORGANIZATION\",\n        \"AGE\": \"AGE\",\n        \"ID\": \"ID\",\n        \"EMAIL\": \"EMAIL\",\n        \"PATIENT\": \"PERSON\",\n        \"STAFF\": \"PERSON\",\n        \"HOSP\": \"ORGANIZATION\",\n        \"PATORG\": \"ORGANIZATION\",\n        \"DATE\": \"DATE_TIME\",\n        \"PHONE\": \"PHONE_NUMBER\",\n    },\n    \"CHUNK_OVERLAP_SIZE\": 40,\n    \"CHUNK_SIZE\": 600,\n    \"ID_SCORE_MULTIPLIER\": 0.4,\n    \"ID_ENTITY_NAME\": \"ID\"\n}\n</pre> BERT_DEID_CONFIGURATION = {     \"PRESIDIO_SUPPORTED_ENTITIES\": [         \"LOCATION\",         \"PERSON\",         \"ORGANIZATION\",         \"AGE\",         \"PHONE_NUMBER\",         \"EMAIL\",         \"DATE_TIME\",         \"ZIP\",         \"PROFESSION\",         \"USERNAME\",         \"ID\"     ],     \"DEFAULT_MODEL_PATH\": \"obi/deid_roberta_i2b2\",     \"LABELS_TO_IGNORE\": [\"O\"],     \"DEFAULT_EXPLANATION\": \"Identified as {} by the obi/deid_roberta_i2b2 NER model\",     \"SUB_WORD_AGGREGATION\": \"simple\",     \"DATASET_TO_PRESIDIO_MAPPING\": {         \"DATE\": \"DATE_TIME\",         \"DOCTOR\": \"PERSON\",         \"PATIENT\": \"PERSON\",         \"HOSPITAL\": \"ORGANIZATION\",         \"MEDICALRECORD\": \"O\",         \"IDNUM\": \"O\",         \"ORGANIZATION\": \"ORGANIZATION\",         \"ZIP\": \"O\",         \"PHONE\": \"PHONE_NUMBER\",         \"USERNAME\": \"\",         \"STREET\": \"LOCATION\",         \"PROFESSION\": \"PROFESSION\",         \"COUNTRY\": \"LOCATION\",         \"LOCATION-OTHER\": \"LOCATION\",         \"FAX\": \"PHONE_NUMBER\",         \"EMAIL\": \"EMAIL\",         \"STATE\": \"LOCATION\",         \"DEVICE\": \"O\",         \"ORG\": \"ORGANIZATION\",         \"AGE\": \"AGE\",     },     \"MODEL_TO_PRESIDIO_MAPPING\": {         \"PER\": \"PERSON\",         \"LOC\": \"LOCATION\",         \"ORG\": \"ORGANIZATION\",         \"AGE\": \"AGE\",         \"ID\": \"ID\",         \"EMAIL\": \"EMAIL\",         \"PATIENT\": \"PERSON\",         \"STAFF\": \"PERSON\",         \"HOSP\": \"ORGANIZATION\",         \"PATORG\": \"ORGANIZATION\",         \"DATE\": \"DATE_TIME\",         \"PHONE\": \"PHONE_NUMBER\",     },     \"CHUNK_OVERLAP_SIZE\": 40,     \"CHUNK_SIZE\": 600,     \"ID_SCORE_MULTIPLIER\": 0.4,     \"ID_ENTITY_NAME\": \"ID\" }"},{"location":"samples/python/transformers_recognizer/transformer_recognizer/","title":"Transformer recognizer","text":"In\u00a0[\u00a0]: Copied! <pre>import copy\nimport logging\nfrom typing import Optional, List\n</pre> import copy import logging from typing import Optional, List In\u00a0[\u00a0]: Copied! <pre>import torch\nfrom presidio_analyzer import (\n    RecognizerResult,\n    EntityRecognizer,\n    AnalysisExplanation,\n)\nfrom presidio_analyzer.nlp_engine import NlpArtifacts\n</pre> import torch from presidio_analyzer import (     RecognizerResult,     EntityRecognizer,     AnalysisExplanation, ) from presidio_analyzer.nlp_engine import NlpArtifacts In\u00a0[\u00a0]: Copied! <pre>from .configuration import BERT_DEID_CONFIGURATION\n</pre> from .configuration import BERT_DEID_CONFIGURATION In\u00a0[\u00a0]: Copied! <pre>logger = logging.getLogger(\"presidio-analyzer\")\n</pre> logger = logging.getLogger(\"presidio-analyzer\") In\u00a0[\u00a0]: Copied! <pre>try:\n    from transformers import (\n        AutoTokenizer,\n        AutoModelForTokenClassification,\n        pipeline,\n        TokenClassificationPipeline,\n    )\n</pre> try:     from transformers import (         AutoTokenizer,         AutoModelForTokenClassification,         pipeline,         TokenClassificationPipeline,     ) In\u00a0[\u00a0]: Copied! <pre>except ImportError:\n    logger.error(\"transformers is not installed\")\n</pre> except ImportError:     logger.error(\"transformers is not installed\") In\u00a0[\u00a0]: Copied! <pre>class TransformersRecognizer(EntityRecognizer):\n    \"\"\"\n    Wrapper for a transformers model, if needed to be used within Presidio Analyzer.\n    The class loads models hosted on HuggingFace - https://huggingface.co/\n    and loads the model and tokenizer into a TokenClassification pipeline.\n    Samples are split into short text chunks, ideally shorter than max_length input_ids of the individual model,\n    to avoid truncation by the Tokenizer and loss of information\n\n    A configuration object should be maintained for each dataset-model combination and translate\n    entities names into a standardized view. A sample of a configuration file is attached in\n    the example.\n    :param supported_entities: List of entities to run inference on\n    :type supported_entities: Optional[List[str]]\n    :param pipeline: Instance of a TokenClassificationPipeline including a Tokenizer and a Model, defaults to None\n    :type pipeline: Optional[TokenClassificationPipeline], optional\n    :param model_path: string referencing a HuggingFace uploaded model to be used for Inference, defaults to None\n    :type model_path: Optional[str], optional\n\n    :example\n    &gt;from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n    &gt;model_path = \"obi/deid_roberta_i2b2\"\n    &gt;transformers_recognizer = TransformersRecognizer(model_path=model_path,\n    &gt;supported_entities = model_configuration.get(\"PRESIDIO_SUPPORTED_ENTITIES\"))\n    &gt;transformers_recognizer.load_transformer(**model_configuration)\n    &gt;registry = RecognizerRegistry()\n    &gt;registry.add_recognizer(transformers_recognizer)\n    &gt;analyzer = AnalyzerEngine(registry=registry)\n    &gt;sample = \"My name is Christopher and I live in Irbid.\"\n    &gt;results = analyzer.analyze(sample, language=\"en\",return_decision_process=True)\n\n    &gt;for result in results:\n    &gt;    print(result,'----', sample[result.start:result.end])\n    \"\"\"\n\n    def load(self) -&gt; None:\n        pass\n\n    def __init__(\n        self,\n        model_path: Optional[str] = None,\n        pipeline: Optional[TokenClassificationPipeline] = None,\n        supported_entities: Optional[List[str]] = None,\n    ):\n        if not supported_entities:\n            supported_entities = BERT_DEID_CONFIGURATION[\n                \"PRESIDIO_SUPPORTED_ENTITIES\"\n            ]\n        super().__init__(\n            supported_entities=supported_entities,\n            name=f\"Transformers model {model_path}\",\n        )\n\n        self.model_path = model_path\n        self.pipeline = pipeline\n        self.is_loaded = False\n\n        self.aggregation_mechanism = None\n        self.ignore_labels = None\n        self.model_to_presidio_mapping = None\n        self.entity_mapping = None\n        self.default_explanation = None\n        self.text_overlap_length = None\n        self.chunk_length = None\n        self.id_entity_name = None\n        self.id_score_reduction = None\n\n    def load_transformer(self, **kwargs) -&gt; None:\n        \"\"\"Load external configuration parameters and set default values.\n\n        :param kwargs: define default values for class attributes and modify pipeline behavior\n        **DATASET_TO_PRESIDIO_MAPPING (dict) - defines mapping entity strings from dataset format to Presidio format\n        **MODEL_TO_PRESIDIO_MAPPING (dict) -  defines mapping entity strings from chosen model format to Presidio format\n        **SUB_WORD_AGGREGATION(str) - define how to aggregate sub-word tokens into full words and spans as defined\n        in HuggingFace https://huggingface.co/transformers/v4.8.0/main_classes/pipelines.html#transformers.TokenClassificationPipeline # noqa\n        **CHUNK_OVERLAP_SIZE (int) - number of overlapping characters in each text chunk\n        when splitting a single text into multiple inferences\n        **CHUNK_SIZE (int) - number of characters in each chunk of text\n        **LABELS_TO_IGNORE (List(str)) - List of entities to skip evaluation. Defaults to [\"O\"]\n        **DEFAULT_EXPLANATION (str) - string format to use for prediction explanations\n        **ID_ENTITY_NAME (str) - name of the ID entity\n        **ID_SCORE_REDUCTION (float) - score multiplier for ID entities\n        \"\"\"\n\n        self.entity_mapping = kwargs.get(\"DATASET_TO_PRESIDIO_MAPPING\", {})\n        self.model_to_presidio_mapping = kwargs.get(\"MODEL_TO_PRESIDIO_MAPPING\", {})\n        self.ignore_labels = kwargs.get(\"LABELS_TO_IGNORE\", [\"O\"])\n        self.aggregation_mechanism = kwargs.get(\"SUB_WORD_AGGREGATION\", \"simple\")\n        self.default_explanation = kwargs.get(\"DEFAULT_EXPLANATION\", None)\n        self.text_overlap_length = kwargs.get(\"CHUNK_OVERLAP_SIZE\", 40)\n        self.chunk_length = kwargs.get(\"CHUNK_SIZE\", 600)\n        self.id_entity_name = kwargs.get(\"ID_ENTITY_NAME\", \"ID\")\n        self.id_score_reduction = kwargs.get(\"ID_SCORE_REDUCTION\", 0.5)\n\n        if not self.pipeline:\n            if not self.model_path:\n                self.model_path = \"obi/deid_roberta_i2b2\"\n                logger.warning(\n                    f\"Both 'model' and 'model_path' arguments are None. Using default model_path={self.model_path}\"\n                )\n\n        self._load_pipeline()\n\n    def _load_pipeline(self) -&gt; None:\n        \"\"\"Initialize NER transformers pipeline using the model_path provided\"\"\"\n\n        logging.debug(f\"Initializing NER pipeline using {self.model_path} path\")\n        device = 0 if torch.cuda.is_available() else -1\n        self.pipeline = pipeline(\n            \"ner\",\n            model=AutoModelForTokenClassification.from_pretrained(self.model_path),\n            tokenizer=AutoTokenizer.from_pretrained(self.model_path),\n            # Will attempt to group sub-entities to word level\n            aggregation_strategy=self.aggregation_mechanism,\n            device=device,\n            framework=\"pt\",\n            ignore_labels=self.ignore_labels,\n        )\n\n        self.is_loaded = True\n\n    def get_supported_entities(self) -&gt; List[str]:\n        \"\"\"\n        Return supported entities by this model.\n        :return: List of the supported entities.\n        \"\"\"\n        return self.supported_entities\n\n    # Class to use transformers with Presidio as an external recognizer.\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Analyze text using transformers model to produce NER tagging.\n        :param text : The text for analysis.\n        :param entities: The list of entities this recognizer is able to detect\n        :param nlp_artifacts: Not used by this recognizer.\n        :return: The list of Presidio RecognizerResult constructed from the recognized\n            transformers detections.\n        \"\"\"\n\n        results = list()\n        # Run transformer model on the provided text\n        ner_results = self._get_ner_results_for_text(text)\n\n        for res in ner_results:\n            res[\"entity_group\"] = self.__check_label_transformer(res[\"entity_group\"])\n            if not res[\"entity_group\"] or res[\"entity_group\"] not in entities:\n                continue\n\n            if res[\"entity_group\"] == self.id_entity_name:\n                print(f\"ID entity found, multiplying score by {self.id_score_reduction}\")\n                res[\"score\"] = res[\"score\"] * self.id_score_reduction\n\n            textual_explanation = self.default_explanation.format(res[\"entity_group\"])\n            explanation = self.build_transformers_explanation(\n                float(round(res[\"score\"], 2)), textual_explanation, res[\"word\"]\n            )\n            transformers_result = self._convert_to_recognizer_result(res, explanation)\n\n            results.append(transformers_result)\n\n        return results\n\n    @staticmethod\n    def split_text_to_word_chunks(\n        input_length: int, chunk_length: int, overlap_length: int\n    ) -&gt; List[List]:\n        \"\"\"The function calculates chunks of text with size chunk_length. Each chunk has overlap_length number of\n        words to create context and continuity for the model\n\n        :param input_length: Length of input_ids for a given text\n        :type input_length: int\n        :param chunk_length: Length of each chunk of input_ids.\n        Should match the max input length of the transformer model\n        :type chunk_length: int\n        :param overlap_length: Number of overlapping words in each chunk\n        :type overlap_length: int\n        :return: List of start and end positions for individual text chunks\n        :rtype: List[List]\n        \"\"\"\n        if input_length &lt; chunk_length:\n            return [[0, input_length]]\n        if chunk_length &lt;= overlap_length:\n            logger.warning(\n                \"overlap_length should be shorter than chunk_length, setting overlap_length to by half of chunk_length\"\n            )\n            overlap_length = chunk_length // 2\n        return [\n            [i, min([i + chunk_length, input_length])]\n            for i in range(\n                0, input_length - overlap_length, chunk_length - overlap_length\n            )\n        ]\n\n    def _get_ner_results_for_text(self, text: str) -&gt; List[dict]:\n        \"\"\"The function runs model inference on the provided text.\n        The text is split into chunks with n overlapping characters.\n        The results are then aggregated and duplications are removed.\n\n        :param text: The text to run inference on\n        :type text: str\n        :return: List of entity predictions on the word level\n        :rtype: List[dict]\n        \"\"\"\n        model_max_length = self.pipeline.tokenizer.model_max_length\n        # calculate inputs based on the text\n        text_length = len(text)\n        # split text into chunks\n        if text_length &lt;= model_max_length:\n            predictions = self.pipeline(text)\n        else:\n            logger.info(\n                f\"splitting the text into chunks, length {text_length} &gt; {model_max_length}\"\n            )\n            predictions = list()\n            chunk_indexes = TransformersRecognizer.split_text_to_word_chunks(\n                text_length, self.chunk_length, self.text_overlap_length\n                )\n\n            # iterate over text chunks and run inference\n            for chunk_start, chunk_end in chunk_indexes:\n                chunk_text = text[chunk_start:chunk_end]\n                chunk_preds = self.pipeline(chunk_text)\n\n                # align indexes to match the original text - add to each position the value of chunk_start\n                aligned_predictions = list()\n                for prediction in chunk_preds:\n                    prediction_tmp = copy.deepcopy(prediction)\n                    prediction_tmp[\"start\"] += chunk_start\n                    prediction_tmp[\"end\"] += chunk_start\n                    aligned_predictions.append(prediction_tmp)\n\n                predictions.extend(aligned_predictions)\n\n        # remove duplicates\n        predictions = [dict(t) for t in {tuple(d.items()) for d in predictions}]\n        return predictions\n\n    @staticmethod\n    def _convert_to_recognizer_result(\n        prediction_result: dict, explanation: AnalysisExplanation\n    ) -&gt; RecognizerResult:\n        \"\"\"The method parses NER model predictions into a RecognizerResult format to enable down the stream analysis\n\n        :param prediction_result: A single example of entity prediction\n        :type prediction_result: dict\n        :param explanation: Textual representation of model prediction\n        :type explanation: str\n        :return: An instance of RecognizerResult which is used to model evaluation calculations\n        :rtype: RecognizerResult\n        \"\"\"\n\n        transformers_results = RecognizerResult(\n            entity_type=prediction_result[\"entity_group\"],\n            start=prediction_result[\"start\"],\n            end=prediction_result[\"end\"],\n            score=float(round(prediction_result[\"score\"], 2)),\n            analysis_explanation=explanation,\n        )\n\n        return transformers_results\n\n    def build_transformers_explanation(\n        self,\n        original_score: float,\n        explanation: str,\n        pattern: str,\n    ) -&gt; AnalysisExplanation:\n        \"\"\"\n        Create explanation for why this result was detected.\n        :param original_score: Score given by this recognizer\n        :param explanation: Explanation string\n        :param pattern: Regex pattern used\n        :return Structured explanation and scores of a NER model prediction\n        :rtype: AnalysisExplanation\n        \"\"\"\n        explanation = AnalysisExplanation(\n            recognizer=self.__class__.__name__,\n            original_score=float(original_score),\n            textual_explanation=explanation,\n            pattern=pattern,\n        )\n        return explanation\n\n    def __check_label_transformer(self, label: str) -&gt; Optional[str]:\n        \"\"\"The function validates the predicted label is identified by Presidio\n        and maps the string into a Presidio representation\n        :param label: Predicted label by the model\n        :return: Returns the adjusted entity name\n        \"\"\"\n\n        # convert model label to presidio label\n        entity = self.model_to_presidio_mapping.get(label, None)\n\n        if entity in self.ignore_labels:\n            return None\n\n        if entity is None:\n            logger.warning(f\"Found unrecognized label {label}, returning entity as is\")\n            return label\n\n        if entity not in self.supported_entities:\n            logger.warning(f\"Found entity {entity} which is not supported by Presidio\")\n            return entity\n        return entity\n</pre> class TransformersRecognizer(EntityRecognizer):     \"\"\"     Wrapper for a transformers model, if needed to be used within Presidio Analyzer.     The class loads models hosted on HuggingFace - https://huggingface.co/     and loads the model and tokenizer into a TokenClassification pipeline.     Samples are split into short text chunks, ideally shorter than max_length input_ids of the individual model,     to avoid truncation by the Tokenizer and loss of information      A configuration object should be maintained for each dataset-model combination and translate     entities names into a standardized view. A sample of a configuration file is attached in     the example.     :param supported_entities: List of entities to run inference on     :type supported_entities: Optional[List[str]]     :param pipeline: Instance of a TokenClassificationPipeline including a Tokenizer and a Model, defaults to None     :type pipeline: Optional[TokenClassificationPipeline], optional     :param model_path: string referencing a HuggingFace uploaded model to be used for Inference, defaults to None     :type model_path: Optional[str], optional      :example     &gt;from presidio_analyzer import AnalyzerEngine, RecognizerRegistry     &gt;model_path = \"obi/deid_roberta_i2b2\"     &gt;transformers_recognizer = TransformersRecognizer(model_path=model_path,     &gt;supported_entities = model_configuration.get(\"PRESIDIO_SUPPORTED_ENTITIES\"))     &gt;transformers_recognizer.load_transformer(**model_configuration)     &gt;registry = RecognizerRegistry()     &gt;registry.add_recognizer(transformers_recognizer)     &gt;analyzer = AnalyzerEngine(registry=registry)     &gt;sample = \"My name is Christopher and I live in Irbid.\"     &gt;results = analyzer.analyze(sample, language=\"en\",return_decision_process=True)      &gt;for result in results:     &gt;    print(result,'----', sample[result.start:result.end])     \"\"\"      def load(self) -&gt; None:         pass      def __init__(         self,         model_path: Optional[str] = None,         pipeline: Optional[TokenClassificationPipeline] = None,         supported_entities: Optional[List[str]] = None,     ):         if not supported_entities:             supported_entities = BERT_DEID_CONFIGURATION[                 \"PRESIDIO_SUPPORTED_ENTITIES\"             ]         super().__init__(             supported_entities=supported_entities,             name=f\"Transformers model {model_path}\",         )          self.model_path = model_path         self.pipeline = pipeline         self.is_loaded = False          self.aggregation_mechanism = None         self.ignore_labels = None         self.model_to_presidio_mapping = None         self.entity_mapping = None         self.default_explanation = None         self.text_overlap_length = None         self.chunk_length = None         self.id_entity_name = None         self.id_score_reduction = None      def load_transformer(self, **kwargs) -&gt; None:         \"\"\"Load external configuration parameters and set default values.          :param kwargs: define default values for class attributes and modify pipeline behavior         **DATASET_TO_PRESIDIO_MAPPING (dict) - defines mapping entity strings from dataset format to Presidio format         **MODEL_TO_PRESIDIO_MAPPING (dict) -  defines mapping entity strings from chosen model format to Presidio format         **SUB_WORD_AGGREGATION(str) - define how to aggregate sub-word tokens into full words and spans as defined         in HuggingFace https://huggingface.co/transformers/v4.8.0/main_classes/pipelines.html#transformers.TokenClassificationPipeline # noqa         **CHUNK_OVERLAP_SIZE (int) - number of overlapping characters in each text chunk         when splitting a single text into multiple inferences         **CHUNK_SIZE (int) - number of characters in each chunk of text         **LABELS_TO_IGNORE (List(str)) - List of entities to skip evaluation. Defaults to [\"O\"]         **DEFAULT_EXPLANATION (str) - string format to use for prediction explanations         **ID_ENTITY_NAME (str) - name of the ID entity         **ID_SCORE_REDUCTION (float) - score multiplier for ID entities         \"\"\"          self.entity_mapping = kwargs.get(\"DATASET_TO_PRESIDIO_MAPPING\", {})         self.model_to_presidio_mapping = kwargs.get(\"MODEL_TO_PRESIDIO_MAPPING\", {})         self.ignore_labels = kwargs.get(\"LABELS_TO_IGNORE\", [\"O\"])         self.aggregation_mechanism = kwargs.get(\"SUB_WORD_AGGREGATION\", \"simple\")         self.default_explanation = kwargs.get(\"DEFAULT_EXPLANATION\", None)         self.text_overlap_length = kwargs.get(\"CHUNK_OVERLAP_SIZE\", 40)         self.chunk_length = kwargs.get(\"CHUNK_SIZE\", 600)         self.id_entity_name = kwargs.get(\"ID_ENTITY_NAME\", \"ID\")         self.id_score_reduction = kwargs.get(\"ID_SCORE_REDUCTION\", 0.5)          if not self.pipeline:             if not self.model_path:                 self.model_path = \"obi/deid_roberta_i2b2\"                 logger.warning(                     f\"Both 'model' and 'model_path' arguments are None. Using default model_path={self.model_path}\"                 )          self._load_pipeline()      def _load_pipeline(self) -&gt; None:         \"\"\"Initialize NER transformers pipeline using the model_path provided\"\"\"          logging.debug(f\"Initializing NER pipeline using {self.model_path} path\")         device = 0 if torch.cuda.is_available() else -1         self.pipeline = pipeline(             \"ner\",             model=AutoModelForTokenClassification.from_pretrained(self.model_path),             tokenizer=AutoTokenizer.from_pretrained(self.model_path),             # Will attempt to group sub-entities to word level             aggregation_strategy=self.aggregation_mechanism,             device=device,             framework=\"pt\",             ignore_labels=self.ignore_labels,         )          self.is_loaded = True      def get_supported_entities(self) -&gt; List[str]:         \"\"\"         Return supported entities by this model.         :return: List of the supported entities.         \"\"\"         return self.supported_entities      # Class to use transformers with Presidio as an external recognizer.     def analyze(         self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts = None     ) -&gt; List[RecognizerResult]:         \"\"\"         Analyze text using transformers model to produce NER tagging.         :param text : The text for analysis.         :param entities: The list of entities this recognizer is able to detect         :param nlp_artifacts: Not used by this recognizer.         :return: The list of Presidio RecognizerResult constructed from the recognized             transformers detections.         \"\"\"          results = list()         # Run transformer model on the provided text         ner_results = self._get_ner_results_for_text(text)          for res in ner_results:             res[\"entity_group\"] = self.__check_label_transformer(res[\"entity_group\"])             if not res[\"entity_group\"] or res[\"entity_group\"] not in entities:                 continue              if res[\"entity_group\"] == self.id_entity_name:                 print(f\"ID entity found, multiplying score by {self.id_score_reduction}\")                 res[\"score\"] = res[\"score\"] * self.id_score_reduction              textual_explanation = self.default_explanation.format(res[\"entity_group\"])             explanation = self.build_transformers_explanation(                 float(round(res[\"score\"], 2)), textual_explanation, res[\"word\"]             )             transformers_result = self._convert_to_recognizer_result(res, explanation)              results.append(transformers_result)          return results      @staticmethod     def split_text_to_word_chunks(         input_length: int, chunk_length: int, overlap_length: int     ) -&gt; List[List]:         \"\"\"The function calculates chunks of text with size chunk_length. Each chunk has overlap_length number of         words to create context and continuity for the model          :param input_length: Length of input_ids for a given text         :type input_length: int         :param chunk_length: Length of each chunk of input_ids.         Should match the max input length of the transformer model         :type chunk_length: int         :param overlap_length: Number of overlapping words in each chunk         :type overlap_length: int         :return: List of start and end positions for individual text chunks         :rtype: List[List]         \"\"\"         if input_length &lt; chunk_length:             return [[0, input_length]]         if chunk_length &lt;= overlap_length:             logger.warning(                 \"overlap_length should be shorter than chunk_length, setting overlap_length to by half of chunk_length\"             )             overlap_length = chunk_length // 2         return [             [i, min([i + chunk_length, input_length])]             for i in range(                 0, input_length - overlap_length, chunk_length - overlap_length             )         ]      def _get_ner_results_for_text(self, text: str) -&gt; List[dict]:         \"\"\"The function runs model inference on the provided text.         The text is split into chunks with n overlapping characters.         The results are then aggregated and duplications are removed.          :param text: The text to run inference on         :type text: str         :return: List of entity predictions on the word level         :rtype: List[dict]         \"\"\"         model_max_length = self.pipeline.tokenizer.model_max_length         # calculate inputs based on the text         text_length = len(text)         # split text into chunks         if text_length &lt;= model_max_length:             predictions = self.pipeline(text)         else:             logger.info(                 f\"splitting the text into chunks, length {text_length} &gt; {model_max_length}\"             )             predictions = list()             chunk_indexes = TransformersRecognizer.split_text_to_word_chunks(                 text_length, self.chunk_length, self.text_overlap_length                 )              # iterate over text chunks and run inference             for chunk_start, chunk_end in chunk_indexes:                 chunk_text = text[chunk_start:chunk_end]                 chunk_preds = self.pipeline(chunk_text)                  # align indexes to match the original text - add to each position the value of chunk_start                 aligned_predictions = list()                 for prediction in chunk_preds:                     prediction_tmp = copy.deepcopy(prediction)                     prediction_tmp[\"start\"] += chunk_start                     prediction_tmp[\"end\"] += chunk_start                     aligned_predictions.append(prediction_tmp)                  predictions.extend(aligned_predictions)          # remove duplicates         predictions = [dict(t) for t in {tuple(d.items()) for d in predictions}]         return predictions      @staticmethod     def _convert_to_recognizer_result(         prediction_result: dict, explanation: AnalysisExplanation     ) -&gt; RecognizerResult:         \"\"\"The method parses NER model predictions into a RecognizerResult format to enable down the stream analysis          :param prediction_result: A single example of entity prediction         :type prediction_result: dict         :param explanation: Textual representation of model prediction         :type explanation: str         :return: An instance of RecognizerResult which is used to model evaluation calculations         :rtype: RecognizerResult         \"\"\"          transformers_results = RecognizerResult(             entity_type=prediction_result[\"entity_group\"],             start=prediction_result[\"start\"],             end=prediction_result[\"end\"],             score=float(round(prediction_result[\"score\"], 2)),             analysis_explanation=explanation,         )          return transformers_results      def build_transformers_explanation(         self,         original_score: float,         explanation: str,         pattern: str,     ) -&gt; AnalysisExplanation:         \"\"\"         Create explanation for why this result was detected.         :param original_score: Score given by this recognizer         :param explanation: Explanation string         :param pattern: Regex pattern used         :return Structured explanation and scores of a NER model prediction         :rtype: AnalysisExplanation         \"\"\"         explanation = AnalysisExplanation(             recognizer=self.__class__.__name__,             original_score=float(original_score),             textual_explanation=explanation,             pattern=pattern,         )         return explanation      def __check_label_transformer(self, label: str) -&gt; Optional[str]:         \"\"\"The function validates the predicted label is identified by Presidio         and maps the string into a Presidio representation         :param label: Predicted label by the model         :return: Returns the adjusted entity name         \"\"\"          # convert model label to presidio label         entity = self.model_to_presidio_mapping.get(label, None)          if entity in self.ignore_labels:             return None          if entity is None:             logger.warning(f\"Found unrecognized label {label}, returning entity as is\")             return label          if entity not in self.supported_entities:             logger.warning(f\"Found entity {entity} which is not supported by Presidio\")             return entity         return entity In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n\n    from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n    from presidio_analyzer.nlp_engine import NlpEngineProvider\n    import spacy\n\n    model_path = \"obi/deid_roberta_i2b2\"\n    supported_entities = BERT_DEID_CONFIGURATION.get(\n        \"PRESIDIO_SUPPORTED_ENTITIES\")\n    transformers_recognizer = TransformersRecognizer(model_path=model_path,\n                                                     supported_entities=supported_entities)\n\n    # This would download a large (~500Mb) model on the first run\n    transformers_recognizer.load_transformer(**BERT_DEID_CONFIGURATION)\n\n    # Add transformers model to the registry\n    registry = RecognizerRegistry()\n    registry.add_recognizer(transformers_recognizer)\n    registry.remove_recognizer(\"SpacyRecognizer\")\n\n    # Use small spacy model, for faster inference.\n    if not spacy.util.is_package(\"en_core_web_sm\"):\n        spacy.cli.download(\"en_core_web_sm\")\n\n    nlp_configuration = {\n        \"nlp_engine_name\": \"spacy\",\n        \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}],\n    }\n\n    nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n\n    analyzer = AnalyzerEngine(registry=registry, nlp_engine=nlp_engine)\n\n    sample = \"My name is John and I live in NY\"\n    results = analyzer.analyze(sample, language=\"en\",\n                               return_decision_process=True,\n                               )\n    print(\"Found the following entities:\")\n    for result in results:\n        print(result, '----', sample[result.start:result.end])\n\n    # Found the following entities:\n    # type: PERSON, start: 11, end: 15, score: 1.0 ---- John\n    # type: LOCATION, start: 30, end: 32, score: 1.0 ---- NY\n</pre> if __name__ == \"__main__\":      from presidio_analyzer import AnalyzerEngine, RecognizerRegistry     from presidio_analyzer.nlp_engine import NlpEngineProvider     import spacy      model_path = \"obi/deid_roberta_i2b2\"     supported_entities = BERT_DEID_CONFIGURATION.get(         \"PRESIDIO_SUPPORTED_ENTITIES\")     transformers_recognizer = TransformersRecognizer(model_path=model_path,                                                      supported_entities=supported_entities)      # This would download a large (~500Mb) model on the first run     transformers_recognizer.load_transformer(**BERT_DEID_CONFIGURATION)      # Add transformers model to the registry     registry = RecognizerRegistry()     registry.add_recognizer(transformers_recognizer)     registry.remove_recognizer(\"SpacyRecognizer\")      # Use small spacy model, for faster inference.     if not spacy.util.is_package(\"en_core_web_sm\"):         spacy.cli.download(\"en_core_web_sm\")      nlp_configuration = {         \"nlp_engine_name\": \"spacy\",         \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}],     }      nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()      analyzer = AnalyzerEngine(registry=registry, nlp_engine=nlp_engine)      sample = \"My name is John and I live in NY\"     results = analyzer.analyze(sample, language=\"en\",                                return_decision_process=True,                                )     print(\"Found the following entities:\")     for result in results:         print(result, '----', sample[result.start:result.end])      # Found the following entities:     # type: PERSON, start: 11, end: 15, score: 1.0 ---- John     # type: LOCATION, start: 30, end: 32, score: 1.0 ---- NY"},{"location":"structured/","title":"Presidio structured","text":""},{"location":"structured/#status","title":"Status","text":"<p>Warning</p> <p>Alpha: This package is currently in alpha, meaning it is in its early stages of development. Features and functionality may change as the project evolves.</p>"},{"location":"structured/#description","title":"Description","text":"<p>The Presidio structured package is a flexible and customizable framework designed to identify and protect structured sensitive data.</p> <p>This tool extends the capabilities of Presidio, focusing on structured data formats such as tabular formats and semi-structured formats (JSON). It leverages the detection capabilities of Presidio-Analyzer to identify columns or keys containing personally identifiable information (PII), and establishes a mapping between these column/keys names and the detected PII entities.</p> <p>Following the detection, Presidio-Anonymizer is used to apply de-identification techniques to each value in columns identified as containing PII, ensuring the sensitive data is appropriately protected.</p> <p>Note that sensitive data might not be automatically detected in some cases. Consequently, additional systems and protections should be employed.</p>"},{"location":"structured/#installation","title":"Installation","text":""},{"location":"structured/#as-a-python-package","title":"As a python package","text":"<p>To install the <code>presidio-structured</code> package, run the following command:</p> <pre><code>pip install presidio-structured\n</code></pre>"},{"location":"structured/#getting-started","title":"Getting started","text":""},{"location":"structured/#example-1-anonymizing-dataframes","title":"Example 1: Anonymizing DataFrames","text":"<pre><code>import pandas as pd\nfrom presidio_structured import StructuredEngine, PandasAnalysisBuilder\nfrom presidio_anonymizer.entities import OperatorConfig\nfrom faker import Faker # optionally using faker as an example\n\n# Initialize the engine with a Pandas data processor (default)\npandas_engine = StructuredEngine()\n\n# Create a sample DataFrame\nsample_df = pd.DataFrame({'name': ['John Doe', 'Jane Smith'], 'email': ['john.doe@example.com', 'jane.smith@example.com']})\n\n# Generate a tabular analysis which describes PII entities in the DataFrame.\ntabular_analysis = PandasAnalysisBuilder().generate_analysis(sample_df)\n\n# Define anonymization operators\nfake = Faker()\noperators = {\n    \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"REDACTED\"}),\n    \"EMAIL_ADDRESS\": OperatorConfig(\"custom\", {\"lambda\": lambda x: fake.safe_email()})\n}\n\n# Anonymize DataFrame\nanonymized_df = pandas_engine.anonymize(sample_df, tabular_analysis, operators=operators)\nprint(anonymized_df)\n</code></pre>"},{"location":"structured/#example-2-anonymizing-json-data","title":"Example 2: Anonymizing JSON Data","text":"<pre><code>from presidio_structured import StructuredEngine, JsonAnalysisBuilder, StructuredAnalysis, JsonDataProcessor\nfrom presidio_anonymizer.entities import OperatorConfig\nfrom faker import Faker # optionally using faker as an example\n\n# Initialize the engine with a JSON data processor\njson_engine = StructuredEngine(data_processor=JsonDataProcessor())\n\n\n# Sample JSON data\nsample_json = {\n    \"user\": {\n        \"name\": \"John Doe\",\n        \"email\": \"john.doe@example.com\"\n    }\n}\n\n# Generate analysis for simple JSON data\njson_analysis = JsonAnalysisBuilder().generate_analysis(sample_json)\n\n# Define anonymization operators\nfake = Faker() # using faker for email generation.\noperators = {\n    \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"REDACTED\"}),\n    \"EMAIL_ADDRESS\": OperatorConfig(\"custom\", {\"lambda\": lambda x: fake.safe_email()})\n}\n\n# Anonymize JSON data\nanonymized_json = json_engine.anonymize(sample_json, json_analysis, operators=operators)\nprint(anonymized_json)\n\n# Handling Json Data with nested objects in lists\nsample_complex_json = {\n    \"users\": [\n        {\"name\": \"John Doe\", \"email\": \"john.doe@example.com\"},\n        {\"name\": \"Jane Smith\", \"email\": \"jane.smith@example.com\"}\n    ]\n}\n\n# Nesting objects in lists is not supported in JsonAnalysisBuilder for now,\n# Manually defining the analysis for complex JSON data\njson_complex_analysis = StructuredAnalysis(entity_mapping={\n    \"users.name\": \"PERSON\",\n    \"users.email\": \"EMAIL_ADDRESS\"\n})\n\n# Anonymize complex JSON data\nanonymized_complex_json = json_engine.anonymize(sample_complex_json, json_complex_analysis, operators=operators)\nprint(anonymized_complex_json)\n</code></pre> <p>A more detailed sample can be found here:</p> <ul> <li>https://github.com/microsoft/presidio/blob/main/docs/samples/python/example_structured.ipynb</li> </ul>"},{"location":"structured/#selection-strategy-for-entity-detection-in-tabular-data","title":"Selection Strategy for Entity Detection in Tabular Data","text":"<ul> <li>Most Common (default):  Identifies the most frequently occurring PII entity in a data column or field.</li> <li>Highest Confidence:  Selects PII entities based on the highest confidence scores, irrespective of their occurrence frequency.</li> <li>Mixed:  Combines the strengths of both the above strategies. It selects the entity with the highest confidence score if that score exceeds a specified threshold (controlled by <code>mixed_strategy_threshold</code>); otherwise, it defaults to the most common entity.</li> </ul>"},{"location":"structured/#usage","title":"Usage","text":"<p>Specify the <code>selection_strategy</code> and optionally the <code>mixed_strategy_threshold</code> in the <code>generate_analysis()</code> method:</p> <pre><code># Generate a tabular analysis using the most common strategy\ntabular_analysis = PandasAnalysisBuilder().generate_analysis(sample_df)\n\n# Generate a tabular analysis using the highest confidence strategy\ntabular_analysis = PandasAnalysisBuilder().generate_analysis(sample_df, selection_strategy=\"highest_confidence\")\n\n# Generate a tabular analysis using the mixed strategy\ntabular_analysis = PandasAnalysisBuilder().generate_analysis(sample_df, selection_strategy=\"mixed\", mixed_strategy_threshold=0.75)\n</code></pre>"},{"location":"structured/#future-work","title":"Future work","text":"<ul> <li>Improve support for datasets with mixed free-text and structure data (e.g. some columns contain free text)</li> <li>Add support for the detection of sensitive column names</li> <li>PySpark implementation</li> <li>Integration of additional anonymization techniques such as K-Anonymity and Differential Privacy.</li> </ul> <p>Contributions are welcome! Please refer to the Contributing Guide.</p>"},{"location":"structured/#more-information","title":"More information","text":"<ul> <li>Join the discussion</li> <li>Relevant issues on Github</li> </ul>"},{"location":"tutorial/","title":"Tutorial: Customization in Microsoft Presidio","text":"<p>This tutorials covers different customization use cases to:</p> <ol> <li>Adapt Presidio to detect new types of PII entities.</li> <li>Adapt Presidio to detect PII entities in a new language.</li> <li>Embed new types of detection modules into Presidio, to improve the coverage of the service.</li> <li>Operate on identified entities: simple de-identification, custom operators and encryption.</li> </ol>"},{"location":"tutorial/#table-of-contents","title":"Table of contents","text":"<ul> <li>Getting started</li> <li>Deny-list based recognizers</li> <li>Regex based PII recognition</li> <li>Rule based logic recognizer</li> <li>Supporting new models and languages</li> <li>Calling an external service for PII detection</li> <li>Using context words</li> <li>Tracing the decision process</li> <li>Loading recognizers from file</li> <li>Ad-Hoc recognizers</li> <li>Simple anonymization</li> <li>Custom anonymization</li> <li>Encryption/Decryption</li> </ul>"},{"location":"tutorial/00_getting_started/","title":"Getting started","text":""},{"location":"tutorial/00_getting_started/#installation","title":"Installation","text":"<p>First, let's install presidio using <code>pip</code>. For detailed documentation, see the installation docs. Install from PyPI:</p> <pre><code>pip install presidio_analyzer\npip install presidio_anonymizer\npython -m spacy download en_core_web_lg\n</code></pre>"},{"location":"tutorial/00_getting_started/#simple-flow","title":"Simple flow","text":"<p>A simple call to Presidio Analyzer:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\n\ntext = \"His name is Mr. Jones and his phone number is 212-555-5555\"\n\nanalyzer = AnalyzerEngine()\nanalyzer_results = analyzer.analyze(text=text, language=\"en\")\n\nprint(analyzer_results)\n</code></pre> <p>Next, we'll go over ways to customize Presidio to specific needs by adding PII recognizers, using context words, NER models and more.</p>"},{"location":"tutorial/01_deny_list/","title":"Example 1: Deny-list based PII recognition","text":"<p>In this example, we will pass a short list of tokens which should be marked as PII if detected. First, let's define the tokens we want to treat as PII. In this case it would be a list of titles:</p> <pre><code>titles_list = [\n    \"Sir\",\n    \"Ma'am\",\n    \"Madam\",\n    \"Mr.\",\n    \"Mrs.\",\n    \"Ms.\",\n    \"Miss\",\n    \"Dr.\",\n    \"Professor\",\n]\n</code></pre> <p>Second, let's create a <code>PatternRecognizer</code> which would scan for those titles, by passing a <code>deny_list</code>:</p> <pre><code>from presidio_analyzer import PatternRecognizer\n\ntitles_recognizer = PatternRecognizer(supported_entity=\"TITLE\", deny_list=titles_list)\n</code></pre> <p>At this point we can call our recognizer directly:</p> <pre><code>from presidio_analyzer import PatternRecognizer\n\ntext1 = \"I suspect Professor Plum, in the Dining Room, with the candlestick\"\nresult = titles_recognizer.analyze(text1, entities=[\"TITLE\"])\nprint(f\"Result:\\n {result}\")\n</code></pre> <p>Finally, let's add this new recognizer to the list of recognizers used by the Presidio <code>AnalyzerEngine</code>:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\n\nanalyzer = AnalyzerEngine()\nanalyzer.registry.add_recognizer(titles_recognizer)\n</code></pre> <p>When initializing the <code>AnalyzerEngine</code>, Presidio loads all available recognizers, including the <code>NlpEngine</code> used to detect entities, and extract tokens, lemmas and other linguistic features.</p> <p>Let's run the analyzer with the new recognizer in place:</p> <pre><code>results = analyzer.analyze(text=text1, language=\"en\")\n</code></pre> <pre><code>print(\"Results:\")\nprint(results)\n</code></pre> <p>As expected, both the name \"Plum\" and the title were identified as PII:</p> <pre><code>print(\"Identified these PII entities:\")\nfor result in results:\n    print(f\"- {text1[result.start:result.end]} as {result.entity_type}\")\n</code></pre>"},{"location":"tutorial/02_regex/","title":"Example 2: Regular-expressions based PII recognition","text":"<p>Another simple recognizer we can add is based on regular expressions. Let's assume we want to be extremely conservative and treat any token which contains a number as PII.</p> <pre><code>from presidio_analyzer import Pattern, PatternRecognizer\n\n# Define the regex pattern in a Presidio `Pattern` object:\nnumbers_pattern = Pattern(name=\"numbers_pattern\", regex=\"\\d+\", score=0.5)\n\n# Define the recognizer with one or more patterns\nnumber_recognizer = PatternRecognizer(\n    supported_entity=\"NUMBER\", patterns=[numbers_pattern]\n)\n</code></pre> <p>Testing the recognizer itself:</p> <pre><code>text2 = \"I live in 510 Broad st.\"\n\nnumbers_result = number_recognizer.analyze(text=text2, entities=[\"NUMBER\"])\n\nprint(\"Result:\")\nprint(numbers_result)\n</code></pre> <p>It's important to mention that recognizers are likely to have errors, both false-positive and false-negative, which would impact the entire performance of Presidio. Consider testing each recognizer on a representative dataset prior to integrating it into Presidio. For more info, see the best practices for developing recognizers documentation.</p>"},{"location":"tutorial/03_rule_based/","title":"Example 3: Rule based logic recognizer","text":"<p>Taking the numbers recognizer one step further, let's say we also would like to detect numbers within words, e.g. \"Number One\". We can leverage the underlying <code>spaCy</code> token attributes, or write our own logic to detect such entities.</p> <p>Notes:</p> <ul> <li> <p>In this example we would create a new class, which implements <code>EntityRecognizer</code>, the basic recognizer in Presidio. This abstract class requires us to implement the <code>load</code> method and <code>analyze</code> method.</p> </li> <li> <p>Each recognizer accepts an object of type <code>NlpArtifacts</code>, which holds pre-computed attributes on the input text.</p> </li> </ul> <p>A new recognizer should have this structure:</p> <pre><code>from typing import List\nfrom presidio_analyzer import EntityRecognizer, RecognizerResult\nfrom presidio_analyzer.nlp_engine import NlpArtifacts\n\n\nclass MyRecognizer(EntityRecognizer):\n    def load(self) -&gt; None:\n        \"\"\"No loading is required.\"\"\"\n        pass\n\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Logic for detecting a specific PII\n        \"\"\"\n        pass\n</code></pre> <p>For example, detecting numbers in either numerical or alphabetic (e.g. Forty five) form:</p> <pre><code>from typing import List\nfrom presidio_analyzer import EntityRecognizer, RecognizerResult\nfrom presidio_analyzer.nlp_engine import NlpArtifacts\n\n\nclass NumbersRecognizer(EntityRecognizer):\n\n    expected_confidence_level = 0.7  # expected confidence level for this recognizer\n\n    def load(self) -&gt; None:\n        \"\"\"No loading is required.\"\"\"\n        pass\n\n    def analyze(\n        self, text: str, entities: List[str], nlp_artifacts: NlpArtifacts\n    ) -&gt; List[RecognizerResult]:\n        \"\"\"\n        Analyzes test to find tokens which represent numbers (either 123 or One Two Three).\n        \"\"\"\n        results = []\n\n        # iterate over the spaCy tokens, and call `token.like_num`\n        for token in nlp_artifacts.tokens:\n            if token.like_num:\n                result = RecognizerResult(\n                    entity_type=\"NUMBER\",\n                    start=token.idx,\n                    end=token.idx + len(token),\n                    score=self.expected_confidence_level,\n                )\n                results.append(result)\n        return results\n\n\n# Instantiate the new NumbersRecognizer:\nnew_numbers_recognizer = NumbersRecognizer(supported_entities=[\"NUMBER\"])\n</code></pre> <p>Since this recognizer requires the <code>NlpArtifacts</code>, we would have to call it as part of the <code>AnalyzerEngine</code> flow:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\n\ntext3 = \"Roberto lives in Five 10 Broad st.\"\nanalyzer = AnalyzerEngine()\nanalyzer.registry.add_recognizer(new_numbers_recognizer)\n\nnumbers_results2 = analyzer.analyze(text=text3, language=\"en\")\nprint(\"Results:\")\nprint(\"\\n\".join([str(res) for res in numbers_results2]))\n</code></pre> <p>The analyzer was able to pick up both numeric and alphabetical numbers, including other types of PII entities from other recognizers (PERSON in this case).</p>"},{"location":"tutorial/04_external_services/","title":"Example 4: Calling an external service/framework for PII detection","text":"<p>In a similar way to example 3, we can write logic to call external services for PII detection. There are two types of external services we support:</p> <ol> <li>Remote services such as a PII detection model hosted somewhere. In this case, the recognizer would do the actual REST request and translate the results to a list of <code>RecognizerResult</code>.</li> <li>Calling PII models from other frameworks, such as transformers or Flair.</li> </ol>"},{"location":"tutorial/04_external_services/#calling-a-remote-service","title":"Calling a remote service","text":"<ol> <li> <p>Documentation on remote recognizers.</p> </li> <li> <p>A sample implementation of a remote recognizer.</p> </li> </ol>"},{"location":"tutorial/04_external_services/#calling-a-model-in-a-different-framework","title":"Calling a model in a different framework","text":"<ul> <li>This example shows a Presidio wrapper for a Flair model.</li> <li>Using a similar approach, we could create wrappers for HuggingFace models, Conditional Random Fields or any other framework.</li> </ul>"},{"location":"tutorial/05_languages/","title":"Example 5: Supporting new models and languages","text":"<p>Two main parts in Presidio handle the text, and should be adapted if a new language is required:</p> <ol> <li>The <code>NlpEngine</code> containing the NLP model which performs tokenization, lemmatization, Named Entity Recognition and other NLP tasks.</li> <li>The different PII recognizers (<code>EntityRecognizer</code> objects) should be adapted or created.</li> </ol>"},{"location":"tutorial/05_languages/#adapting-the-nlp-engine","title":"Adapting the NLP engine","text":"<p>As its internal NLP engine, Presidio supports both spaCy and Stanza. Make sure you download the required models from spacy/stanza prior to using them. More details here. For example, to download the Spanish medium spaCy model: <code>python -m spacy download es_core_news_md</code></p> <p>In this example we will configure Presidio to use spaCy as its underlying NLP framework, with NLP models in English and Spanish:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\nfrom presidio_analyzer.nlp_engine import NlpEngineProvider\n\n# import spacy\n# spacy.cli.download(\"es_core_news_md\")\n\n# Create configuration containing engine name and models\nconfiguration = {\n    \"nlp_engine_name\": \"spacy\",\n    \"models\": [\n        {\"lang_code\": \"es\", \"model_name\": \"es_core_news_md\"},\n        {\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"},\n    ],\n}\n\n# Create NLP engine based on configuration\nprovider = NlpEngineProvider(nlp_configuration=configuration)\nnlp_engine_with_spanish = provider.create_engine()\n\n# Pass the created NLP engine and supported_languages to the AnalyzerEngine\nanalyzer = AnalyzerEngine(\n    nlp_engine=nlp_engine_with_spanish, supported_languages=[\"en\", \"es\"]\n)\n\n# Analyze in different languages\nresults_spanish = analyzer.analyze(text=\"Mi nombre es Morris\", language=\"es\")\nprint(\"Results from Spanish request:\")\nprint(results_spanish)\n\nresults_english = analyzer.analyze(text=\"My name is Morris\", language=\"en\")\nprint(\"Results from English request:\")\nprint(results_english)\n</code></pre> <p>See this documentation for more details on setting up additional NLP models and languages.</p>"},{"location":"tutorial/05_languages/#using-external-modelsframeworks","title":"Using external models/frameworks","text":"<p>Some languages are not supported by spaCy/Stanza/huggingface, or have very limited support in those. In this case, other frameworks could be leveraged. (see example 4 for more information).</p> <p>Since Presidio requires a spaCy model to be passed, we propose to use a simple spaCy pipeline such as <code>en_core_web_sm</code> as the NLP engine's model, and a recognizer calling an external framework/service as the Named Entity Recognition (NER) model.</p>"},{"location":"tutorial/06_context/","title":"Example 6: Leveraging context words","text":"<p>Presidio has an internal mechanism for leveraging context words. This mechanism would increase the detection confidence of a PII entity in case a specific word appears before or after it.</p> <p>Furthermore, it is possible to create your own context enhancer, if you require a different logic for identifying context terms. The default context-aware enhancer in Presidio is the <code>LemmaContextAwareEnhancer</code> which compares each recognizer's context terms with the lemma of each token in the sentence.</p> <p>In this example we would first implement a zip code recognizer without context, and then add context to see how the confidence changes. Zip regex patterns (essentially 5 digits) are very weak, so we would want the initial confidence to be low, and increased with the existence of context words.</p>"},{"location":"tutorial/06_context/#example-adding-context-words-support-to-recognizers","title":"Example: Adding context words support to recognizers","text":"<p>First, let's create a simple <code>US_ZIP_CODE</code> recognizer:</p> <pre><code>from presidio_analyzer import (\n    Pattern,\n    PatternRecognizer,\n    RecognizerRegistry,\n    AnalyzerEngine,\n)\n\n# Define the regex pattern\nregex = r\"(\\b\\d{5}(?:\\-\\d{4})?\\b)\"  # very weak regex pattern\nzipcode_pattern = Pattern(name=\"zip code (weak)\", regex=regex, score=0.01)\n\n# Define the recognizer with the defined pattern\nzipcode_recognizer = PatternRecognizer(\n    supported_entity=\"US_ZIP_CODE\", patterns=[zipcode_pattern]\n)\n\nregistry = RecognizerRegistry()\nregistry.add_recognizer(zipcode_recognizer)\nanalyzer = AnalyzerEngine(registry=registry)\n\n# Test\nresults = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\")\n\nprint(f\"Result:\\n {results}\")\n</code></pre> <p>So this is working, but would catch any 5 digit string. This is why we set the score to 0.01. Let's use context words to increase score:</p> <pre><code>from presidio_analyzer import PatternRecognizer\n\n# Define the recognizer with the defined pattern and context words\nzipcode_recognizer_w_context = PatternRecognizer(\n    supported_entity=\"US_ZIP_CODE\",\n    patterns=[zipcode_pattern],\n    context=[\"zip\", \"zipcode\"],\n)\n</code></pre> <p>When creating an <code>AnalyzerEngine</code> we can provide our own context enhancement logic by passing it to <code>context_aware_enhancer</code> parameter. <code>AnalyzerEngine</code> will create <code>LemmaContextAwareEnhancer</code> by default if not passed, which will enhance score of each matched result if its recognizer holds context words and the lemma of those words are found in the surroundings of the matched entity.</p> <p>Creating the <code>AnalyzerEngine</code> and adding the new recognizer:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\nregistry = RecognizerRegistry()\nregistry.add_recognizer(zipcode_recognizer_w_context)\nanalyzer = AnalyzerEngine(registry=registry)\n\n# Test\nresults = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\")\nprint(\"Result:\")\nprint(results)\n</code></pre> <p>The confidence score is now 0.4, instead of 0.01, since the <code>LemmaContextAwareEnhancer</code> default context similarity factor is 0.35 and default minimum score with context similarity is 0.4. We can change that by passing other values to the <code>context_similarity_factor</code> and <code>min_score_with_context_similarity</code> parameters of the <code>LemmaContextAwareEnhancer</code> object. For example:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\nfrom presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer\n\ncontext_aware_enhancer = LemmaContextAwareEnhancer(\n    context_similarity_factor=0.45, min_score_with_context_similarity=0.4\n)\n\nregistry = RecognizerRegistry()\nregistry.add_recognizer(zipcode_recognizer_w_context)\nanalyzer = AnalyzerEngine(\n    registry=registry, context_aware_enhancer=context_aware_enhancer\n)\n\n# Test\nresults = analyzer.analyze(text=\"My zip code is 90210\", language=\"en\")\nprint(\"Result:\")\nprint(results)\n</code></pre> <p>The confidence score is now 0.46 because it got enhanced from 0.01 with 0.45 and is more than the minimum of 0.4.</p> <p>In addition to surrounding words, additional context words could be passed on the request level. This is useful when there is context coming from metadata such as column names or a specific user input. In the following example, notice how the \"zip\" context word doesn't appear in the text but still enhances the confidence score from 0.01 to 0.4:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry, PatternRecognizer\n\n# Define the recognizer with the defined pattern and context words\nzipcode_recognizer = PatternRecognizer(\n    supported_entity=\"US_ZIP_CODE\",\n    patterns=[zipcode_pattern],\n    context=[\"zip\", \"zipcode\"],\n)\nregistry = RecognizerRegistry()\nregistry.add_recognizer(zipcode_recognizer)\nanalyzer = AnalyzerEngine(registry=registry)\n\n# Test with an example record having a column name which could be injected as context\nrecord = {\"column_name\": \"zip\", \"text\": \"My code is 90210\"}\n\nresult = analyzer.analyze(\n    text=record[\"text\"], language=\"en\", context=[record[\"column_name\"]]\n)\n\nprint(\"Result:\")\nprint(result)\n</code></pre>"},{"location":"tutorial/07_decision_process/","title":"Example 7: Tracing the decision process","text":"<p>Presidio-analyzer's decision process exposes information on why a specific PII was detected. Such information could contain:</p> <ul> <li>Which recognizer detected the entity</li> <li>Which regex pattern was used</li> <li>Interpretability mechanisms in ML models</li> <li>Which context words improved the score</li> <li>Confidence scores before and after each step And more.</li> </ul> <p>For more information, refer to the decision process documentation.</p> <p>Let's use the decision process output to understand how the zip code value was detected:</p> <pre><code>from presidio_analyzer import AnalyzerEngine\nimport pprint\n\nanalyzer = AnalyzerEngine()\n\nresults = analyzer.analyze(\n    text=\"My zip code is 90210\", language=\"en\", return_decision_process=True\n)\n\ndecision_process = results[0].analysis_explanation\n\npp = pprint.PrettyPrinter()\nprint(\"Decision process output:\\n\")\npp.pprint(decision_process.__dict__)\n</code></pre> <p>When developing new recognizers, one can add information to this explanation and extend it with additional findings.</p>"},{"location":"tutorial/08_no_code/","title":"Example 8: Creating no-code pattern recognizers","text":"<p>No-code pattern recognizers can be helpful in two scenarios:</p> <ol> <li>There's an existing set of regular expressions / deny-lists which needs to be added to Presidio.</li> <li>Non-technical team members who require adding logic without writing code.</li> </ol> <p>Regular expression or deny-list based recognizers can be written in a YAML file, and added to the list of recognizers in Presidio.</p> <p>An example YAML file can be found here.</p> <p>For more information on the schema, see the <code>PatternRecognizer</code> definition on the API Docs).</p> <p>Once the YAML file is created, it can be loaded into the <code>RecognizerRegistry</code> instance.</p> <p>This example creates a <code>RecognizerRegistry</code> holding only the recognizers in the YAML file:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\nyaml_file = \"recognizers.yaml\"\nregistry = RecognizerRegistry()\nregistry.add_recognizers_from_yaml(yaml_file)\n\nanalyzer = AnalyzerEngine(registry=registry)\nanalyzer.analyze(text=\"Mr. and Mrs. Smith\", language=\"en\")\n</code></pre> <p>This example adds the new recognizers to the predefined recognizers in Presidio:</p> <pre><code>from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n\nyaml_file = \"recognizers.yaml\"  # path to YAML file\nregistry = RecognizerRegistry()\nregistry.load_predefined_recognizers()  # Loads all the predefined recognizers (Credit card, phone number etc.)\n\nregistry.add_recognizers_from_yaml(yaml_file)\n\nanalyzer = AnalyzerEngine(registry=registry)\nanalyzer.analyze(text=\"Mr. Plum wrote a book\", language=\"en\")\n</code></pre> <p>Finally, for initializing and customizing recognizer registry from file see the following section.</p>"},{"location":"tutorial/09_ad_hoc/","title":"Example 9: Ad-hoc recognizers","text":"<p>In addition to recognizers in code or in a YAML file, it is possible to create ad-hoc recognizers via the Presidio Analyzer API for regex and deny-list based logic. These recognizers, in JSON form, are added to the <code>/analyze</code> request and are only used in the context of this request.</p> <p>Note</p> <p>These ad-hoc recognizers could be useful if Presidio is already deployed, but requires additional detection logic to be added.</p> <ul> <li> <p>The json structure for a regex ad-hoc recognizer is the following:</p> <pre><code>{\n    \"text\": \"John Smith drivers license is AC432223. Zip code: 10023\",\n    \"language\": \"en\",\n    \"ad_hoc_recognizers\":[\n        {\n        \"name\": \"Zip code Recognizer\",\n        \"supported_language\": \"en\",\n        \"patterns\": [\n            {\n            \"name\": \"zip code (weak)\", \n            \"regex\": \"(\\\\b\\\\d{5}(?:\\\\-\\\\d{4})?\\\\b)\", \n            \"score\": 0.01\n            }\n        ],\n        \"context\": [\"zip\", \"code\"],\n        \"supported_entity\":\"ZIP\"\n        }\n    ]\n}\n</code></pre> </li> <li> <p>The json structure for deny-list based recognizers is the following:</p> <pre><code>{\n    \"text\": \"Mr. John Smith's drivers license is AC432223\",\n    \"language\": \"en\",\n    \"ad_hoc_recognizers\":[\n        {\n        \"name\": \"Mr. Recognizer\",\n        \"supported_language\": \"en\",\n        \"deny_list\": [\"Mr\", \"Mr.\", \"Mister\"],\n        \"supported_entity\":\"MR_TITLE\"\n        },\n        {\n        \"name\": \"Ms. Recognizer\",\n        \"supported_language\": \"en\",\n        \"deny_list\": [\"Ms\", \"Ms.\", \"Miss\", \"Mrs\", \"Mrs.\"],\n        \"supported_entity\":\"MS_TITLE\"\n        }\n    ]\n}\n</code></pre> </li> </ul> <p>In both examples, the <code>/analyze</code> request is extended with a list of <code>ad_hoc_recognizers</code>, which could be either <code>patterns</code>, <code>deny_list</code> or both.</p> <p>Example call to the <code>/analyze</code> service:</p> <pre><code>{\n  \"text\": \"John Smith drivers license is AC432223 and the zip code is 12345\",\n  \"language\": \"en\",\n  \"return_decision_process\": false,\n  \"correlation_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n  \"score_threshold\": 0.6,\n  \"entities\": [\n    \"US_DRIVER_LICENSE\",\n    \"ZIP\"\n  ],\n  \"trace\": false,\n  \"ad_hoc_recognizers\": [\n    {\n      \"name\": \"Zip code Recognizer\",\n      \"supported_language\": \"en\",\n      \"patterns\": [\n        {\n          \"name\": \"zip code (weak)\",\n          \"regex\": \"(\\\\b\\\\d{5}(?:\\\\-\\\\d{4})?\\\\b)\",\n          \"score\": 0.01\n        }\n      ],\n      \"context\": [\n        \"zip\",\n        \"code\"\n      ],\n      \"supported_entity\": \"ZIP\"\n    }\n  ]\n}\n</code></pre> <p>For more examples of deny-list recognizers, see this sample.</p>"},{"location":"tutorial/10_simple_anonymization/","title":"Example 10: Simple anonymization","text":"<p>Once we have the identified PII entities, we can perform different de-identification operations on them. For more information on the supported operators, see the anonymizer documentation.</p> <p>The anonymizer requires a configuration specifying the requested operation on each entity type. There's also a default operator which replaces a PII entity with the entity type name.</p> <p>Each operator has a unique configuration with the parameters needed to perform the operation (redact, hash, mask, replace, encrypt etc.)</p> <p>Here's an simple example of using presidio-anonymizer:</p> <pre><code>from presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import RecognizerResult\n\n# Analyzer output\nanalyzer_results = [\n    RecognizerResult(entity_type=\"PERSON\", start=11, end=15, score=0.8),\n    RecognizerResult(entity_type=\"PERSON\", start=17, end=27, score=0.8),\n]\n\n# Initialize the engine:\nengine = AnonymizerEngine()\n\n# Invoke the anonymize function with the text,\n# analyzer results (potentially coming from presidio-analyzer) and\n# Operators to get the anonymization output:\nresult = engine.anonymize(\n    text=\"My name is Bond, James Bond\", analyzer_results=analyzer_results\n)\n\nprint(\"De-identified text\")\nprint(result.text)\n</code></pre> <p>To introduce additional operators, we can pass an <code>OperatorConfig</code>. In this example we:</p> <ol> <li>Mask the last 12 chars of a <code>PHONE_NUMBER</code> entity and replace them with <code>*</code></li> <li>Redact a <code>TITLE</code> entity</li> <li>Replace all other entities with the string <code>&lt;ANONYMIZED&gt;</code>.</li> </ol> <p>Defining the operators:</p> <pre><code># Define anonymization operators\noperators = {\n    \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"&lt;ANONYMIZED&gt;\"}),\n    \"PHONE_NUMBER\": OperatorConfig(\n        \"mask\",\n        {\n            \"type\": \"mask\",\n            \"masking_char\": \"*\",\n            \"chars_to_mask\": 12,\n            \"from_end\": True,\n        },\n    ),\n    \"TITLE\": OperatorConfig(\"redact\", {}),\n}\n</code></pre> <p>Full example:</p> <pre><code>from pprint import pprint\nimport json\n\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig, RecognizerResult\n\n\n# Analyzer output\nanalyzer_results = [\n    RecognizerResult(entity_type=\"PERSON\", start=11, end=15, score=0.8),\n    RecognizerResult(entity_type=\"PERSON\", start=17, end=27, score=0.8),\n]\n\ntext_to_anonymize = \"My name is Bond, James Bond\"\n\nanonymizer = AnonymizerEngine()\n\n# Define anonymization operators\noperators = {\n    \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"&lt;ANONYMIZED&gt;\"}),\n    \"PHONE_NUMBER\": OperatorConfig(\n        \"mask\",\n        {\n            \"type\": \"mask\",\n            \"masking_char\": \"*\",\n            \"chars_to_mask\": 12,\n            \"from_end\": True,\n        },\n    ),\n    \"TITLE\": OperatorConfig(\"redact\", {}),\n}\n\nanonymized_results = anonymizer.anonymize(\n    text=text_to_anonymize, analyzer_results=analyzer_results, operators=operators\n)\n\nprint(f\"text: {anonymized_results.text}\")\nprint(\"detailed result:\")\n\npprint(json.loads(anonymized_results.to_json()))\n</code></pre>"},{"location":"tutorial/11_custom_anonymization/","title":"Example 11: Custom anonymization","text":"<p>Presidio-anonymizer can accept arbitrary operations to perform on identified entities. These operations can be passed in the form of a lambda function.</p> <p>In the following example, we use fake values to perform pseudonymization. First, let's look at the operator:</p> <pre><code>from faker import Faker\nfrom presidio_anonymizer.entities import OperatorConfig\n\nfake = Faker()\n\n# Create faker function (note that it has to receive a value)\ndef fake_name(x):\n    return fake.name()\n\n\n# Create custom operator for the PERSON entity\noperators = {\"PERSON\": OperatorConfig(\"custom\", {\"lambda\": fake_name})}\n</code></pre> <p>Full example:</p> <pre><code>from presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig, EngineResult, RecognizerResult\nfrom faker import Faker\n\n\nfake = Faker()\n\n# Create faker function (note that it has to receive a value)\ndef fake_name(x):\n    return fake.name()\n\n\n# Create custom operator for the PERSON entity\noperators = {\"PERSON\": OperatorConfig(\"custom\", {\"lambda\": fake_name})}\n\n# Analyzer output\nanalyzer_results = [RecognizerResult(entity_type=\"PERSON\", start=11, end=18, score=0.8)]\n\ntext_to_anonymize = \"My name is Raphael and I like to fish.\"\n\nanonymizer = AnonymizerEngine()\n\nanonymized_results = anonymizer.anonymize(\n    text=text_to_anonymize, analyzer_results=analyzer_results, operators=operators\n)\n\nprint(anonymized_results.text)\n</code></pre> <p>This is a simple example, but here are some examples for more advanced anonymization options:</p> <ul> <li>Identify the gender and create a random value from the same gender (e.g., Laura -&gt; Pam)</li> <li>Identifying the date pattern and perform date shift (01-01-2020 -&gt; 05-01-2020)</li> <li>Identify the age and bucket by decade (89 -&gt; 80-90)</li> </ul>"},{"location":"tutorial/12_encryption/","title":"Example 12: Encryption and decryption","text":"<p>This sample shows how to use Presidio Anonymizer built-in functionality, to encrypt and decrypt identified entities. The encryption is using AES cypher in CBC mode and requires a cryptographic key as an input for both the encryption and the decryption.</p>"},{"location":"tutorial/12_encryption/#set-up-imports","title":"Set up imports","text":"<pre><code>from presidio_anonymizer import AnonymizerEngine, DeanonymizeEngine\nfrom presidio_anonymizer.entities import (\n    RecognizerResult,\n    OperatorResult,\n    OperatorConfig,\n)\n</code></pre>"},{"location":"tutorial/12_encryption/#define-a-cryptographic-key-for-both-encryption-and-decryption","title":"Define a cryptographic key (for both encryption and decryption)","text":"<pre><code>crypto_key = \"WmZq4t7w!z%C&amp;F)J\"\n</code></pre>"},{"location":"tutorial/12_encryption/#presidio-anonymizer-encrypt","title":"Presidio Anonymizer: Encrypt","text":"<pre><code>engine = AnonymizerEngine()\n\n# Invoke the anonymize function with the text,\n# analyzer results (potentially coming from presidio-analyzer)\n# and an 'encrypt' operator to get an encrypted anonymization output:\nanonymize_result = engine.anonymize(\n    text=\"My name is James Bond\",\n    analyzer_results=[\n        RecognizerResult(entity_type=\"PERSON\", start=11, end=21, score=0.8),\n    ],\n    operators={\"PERSON\": OperatorConfig(\"encrypt\", {\"key\": crypto_key})},\n)\n\nanonymize_result\n</code></pre> <p>The output contains both the anonymized text, as well as the location of the encrypted entities. This is useful as we would need to decrypt only the entities and not the full text:</p> <pre><code># Fetch the anonymized text from the result.\nanonymized_text = anonymize_result.text\n\n# Fetch the anonynized entities from the result.\nanonymized_entities = anonymize_result.items\n</code></pre>"},{"location":"tutorial/12_encryption/#presidio-anonymizer-decrypt","title":"Presidio Anonymizer: Decrypt","text":"<pre><code># Initialize the engine:\nengine = DeanonymizeEngine()\n\n# Invoke the deanonymize function with the text, anonymizer results\n# and a 'decrypt' operator to get the original text as output.\ndeanonymized_result = engine.deanonymize(\n    text=anonymized_text,\n    entities=anonymized_entities,\n    operators={\"DEFAULT\": OperatorConfig(\"decrypt\", {\"key\": crypto_key})},\n)\n\ndeanonymized_result\n</code></pre>"},{"location":"tutorial/12_encryption/#alternatively-call-the-decrypt-operator-directly","title":"Alternatively, call the Decrypt operator directly","text":"<pre><code>from presidio_anonymizer.operators import Decrypt\n\n# Fetch the encrypted entity value from the previous stage\nencrypted_entity_value = anonymize_result.items[0].text\n\n# Restore the original entity value\nDecrypt().operate(text=encrypted_entity_value, params={\"key\": crypto_key})\n</code></pre>"},{"location":"tutorial/13_allow_list/","title":"Example 13: Allow-list to exclude words from being identified as PII","text":"<p>In this example, we will define a list of tokens that should not be marked as PII even if we want to identify others of that kind.</p> <p>In this example, we will pass a short list of tokens which should not be marked as PII even if detected by one of the recognizers.</p> <pre><code>websites_list = [\n    \"bing.com\",\n    \"microsoft.com\"\n]\n</code></pre> <p>We will use the built in recognizers that include the <code>URLRecognizer</code> and the NLP model <code>EntityRecognizer</code> and see the default functionality if we don't specify any list of words for the detector to allow to keep in the text.</p> <pre><code>from presidio_analyzer import AnalyzerEngine\ntext1 = \"My favorite website is bing.com, his is microsoft.com\"\nanalyzer = AnalyzerEngine()\nresult = analyzer.analyze(text = text1, language = 'en')\nprint(f\"Result: \\n {result}\")\n</code></pre> <p>To specify an allow list we just pass a list of values we want to keep as a parameter to call to <code>analyze</code>. Now we can see that in the results, <code>bing.com</code> is no longer being recognized as a PII item, only <code>microsoft.com</code> is still recognized since we did include it in the allow list.</p> <pre><code>result = analyzer.analyze(text = text1, language = 'en', allow_list = [\"bing.com\"] )\nprint(f\"Result:\\n {result}\")\n</code></pre>"}]}